<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">



<head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-20JYM3ZFN0"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-20JYM3ZFN0');
</script>



	  
	  <title>The Point is Addressing - ACM Queue</title>

	  

	  <meta name='description' value='' />
	  <meta name='keywords' value='Computer Architecture' />

<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-P52H78L');</script>
<!-- End Google Tag Manager -->

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="shortcut icon" href="favicon.ico" />

<script type="text/javascript" src="/js/jquery-1.2.6.min.js"></script>
<script type="text/javascript" src="/js/jquery.validate.min.js"></script>
<script type="text/javascript" src="/js/global.js"></script>



<!--
<link rel="alternate" type="application/rss+xml" title="Latest Queue Content RSS 2.0" href="/rss/feeds/latestitems.xml" />
-->
<link rel="alternate" type="application/rss+xml" title="All Queue Content RSS 2.0" href="/rss/feeds/queuecontent.xml" />
<link rel="alternate" type="application/rss+xml" title="Curmudgeon RSS 2.0"     href="/rss/feeds/curmudgeon.xml" />
<link rel="alternate" type="application/rss+xml" title="Opinion RSS 2.0"        href="/rss/feeds/opinion.xml" />
<link rel="alternate" type="application/rss+xml" title="Kode Vicious RSS 2.0"   href="/rss/feeds/kodevicious.xml" />
<link rel="alternate" type="application/rss+xml" title="ACM TechNews RSS"       href="https://www.infoinc.com/acm/TechNews.rss" />
<link rel="alternate" type="application/rss+xml" title="Washington Updates RSS" href="https://usacm.acm.org/weblog2/?feed=rss2" />
<link rel="alternate" type="application/rss+xml" title="RISKS Forum RSS"        href="/rss/feeds/risksforum.xml" />


<link rel="alternate" type="application/rss+xml" title="AI RSS 2.0"        href="/rss/feeds/ai.xml" />

<link rel="alternate" type="application/rss+xml" title="API Design RSS 2.0"        href="/rss/feeds/apidesign.xml" />

<link rel="alternate" type="application/rss+xml" title="Bioscience RSS 2.0"        href="/rss/feeds/bioscience.xml" />

<link rel="alternate" type="application/rss+xml" title="Blockchain RSS 2.0"        href="/rss/feeds/blockchain.xml" />

<link rel="alternate" type="application/rss+xml" title="Business/Management RSS 2.0"        href="/rss/feeds/business/management.xml" />

<link rel="alternate" type="application/rss+xml" title="Compliance RSS 2.0"        href="/rss/feeds/compliance.xml" />

<link rel="alternate" type="application/rss+xml" title="Component Technologies RSS 2.0"        href="/rss/feeds/componenttechnologies.xml" />

<link rel="alternate" type="application/rss+xml" title="Computer Architecture RSS 2.0"        href="/rss/feeds/computerarchitecture.xml" />

<link rel="alternate" type="application/rss+xml" title="Concurrency RSS 2.0"        href="/rss/feeds/concurrency.xml" />

<link rel="alternate" type="application/rss+xml" title="Cryptocurrency RSS 2.0"        href="/rss/feeds/cryptocurrency.xml" />

<link rel="alternate" type="application/rss+xml" title="DSPs RSS 2.0"        href="/rss/feeds/dsps.xml" />

<link rel="alternate" type="application/rss+xml" title="Data RSS 2.0"        href="/rss/feeds/data.xml" />

<link rel="alternate" type="application/rss+xml" title="Databases RSS 2.0"        href="/rss/feeds/databases.xml" />

<link rel="alternate" type="application/rss+xml" title="Debugging RSS 2.0"        href="/rss/feeds/debugging.xml" />

<link rel="alternate" type="application/rss+xml" title="Development RSS 2.0"        href="/rss/feeds/development.xml" />

<link rel="alternate" type="application/rss+xml" title="Distributed Computing RSS 2.0"        href="/rss/feeds/distributedcomputing.xml" />

<link rel="alternate" type="application/rss+xml" title="Distributed Development RSS 2.0"        href="/rss/feeds/distributeddevelopment.xml" />

<link rel="alternate" type="application/rss+xml" title="Education RSS 2.0"        href="/rss/feeds/education.xml" />

<link rel="alternate" type="application/rss+xml" title="Email and IM RSS 2.0"        href="/rss/feeds/emailandim.xml" />

<link rel="alternate" type="application/rss+xml" title="Embedded Systems RSS 2.0"        href="/rss/feeds/embeddedsystems.xml" />

<link rel="alternate" type="application/rss+xml" title="Failure and Recovery RSS 2.0"        href="/rss/feeds/failureandrecovery.xml" />

<link rel="alternate" type="application/rss+xml" title="File Systems and Storage RSS 2.0"        href="/rss/feeds/filesystemsandstorage.xml" />

<link rel="alternate" type="application/rss+xml" title="Game Development RSS 2.0"        href="/rss/feeds/gamedevelopment.xml" />

<link rel="alternate" type="application/rss+xml" title="Graphics RSS 2.0"        href="/rss/feeds/graphics.xml" />

<link rel="alternate" type="application/rss+xml" title="HCI RSS 2.0"        href="/rss/feeds/hci.xml" />

<link rel="alternate" type="application/rss+xml" title="Managing Megaservices RSS 2.0"        href="/rss/feeds/managingmegaservices.xml" />

<link rel="alternate" type="application/rss+xml" title="Mobile Computing RSS 2.0"        href="/rss/feeds/mobilecomputing.xml" />

<link rel="alternate" type="application/rss+xml" title="Networks RSS 2.0"        href="/rss/feeds/networks.xml" />

<link rel="alternate" type="application/rss+xml" title="Object-Relational Mapping RSS 2.0"        href="/rss/feeds/object-relationalmapping.xml" />

<link rel="alternate" type="application/rss+xml" title="Open Source RSS 2.0"        href="/rss/feeds/opensource.xml" />

<link rel="alternate" type="application/rss+xml" title="Patching and Deployment RSS 2.0"        href="/rss/feeds/patchinganddeployment.xml" />

<link rel="alternate" type="application/rss+xml" title="Performance RSS 2.0"        href="/rss/feeds/performance.xml" />

<link rel="alternate" type="application/rss+xml" title="Power Management RSS 2.0"        href="/rss/feeds/powermanagement.xml" />

<link rel="alternate" type="application/rss+xml" title="Privacy and Rights RSS 2.0"        href="/rss/feeds/privacyandrights.xml" />

<link rel="alternate" type="application/rss+xml" title="Processors RSS 2.0"        href="/rss/feeds/processors.xml" />

<link rel="alternate" type="application/rss+xml" title="Programming Languages RSS 2.0"        href="/rss/feeds/programminglanguages.xml" />

<link rel="alternate" type="application/rss+xml" title="Purpose-built Systems RSS 2.0"        href="/rss/feeds/purpose-builtsystems.xml" />

<link rel="alternate" type="application/rss+xml" title="Quality Assurance RSS 2.0"        href="/rss/feeds/qualityassurance.xml" />

<link rel="alternate" type="application/rss+xml" title="RFID RSS 2.0"        href="/rss/feeds/rfid.xml" />

<link rel="alternate" type="application/rss+xml" title="SIP RSS 2.0"        href="/rss/feeds/sip.xml" />

<link rel="alternate" type="application/rss+xml" title="Search Engines RSS 2.0"        href="/rss/feeds/searchengines.xml" />

<link rel="alternate" type="application/rss+xml" title="Security RSS 2.0"        href="/rss/feeds/security.xml" />

<link rel="alternate" type="application/rss+xml" title="Semi-structured Data RSS 2.0"        href="/rss/feeds/semi-structureddata.xml" />

<link rel="alternate" type="application/rss+xml" title="Social Computing RSS 2.0"        href="/rss/feeds/socialcomputing.xml" />

<link rel="alternate" type="application/rss+xml" title="System Administration RSS 2.0"        href="/rss/feeds/systemadministration.xml" />

<link rel="alternate" type="application/rss+xml" title="System Evolution RSS 2.0"        href="/rss/feeds/systemevolution.xml" />

<link rel="alternate" type="application/rss+xml" title="Testing RSS 2.0"        href="/rss/feeds/testing.xml" />

<link rel="alternate" type="application/rss+xml" title="Virtual Machines RSS 2.0"        href="/rss/feeds/virtualmachines.xml" />

<link rel="alternate" type="application/rss+xml" title="Virtualization RSS 2.0"        href="/rss/feeds/virtualization.xml" />

<link rel="alternate" type="application/rss+xml" title="Visualization RSS 2.0"        href="/rss/feeds/visualization.xml" />

<link rel="alternate" type="application/rss+xml" title="VoIP RSS 2.0"        href="/rss/feeds/voip.xml" />

<link rel="alternate" type="application/rss+xml" title="Web Development RSS 2.0"        href="/rss/feeds/webdevelopment.xml" />

<link rel="alternate" type="application/rss+xml" title="Web Security RSS 2.0"        href="/rss/feeds/websecurity.xml" />

<link rel="alternate" type="application/rss+xml" title="Web Services RSS 2.0"        href="/rss/feeds/webservices.xml" />

<link rel="alternate" type="application/rss+xml" title="Workflow Systems RSS 2.0"        href="/rss/feeds/workflowsystems.xml" />

<script type="text/javascript">
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-6562869-1']);
_gaq.push(['_trackPageview']);
(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'stats.g.doubleclick.net/dc.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();
</script>

<script type="text/javascript">
function plusone_vote( obj ) {
_gaq.push(['_trackEvent','plusone',obj.state]);
}
</script>



<style>
body {
	font-family: jaf-bernino-sans, 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Verdana, sans-serif;
	color: #333;
	max-width: 100%;
}
div.container p {
	line-height: 1.65em;
}
h1 {
	font-size: 32px;
}
h3 {
	font-size: 18px;
}
h4 {
	font-size: 14px;
}

div.container {
	margin-left: auto;
	margin-right: auto;
}

div {
	margin: 64px;
//	max-width: 800px;
	position: relative;
}

@media only screen and (min-width: 1024px) {
	div {
		max-width: 800px;
	}
}

img {
    max-width: 100%;
    height: auto;
    width: auto\9; /* ie8 */
}
a {
	color: #009;
	text-decoration: none;
}
a:hover {
	text-decoration: underline;
}
hr {
	margin:64px;
}
label {
	font-size: 0.8em;
	color: #666;
}
input {
	color: #999;
}

/* NAVBAR */
.navbar {
//	position: fixed;
	background: #EEEEEE;
	top: -64px;
	z-index: 10000;
	width: 100%;
	clear: both;
	padding: 0px;
	margin: 0px;
	padding-top: 10px;
	padding-left: 10px;
	padding-right: 10px;
}

/*  SECTIONS  */
.section {
	clear: both;
	padding: 0px;
	margin: 0px;
}

/*  COLUMN SETUP  */
.col {
	display: block;
	float:left;
	margin: 1% 0 1% 1.6%;
}
.col:first-child { margin-left: 0; }


/*  GROUPING  */
.group:before,
.group:after {
	content:"";
	display:table;
}
.group:after {
	clear:both;
}
.group {
    zoom:1; /* For IE 6/7 */
}

/*  GRID OF THREE  */
.span_3_of_3 {
	width: 100%;
}
.span_2_of_3 {
	width: 66.1%;
}
.span_1_of_3 {
	width: 32.2%;
}

/*  GO FULL WIDTH AT LESS THAN 480 PIXELS */

@media only screen and (max-width: 480px) {
	.col {
		margin: 1% 0 1% 0%;
	}
}

@media only screen and (max-width: 480px) {
	.span_3_of_3 {
		width: 100%;
	}
	.span_2_of_3 {
		width: 100%;
	}
	.span_1_of_3 {
		width: 100%;
	}
}

.span_2_of_2 {
	width: 100%;
}

.span_1_of_2 {
	width: 49.2%;
}

/*  GO FULL WIDTH AT LESS THAN 480 PIXELS */

@media only screen and (max-width: 480px) {
	.span_2_of_2 {
		width: 100%;
	}
	.span_1_of_2 {
		width: 100%;
	}
}
</style>


<style>
body {
	font-size: 19px;
}
#form-search > .st-default-search-input {
	width: 170px;
  display: inline-block;
  height: 16px;
  padding: 7px 11px 7px 28px;
  border: 1px solid #bbb;
  border: 1px solid rgba(0,0,0,0.25);
  font-weight: 400;
  color: #3B454F;
  font-size: 14px;
  line-height: 16px;
  -webkit-box-sizing: content-box;
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-box-shadow: none;
  -moz-box-shadow: none;
  box-shadow: none;
  font-family: system, -apple-system, BlinkMacSystemFont, "Helvetica Neue", "Lucida Grande", sans-serif;
}


blockquote
{
    color: #666;
    font-size: 1.1em;
    background: none;
    border-left: .2rem solid #d3d3d3;

    display: block;
    padding: 20px 20px 10px 45px;
    margin: 20px 0;
    font-style: italic;

    margin-block-start: 1em;
    margin-block-end: 1em;
    margin-inline-start: 40px;
    margin-inline-end: 40px;

	font-family: Georgia, Palatino, "Palatino Linotype", Times, "Times New Roman", serif;
}

.ldq {
	display: block;
    padding-left: 10px;
    content: "\201C";
    font-size: 60px;
    position: relative;
    left: -50px;
    top: 0;
    height: 0;
    color: #7a7a7a;
}
code {
//	font-size:1.25em;
}
a {overflow-wrap: break-word;}
pre {
	overflow-x: auto;
	white-space: pre-wrap;
	word-wrap: break-word;
}
</style>
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>
<!-- Google Tag Manager (noscript)
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-P52H78L"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
 End Google Tag Manager (noscript) -->



<div class=container>
	<div class="navbar">
		<form id="form-search" name="searchform" onsubmit="return false;" style='float:right;'>
				<input type="text" class="st-default-search-input">
<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install','UyYECD1kdsPnbHJtPyzG','2.0.0');
</script>
				<br />
			
			<a href="issuedetail.cfm?issue=3765291" style='width:150px;font-size:0.7em;'>Current Issue</a> &nbsp; <a href="pastissues.cfm" style='width:150px;font-size:0.7em;'>Past Issues</a> &nbsp; <a href="topics.cfm" style='width:150px;font-size:0.7em;'>Topics</a>
			
		</form>
		<a href='/'><img src='https://queue.acm.org/img/acmqueue_logo.gif' /></a>

	</div>

<!--
<p style='text-align:center;'>
<a href='/app/' target='_new'><img src='/app/2021_03-04_lrg.png' with=90 height=120 style='float:right;width:90px;height:120px;' alt='March/April 2021 issue of acmqueue' /></a>
<b><a href='/app/'>The March/April 2021 issue of acmqueue is out now</a></b>
<br />
<br />
<a href='https://cdn.coverstand.com/3rd_pty/acm/login.html?&btx_i=705849'>Subscribers and ACM Professional members login here</a>
<br clear=all />
<hr style='display:block;color:red;margin:5px;' />
</p>
-->
<br />


		<h3><a href='/listing.cfm?sort=publication_date&order=desc&qc_type=Researchforpractice&page_title=Research%20for%20Practice'>Research for Practice</a></h3>
	

<label>May 30, 2025<br /><b><a class="descriptor" href="issuedetail.cfm?issue=3735580">Volume 23, issue 2 </a></b></label>


<p>
<!-- // Check for existence of associated MP3 file-->

 &nbsp;
	
			<a href="https://spawn-queue.acm.org/doi/pdf/10.1145/3733700">
				<img src="img/icon_pdf.png" alt="Download PDF version of this article" />
				PDF
			</a>
		
</p>


 
  <h1 class="hidetitle">The Point is Addressing</h1> 
  <h2>A brief tour of efforts to reimagine <br />programming in a world of changing memories</h2> 
  <h3>Daniel Bittman <br />with introduction by Peter Alvaro</h3> 
  <p><i>Research for Practice combines the resources of the ACM Digital Library, the largest collection of computer science research in the world, with the expertise of the ACM membership. Research for Practice columns have a common goal of sharing the joy and utility of reading about computer science research exchanged between academics and their counterparts in industry.</i></p> 
  <p>&nbsp;</p> 
  <p>In his 2023 Ph.D. dissertation, "Operating Systems for Far Out Memories," Daniel Bittman argues that a recent convergence of hardware trends—including increased memory heterogeneity, faster interconnects that allow loads and stores to escape the confines of individual hosts, and fine-grained persistence—have pushed traditional approaches for how to organize, manage, and share memory to a breaking point. "Retrofitting existing interfaces is insufficient," he argues. "Instead, the correct approach to reimagining programming in a world of changing memories is to rebuild the operating system from the ground up." </p> 
  <p>As one of Daniel's advisors at UC Santa Cruz, I was impressed by the audacity of his vision and influenced considerably by his thinking. So, I too have taken to using "far out memories" as a blanket label for emerging technologies (or systems designed as reactions to them) that challenge traditional assumptions about the memory hierarchy—including disaggregated, far, nonvolatile, device-attached, and distributed shared memories. To restart Research for Practice after a six-month hiatus, I asked Daniel to curate a collection of papers about "anything related to far-out memories." It is a <i>very</i> broad topic from which to choose a handful of representative publications, but I knew Daniel would not only pick a rich selection but also employ an appropriately constrained lens through which to study it.</p> 
  <p>His RfP installment, which follows here, takes us through more than 30 years of research, from single-address-space operating systems, to software-based distributed shared memory, to far memory offload, to single-level stores for persistent memory. The featured papers challenge assumptions about isolation, sharing and locality, transparency, and movement of memory and computation. The thread that ties all these selections together in Daniel's analysis is the topic of <i>addressing</i>, or <i>how data references data</i>. As we see this through Daniel's eyes, implementation details regarding addressing often reveal fundamental design constraints that reflect how the systems can and should be used. For example, Sinfonia and Twizzler choose addressing schemes that permit (or force?) programmers to reason about locality; systems such as Carbink instead prioritize transparent data movement even if this introduces overheads. </p> 
  <p align="right" style="text-align:right"><i>—Peter Alvaro</i></p> 
  <p>&nbsp;</p> 
  <h3>The Point is Addressing</h3> 
  <p>Large memory systems that process huge amounts of data are widespread these days, driven in part by the recent explosion of application demands on memory. We have long surpassed the point where we could reasonably fit all the data on a single node and so instead are grappling with the challenges that come from <i>disaggregating</i> memory across nodes, racks, and datacenters. Recent additions to Linux, like transparent page placement, are among the freshest efforts in a wave of attempts to assist programmers with accessing "far" memory (i.e., memory that exists on another node). Hardware advances such as CXL (Compute Express Link) or, perhaps, UALink, also are efforts to make widespread memory sharing possible. Now, given all this activity, the time is ripe to evaluate how data is organized and accessed within such systems.</p> 
  <p>Sharing memory across computers has a rich and storied history, filled with challenges such as handling failure, maintaining consistency, dealing with locality, and still others. Equally fundamental is how an application <i>addresses</i> (or refers to) data. Constructing in-memory data structures typically involves <i>pointing to data</i>, typically using a virtual address. As we'll see, this limits how data can be shared, since virtual addresses are (traditionally) tied to the context of the creation process, resulting in friction when you want to move data to and from far memory. </p> 
  <p>To gain some perspective, let's walk through some papers about what is loosely categorized as DSM (distributed shared memory); each presents interesting and unique ways of addressing data. As we discuss how these papers adopt different addressing schemes to solve this sharing problem, we'll see tradeoffs in a variety of design spaces and observe how these particular design choices affect things like scaling, locality, and transparency.</p> 
  <p>&nbsp;</p> 
  <h4>Opal</h4> 
  <p> Jeffrey S. Chase, Henry M. Levy, Michael J. Feeley, and Edward D. Lazowska. <br />1994. <br />Sharing and protection in a single-address-space operating system. <br /><i>ACM Transactions on Computer Systems</i> 12(4). <br /><a href="https://dl.acm.org/doi/pdf/10.1145/195792.195795">https://dl.acm.org/doi/pdf/10.1145/195792.195795</a> </p> 
  <p>Opal came about in the early '90s when CPU manufacturers started making processors that could support "wide" (64-bit) memory addresses. The key insight was to consider wide-address architectures as an opportunity for a new paradigm, shifting the way programmers organize data <i>for the purpose of sharing</i>. Instead of running each program in a separate virtual address space (as the traditional Unix process model would), Opal runs a mostly traditional threading model across a <i>single</i> virtual address space while still using the memory-management hardware to enforce isolation. This means that in-memory data is allocated and kept in a single location in virtual memory, such that any running program can operate on that data—including<i> following pointers</i> in pointer-rich data structures (e.g., a linked list). </p> 
  <p>Essentially, by changing how the operating system manages the virtual memory space, the overhead that comes from serializing and moving data between fully isolated processes can be eliminated, while allowing different programs to easily share in-memory data structures.</p> 
  <p>This approach has some great advantages, such as enabling mostly isolated programs to share key data structures in shared memory without opening sockets or sending bytes down pipes between processes. The paper describes how the authors were able to build a computer-aided design software package atop their system for Boeing as a way of proving the potential for single-address-space operating systems. (Perhaps not the best advertisement these days ) </p> 
  <p>The choice of 64-bit virtual addresses as data references was largely influenced by the novel hardware at the time, but you could ask if the size of the address space is sufficient for all the data across all running programs. The paper discusses this by using one of my favorite kinds of "napkin math," arguing how long you would be able to continuously allocate memory on a single machine before running out (they estimated 500 years!). But the paper places a limit on scaling beyond that, indicating that, while a small cluster is viable, many independent machines would quickly exhaust the address space.</p> 
  <p>&nbsp;</p> 
  <h4>Sinfonia</h4> 
  <p> Marcos K. Aguilera, Arif Merchant, Mehul Shah, Alistair Veitch, Christos Karamanolis. <br />2007. <br />Sinfonia: a new paradigm for building scalable distributed systems. <br /><i>Proceedings of the 21st ACM Symposium on Operating System Principles.</i> <br /><a href="https://www.cs.princeton.edu/courses/archive/fall08/cos597B/papers/sinfonia.pdf">https://www.cs.princeton.edu/courses/archive/fall08/cos597B/papers/sinfonia.pdf</a> </p> 
  <p>Sinfonia presents a method of manipulating memory focused on consistency guarantees and fault tolerance between cooperating nodes in a cluster, all sharing memory. Applications submit "mini-transactions" to the system, which contain a collection of memory operations across a variety of memory locations within the system. These mini-transactions provide ACID (atomicity, consistency, isolation, and durability) guarantees while significantly reducing the number of network roundtrips needed to commit the transactions. In this way, mini-transactions act as a powerful primitive that enables programmers to build complex infrastructure-level applications, as the authors of this paper demonstrate by building a distributed file server.</p> 
  <p>Sinfonia's memory addresses are tuples, each comprising a node ID and an offset within a per-node linear address space. We can see how this scales further than Opal's 64-bit address space, since per-node spaces provide much larger addresses, and thus more data to which we can refer. But there is also no longer a need to worry about coordinating a single address space across all machines. One downside is that the data model is tightly coupled with hosts, since node IDs are explicit; this can make moving data or altering cluster topology more difficult. </p> 
  <p>In addition to the larger address space, the per-node linear address space allows programmers to express <i>locality</i> when laying out data. Operations (transactional ones in particular) on a collection of data are much faster if all the data is <i>local</i> (i.e., in one place). Since Sinfonia makes locality explicit in the address scheme, the programmer has an opportunity to take advantage of program semantics to inform how to lay out data while keeping node locality in mind.</p> 
  <p>&nbsp;</p> 
  <h4>Carbink</h4> 
  <p> Yang Zhou, Hassan M. G. Wassel, Sihang Liu, Jiaqi Gao, James Mickens, Minlan Yu, Chris Kennelly, Paul Turner, David E. Culler, Henry M. Levy, Amin Vahdat. <br />2022. <br />Carbink: fault-tolerant far memory. <br /><i>Proceedings of the 16th Usenix Symposium on Operating Systems Design and Implementation.</i> <br /><a href="https://www.usenix.org/system/files/osdi22-zhou-yang.pdf">https://www.usenix.org/system/files/osdi22-zhou-yang.pdf</a> </p> 
  <p>So far, the papers referred to here have chosen a more "fixed" addressing scheme, where data addresses do not change over time. (Or, if they do, the data is manually copied and the application must manually update pointers.) Carbink, by contrast, uses a notion of "remotable" pointers, where—instead of maintaining a large enough address space for all the data—the system rewrites pointers whenever data is moved to "far" memory. </p> 
  <p>This is done in a particularly clever way, leveraging C++ smart pointers and <i>reverse pointers</i> so that data that might move can find all the associated pointers and update them. Pointers, then, act as virtual addresses when the pointed-to-data is local and as remote data identifiers when it is far. As a result, the system comes with some overhead—for example, moving data to a remote host could require a fair bit of pointer manipulation, and shared pointers need some extra space. The paper discusses this overhead, along with some additional optimizations that can be used to reduce the costs (e.g., using RCU [read-copy update] for synchronizing pointer updates).</p> 
  <p>While Carbink is <a href="https://dl.acm.org/doi/10.5555/3488766.3488784">not the first</a> system to use such a scheme, it applies some clever tricks. Since the system can update pointers, it can <i>transparently</i> move data structures. This lets Carbink group data automatically into hot and cold tiers so as to better select candidates for eviction to far memory. This can be contrasted with Sinfonia's addressing choice that followed directly from the need to take advantage of node locality and a desire to give the programmer direct control over layout. Carbink instead focuses on <i>transparency</i>, which significantly reduces program complexity but relies on a heuristic to automatically determine application access patterns.</p> 
  <p>&nbsp;</p> 
  <h4>Twizzler</h4> 
  <p> Daniel Bittman. <br />2023. <br />Operating systems for far out memories. <br />Ph.D. dissertation. <br /><a href="https://dbittman.com/papers/dbittman-dissertation.pdf">https://dbittman.com/papers/dbittman-dissertation.pdf</a> </p> 
  <p>Twizzler is a data-centric operating system that's designed to enable fluid movement of data as well as shared access to far memory, with the goal being to reduce coordination and allow pointer-rich data to be moved without modification between nodes. Twizzler's approach is more along the lines of Opal: an operating system reimagined for evolving memory hierarchies and access abilities. It defines a single address space for all data, organized into collections of bytes called <i>objects,</i> which are uniquely identified with a 128-bit ID. </p> 
  <p>Twizzler's pointer scheme involves <i>invariant</i> pointers, which, like Sinfonia, consist of a tuple—only one that contains an object ID and an offset into the (possibly large) object. The key idea is that, through invariant pointers, in-memory data structures can be built that are fast to access while still allowing those data structures to move freely, without modification, between nodes in the system since the pointers are <i>invariant</i>—that is, they can be understood regardless of which host or process is looking at the data. Unlike Sinfonia, Twizzler splits the tuple and stores IDs separate from the offset in a per-object table of "outgoing references," where each entry can be used for multiple pointers. The result is that in-memory data structures can point to data across objects in a <i>huge</i> address space without increasing pointer size over the native representation (64 bits). </p> 
  <p>Invariant pointers with 128-bit IDs improve scaling by providing a large address space without tying the data model to hosts and by allowing multiple machines to operate on shared data without the need for expensive clusterwide address space coordination. Objects in Twizzler act as an <i>abstraction</i> of memory regions, allowing programmers to build data structures independent of the underlying hardware topology while still expressing locality that the infrastructure can exploit. This kind of <i>logical</i> locality lets optimizations based around placement make good decisions informed by application semantics while separating data from hosts for better flexibility. The invariant pointer scheme also exploits data locality for its own purposes—since local pointers don't take up table entries, many pointers to the same object can reuse entries. </p> 
  <p>When starting Twizzler, I focused on non-volatile memory, but the ideas applied equally well to far memory. For the very curious reader, more details can be found <a href="https://dbittman.com/papers/dbittman-dissertation.pdf">here</a>.</p> 
  <p>&nbsp;</p> 
  <h4>Conclusion</h4> 
  <p>The papers discussed here have far more gems in them than could be covered in this admittedly narrow focus on addressing. Both Sinfonia and Carbink tackle challenges of fault tolerance and network overhead, and I would be remiss if I failed to mention that these challenges also affect the systems' choices for addressing. Opal documentation includes a fascinating discussion on how single-address-space designs affect linkers and how the prototype was implemented on Mach. Of course, there is also a wealth of additional work (e.g., <a href="https://dbittman.com/papers/bittman-acm-tos21.pdf">Twizzler TOS</a>) in this area, and the topic is a timely one, since application memory demands continue to push and strain the abilities of our infrastructure.</p> 
  <p>One thing that becomes clear from reading these papers is that even something as innocent as addressing comes from a rich design space filled with tradeoffs between important considerations such as scaling, transparency, overhead, and programmer control. These tradeoffs are just some of the examples of the many challenges facing programmers today, especially as we drive our applications to larger scales. The way we refer to and address data <i>matters</i>, with reasons ranging from speed to complexity to consistency, and can have unexpected effects down the line if we do not carefully consider how we talk about and refer to data at large. The papers presented here indicate a clear desire and need to directly share data at larger scales, and I can't wait to see where the community goes next. </p> 
  <p>&nbsp;</p> 
  <p><b>Peter Alvaro</b> is an associate professor of computer science at the University of California Santa Cruz, where he leads the Disorderly Labs research group (<a href="https://disorderlylabs.github.io/">disorderlylabs.github.io</a>). His research focuses on using data-centric languages and analysis techniques to build and reason about data-intensive distributed systems in order to make them scalable, predictable, and robust to the failures and nondeterminism endemic to large-scale distribution. He earned his Ph.D. at UC Berkeley, where he studied with Joseph M. Hellerstein. He is a recipient of the National Science Foundation Career Award, Facebook Research Award, Usenix ATC 2020 Best Presentation Award, SIGMOD 2021 Distinguished PC Award, and UCSC Excellence in Teaching Award.</p> 
  <p><b>Daniel Bittman</b> leads the Twizzler project, developing and building new OS abstractions for far memory, persistence, distribution, and security. He received his Ph.D. from UC Santa Cruz in 2023, studying under Peter Alvaro and Ethan Miller. He is currently CTO of Elephance Memory, a startup bringing programmable far pointers to disaggregated memory systems using Twizzler. More at <a href="https://dbittman.com/">https://dbittman.com</a>.</p> 
  <p>Copyright © 2025 held by owner/author. Publication rights licensed to ACM.</p>  
 <script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'9790c07a2f71242f',t:'MTc1Njg1NTM3Mi4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script> 

	<p>
	
		<img class="floatLeft" src="img/q stamp_small.jpg" width="26" height="45" alt="acmqueue"><br><br>
	
	<em>Originally published in Queue vol. 23, no. 2</em>&#8212;
 	<br>
	Comment on this article in the <a href="http://portal.acm.org/citation.cfm?id=3733700">ACM Digital Library</a>
	
	</p>
	



<br />
<!--
<a href="https://twitter.com/share" class="twitter-share-button" data-via="ACMQueue">Tweet</a>
-->
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

<br />

<!--
<fb:like></fb:like>
-->

<br />

<div class="g-plusone" data-size="small" data-annotation="inline" data-width="120"></div>

<!-- these get hooked up to js events -->
<script type="text/javascript">
	addthis_pub             = 'acm';
	addthis_logo            = 'http://queue.acm.org/img/logo_queue_small.gif';
	addthis_logo_background = '#ffffff';
	addthis_logo_color      = '000000';
	addthis_brand           = 'ACM Queue';
	addthis_options         = 'reddit, slashdot, facebook, favorites, email, delicious, digg, technorati, blinklist, furl, myspace, google, live, more';
</script>

<!-- FB Like -->
<!--
<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "connect.facebook.net/en_US/all.js#xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<div id="fb-root"></div>
-->

<!-- Place this tag after the last +1 button tag. -->

<!--
<script type="text/javascript">
  (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  })();
</script>

<br />
<script src="https://connect.facebook.net/en_US/all.js#xfbml=1"></script>

<script>
FB.Event.subscribe('edge.create', function(targetUrl) {
  _gaq.push(['_trackSocial', 'facebook', 'like', targetUrl]);
});
</script>
-->



<hr noshade size=1 />




More related articles:

	  <p>
	  <span>David Chisnall</span> - <a href="detail.cfm?id=3639445"><b>How to Design an ISA</b></a>
	  <br />
	  Over the past decade I've been involved in several projects that have designed either ISA (instruction set architecture) extensions or clean-slate ISAs for various kinds of processors (you'll even find my name in the acknowledgments for the RISC-V spec, right back to the first public version). When I started, I had very little idea about what makes a good ISA, and, as far as I can tell, this isn't formally taught anywhere.
	  </p>
	  <br />

	  <p>
	  <span>Gabriel Falcao, Jo&#227;o Dinis Ferreira</span> - <a href="detail.cfm?id=3580503"><b>To PiM or Not to PiM</b></a>
	  <br />
	  As artificial intelligence becomes a pervasive tool for the billions of IoT (Internet of things) devices at the edge, the data movement bottleneck imposes severe limitations on the performance and autonomy of these systems. PiM (processing-in-memory) is emerging as a way of mitigating the data movement bottleneck while satisfying the stringent performance, energy efficiency, and accuracy requirements of edge imaging applications that rely on CNNs (convolutional neural networks).
	  </p>
	  <br />

	  <p>
	  <span>Mohamed Zahran</span> - <a href="detail.cfm?id=3038873"><b>Heterogeneous Computing: Here to Stay</b></a>
	  <br />
	  Mentions of the buzzword heterogeneous computing have been on the rise in the past few years and will continue to be heard for years to come, because heterogeneous computing is here to stay. What is heterogeneous computing, and why is it becoming the norm? How do we deal with it, from both the software side and the hardware side? This article provides answers to some of these questions and presents different points of view on others.
	  </p>
	  <br />

	  <p>
	  <span>David Chisnall</span> - <a href="detail.cfm?id=2687011"><b>There&#8217;s No Such Thing as a General-purpose Processor</b></a>
	  <br />
	  There is an increasing trend in computer architecture to categorize processors and accelerators as &quot;general purpose.&quot; Of the papers published at this year&#8217;s International Symposium on Computer Architecture (ISCA 2014), nine out of 45 explicitly referred to general-purpose processors; one additionally referred to general-purpose FPGAs (field-programmable gate arrays), and another referred to general-purpose MIMD (multiple instruction, multiple data) supercomputers, stretching the definition to the breaking point. This article presents the argument that there is no such thing as a truly general-purpose processor and that the belief in such a device is harmful.
	  </p>
	  <br />


<hr noshade size=1 />





<hr noshade size=1 />

	<p>
	<a href='#'><img src='https://queue.acm.org/img/logo_acm.gif' /></a>
	<br />
	&copy; ACM, Inc. All Rights Reserved.
	</p>

</div>



</body>
</html>