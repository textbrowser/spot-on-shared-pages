<!doctype html>
<html lang="en-US" class="view-grid">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Why AI language models choke on too much text &#x2d; Ars Technica</title>
	<style>img:is([sizes="auto" i], [sizes^="auto," i]) { contain-intrinsic-size: 3000px 1500px }</style>
	<link rel="preconnect" href="https://c.arstechnica.com">

<!-- The SEO Framework by Sybre Waaijer -->
<meta name="robots" content="max-snippet:-1,max-image-preview:large,max-video-preview:-1" />
<link rel="canonical" href="https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/" />
<meta name="description" content="Compute costs scale with the square of the input size. That&rsquo;s not great." />
<meta property="og:type" content="article" />
<meta property="og:locale" content="en_US" />
<meta property="og:site_name" content="Ars Technica" />
<meta property="og:title" content="Why AI language models choke on too much text" />
<meta property="og:description" content="Compute costs scale with the square of the input size. That&rsquo;s not great." />
<meta property="og:url" content="https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/" />
<meta property="og:image" content="https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1152x648.jpg" />
<meta property="og:image:width" content="1152" />
<meta property="og:image:height" content="648" />
<meta property="article:published_time" content="2024-12-20T13:00:56+00:00" />
<meta property="article:modified_time" content="2024-12-19T22:21:38+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:title" content="Why AI language models choke on too much text" />
<meta name="twitter:description" content="Compute costs scale with the square of the input size. That&rsquo;s not great." />
<meta name="twitter:image" content="https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1152x648.jpg" />
<script type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://arstechnica.com/#/schema/WebSite","url":"https://arstechnica.com/","name":"Ars Technica","description":"Serving the Technologist since 1998. News, reviews, and analysis.","inLanguage":"en-US","potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://arstechnica.com/search/{search_term_string}/"},"query-input":"required name=search_term_string"},"publisher":{"@type":"Organization","@id":"https://arstechnica.com/#/schema/Organization","name":"Ars Technica","url":"https://arstechnica.com/","logo":{"@type":"ImageObject","url":"https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480.png","contentUrl":"https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480.png","width":512,"height":512,"contentSize":"34417"}}},{"@type":"WebPage","@id":"https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/","url":"https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/","name":"Why AI language models choke on too much text &#x2d; Ars Technica","description":"Compute costs scale with the square of the input size. That&rsquo;s not great.","inLanguage":"en-US","isPartOf":{"@id":"https://arstechnica.com/#/schema/WebSite"},"breadcrumb":{"@type":"BreadcrumbList","@id":"https://arstechnica.com/#/schema/BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":"https://arstechnica.com/","name":"Ars Technica"},{"@type":"ListItem","position":2,"item":"https://arstechnica.com/ai/","name":"Category: AI"},{"@type":"ListItem","position":3,"name":"Why AI language models choke on too much text"}]},"potentialAction":{"@type":"ReadAction","target":"https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/"},"datePublished":"2024-12-20T13:00:56+00:00","dateModified":"2024-12-19T22:21:38+00:00","author":{"@type":"Person","@id":"https://arstechnica.com/#/schema/Person/9efb011d2228a88f50c9da1c3e1f7f94","name":"Timothy B. Lee","description":"Timothy B. Lee was on staff at Ars Technica from 2017 to 2021, covering technology policy and the future of transportation. He holds a master&#039;s degree in computer science from Princeton. He lives with his family in Washington, DC. You can follow him..."}}]}</script>
<script type="application/ld+json">{"@context":"https://schema.org","@type":"NewsArticle","mainEntityOfPage":{"@type":"WebPage","@id":"https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/"},"headline":"Why AI language models choke on too much text","image":{"@type":"ImageObject","url":"https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1152x648.jpg","width":1152,"height":648},"datePublished":"2024-12-20T13:00:56+00:00","dateModified":"2024-12-19T22:21:38+00:00","author":{"@type":"Person","name":"Timothy B. Lee","url":"https://arstechnica.com/author/timlee/"},"publisher":{"@type":"Organization","name":"Ars Technica","logo":{"@type":"ImageObject","url":"https://cdn.arstechnica.net/wp-content/uploads/2024/10/ars-logo-186x60.png","width":186,"height":60}},"description":"Compute costs scale with the square of the input size. That\u0026rsquo;s not great."}</script>
<!-- / The SEO Framework by Sybre Waaijer | 8.99ms meta | 0.15ms boot -->

<link rel="preconnect" href="https://cdn.cookielaw.org">
<link rel="preconnect" href="https://geolocation.onetrust.com">
<!-- OneTrust Cookies Consent Notice start -->
<script
  src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js"
  data-domain-script="b10882a1-8446-4e7d-bfb2-ce2c770ad910"
></script>

<script id="oneTrustScripts">
  window.OptanonWrapper = function() {
    var CCPAButton = document.getElementById('ot-sdk-btn');
    CCPAButton && CCPAButton.classList.add('ot-sdk-btn--visible');
    window.dataLayer && window.dataLayer.push({
      event: 'OneTrustGroupsUpdated'
    });
    window.cnBus && window.cnBus.emit('onetrust.OneTrustGroupsUpdated');
  };
</script>
<script
  src="https://cdn.cookielaw.org/opt-out/otCCPAiab.js"
  ccpa-opt-out-ids="C0002,C0003,C0004,C0005"
  ccpa-opt-out-geo="ca"
  ccpa-opt-out-lspa="true"
></script>
<!-- OneTrust Cookies Consent Notice end -->
<!-- Google Tag Manager DataLayer -->
<script>
  window.dataLayer = window.dataLayer || [];
  window.dataLayer.push({"event":"data-layer-loaded","user":{"ars_userId":undefined,"amg_userId":undefined,"uID":undefined,"sID":undefined,"loginStatus":false,"subscriberStatus":"none","infinityId":undefined,"registrationSource":undefined,"mdw_cnd_id":undefined,"monthlyVisits":undefined,"accessPaywall":undefined,"view":"grid","theme":"system","show_comments":undefined},"content":{"pageTemplate":"single","pageType":"article|report","contentCategory":"homepage","section":"homepage","subsection":undefined,"contributor":"Timothy B. Lee","contentID":2067918,"contentLength":4797,"display":"Why AI language models choke on too much text","contentSource":"web","pageAssets":undefined,"uniqueContentCount":undefined,"monthlyContentCount":undefined,"publishDate":"2024-12-20T13:00:56-05:00","modifiedDate":"2024-12-19T22:21:38-05:00","keywords":"AI|Anthropic|context windows|google deepmind|LLMs|openai","dataSource":undefined},"marketing":{"campaignName":undefined,"circCampaignId":undefined,"internalCampaignId":undefined,"brand":"Ars Technica","certified_mrc_data":undefined,"condeNastId":undefined},"page":{"pID":undefined,"syndicatorUrl":undefined,"pageURL":"https:\/\/arstechnica.com\/?p=2067918","canonical":"https:\/\/arstechnica.com\/ai\/2024\/12\/why-ai-language-models-choke-on-too-much-text\/","canonicalPathName":"\/ai\/2024\/12\/why-ai-language-models-choke-on-too-much-text\/"},"search":{"facets":undefined,"searchTerms":undefined},"site":{"appVersion":"1.0.0"}});
</script>
<!-- End Google Tag Manager DataLayer -->
<!-- Google Tag Manager -->
<script>
  (function(w, d, s, l, i) {
    w[l] = w[l] || [];
    w[l].push({
      'gtm.start': new Date().getTime(),
      event: 'gtm.js'
    });
    var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s),
      dl = l != 'dataLayer' ? '&l=' + l : '';
    j.async = true;
    j.src =
      'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
    f.parentNode.insertBefore(j, f);
  })(window, document, 'script', 'dataLayer', 'GTM-NLXNPCQ');
</script>
<!-- End Google Tag Manager -->
<style id='elasticpress-related-posts-style-inline-css'>
.editor-styles-wrapper .wp-block-elasticpress-related-posts ul,.wp-block-elasticpress-related-posts ul{list-style-type:none;padding:0}.editor-styles-wrapper .wp-block-elasticpress-related-posts ul li a>div{display:inline}

</style>
<link rel='stylesheet' id='elasticpress-facets-css' href='https://cdn.arstechnica.net/wp-content/plugins/_composer_elasticpress/dist/css/facets-styles.css?ver=7d568203f3965dc85d8a' media='all' />
<link rel='stylesheet' id='searchterm-highlighting-css' href='https://cdn.arstechnica.net/wp-content/plugins/_composer_elasticpress/dist/css/highlighting-styles.css?ver=252562c4ed9241547293' media='all' />
<link rel='stylesheet' id='app/0-css' href='https://cdn.arstechnica.net/wp-content/themes/ars-v9/public/css/app.661760.css' media='all' />
<link rel='stylesheet' id='ads/0-css' href='https://cdn.arstechnica.net/wp-content/themes/ars-v9/public/css/ads.a55585.css' media='all' />
<script src="https://cdn.arstechnica.net/wp-content/themes/ars-v9/resources/scripts/jquery-3.7.1.min.js?ver=3.7.1" id="jquery-js"></script>
<meta property="article:published_time" content="2024-12-20T13:00:56+00:00">
<meta property="article:modified_time" content="2024-12-19T22:21:38+00:00">
<script>window.ars = {"subscriber":false,"hasAdFree":false,"hasTrackerFree":false,"loggedIn":false}</script>
<script>
    const theme = "system";
    let darkMode = false;
    if (theme === "dark" || (theme === "system" && (window.matchMedia("(prefers-color-scheme: dark)").matches))) {
        darkMode = true;
        document.documentElement.classList.add("dark");
    }
    if (theme === "dusk" || (theme === "system" && (window.matchMedia("(prefers-color-scheme: light)").matches))) {
        darkMode = false;
        document.documentElement.classList.add("dusk");
    }
    if (theme === "light") {
        darkMode = false;
        document.documentElement.classList.add("light");
    }
    window.darkMode = darkMode;
</script>
<script>
    const settings = JSON.parse(localStorage.getItem("text-settings")) || {};
    const { size = "standard", links = "standard", width = "standard", position="story" } = settings;

    const html = document.querySelector("html");
    html.classList.add(`text-settings-size-${size}`);
    html.classList.add(`text-settings-links-${links}`);
    html.classList.add(`text-settings-width-${width}`);
    html.classList.add(`text-settings-position-${position}`);
</script>
<meta name="twitter:site" content="@arstechnica" />
<meta name="twitter:domain" content="arstechnica.com" />
<meta property="facebook-domain-verification" content="qptjyerza2q11uv3fe6aay6hbsncr8" />
<style>[x-cloak] { display: none !important; }</style>
<link rel="preconnect" href="https://globalservices.conde.digital">
<link rel="preconnect" href="https://player.cnevids.com">
<script>
  window.permutiveCohorts = {"cached_until":{"date":"2024-12-22 19:08:16.031648","timezone_type":3,"timezone":"UTC"},"cohorts":["bvbt","bybf","bvch","byoo","bvcs","bvqu","bvln","bvro","bvnx","bvrp","bvqj","buzk","bvpb","bvgu","bvib","bvlf","bvcu","bjfa","bvrs","bxxe","bvfp","bvml","bvvp","bvpy","bvqt","bute","bvid","bvck","bvmy","bvpr","buzu","bvqm","bvhx","bvls","bvrn","bvgr","bvgt","bvqs","bvhs","bvpt","bvbx","bvfb","busz","bzeu","bvgv","bvdx","bvbw","bvpf","bvlt","bvqh","bvpx","bvns","bvps","bvpd","bvgs","bvqn","bvcc","bvia","butc","bveo","bvoz","busy","bvmk","bvek","bvpa","bvig","bvrc","bvku","bvct","bvnt","bvms","bvpe","bvfn","bycl"],"activations":{"target_dfp":["bvbt","bybf","bvch","bvcs","bvqu","bvln","bvro","bvnx","bvrp","bvqj","buzk","bvpb","bvgu","bvib","bvlf","bvcu","bjfa","bvrs","bxxe","bvfp","bvml","bvvp","bvpy","bvqt","bute","bvid","bvck","bvmy","bvpr","buzu","bvqm","bvhx","bvls","bvrn","bvgr","bvgt","bvqs","bvhs","bvpt","bvbx","bvfb","busz","bzeu","bvgv","bvdx","bvbw","bvpf","bvlt","bvqh","bvpx","bvns","bvps","bvpd","bvgs","bvqn","bvcc","bvia","butc","bveo","bvoz","busy","bvmk","bvek","bvpa","bvig","bvrc","bvku","bvct","bvnt","bvms","bvpe","bvfn","bycl"]},"gam":["bvbt","bybf","bvch","bvcs","bvqu","bvln","bvro","bvnx","bvrp","bvqj","buzk","bvpb","bvgu","bvib","bvlf","bvcu","bjfa","bvrs","bxxe","bvfp","bvml","bvvp","bvpy","bvqt","bute","bvid","bvck","bvmy","bvpr","buzu","bvqm","bvhx","bvls","bvrn","bvgr","bvgt","bvqs","bvhs","bvpt","bvbx","bvfb","busz","bzeu","bvgv","bvdx","bvbw","bvpf","bvlt","bvqh","bvpx","bvns","bvps","bvpd","bvgs","bvqn","bvcc","bvia","butc","bveo","bvoz","busy","bvmk","bvek","bvpa","bvig","bvrc","bvku","bvct","bvnt","bvms","bvpe","bvfn","bycl"],"xandr":[],"config":{"time_to_wait_for_consent_in_millis":4000}};
  window.permutiveContextInfo = {"pageProperties":{"client":{"url":"https:\/\/arstechnica.com\/ai\/2024\/12\/why-ai-language-models-choke-on-too-much-text\/","referrer":"","type":"web","user_agent":"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/80.0.3987.163 Safari\/537.36","domain":"arstechnica.com","title":"Why AI language models choke on too much text &#x2d; Ars Technica"},"type":"article","article":{"id":"2067918","category":"ai","subcategory":"","title":"Why AI language models choke on too much text","tags":["ai","anthropic","context-windows","google-deepmind","llms","openai"]}},"url":"https:\/\/arstechnica.com\/ai\/2024\/12\/why-ai-language-models-choke-on-too-much-text\/"};
</script>
<script
  src="https://www.googletagservices.com/tag/js/gpt.js"
  id="gpt-script"
  async
></script>
<script>
  window.googletag = window.googletag || {};
  window.googletag.cmd = window.googletag.cmd || [];
  window.cns = window.cns || {};
  window.cns.queue = [];
  window.cns.async = function(s, c) {
    cns.queue.push({
      service: s,
      callback: c
    })
  };
  window.cns.pageContext = {"contentType":"article","templateType":"article","channel":"ai","subChannel":"","slug":"why-ai-language-models-choke-on-too-much-text","server":"production","keywords":{"tags":["ai","anthropic","context-windows","google-deepmind","llms","openai"],"cm":[],"platform":["wordpress"],"copilotid":""}};
</script>


<script
  src="https://ads-static.conde.digital/production/cns/builds/ars-technica/ars-technica.min.js"
  async
></script>


  <script type="text/javascript">
    window._taboola = window._taboola || [];
    _taboola.push({
      article: 'auto'
    });
    ! function(e, f, u, i) {
      if (!document.getElementById(i)) {
        e.async = 1;
        e.src = u;
        e.id = i;
        f.parentNode.insertBefore(e, f);
      }
    }(document.createElement('script'),
      document.getElementsByTagName('script')[0],
      '//cdn.taboola.com/libtrc/condenast1-network/loader.js',
      'tb_loader_script');
    if (window.performance && typeof window.performance.mark == 'function') {
      window.performance.mark('tbl_ic');
    }
  </script>
<script type="text/javascript">!(function(o,_name){function n(){(n.q=n.q||[]).push(arguments)}n.v=1,o[_name]=o[_name]||n;!(function(o,t,n,c){function e(n){(function(){try{return(localStorage.getItem("v4ac1eiZr0")||"").split(",")[4]>0}catch(o){}return!1})()&&(n=o[t].pubads())&&n.setTargeting("admiral-engaged","true")}(c=o[t]=o[t]||{}).cmd=c.cmd||[],typeof c.pubads===n?e():typeof c.cmd.unshift===n?c.cmd.unshift(e):c.cmd.push(e)})(window,"googletag","function");})(window,String.fromCharCode(97,100,109,105,114,97,108));!(function(t,c,i){i=t.createElement(c),t=t.getElementsByTagName(c)[0],i.async=1,i.src="https://shiverscissors.com/v2fumwIJOo-LsCB0dlG18VSTW43CpWhUEPJuKeRTzrEQdSPPlMr5GymU",t.parentNode.insertBefore(i,t)})(document,"script");</script>

<meta name="twitter:partner" content="tfwp"><meta name='parsely-page' content='{"title":"Why AI language models choke on too much text","link":"https:\/\/arstechnica.com\/ai\/2024\/12\/why-ai-language-models-choke-on-too-much-text\/","type":"post","author":"Timothy B. Lee","post_id":2067918,"pub_date":"2024-12-20T08:00:56-05:00","section":"AI","tags":["ai","anthropic","context-windows","google-deepmind","llms","openai"],"image_url":"https:\/\/cdn.arstechnica.net\/wp-content\/uploads\/2024\/12\/LLM-soup-500x500.jpg"}'>
<meta name='parsely-metadata' content='{"type":"post","title":"Why AI language models choke on too much text","post_id":2067918,"lower_deck":"Compute costs scale with the square of the input size. That&apos;s not great.","image_url":"https:\/\/cdn.arstechnica.net\/wp-content\/uploads\/2024\/12\/LLM-soup-500x500.jpg","listing_image_url":"https:\/\/cdn.arstechnica.net\/wp-content\/uploads\/2024\/12\/LLM-soup-768x432.jpg"}'>
<!-- Start Headline A/B -->
<script type="text/javascript">
  class ABTest {
    constructor(post_id, init_method) {
      this.post_id = post_id;
      this.ajaxurl = '/services/ars-ajax-handler.php';
      this.expireDays = 1 / 48; // 30 min
      this.group = this.getGroup();
      this.uid = this.getUid();
      this.init_method = init_method;
      this.setTitle();

      if (this.init_method === 'click') {
        this.click();
      } else {
        this.impression();
      }
    }

    setCookie(name, value, days) {
      var expires = "";
      if (days) {
        var date = new Date();
        date.setTime(date.getTime() + (days * 24 * 60 * 60 * 1000));
        expires = "; expires=" + date.toUTCString();
      }
      document.cookie = name + "=" + (value || "") + expires + "; path=/";
    }

    getCookie(name) {
      var nameEQ = name + "=";
      var ca = document.cookie.split(';');
      for (var i = 0; i < ca.length; i++) {
        var c = ca[i];
        while (c.charAt(0) == ' ') c = c.substring(1, c.length);
        if (c.indexOf(nameEQ) == 0) return c.substring(nameEQ.length, c.length);
      }
      return null;
    }

    // Retrieves a unique id for determining whether the event should be recorded
    getUid() {
      var uid = this.getCookie('ars_ab_' + this.post_id + '_uid');
      if (!uid) {
        uid = (Math.random() + 1).toString(36).substring(2, 7);
        this.setCookie('ars_ab_' + this.post_id + '_uid', uid, this.expireDays);
      }
      return uid;
    };

    // Places the user in either A or B for this post id
    getGroup() {
      var group = this.getCookie('ars_ab_' + this.post_id + '_group');
      if (!group) {
        group = String.fromCharCode(Math.floor(Math.random() * 2) + 65).toLowerCase();
        this.setCookie('ars_ab_' + this.post_id + '_group', group, this.expireDays);
      }
      return group;
    };

    // Records a headline impression (from homepage or other listing)
    impression() {
      // Send fake ajax
      var params = {
        nonce: 'a371552211',
        action: 'ars_ab_impression',
        id: this.post_id,
        group: this.group,
        uid: this.uid,
        ts: (new Date()).getTime()
      };
      var url = this.ajaxurl + '?' + this.encodeParams(params);
      document.write('\x3Cscript type="text/javascript" src="' + url + '">\x3C/script>');
    };

    // Records a headline click from the actual post page
    click() {
      // Send fake ajax
      var params = {
        nonce: '51dcd0890d',
        action: 'ars_ab_click',
        id: this.post_id,
        group: this.group,
        uid: this.uid,
        ts: (new Date()).getTime()
      };
      var url = this.ajaxurl + '?' + this.encodeParams(params);
      document.write('\x3Cscript type="text/javascript" src="' + url + '">\x3C/script>');
    };

    // If user is in B group, dynamically set title
    setTitle() {
      if (this.group == 'b') {
        var span = document.getElementById('ars_ab_' + this.post_id);
        var title = span.parentNode;
        title.innerHTML = span.getAttribute('data-title-b');
      }
    };

    encodeParams(data) {
      var ret = [];
      for (var d in data)
        ret.push(encodeURIComponent(d) + "=" + encodeURIComponent(data[d]));
      return ret.join("&");
    };

  };
</script>
<!-- End Headline A/B -->
<link rel="icon" href="https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-60x60.png" sizes="32x32" />
<link rel="icon" href="https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-300x300.png" sizes="192x192" />
<link rel="apple-touch-icon" href="https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-300x300.png" />
<meta name="msapplication-TileImage" content="https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-300x300.png" />

<!--
	generated 103 seconds ago
	generated in 0.317 seconds
	served from batcache in 0.005 seconds
	expires in 197 seconds
	view: grid 
	theme: system 
	xf_style_id: 3 
 -->
</head>

<body class="post-template-default single single-post postid-2067918 single-format-standard wp-embed-responsive why-ai-language-models-choke-on-too-much-text bg-white dusk:bg-gray-100 text-gray-700 dark:text-gray-250 dark:bg-gray-50 singular">
  <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NLXNPCQ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
  
  <div id="app">
    <a class="sr-only focus:not-sr-only" href="#main">
  Skip to content
</a>

<div class="ad-wrapper is-fullwidth is-hero">
        <div class="ad-wrapper-inner">
            <div class="ad ad--hero"></div>
        </div>
    </div>

<header
  class="banner font-impact xxl:max-w-xxl mdl:rounded-sm sticky top-0 z-30 mx-auto flex h-14 max-w-6xl flex-row flex-nowrap items-center justify-between bg-gray-700 px-[15px] font-semibold uppercase transition-[top] duration-500 dark:bg-black sm:px-5 md:my-5 md:h-10 lg:my-10"
  id="site-header">
  <a id = "header-logo" href="https://arstechnica.com/" aria-label="Ars Technica home">
    <span class="sr-only">Ars Technica home</span>
          <svg class="h-[36px] w-[109px] md:h-[65px] md:w-[197px]" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 436 144.1"><defs><clipPath id="ars-full_svg__a"><path fill="none" d="M0 0h436v144.1H0z"/></clipPath><clipPath id="ars-full_svg__b"><path fill="none" d="M0 0h436v144.1H0z"/></clipPath></defs><g clip-path="url(#ars-full_svg__a)"><g fill="none" clip-path="url(#ars-full_svg__b)"><path fill="#ff4e00" d="M72 0c39.8 0 72.1 32.3 72.1 72.1s-32.3 72.1-72.1 72.1S0 111.8 0 72.1 32.3 0 72 0"/><path fill="#fff" d="m46.5 94-.9-5.9c-4 4.4-9.6 6.8-15.6 6.8-8 0-13-4.8-13-12.3 0-11 9.4-15.4 27.8-17.3v-1.9c0-5.6-3.3-7.5-8.4-7.5s-10.5 1.7-15.3 3.8L20 52.6c5.3-2.1 10.3-3.7 17.1-3.7 10.7 0 15.9 4.3 15.9 14.2v30.8h-6.7Zm-1.6-22.4c-16.3 1.6-19.7 6-19.7 10.6s2.4 5.9 6.6 5.9 9.4-2.4 13.1-6.2zm27.3-3.7v26H64v-44h6.6l1.4 9c3.1-5 8.2-9.5 15.5-9.9l1.3 7.9c-7.4.3-13.6 5.2-16.6 11m37.2 26.9c-5.6-.1-11.1-1.6-16.1-4.2l1.2-7.8c4.6 3.2 10 5 15.6 5.1 5.6 0 9-2.1 9-5.8s-2.5-5.6-10.5-7.5C98.2 72 94.1 68.9 94.1 61s5.9-12.2 15.6-12.2c5 0 9.9 1 14.5 3l-1.3 7.8c-4.1-2.4-8.7-3.7-13.4-3.8-5 0-7.6 1.9-7.6 5.1s2.2 4.6 9.2 6.4c10.9 2.8 15.8 5.9 15.8 14.3s-6.1 13.2-17.5 13.2m109.4-11.1c-4.4 3.7-8.4 5-12.8 5-7.7 0-12.7-5.3-13.5-14h24.8l.9-5.5h-25.7c.8-8.7 5.7-14.1 12.9-14.1s8.8 1.7 12.9 5.1l1-5.9c-4-2.9-8.8-4.4-13.7-4.3-10.7 0-19.2 7.8-19.2 21.9s8.3 21.9 18.9 21.9c5.2.1 10.2-1.6 14.3-4.8zm-48.7-27.5v36.9h-5.8V56.2h-13.4v-5.3H183l.9 5.3H170Zm74.5 37.6c-11.9 0-19.5-8.8-19.5-21.8s7.8-22 19.6-22c4.3-.1 8.5 1.1 12 3.5l-.9 5.9c-3.2-2.6-7.1-4-11.2-4.1-8.6 0-13.6 6.5-13.6 16.6s5.1 16.6 13.6 16.6c4.3 0 8.5-1.6 11.9-4.2l.9 5.4c-3.7 2.6-8.2 4.1-12.8 4.1M292 93V73.5h-21.4V93h-5.8V50.9h5.8v17.5H292V50.9h5.8V93zm42.9 0-23.2-32.8V93h-5.3V50.9h5.1l22.4 31.5V50.9h5.3V93zm13.4-42.1h5.8V93h-5.8zm32.6 42.9c-11.9 0-19.5-8.8-19.5-21.8s7.8-22 19.6-22c4.3-.1 8.5 1.1 12 3.5l-.9 5.9c-3.2-2.6-7.1-4-11.2-4.1-8.6 0-13.6 6.5-13.6 16.6s5.1 16.6 13.6 16.6c4.3 0 8.5-1.6 11.9-4.2l.9 5.4c-3.7 2.6-8.2 4.1-12.8 4.1m32.9-43.1h5.8l16.3 41.5-5.6 1.2-5-13.1h-17.4L403.1 93h-5.8zm-4 24.6h13.5l-6.8-17.9z"/></g></g></svg>
      </a>

  <div class="flex flex-row flex-nowrap items-center gap-3 md:gap-5 xl:gap-4">
    
          <div class="xxl:hidden">
  <div x-data="{
      open: false,
      toggle() {
          if (this.open) {
              return this.close()
          }
          // If we're inside main header, add a data attribute to the header
          if (this.$el.closest('#site-header')) {
              this.$el.closest('#site-header').dataset.dropdownOpen = 'true';
          }
          this.open = true
      },
      close() {
          if (!this.open) {
              return;
          }
          // If we're inside main header, add a data attribute to the header
          if (this.$el.closest('#site-header')) {
              this.$el.closest('#site-header').dataset.dropdownOpen = 'false';
          }
          this.open = false
      }
  }" @keydown.escape.prevent.stop="close($refs.button)"
    @focusin.window="! $refs.panel.contains($event.target) && close()" x-id="['dropdown-button']">

    <!-- Button -->
    <button type="button" x-ref="button"
      x-on:click="
      toggle();
      $dispatch('dropdown-opened', { panel: $refs.panel });
      "
      :aria-expanded="open" :aria-controls="$id('dropdown-button')" :class="{ selected: open }"
      class="group flex items-center focus:outline-none" arial-label="" aria-label="Open Sections menu dropdown">
      <svg class="group-with-selected:text-gray-200 h-5 w-5 text-gray-300 hover:text-gray-100 group-focus:text-gray-100 sm:hidden" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><path fill="currentColor" d="M0 0h40v8H0zm0 16h40v8H0zm24 24H0v-8h16z"/><path fill="#04cc74" d="M23 32h17l-8 8h-.3z"/></svg>
          <span
            class="group-with-selected:text-gray-100 hidden flex-row flex-nowrap items-center gap-1 uppercase text-gray-300 hover:text-gray-100 group-focus:text-gray-100 sm:flex xl:text-sm">
            Sections
            <svg class="h-1 text-gray-300" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 19.3"><defs><clipPath id="arrow-down_svg__a"><path fill="none" d="M0 0h40v19.3H0z"/></clipPath><clipPath id="arrow-down_svg__b"><path fill="none" d="M0 0h40v19.3H0z"/></clipPath></defs><g clip-path="url(#arrow-down_svg__a)"><g fill="none" clip-path="url(#arrow-down_svg__b)"><path fill="currentColor" d="m0 0 18.9 18.9c.6.6 1.6.6 2.2 0L40 0z"/></g></g></svg>
          </span>
    </button>

    <!-- Panel -->
    <div x-cloak x-ref="panel" x-show="open" x-transition.origin.top.center x-on:click.outside="close()"
      :id="$id('dropdown-button')" class="absolute overflow-hidden z-50 bg-gray-550 xxs:max-w-[400px] absolute right-0 top-14 mt-[1px] w-full rounded-sm sm:right-auto sm:max-w-[200px] md:top-10">
      <nav class="topnav-sections">
            
            <div
              class="flex flex-row flex-nowrap items-center justify-between bg-gray-700 px-10 py-2 sm:hidden sm:flex-col sm:items-start">
              <a class="text-green-400 hover:text-green-500 focus:text-green-500" href="/civis/">
                Forum
              </a>

                              
                <div class="h-5 w-[1px] bg-gray-400"></div>

                <a class="text-orange-400 hover:text-orange-500 focus:text-orange-500"
                  href="/store/product/subscriptions/">
                  Subscribe
                </a>
              
              
              <div class="h-5 w-[1px] bg-gray-400"></div>

              <a class="flex flex-row flex-nowrap items-center gap-2 text-gray-300 hover:text-gray-100 focus:text-gray-100"
                href="/search/">
                <svg class="h-5 w-5" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="magnify_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="magnify_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#magnify_svg__a)"><g fill="none" clip-path="url(#magnify_svg__b)"><path fill="currentColor" d="M39.2 35.4 29 25.2c4.4-6.2 3.9-15-1.7-20.6C24.2 1.6 20.1 0 16 0S7.8 1.6 4.7 4.7c-6.2 6.2-6.2 16.4 0 22.6C7.8 30.4 11.9 32 16 32s6.5-1 9.3-3l10.2 10.2c.5.5 1.2.8 1.9.8s1.4-.3 1.9-.8c1-1 1-2.7 0-3.8M8.5 23.5c-2-2-3.1-4.7-3.1-7.5s1.1-5.5 3.1-7.5 4.7-3.1 7.5-3.1 5.5 1.1 7.5 3.1c4.2 4.2 4.2 10.9 0 15.1-2 2-4.7 3.1-7.5 3.1s-5.5-1.1-7.5-3.1"/></g></g></svg>

                              </a>
            </div>

            <ul class="my-3 grid grid-cols-2 sm:grid-cols-1">
                              <li>
                  <a class="group flex flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                    href="https://arstechnica.com/ai/">
                    <svg class="mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="section-ai_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="section-ai_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#section-ai_svg__a)"><g fill="currentColor" clip-path="url(#section-ai_svg__b)"><path d="M20 2.4c9.7 0 17.6 7.9 17.6 17.6S29.7 37.6 20 37.6 2.4 29.7 2.4 20 10.3 2.4 20 2.4M20 0C9 0 0 9 0 20s9 20 20 20 20-9 20-20S31 0 20 0"/><path d="M20 13q2.85 0 5.4.9c.7.2 1.4-.1 1.6-.9l1.4-5.5C26 5.9 23.1 4.9 20 4.9s-6 .9-8.4 2.6L13 13c.2.7.9 1.1 1.6.9Q17 13 20 13M8.9 18.3c.4-.8 1-1.5 1.7-2.1l-2.2-5.7C7 12.2 6 14.1 5.5 16.3l1.3 2.1c.5.8 1.7.8 2.2 0m24.3 0 1.3-2.1c-.5-2.2-1.5-4.1-2.9-5.8l-2.2 5.7c.7.6 1.3 1.3 1.7 2.1.5.8 1.6.9 2.2 0M23.2 20c0 1.8-1.5 3.2-3.2 3.2s-3.2-1.4-3.2-3.2 1.5-3.2 3.2-3.2 3.2 1.4 3.2 3.2"/></g></g></svg>
                    AI
                  </a>
                </li>
                              <li>
                  <a class="group flex flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                    href="https://arstechnica.com/information-technology/">
                    <svg class="mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="section-information-technology_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="section-information-technology_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#section-information-technology_svg__a)"><g fill="currentColor" clip-path="url(#section-information-technology_svg__b)"><path d="M35 0H5C2.2 0 0 2.2 0 5s2.2 5 5 5h30c2.8 0 5-2.2 5-5s-2.2-5-5-5m-6.9 7c-1.1 0-2-.9-2-2s.9-2 2-2 2 .9 2 2-.9 2-2 2m6 0c-1.1 0-2-.9-2-2s.9-2 2-2 2 .9 2 2-.9 2-2 2m.9 8H5c-2.8 0-5 2.2-5 5s2.2 5 5 5h30c2.8 0 5-2.2 5-5s-2.2-5-5-5m-6.9 7.2c-1.1 0-2-.9-2-2s.9-2 2-2 2 .9 2 2-.9 2-2 2m6 0c-1.1 0-2-.9-2-2s.9-2 2-2 2 .9 2 2-.9 2-2 2M35 30H5c-2.8 0-5 2.2-5 5s2.2 5 5 5h30c2.8 0 5-2.2 5-5s-2.2-5-5-5m-6.9 7.4c-1.1 0-2-.9-2-2s.9-2 2-2 2 .9 2 2-.9 2-2 2m6 0c-1.1 0-2-.9-2-2s.9-2 2-2 2 .9 2 2-.9 2-2 2"/></g></g></svg>
                    Biz &amp; IT
                  </a>
                </li>
                              <li>
                  <a class="group flex flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                    href="https://arstechnica.com/cars/">
                    <svg class="mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="section-cars_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="section-cars_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#section-cars_svg__a)"><g fill="none" clip-path="url(#section-cars_svg__b)"><path fill="currentColor" d="M39.7 23.5c.2-1.2.3-2.3.3-3.5s-.1-2.4-.3-3.5l-1.3-.4c-.1-.6-.3-1.2-.5-1.8l.9-1c-.8-2.3-2-4.3-3.5-6.1l-1.3.3c-.4-.4-.8-.9-1.3-1.3l.3-1.3a20.6 20.6 0 0 0-6.1-3.5l-1 .9c-.6-.2-1.2-.3-1.8-.5L23.7.5C22.4.1 21.2 0 20 0s-2.4.1-3.5.3l-.4 1.3c-.6.1-1.2.3-1.8.5l-1-.9C11 2 9 3.2 7.2 4.7L7.5 6c-.4.4-.9.8-1.3 1.3L4.9 7a20.6 20.6 0 0 0-3.5 6.1l.9 1c-.2.6-.3 1.2-.5 1.8l-1.3.4C.1 17.6 0 18.8 0 20s.1 2.4.3 3.5l1.3.4c.1.6.3 1.2.5 1.8l-.9 1c.8 2.3 2 4.3 3.5 6.1l1.3-.3c.4.4.8.9 1.3 1.3L7 35.1c1.8 1.5 3.9 2.7 6.1 3.5l1-.9c.6.2 1.2.3 1.8.5l.4 1.3c1.1.2 2.3.3 3.5.3s2.4-.1 3.5-.3l.4-1.3c.6-.1 1.2-.3 1.8-.5l1 .9c2.3-.8 4.3-2 6.1-3.5l-.3-1.3c.4-.4.9-.8 1.3-1.3l1.3.3c1.5-1.8 2.7-3.9 3.5-6.1l-.9-1c.2-.6.3-1.2.5-1.8l1.3-.4ZM25.9 8.2c1.3.6 2.4 1.5 3.4 2.5l-3.1 6.2-2.6.9c-.6-.9-1.5-1.6-2.6-1.9v-2.8zM22 19.9c0 1.1-.9 2-2 2s-2-.9-2-2 .9-2 2-2 2 .9 2 2M20 6.8q2.1 0 3.9.6L20 11.3l-3.9-3.9q1.8-.6 3.9-.6m-5.9 1.4 4.9 4.9v2.8c-1.1.3-2 .9-2.6 1.9l-2.6-.9-3.1-6.2c1-1 2.2-1.9 3.4-2.5m-4.8 4.2 2.5 4.9-4.9 2.5c0-2.7.9-5.3 2.4-7.4m.2 15.4 5.4-.9.9 5.4c-2.5-.9-4.7-2.5-6.3-4.5m5.7-2.9L8.4 26c-.6-1.2-1.1-2.6-1.3-4.1l6.2-3.1 2.6.9v.3c0 1 .4 2 1 2.7l-1.6 2.2Zm7 8c-.7.1-1.4.2-2.1.2s-1.4 0-2.1-.2l-1.1-6.8 1.6-2.2c.5.2 1 .3 1.6.3s1.1-.1 1.6-.3l1.6 2.2zm2.1-.5.9-5.4 5.4.9c-1.6 2.1-3.7 3.7-6.3 4.5m7.4-6.4-6.8-1.1-1.6-2.2c.6-.7 1-1.7 1-2.7v-.3l2.6-.9 6.2 3.1c-.2 1.4-.7 2.8-1.3 4.1m-3.4-8.7 2.5-4.9c1.5 2.1 2.4 4.6 2.4 7.4z"/></g></g></svg>
                    Cars
                  </a>
                </li>
                              <li>
                  <a class="group flex flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                    href="https://arstechnica.com/culture/">
                    <svg class="mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="section-culture_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="section-culture_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#section-culture_svg__a)"><g fill="currentColor" clip-path="url(#section-culture_svg__b)"><path d="M19 32v7.1c0 .5.4 1 1 1s1-.4 1-1V32zm2-24V1c0-.6-.5-1-1-1s-1 .4-1 1v7.1h2m-8.3 22.6L9.6 36c-.3.5-.1 1 .3 1.3.5.3 1 .1 1.3-.3l3.3-5.7c-.5-.1-1-.3-1.5-.4-.1 0-.3 0-.4-.1M27.3 9.3 30.4 4c.3-.5.1-1-.3-1.3-.5-.3-1-.1-1.3.3l-3.3 5.7c.5.1 1 .2 1.5.4.1 0 .3 0 .4.1m-21.8 18L3 28.7c-.5.3-.6.8-.3 1.3s.8.6 1.3.3l3.5-2-.9-.6-.9-.6m28.7-14.3 2.6-1.5c.5-.3.6-.8.3-1.3s-.8-.6-1.3-.3l-3.5 2c.3.2.6.3 1 .5zm-9 18.5 3.3 5.7c.3.5.8.6 1.3.3s.6-.8.3-1.3l-3.1-5.3c-.1 0-.3 0-.4.1-.5.2-1 .3-1.5.4M14.6 8.7 11.3 3c-.3-.5-.8-.6-1.3-.3s-.6.8-.3 1.3l3.1 5.3c.1 0 .3 0 .4-.1.5-.2 1-.3 1.5-.4m17.9 19.6 3.5 2c.5.3 1 .1 1.3-.3.3-.5.1-1-.3-1.3l-2.6-1.5-.9.6-.9.6M7.4 11.6l-3.5-2c-.5-.3-1-.1-1.3.3-.3.5-.1 1 .3 1.3l2.6 1.5.9-.6.9-.6m25.2 2.4c-.6-.4-1.3-.7-1.9-1.1-1.3-.7-2.7-1.3-4.3-1.8-.6-.2-1.3-.4-1.9-.5-1.1-.3-2.3-.4-3.4-.5h-2c-1.2 0-2.3.2-3.4.5-.6.1-1.3.3-1.9.5-1.5.5-2.9 1.1-4.3 1.8-.7.3-1.3.7-1.9 1.1C2.9 16.7 0 20 0 20s2.9 3.3 7.5 6.1c.6.4 1.3.7 1.9 1.1 1.3.7 2.7 1.3 4.3 1.8.6.2 1.3.4 1.9.5 1.1.3 2.3.4 3.4.5h2c1.2 0 2.3-.2 3.4-.5.6-.1 1.3-.3 1.9-.5 1.5-.5 2.9-1.1 4.3-1.8.7-.3 1.3-.7 1.9-1.1C37.1 23.3 40 20 40 20s-2.9-3.3-7.5-6.1M20 28c-4.4 0-8-3.6-8-8s3.6-8 8-8 8 3.6 8 8-3.6 8-8 8"/><path d="M25 20c0 2.8-2.2 5-5 5s-5-2.2-5-5 2.2-5 5-5 5 2.2 5 5"/></g></g></svg>
                    Culture
                  </a>
                </li>
                              <li>
                  <a class="group flex flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                    href="https://arstechnica.com/gaming/">
                    <svg class="mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="section-gaming_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="section-gaming_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#section-gaming_svg__a)"><g fill="none" clip-path="url(#section-gaming_svg__b)"><path fill="currentColor" d="M30.7 39.7c-.7-1.1-1.7-1.8-2.5-2.8-.9-1.2 0-2 .8-3 .6-.9 1-1.9.8-3-.6-2.7-3.4-3.3-5.8-3.6-.7-.1-1.8-.2-2.3-.7s-.5-1.4-.5-2.1v-.4l15.5-3.6c2.3-.5 3.7-2.8 3.2-5.1l-2.8-12C36.6 1.1 34.3-.3 32 .2L3.3 6.8C1 7.4-.4 9.7.1 12l2.8 12c.5 2.3 2.8 3.7 5.1 3.2l11.1-2.6c0 1 .2 2.1.7 2.9 1.7 2.7 6 .8 7.6 3.3.8 1.2-.5 2.3-1.1 3.3-.6.9-.9 2-.4 3 .4 1.1 1.4 1.8 2.2 2.6 0 .1.2.2.3.3h2.4c0-.1-.1-.2-.2-.3m.7-28.7c1.3-.3 2.7.5 3 1.9.3 1.3-.5 2.7-1.9 3-1.3.3-2.7-.5-3-1.9-.3-1.3.5-2.7 1.9-3m-6-3.7c1.3-.3 2.7.5 3 1.9.3 1.3-.5 2.7-1.9 3-1.3.3-2.7-.5-3-1.9-.3-1.3.5-2.7 1.9-3m-9.9 13.2-2.7.6-1-4.1-4.1 1-.6-2.7 4.1-1-1-4.1 2.7-.6 1 4.1 4.1-1 .6 2.7-4.1 1z"/></g></g></svg>
                    Gaming
                  </a>
                </li>
                              <li>
                  <a class="group flex flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                    href="https://arstechnica.com/health/">
                    <svg class="mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="section-health_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="section-health_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#section-health_svg__a)"><g fill="currentColor" clip-path="url(#section-health_svg__b)"><path d="M10.4 21.6c-.4-.4-1-.4-1.4 0l-3.9 3.9c-.4.4-.4 1 0 1.4s1 .4 1.4 0l3.9-3.9c.4-.4.4-1 0-1.4"/><path d="M40 10.6c0-2.7-1-5.4-3.1-7.5C33.8 0 29.2-.8 25.4.8c-1.3.5-2.5 1.3-3.5 2.3L3.1 21.9c-4.2 4.2-4.2 10.9 0 15C5.2 39 7.9 40 10.6 40s5.4-1 7.5-3.1l18.7-18.7c2.1-2.1 3.1-4.8 3.1-7.5m-6.6-4c-.4-.4-.4-1 0-1.4s1-.4 1.4 0c3 3 3 7.8 0 10.8L26 24.8c-.4.4-1 .4-1.4 0s-.4-1 0-1.4l8.7-8.7c2.2-2.2 2.2-5.8 0-8M10.6 38.1c-2.3 0-4.5-.9-6.1-2.5-3.4-3.4-3.4-8.8 0-12.2l7.6-7.6c.6 2.1 2.3 4.9 4.8 7.4s5.2 4.2 7.4 4.8l-7.6 7.6c-1.6 1.6-3.8 2.5-6.1 2.5"/></g></g></svg>
                    Health
                  </a>
                </li>
                              <li>
                  <a class="group flex flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                    href="https://arstechnica.com/tech-policy/">
                    <svg class="mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="section-tech-policy_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="section-tech-policy_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#section-tech-policy_svg__a)"><path fill="currentColor" d="M12.8 0 6.4 6.4 0 12.8l4 1.4L14.2 4z"/><g clip-path="url(#section-tech-policy_svg__b)"><path fill="currentColor" d="M34.8 31.7c-4.4-10.4-6.1-23.6-6.1-23.6L15.4 5.4l-9.9 10 2.7 13.3s13.2 1.6 23.6 6.1c-.4 1.4 0 2.9 1.1 4 1.4 1.4 3.6 1.6 5.2.6L18.5 19.8c-1.6 1-3.8.8-5.2-.6-1.6-1.6-1.6-4.3 0-5.9s4.3-1.6 5.9 0c1.4 1.4 1.6 3.6.6 5.2L39.3 38c1-1.6.8-3.8-.6-5.2-1.1-1.1-2.6-1.4-4-1.1"/></g></g></svg>
                    Policy
                  </a>
                </li>
                              <li>
                  <a class="group flex flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                    href="https://arstechnica.com/science/">
                    <svg class="mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="section-science_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="section-science_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#section-science_svg__a)"><g fill="none" clip-path="url(#section-science_svg__b)"><path fill="currentColor" d="M39.6 34.5 28 14.6V4h1.1c.5 0 .9-.4.9-.9V.9c0-.5-.4-.9-.9-.9H10.9c-.5 0-.9.4-.9.9V3c0 .5.4.9.9.9H12v10.6L.4 34.5C-.9 37 .8 40 3.6 40h32.8c2.7 0 4.5-3 3.2-5.5M21.9 13.2c1.7 0 3 1.3 3 3s-1.3 3-3 3-3-1.3-3-3 1.3-3 3-3m-5-6c1.1 0 2 .9 2 2s-.9 2-2 2-2-.9-2-2 .9-2 2-2M4.1 36l6-10.3c.2-.3.5-.5.8-.5H13c-.1-.3-.2-.6-.2-1 0-1.7 1.3-3 3-3s3 1.3 3 3 0 .7-.2 1h4.2c0-1.1.9-2 2-2s2 .9 2 2h2.1c.3 0 .6.2.8.5l6 10.3H4.2Z"/></g></g></svg>
                    Science
                  </a>
                </li>
                              <li>
                  <a class="group flex flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                    href="https://arstechnica.com/security/">
                    <svg class="mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="section-security_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="section-security_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#section-security_svg__a)"><g fill="none" clip-path="url(#section-security_svg__b)"><path fill="currentColor" d="M37.7 21.1C39.7 10.4 32.8 0 20.8 0h-1.6C7.2 0 .3 10.4 2.3 21.1c.5 2.6-2.3 3.5-2.3 6.6 0 3.2 3.5 4 5.9 4.1h2.8c1.3 0 1.8.5 1.8 1.6 0 1.5.2 4.1.3 5.6 0 .2.7.4 1.9.5v-3.4c0-.4.3-.8.7-.8s.8.3.8.8v3.5c.9 0 1.8.1 2.9.1v-3.6c0-.4.3-.8.8-.8s.8.3.8.8v3.7h2.9v-3.7c0-.4.3-.8.8-.8s.8.3.8.8v3.6c1 0 2 0 2.9-.1v-3.5c0-.4.3-.8.8-.8s.8.3.8.8v3.4c1.1-.1 1.8-.3 1.9-.5.1-1.5.3-4.1.3-5.6 0-1.1.5-1.7 1.8-1.6h2.8c2.4-.1 5.9-.9 5.9-4.1 0-3.1-2.8-4-2.3-6.7m-26.7 4.7c-4 0-6.6-4-4.9-7.2 1.1-2 3.1-3.2 5.2-3.7 4.1-.9 7.6 2.9 6.7 6.6-.7 2.7-3.5 3.9-7 4.2m8.6 2.1-1 3c-.2.5-.7.8-1.1.6s-.7-.8-.5-1.3l.9-3c.2-.5.7-.8 1.1-.6s.7.8.5 1.3m2.8 3.6c-.4.2-.9 0-1.1-.6l-1-3c-.2-.5 0-1.1.5-1.3.4-.2.9 0 1.1.6l.9 3c.2.5 0 1.1-.5 1.3m6.6-5.7c-3.5-.4-6.3-1.5-7-4.2-.9-3.7 2.6-7.6 6.7-6.6 2.1.5 4.1 1.7 5.2 3.7 1.8 3.2-.9 7.2-4.9 7.2"/></g></g></svg>
                    Security
                  </a>
                </li>
                              <li>
                  <a class="group flex flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                    href="https://arstechnica.com/space/">
                    <svg class="mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="section-space_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="section-space_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#section-space_svg__a)"><g fill="currentColor" clip-path="url(#section-space_svg__b)"><path d="M32.9 13.1c-2.5-4.7-7.5-7.8-13.2-7.8-8.3 0-15 6.7-15 15s3.1 10.6 7.7 13.1c3.1-2.5 6.9-5.8 11-10 3.9-3.9 7-7.4 9.4-10.3M14.4 34.3c1.6.6 3.4 1 5.2 1 8.3 0 15-6.7 15-15s-.3-3.5-.9-5.2c-2.5 3-5.5 6.4-8.9 9.7-3.6 3.6-7.2 6.9-10.4 9.5"/><path d="M28.5 5.8c.6.4 1.2.8 1.7 1.2 3.5-2.7 6.1-4.2 7.6-4.8-.5 1.4-2.1 4.1-4.8 7.6-2.6 3.4-6.2 7.5-10.9 12.3s-9.6 8.9-13 11.5c-3.2 2.4-5.5 3.7-6.9 4.2.5-1.3 1.9-3.7 4.2-6.9-.4-.5-.8-1.1-1.2-1.7-4 5.4-6 9.4-4.9 10.5s5.1-.9 10.5-4.9c3.8-2.9 8.2-6.8 12.7-11.3s7.9-8.4 10.7-12c4.4-5.7 6.7-10 5.5-11.2s-5.5 1.1-11.2 5.5"/></g></g></svg>
                    Space
                  </a>
                </li>
                              <li>
                  <a class="group flex flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                    href="https://arstechnica.com/gadgets/">
                    <svg class="mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="section-gadgets_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="section-gadgets_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#section-gadgets_svg__a)"><g fill="currentColor" clip-path="url(#section-gadgets_svg__b)"><path d="M38 22c1.1 0 2-.9 2-2s-.9-2-2-2h-2v-6h2c1.1 0 2-.9 2-2s-.9-2-2-2h-2V4h-4V2c0-1.1-.9-2-2-2s-2 .9-2 2v2h-6V2c0-1.1-.9-2-2-2s-2 .9-2 2v2h-6V2c0-1.1-.9-2-2-2S8 .9 8 2v2H4v4H2c-1.1 0-2 .9-2 2s.9 2 2 2h2v6H2c-1.1 0-2 .9-2 2s.9 2 2 2h2v6H2c-1.1 0-2 .9-2 2s.9 2 2 2h2v4h4v2c0 1.1.9 2 2 2s2-.9 2-2v-2h6v2c0 1.1.9 2 2 2s2-.9 2-2v-2h6v2c0 1.1.9 2 2 2s2-.9 2-2v-2h4v-4h2c1.1 0 2-.9 2-2s-.9-2-2-2h-2v-6zm-6 10H8V8h24z"/><path d="M24.7 17.3 20 12h-7.1c-.6 0-1 .4-1 1s.4 1 1 1h6.3l4.1 4.7L20 22h8v-8z"/><path d="m15.2 22.7 4.7 5.3H27c.6 0 1-.4 1-1s-.4-1-1-1h-6.3l-4.1-4.7 3.3-3.3h-8v8z"/></g></g></svg>
                    Tech
                  </a>
                </li>
                          </ul>

            
            <div class="mx-3 h-[1px] bg-gray-400"></div>

            
            <ul class="my-3 grid grid-cols-2 sm:grid-cols-1">
              <li>
                <a class="group flex flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                  href="/features/">
                  <svg class="mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 37.8"><defs><clipPath id="star_svg__a"><path fill="none" d="M0 0h40v37.8H0z"/></clipPath></defs><g fill="none" clip-path="url(#star_svg__a)"><path fill="currentColor" d="m20 0-6.2 12.4-13.8 2L10 24 7.6 37.8 20 31.3l12.4 6.5L30 24l10-9.6-13.8-2z"/></g></svg>
                  Feature
                </a>
              </li>
              <li>
                <a class="group flex flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                  href="/reviews/">
                  <svg class="mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="section-reviews_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="section-reviews_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#section-reviews_svg__a)"><g fill="currentColor" clip-path="url(#section-reviews_svg__b)"><path d="M19.3 9.4V16l4.7 4.7h6.6l4.7-4.7V9.4l-4.7-4.7H24zm10.8.5c1.6 1.6 1.6 4.1 0 5.7s-4.1 1.6-5.7 0-1.6-4.1 0-5.7 4.1-1.6 5.7 0"/><path d="M31.4 22.7h-8.3l-5.9-5.9V8.5L25.9 0H12L6.9 5.1V19L0 25.9C0 33.7 6.3 40 14.1 40l6.9-6.9h13.9L40 28V14.1z"/></g></g></svg>
                  Reviews
                </a>
              </li>
              <li>
                <a class="group flex flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                  href="/store/">
                  <svg class="mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="section-store_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="section-store_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#section-store_svg__a)"><g fill="none" clip-path="url(#section-store_svg__b)"><path fill="currentColor" d="M37.9 8.5h-9.4C28.5 3.8 24.7 0 20 0s-8.5 3.8-8.5 8.5H2.1L0 40h40zM20 2c3.6 0 6.5 2.9 6.5 6.5h-13C13.5 4.9 16.4 2 20 2m0 17c-4.7 0-8.5-3.8-8.5-8.5h2c0 3.6 2.9 6.5 6.5 6.5s6.5-2.9 6.5-6.5h2c0 4.7-3.8 8.5-8.5 8.5"/></g></g></svg>
                  Store
                </a>
              </li>
            </ul>
          </nav>
    </div>
  </div>
</div>
        

    
    <ul class="xxl:flex hidden gap-4 text-sm">
              <li>
          <a class="text-gray-250 hover:text-green-400 focus:text-green-400" href="https://arstechnica.com/ai/">
            AI
          </a>
        </li>
              <li>
          <a class="text-gray-250 hover:text-green-400 focus:text-green-400" href="https://arstechnica.com/information-technology/">
            Biz &amp; IT
          </a>
        </li>
              <li>
          <a class="text-gray-250 hover:text-green-400 focus:text-green-400" href="https://arstechnica.com/cars/">
            Cars
          </a>
        </li>
              <li>
          <a class="text-gray-250 hover:text-green-400 focus:text-green-400" href="https://arstechnica.com/culture/">
            Culture
          </a>
        </li>
              <li>
          <a class="text-gray-250 hover:text-green-400 focus:text-green-400" href="https://arstechnica.com/gaming/">
            Gaming
          </a>
        </li>
              <li>
          <a class="text-gray-250 hover:text-green-400 focus:text-green-400" href="https://arstechnica.com/health/">
            Health
          </a>
        </li>
              <li>
          <a class="text-gray-250 hover:text-green-400 focus:text-green-400" href="https://arstechnica.com/tech-policy/">
            Policy
          </a>
        </li>
              <li>
          <a class="text-gray-250 hover:text-green-400 focus:text-green-400" href="https://arstechnica.com/science/">
            Science
          </a>
        </li>
              <li>
          <a class="text-gray-250 hover:text-green-400 focus:text-green-400" href="https://arstechnica.com/security/">
            Security
          </a>
        </li>
              <li>
          <a class="text-gray-250 hover:text-green-400 focus:text-green-400" href="https://arstechnica.com/space/">
            Space
          </a>
        </li>
              <li>
          <a class="text-gray-250 hover:text-green-400 focus:text-green-400" href="https://arstechnica.com/gadgets/">
            Tech
          </a>
        </li>
          </ul>
    

    <a class="hidden text-green-400 sm:block xl:text-sm" href="/civis/">
      Forum
    </a>

          
      <div class="hidden h-5 w-[1px] bg-gray-400 lg:block"></div>

      <a class="hidden text-orange-400 lg:block xl:text-sm" href="/store/product/subscriptions/">
        Subscribe
      </a>
    
    
    <div class="h-5 w-[1px] bg-gray-400"></div>

    
          <div class="text-settings-dropdown-nav">
  <div x-data="{
      open: false,
      toggle() {
          if (this.open) {
              return this.close()
          }
          // If we're inside main header, add a data attribute to the header
          if (this.$el.closest('#site-header')) {
              this.$el.closest('#site-header').dataset.dropdownOpen = 'true';
          }
          this.open = true
      },
      close() {
          if (!this.open) {
              return;
          }
          // If we're inside main header, add a data attribute to the header
          if (this.$el.closest('#site-header')) {
              this.$el.closest('#site-header').dataset.dropdownOpen = 'false';
          }
          this.open = false
      }
  }" @keydown.escape.prevent.stop="close($refs.button)"
    @focusin.window="! $refs.panel.contains($event.target) && close()" x-id="['dropdown-button']">

    <!-- Button -->
    <button type="button" x-ref="button"
      x-on:click="
      toggle();
      $dispatch('dropdown-opened', { panel: $refs.panel });
      "
      :aria-expanded="open" :aria-controls="$id('dropdown-button')" :class="{ selected: open }"
      class="group flex items-center group" arial-label="" aria-label="Open text settings dropdown">
      <svg class="h-5 w-5 text-gray-300 group-hover:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="text-settings-open_svg__a"><path fill="none" stroke-width="0" d="M0 0h40v40H0z"/></clipPath><clipPath id="text-settings-open_svg__b"><path fill="none" stroke-width="0" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#text-settings-open_svg__a)"><g fill="currentColor" clip-path="url(#text-settings-open_svg__b)"><path d="M26.38 23.2c-.19.21-.28.49-.28.85v.58c0 .4.11.72.34.93.23.22.59.33 1.09.33.42 0 .88-.09 1.37-.27q.735-.27 1.47-.75c.06-.04.11-.09.17-.13v-1.87h-3.23q-.66.015-.93.33"/><path d="M32 0H8C3.58 0 0 3.58 0 8v24.01C0 36.42 3.58 40 8 40h24c4.42 0 8-3.58 8-8V8c0-4.42-3.58-8-8-8M17.88 28.23l-1.23-4.42h-5.77l-1.23 4.42H5.84l4.88-15.77a1.316 1.316 0 0 1 1.28-.97h3.52q.465 0 .81.27c.23.18.39.41.47.7l4.85 15.77h-3.79Zm16.28 0H31.3l-.38-1.92c-.27.33-.59.65-.98.96-.44.35-.95.64-1.53.89-.58.24-1.25.36-1.99.36s-1.38-.13-1.97-.39q-.87-.39-1.38-1.14c-.34-.5-.51-1.12-.51-1.87v-1.24c0-.95.32-1.7.97-2.23s1.54-.8 2.67-.8h4.34v-.56c0-.57-.13-.98-.4-1.24s-.77-.39-1.52-.39c-.61 0-1.38.02-2.3.06s-1.87.09-2.84.16l-.34-2.38c.58-.11 1.25-.21 2.02-.29q1.14-.12 2.28-.21t2.04-.09c1 0 1.85.13 2.55.4.69.27 1.22.72 1.59 1.36.36.64.55 1.52.55 2.63v7.91Z"/><path d="M14.26 15.09c-.06-.28-.12-.55-.17-.81h-.65c-.05.26-.1.53-.16.81s-.12.56-.21.84l-1.42 5.1h4.22l-1.42-5.1c-.07-.27-.13-.55-.19-.84"/></g></g></svg>
    </button>

    <!-- Panel -->
    <div x-cloak x-ref="panel" x-show="open" x-transition.origin.top.center x-on:click.outside="close()"
      :id="$id('dropdown-button')" class="absolute overflow-hidden z-50 bg-gray-550 absolute right-0 top-14 mt-[1px] min-w-[200px] rounded-sm md:top-10">
      <div class="text-settings">
      <div class="text-settings-menu bg-gray-550 w-60">
        <div class="flex items-center bg-gray-600 px-5 py-2">
          <span class="font-impact text-gray-350 text-base font-semibold uppercase">Story text</span>
        </div>

        <div class="grid grid-cols-3 items-center gap-3 px-5 py-2">
          <label class="font-impact w-20 text-base font-semibold uppercase text-gray-100" for="text-settings-size">Size</label>
<select name="text-settings-size" class="text-settings-size col-span-2 bg-gray-600 text-sm text-gray-300">
  <option value="small">Small</option>
  <option value="standard" selected>Standard</option>
  <option value="large">Large</option>
</select>


<label class="font-impact hidden w-20 text-base font-semibold uppercase text-gray-100 md:block"
  for="text-settings-width">Width
      <span class="text-gray-400">*</span>
  </label>
<select name="text-settings-width"
  class="text-settings-width col-span-2 hidden bg-gray-600 text-sm text-gray-300 md:block">
  <option value="standard" selected>Standard</option>
  <option value="wide">Wide</option>
</select>


<label class="font-impact w-20 text-base font-semibold uppercase text-gray-100" for="text-settings-links">Links</label>
<select name="text-settings-links" class="text-settings-links col-span-2 bg-gray-600 text-sm text-gray-300">
  <option value="standard" selected>Standard</option>
  <option value="orange">Orange</option>
</select>


  <div class="font-impact col-span-3 hidden text-sm font-semibold uppercase text-gray-400 md:block">
    <span class="mb-0 italic">* Subscribers only</span><br>
    &nbsp;&nbsp;<a href="/store/product/subscriptions/" class="text-green-400">Learn more</a>
  </div>

          
          <button
            class="font-impact text-settings-position col-span-3 mx-auto my-3 block rounded-sm border-2 border-green-400 px-3 py-1 text-base font-semibold uppercase text-gray-100"
            value="story">
            Pin to story
          </button>
        </div>
      </div>
    </div>
    </div>
  </div>
</div>
    
    
    <div class="">
  <div x-data="{
      open: false,
      toggle() {
          if (this.open) {
              return this.close()
          }
          // If we're inside main header, add a data attribute to the header
          if (this.$el.closest('#site-header')) {
              this.$el.closest('#site-header').dataset.dropdownOpen = 'true';
          }
          this.open = true
      },
      close() {
          if (!this.open) {
              return;
          }
          // If we're inside main header, add a data attribute to the header
          if (this.$el.closest('#site-header')) {
              this.$el.closest('#site-header').dataset.dropdownOpen = 'false';
          }
          this.open = false
      }
  }" @keydown.escape.prevent.stop="close($refs.button)"
    @focusin.window="! $refs.panel.contains($event.target) && close()" x-id="['dropdown-button']">

    <!-- Button -->
    <button type="button" x-ref="button"
      x-on:click="
      toggle();
      $dispatch('dropdown-opened', { panel: $refs.panel });
      "
      :aria-expanded="open" :aria-controls="$id('dropdown-button')" :class="{ selected: open }"
      class="group flex items-center theme-selection-active group" arial-label="" aria-label="Open Theme selection dropdown">
      <span class="sr-only">Theme</span>
        
        <svg class="theme-selection-active-dark hidden h-5 w-5 text-yellow-100 group-hover:text-yellow-200" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 38.4 38.4"><defs><clipPath id="theme-dark_svg__a"><path fill="none" d="M0 0h38.4v38.4H0z"/></clipPath><clipPath id="theme-dark_svg__b"><path fill="none" d="M0 0h38.4v38.4H0z"/></clipPath></defs><g clip-path="url(#theme-dark_svg__a)"><g fill="currentColor" clip-path="url(#theme-dark_svg__b)"><path d="M14.5 11.4c0-4.3 1.4-8.2 3.7-11.4C8.8 1.3 1.6 9.3 1.6 19.1s8.6 19.3 19.3 19.3 12.1-3.1 15.6-7.9c-.9.1-1.8.2-2.7.2-10.7 0-19.3-8.6-19.3-19.3m17.8-6.8v2.1c0 .8-.6 1.4-1.4 1.4s-1.4-.6-1.4-1.4V4.6c0-.8.6-1.4 1.4-1.4s1.4.6 1.4 1.4m0 6.8v2.1c0 .8-.6 1.4-1.4 1.4s-1.4-.6-1.4-1.4v-2.1c0-.8.6-1.4 1.4-1.4s1.4.6 1.4 1.4m-5.8-3.7h2.1c.8 0 1.4.6 1.4 1.4s-.6 1.4-1.4 1.4h-2.1c-.8 0-1.4-.6-1.4-1.4s.6-1.4 1.4-1.4m6.8 0h2.1c.8 0 1.4.6 1.4 1.4s-.6 1.4-1.4 1.4h-2.1c-.8 0-1.4-.6-1.4-1.4s.6-1.4 1.4-1.4"/></g></g></svg>
        <svg class="theme-selection-active-dusk hidden h-5 w-5 text-yellow-400 group-hover:text-yellow-200" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 38.18 40"><defs><clipPath id="theme-dusk_svg__a"><path fill="none" d="M0 0h38.18v40H0z"/></clipPath><clipPath id="theme-dusk_svg__b"><path fill="none" d="M0 0h38.18v40H0z"/></clipPath></defs><g clip-path="url(#theme-dusk_svg__a)"><g fill="currentColor" clip-path="url(#theme-dusk_svg__b)"><path d="M19.09 5.86C11.28 5.86 4.95 12.19 4.95 20s6.33 14.14 14.14 14.14S33.23 27.81 33.23 20 26.9 5.86 19.09 5.86m0 26.28C12.4 32.14 6.95 26.69 6.95 20c0-6.13 4.57-11.2 10.48-12.01a12.07 12.07 0 0 0-2.63 7.52c0 6.7 5.45 12.14 12.14 12.14.56 0 1.11-.05 1.66-.13-2.23 2.81-5.66 4.62-9.52 4.62m1.43-30.72v2.17c0 .78-.63 1.42-1.42 1.42s-1.42-.63-1.42-1.42V1.42a1.419 1.419 0 1 1 2.84 0M9.31 4.13l1.27 1.75c.46.63.32 1.52-.31 1.98s-1.52.32-1.98-.31L7.02 5.8a1.42 1.42 0 0 1 .31-1.98 1.42 1.42 0 0 1 1.98.31m-7.45 8.78 2.06.67c.74.24 1.15 1.04.91 1.79s-1.04 1.15-1.79.91l-2.06-.67a1.417 1.417 0 0 1-.91-1.78c.24-.74 1.04-1.15 1.79-.91M.98 24.39l2.06-.67c.74-.24 1.54.16 1.79.91.24.74-.17 1.54-.91 1.78l-2.06.67a1.42 1.42 0 0 1-1.79-.91c-.24-.74.17-1.54.91-1.79m6.04 9.82 1.27-1.75a1.42 1.42 0 0 1 1.98-.31c.63.46.77 1.35.31 1.98l-1.27 1.75c-.46.63-1.35.77-1.98.31a1.42 1.42 0 0 1-.31-1.98m10.65 4.38v-2.16c0-.78.63-1.42 1.42-1.42s1.42.63 1.42 1.42v2.16c0 .78-.63 1.42-1.42 1.42s-1.42-.63-1.42-1.42m11.2-2.71-1.27-1.75a1.42 1.42 0 0 1 .31-1.98 1.42 1.42 0 0 1 1.98.31l1.27 1.75c.46.63.32 1.52-.31 1.98s-1.52.32-1.98-.31m7.46-8.78-2.06-.67a1.424 1.424 0 0 1-.91-1.79c.24-.74 1.04-1.15 1.79-.91l2.06.67c.74.24 1.15 1.04.91 1.78s-1.04 1.15-1.79.91m.87-11.47-2.06.67c-.74.24-1.54-.17-1.79-.91-.24-.74.17-1.54.91-1.78l2.06-.67c.74-.24 1.54.16 1.79.91.24.74-.17 1.54-.91 1.79M31.16 5.8l-1.27 1.75c-.46.63-1.34.77-1.98.31a1.42 1.42 0 0 1-.31-1.98l1.27-1.75a1.42 1.42 0 0 1 1.98-.31c.63.46.77 1.35.31 1.98"/></g></g></svg>
        <svg class="theme-selection-active-light hidden h-5 w-5 text-yellow-400 group-hover:text-yellow-200" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="theme-light_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="theme-light_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#theme-light_svg__a)"><g fill="currentColor" clip-path="url(#theme-light_svg__b)"><path d="M30 20c0 5.5-4.5 10-10 10s-10-4.5-10-10 4.5-10 10-10 10 4.5 10 10m8.6 1.4h-2.2c-.8 0-1.4-.6-1.4-1.4s.6-1.4 1.4-1.4h2.2c.8 0 1.4.6 1.4 1.4s-.6 1.4-1.4 1.4M34.1 7.9l-1.5 1.5c-.6.6-1.5.6-2 0-.6-.6-.6-1.5 0-2l1.5-1.5c.6-.6 1.5-.6 2 0 .6.6.6 1.5 0 2M21.4 1.4v2.2c0 .8-.6 1.4-1.4 1.4s-1.4-.6-1.4-1.4V1.4c0-.8.6-1.4 1.4-1.4s1.4.6 1.4 1.4M7.9 5.9l1.5 1.5c.6.6.6 1.5 0 2-.6.6-1.5.6-2 0L5.9 7.9c-.6-.6-.6-1.5 0-2 .6-.6 1.5-.6 2 0M1.4 18.6h2.2c.8 0 1.4.6 1.4 1.4s-.6 1.4-1.4 1.4H1.4C.6 21.4 0 20.8 0 20s.6-1.4 1.4-1.4m4.5 13.5 1.5-1.5c.6-.6 1.4-.6 2 0s.6 1.5 0 2l-1.5 1.5c-.6.6-1.5.6-2 0-.6-.6-.6-1.5 0-2m12.7 6.5v-2.2c0-.8.6-1.4 1.4-1.4s1.4.6 1.4 1.4v2.2c0 .8-.6 1.4-1.4 1.4s-1.4-.6-1.4-1.4m13.5-4.5-1.5-1.5c-.6-.6-.6-1.4 0-2s1.5-.6 2 0l1.5 1.5c.6.6.6 1.5 0 2-.6.6-1.5.6-2 0"/></g></g></svg>
    </button>

    <!-- Panel -->
    <div x-cloak x-ref="panel" x-show="open" x-transition.origin.top.center x-on:click.outside="close()"
      :id="$id('dropdown-button')" class="absolute overflow-hidden z-50 bg-gray-550 absolute right-0 top-14 mt-[1px] min-w-[200px] rounded-sm py-3 md:top-10">
      <nav>
          <ul class="theme-selection-dropdown">
                          <li
                class="theme-selection-item group flex w-full cursor-pointer flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                data-theme="light"
                data-selected="false">
                <svg class="theme-selection-icon mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-inherit" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="theme-light_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="theme-light_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#theme-light_svg__a)"><g fill="currentColor" clip-path="url(#theme-light_svg__b)"><path d="M30 20c0 5.5-4.5 10-10 10s-10-4.5-10-10 4.5-10 10-10 10 4.5 10 10m8.6 1.4h-2.2c-.8 0-1.4-.6-1.4-1.4s.6-1.4 1.4-1.4h2.2c.8 0 1.4.6 1.4 1.4s-.6 1.4-1.4 1.4M34.1 7.9l-1.5 1.5c-.6.6-1.5.6-2 0-.6-.6-.6-1.5 0-2l1.5-1.5c.6-.6 1.5-.6 2 0 .6.6.6 1.5 0 2M21.4 1.4v2.2c0 .8-.6 1.4-1.4 1.4s-1.4-.6-1.4-1.4V1.4c0-.8.6-1.4 1.4-1.4s1.4.6 1.4 1.4M7.9 5.9l1.5 1.5c.6.6.6 1.5 0 2-.6.6-1.5.6-2 0L5.9 7.9c-.6-.6-.6-1.5 0-2 .6-.6 1.5-.6 2 0M1.4 18.6h2.2c.8 0 1.4.6 1.4 1.4s-.6 1.4-1.4 1.4H1.4C.6 21.4 0 20.8 0 20s.6-1.4 1.4-1.4m4.5 13.5 1.5-1.5c.6-.6 1.4-.6 2 0s.6 1.5 0 2l-1.5 1.5c-.6.6-1.5.6-2 0-.6-.6-.6-1.5 0-2m12.7 6.5v-2.2c0-.8.6-1.4 1.4-1.4s1.4.6 1.4 1.4v2.2c0 .8-.6 1.4-1.4 1.4s-1.4-.6-1.4-1.4m13.5-4.5-1.5-1.5c-.6-.6-.6-1.4 0-2s1.5-.6 2 0l1.5 1.5c.6.6.6 1.5 0 2-.6.6-1.5.6-2 0"/></g></g></svg>
                HyperLight
              </li>
                          <li
                class="theme-selection-item group flex w-full cursor-pointer flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                data-theme="dusk"
                data-selected="false">
                <svg class="theme-selection-icon mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-inherit" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 38.18 40"><defs><clipPath id="theme-dusk_svg__a"><path fill="none" d="M0 0h38.18v40H0z"/></clipPath><clipPath id="theme-dusk_svg__b"><path fill="none" d="M0 0h38.18v40H0z"/></clipPath></defs><g clip-path="url(#theme-dusk_svg__a)"><g fill="currentColor" clip-path="url(#theme-dusk_svg__b)"><path d="M19.09 5.86C11.28 5.86 4.95 12.19 4.95 20s6.33 14.14 14.14 14.14S33.23 27.81 33.23 20 26.9 5.86 19.09 5.86m0 26.28C12.4 32.14 6.95 26.69 6.95 20c0-6.13 4.57-11.2 10.48-12.01a12.07 12.07 0 0 0-2.63 7.52c0 6.7 5.45 12.14 12.14 12.14.56 0 1.11-.05 1.66-.13-2.23 2.81-5.66 4.62-9.52 4.62m1.43-30.72v2.17c0 .78-.63 1.42-1.42 1.42s-1.42-.63-1.42-1.42V1.42a1.419 1.419 0 1 1 2.84 0M9.31 4.13l1.27 1.75c.46.63.32 1.52-.31 1.98s-1.52.32-1.98-.31L7.02 5.8a1.42 1.42 0 0 1 .31-1.98 1.42 1.42 0 0 1 1.98.31m-7.45 8.78 2.06.67c.74.24 1.15 1.04.91 1.79s-1.04 1.15-1.79.91l-2.06-.67a1.417 1.417 0 0 1-.91-1.78c.24-.74 1.04-1.15 1.79-.91M.98 24.39l2.06-.67c.74-.24 1.54.16 1.79.91.24.74-.17 1.54-.91 1.78l-2.06.67a1.42 1.42 0 0 1-1.79-.91c-.24-.74.17-1.54.91-1.79m6.04 9.82 1.27-1.75a1.42 1.42 0 0 1 1.98-.31c.63.46.77 1.35.31 1.98l-1.27 1.75c-.46.63-1.35.77-1.98.31a1.42 1.42 0 0 1-.31-1.98m10.65 4.38v-2.16c0-.78.63-1.42 1.42-1.42s1.42.63 1.42 1.42v2.16c0 .78-.63 1.42-1.42 1.42s-1.42-.63-1.42-1.42m11.2-2.71-1.27-1.75a1.42 1.42 0 0 1 .31-1.98 1.42 1.42 0 0 1 1.98.31l1.27 1.75c.46.63.32 1.52-.31 1.98s-1.52.32-1.98-.31m7.46-8.78-2.06-.67a1.424 1.424 0 0 1-.91-1.79c.24-.74 1.04-1.15 1.79-.91l2.06.67c.74.24 1.15 1.04.91 1.78s-1.04 1.15-1.79.91m.87-11.47-2.06.67c-.74.24-1.54-.17-1.79-.91-.24-.74.17-1.54.91-1.78l2.06-.67c.74-.24 1.54.16 1.79.91.24.74-.17 1.54-.91 1.79M31.16 5.8l-1.27 1.75c-.46.63-1.34.77-1.98.31a1.42 1.42 0 0 1-.31-1.98l1.27-1.75a1.42 1.42 0 0 1 1.98-.31c.63.46.77 1.35.31 1.98"/></g></g></svg>
                Day & Night
              </li>
                          <li
                class="theme-selection-item group flex w-full cursor-pointer flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                data-theme="dark"
                data-selected="false">
                <svg class="theme-selection-icon mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-inherit" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 38.4 38.4"><defs><clipPath id="theme-dark_svg__a"><path fill="none" d="M0 0h38.4v38.4H0z"/></clipPath><clipPath id="theme-dark_svg__b"><path fill="none" d="M0 0h38.4v38.4H0z"/></clipPath></defs><g clip-path="url(#theme-dark_svg__a)"><g fill="currentColor" clip-path="url(#theme-dark_svg__b)"><path d="M14.5 11.4c0-4.3 1.4-8.2 3.7-11.4C8.8 1.3 1.6 9.3 1.6 19.1s8.6 19.3 19.3 19.3 12.1-3.1 15.6-7.9c-.9.1-1.8.2-2.7.2-10.7 0-19.3-8.6-19.3-19.3m17.8-6.8v2.1c0 .8-.6 1.4-1.4 1.4s-1.4-.6-1.4-1.4V4.6c0-.8.6-1.4 1.4-1.4s1.4.6 1.4 1.4m0 6.8v2.1c0 .8-.6 1.4-1.4 1.4s-1.4-.6-1.4-1.4v-2.1c0-.8.6-1.4 1.4-1.4s1.4.6 1.4 1.4m-5.8-3.7h2.1c.8 0 1.4.6 1.4 1.4s-.6 1.4-1.4 1.4h-2.1c-.8 0-1.4-.6-1.4-1.4s.6-1.4 1.4-1.4m6.8 0h2.1c.8 0 1.4.6 1.4 1.4s-.6 1.4-1.4 1.4h-2.1c-.8 0-1.4-.6-1.4-1.4s.6-1.4 1.4-1.4"/></g></g></svg>
                Dark
              </li>
                          <li
                class="theme-selection-item group flex w-full cursor-pointer flex-row items-center px-5 py-2 text-gray-300 hover:bg-gray-700 hover:text-green-400 focus:bg-gray-700 focus:text-green-400"
                data-theme="system"
                data-selected="true">
                <svg class="theme-selection-icon mr-2 inline-block h-5 w-5 text-gray-100 group-hover:text-green-400 group-focus:text-inherit" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="theme-system_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="theme-system_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#theme-system_svg__a)"><g clip-path="url(#theme-system_svg__b)"><path fill="currentColor" d="M20 0C8.95 0 0 8.95 0 20s8.95 20 20 20 20-8.95 20-20S31.05 0 20 0m0 38V2c9.92 0 18 8.08 18 18s-8.08 18-18 18"/></g></g></svg>
                System
              </li>
                      </ul>
        </nav>
    </div>
  </div>
</div>
    

    
    <div class="hidden sm:flex md:justify-center" data-modal-id="search" x-data="{
    open: false,
    init() {
        this.modalId = this.$el.dataset.modalId;
    },
    show() {
        console.log(this.data);
        this.open = true;
        this.$dispatch('modal-opened', {
            panel: this.$refs.panel,
            modalId: this.modalId,
        });
    },
    hide() {
        this.open = false
    },
}">
  
  <button type="button" aria-label="Search dialog..." class="search-button flex flex-row items-center text-gray-300 hover:text-gray-100" aria-label="Open search dialog" x-on:click="show()">
    <svg class="h-5 w-5" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="magnify_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="magnify_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#magnify_svg__a)"><g fill="none" clip-path="url(#magnify_svg__b)"><path fill="currentColor" d="M39.2 35.4 29 25.2c4.4-6.2 3.9-15-1.7-20.6C24.2 1.6 20.1 0 16 0S7.8 1.6 4.7 4.7c-6.2 6.2-6.2 16.4 0 22.6C7.8 30.4 11.9 32 16 32s6.5-1 9.3-3l10.2 10.2c.5.5 1.2.8 1.9.8s1.4-.3 1.9-.8c1-1 1-2.7 0-3.8M8.5 23.5c-2-2-3.1-4.7-3.1-7.5s1.1-5.5 3.1-7.5 4.7-3.1 7.5-3.1 5.5 1.1 7.5 3.1c4.2 4.2 4.2 10.9 0 15.1-2 2-4.7 3.1-7.5 3.1s-5.5-1.1-7.5-3.1"/></g></g></svg>
  </button>

  
  <template x-teleport="body">
    <div class="fixed inset-0 z-[99999] overflow-y-auto" role="dialog" aria-modal="true" x-cloak x-show="open"
      x-on:keydown.escape.window.prevent.stop="open = false" x-id="['modal-title']" x-ref="panel"
      :aria-labelledby="$id('modal-title')">

      
      <div class="fixed inset-0 bg-slate-900/80 opacity-100 backdrop-blur" x-show="open" x-transition.duration.150ms>
      </div>

      
      <div class="relative flex min-h-screen items-center justify-center" x-on:click="open = false" x-show="open"
        x-transition.duration.150ms>
        <div  x-on:click.stop x-trap.noscroll.inert="open">
          
          <span class="sr-only" :id="$id('modal-title')">
            Search dialog...
          </span>

          
          <div class="search-wrapper relative z-[99999] w-screen p-5">
          <div class="gcse-search"></div>
        </div>
        </div>
      </div>
    </div>
  </template>
</div>
    

    
    

    
    <div class="h-5 w-[1px] bg-gray-400"></div>

    
          
      <div class="flex md:justify-center" data-modal-id="sign-in" x-data="{
    open: false,
    init() {
        this.modalId = this.$el.dataset.modalId;
    },
    show() {
        console.log(this.data);
        this.open = true;
        this.$dispatch('modal-opened', {
            panel: this.$refs.panel,
            modalId: this.modalId,
        });
    },
    hide() {
        this.open = false
    },
}">
  
  <button type="button" aria-label="Sign in dialog..." class="whitespace-nowrap text-gray-300 hover:text-gray-100" aria-label="Open sign in dialog" x-on:click="show()">
    Sign In
  </button>

  
  <template x-teleport="body">
    <div class="fixed inset-0 z-[99999] overflow-y-auto" role="dialog" aria-modal="true" x-cloak x-show="open"
      x-on:keydown.escape.window.prevent.stop="open = false" x-id="['modal-title']" x-ref="panel"
      :aria-labelledby="$id('modal-title')">

      
      <div class="fixed inset-0 bg-slate-900/80 opacity-100 backdrop-blur" x-show="open" x-transition.duration.150ms>
      </div>

      
      <div class="relative flex min-h-screen items-center justify-center" x-on:click="open = false" x-show="open"
        x-transition.duration.150ms>
        <div  x-on:click.stop x-trap.noscroll.inert="open">
          
          <span class="sr-only" :id="$id('modal-title')">
            Sign in dialog...
          </span>

          
          <div
  class="sign-in-panel absolute left-1/2 top-1/2 w-3/4 min-w-[320px] max-w-xl -translate-x-1/2 -translate-y-1/2"
>
  
  <header
    class="font-impact flex items-center justify-between bg-gray-600 px-7 py-4 font-semibold uppercase"
  >
    <div class="text-gray-350 flex items-center gap-3">
      <svg class="h-3 w-3 text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="arrow-blocks-right_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g fill="currentColor" clip-path="url(#arrow-blocks-right_svg__a)"><path d="M32 16h8v8h-8zm-8 8h8v8h-8zm-8 8h8v8h-8zm8-24h8v8h-8zm-8-8h8v8h-8zM0 16h16v8H0z"/></g></svg>
      Sign in
    </div>
    <button
      class="text-gray-300 hover:text-gray-100 focus:text-gray-100"
      x-on:click="open = false"
    >
      <svg class="h-3 w-3" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 34.7 40"><defs><clipPath id="x_svg__a"><path fill="none" d="M0 0h34.7v40H0z"/></clipPath></defs><g fill="none" clip-path="url(#x_svg__a)"><path fill="currentColor" d="m26.4 0-8.5 16.9h-1.1L8.3 0H.8l10.1 19.4L0 40h7.6l9.2-18.3h1.1L27.1 40h7.6L23.8 19.4 33.9 0z"/></g></svg>
    </button>
  </header>

  
  <div class="sign-in-panel-body bg-gray-700 px-7 py-4">

    
    <div
      class="col-span-3 normal-case text-gray-300"
      x-data="{ html: '', form: '', triggered: false }"
      x-on:modal-opened.window="
        panel = $el.parentElement.parentElement.parentElement.parentElement.parentElement;
        if (triggered || panel !== event.detail.panel) {
          return;
        }
        triggered = true;
        html = await (await fetch('/civis/login')).text();
        // Parse html for form with action=/civis/login/login
        parser = new DOMParser();
        doc = parser.parseFromString(html, 'text/html');
        form = doc.querySelector('form[action=&quot;/civis/login/login&quot;]');
        // Remove autofocus and set focus to username field
        username = form.querySelector('input[name=&quot;login&quot;]');
        username.removeAttribute('autofocus');
        document.querySelector('.sign-in-form').appendChild(form);
        username.focus();
      "
    >
      <div class="sign-in-form"></div>
    </div>
  </div>
  
</div>
        </div>
      </div>
    </div>
  </template>
</div>
        
  </div>
</header>

<main class="main relative -mt-4 lg:mt-6" id="main">
            <article class="double-column h-entry post-2067918 post type-post status-publish format-standard has-post-thumbnail hentry category-ai category-features tag-ai tag-anthropic tag-context-windows tag-google-deepmind tag-llms tag-openai" data-id="2067918">
  
  <header>
  <div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7">
  <div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0">
    <div class="">
      <div class="mb-1 px-[15px] sm:px-5 md:px-0">
        <div
  class="upper-deck font-impact text-green-450 dusk:text-green-400 inline-flex flex-row flex-nowrap items-center gap-2 text-left text-sm font-semibold uppercase leading-tight dark:text-green-400">
  <span class="upper-deck__icon">
    <svg class="h-5 w-5" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="section-ai_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="section-ai_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#section-ai_svg__a)"><g fill="currentColor" clip-path="url(#section-ai_svg__b)"><path d="M20 2.4c9.7 0 17.6 7.9 17.6 17.6S29.7 37.6 20 37.6 2.4 29.7 2.4 20 10.3 2.4 20 2.4M20 0C9 0 0 9 0 20s9 20 20 20 20-9 20-20S31 0 20 0"/><path d="M20 13q2.85 0 5.4.9c.7.2 1.4-.1 1.6-.9l1.4-5.5C26 5.9 23.1 4.9 20 4.9s-6 .9-8.4 2.6L13 13c.2.7.9 1.1 1.6.9Q17 13 20 13M8.9 18.3c.4-.8 1-1.5 1.7-2.1l-2.2-5.7C7 12.2 6 14.1 5.5 16.3l1.3 2.1c.5.8 1.7.8 2.2 0m24.3 0 1.3-2.1c-.5-2.2-1.5-4.1-2.9-5.8l-2.2 5.7c.7.6 1.3 1.3 1.7 2.1.5.8 1.6.9 2.2 0M23.2 20c0 1.8-1.5 3.2-3.2 3.2s-3.2-1.4-3.2-3.2 1.5-3.2 3.2-3.2 3.2 1.4 3.2 3.2"/></g></g></svg>
  </span>
  <span class="upper-deck__text">
    Scaling problems
  </span>
</div>
      </div>

      <h1
        class="dusk:text-gray-100 mb-3 px-[15px] font-serif text-3xl font-semibold leading-none text-gray-700 dark:text-gray-100 sm:px-5 md:px-0 md:text-4xl lg:text-5xl">
        Why AI language models choke on too much text
      </h1>

      <p
        class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0">
        Compute costs scale with the square of the input size. That's not great.
      </p>

      <div class="mt-2 px-[15px] sm:px-5 md:px-0">
        <div class="font-impact text-xs font-semibold uppercase text-gray-300"><a class="text-orange-400 hover:text-orange-500" href="https://arstechnica.com/author/timlee/">
    Timothy B. Lee
  </a>
–
<span class="whitespace-nowrap">
  <time class="mr-[2px] inline-block cursor-default" title="2024-12-20T08:00:56-05:00" datetime="2024-12-20T08:00:56-05:00"
    x-data="{
        compact: false,
        open: false,
        date: new Date('2024-12-20T08:00:56-05:00'),
        updatedTimestamp: false,
        format: function() {
            let dateFormat = {
                year: 'numeric',
                month: 'short',
                day: 'numeric'
            };
    
            let timeFormat = {
                hour: 'numeric',
                minute: 'numeric'
            };
    
            let formatted =
                this.date.toLocaleDateString(undefined, dateFormat) +
                ' ' +
                this.date.toLocaleTimeString(undefined, timeFormat);
    
            if (this.compact) {
                if (this.date.toDateString() === new Date().toDateString()) {
                    formatted = this.date.toLocaleTimeString(undefined, timeFormat);
                    if (this.updatedTimestamp) {
                        formatted = 'at ' + formatted;
                    }
                } else {
                    formatted = this.date.toLocaleDateString(undefined, {
                        year: 'numeric',
                        month: 'numeric',
                        day: 'numeric'
                    });
                }
            }
    
            if (this.updatedTimestamp) {
                formatted = 'Updated ' + formatted;
            }
    
            return formatted;
        }
    }" x-text="format()">
    Dec 20, 2024 8:00 am
  </time>
  <span class="text-gray-550">|</span> <a class="view-comments text-gray-300 hover:text-gray-500"
    href="https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/#comments" title="107 comments">
    <svg class="-mt-1 ml-1 mr-[2px] inline-block h-4 w-4" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"/></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"/></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"/><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"/></g></g></svg>
    107
  </a>
</span></div>
      </div>
    </div>

    <div class="min-h-1 mt-4 lg:mt-0">
              <div class="relative aspect-video overflow-hidden">
                      <div class="ars-lightbox">
              <div class="ars-lightbox-item">
                <a class="cursor-zoom-in" data-pswp-width="2560"
                  data-pswp-height="1440" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup.jpg 2560w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-2048x1152.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1440x810.jpg 1440w"
                  data-cropped="true" href="https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup.jpg" target="_blank">
                  <img width="640" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-640x360.jpg" class="absolute inset-0 w-full h-full object-cover hidden" alt="" loading="eager" decoding="async" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-2048x1152.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1440x810.jpg 1440w" sizes="(max-width: 640px) 100vw, 640px" />
                  <img width="1152" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1152x648.jpg" class="intro-image absolute min-w-full min-h-full h-auto object-cover" alt="" loading="eager" decoding="async" fetchpriority="high" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-2048x1152.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/12/LLM-soup-1440x810.jpg 1440w" sizes="(max-width: 1152px) 100vw, 1152px" />
                </a>
                <div class="pswp-caption-content" id="caption-2067981">
                  <div
    class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300">
    <div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"></div>
    <div class="caption-content">
      

              <span class="caption-credit mt-2 text-xs">
          Credit:

          
          Aurich Lawson | Getty Images

                  </span>
          </div>
  </div>
                </div>
              </div>
            </div>
          
        </div>
        <div class="px-[15px] sm:px-5 md:px-0"><div
    class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300">
    <div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"></div>
    <div class="caption-content">
      

              <span class="caption-credit mt-2 text-xs">
          Credit:

          
          Aurich Lawson | Getty Images

                  </span>
          </div>
  </div></div>
          </div>
  </div>
</div>
</header>
<div class="text-settings-dropdown-story mdl:absolute mdl:z-10 mdl:mb-0 mdl:mt-1 relative -mt-4 mb-2">
  <div x-data="{
      open: false,
      toggle() {
          if (this.open) {
              return this.close()
          }
          // If we're inside main header, add a data attribute to the header
          if (this.$el.closest('#site-header')) {
              this.$el.closest('#site-header').dataset.dropdownOpen = 'true';
          }
          this.open = true
      },
      close() {
          if (!this.open) {
              return;
          }
          // If we're inside main header, add a data attribute to the header
          if (this.$el.closest('#site-header')) {
              this.$el.closest('#site-header').dataset.dropdownOpen = 'false';
          }
          this.open = false
      }
  }" @keydown.escape.prevent.stop="close($refs.button)"
    @focusin.window="! $refs.panel.contains($event.target) && close()" x-id="['dropdown-button']">

    <!-- Button -->
    <button type="button" x-ref="button"
      x-on:click="
      toggle();
      $dispatch('dropdown-opened', { panel: $refs.panel });
      "
      :aria-expanded="open" :aria-controls="$id('dropdown-button')" :class="{ selected: open }"
      class="group flex items-center bg-gray-150 dark:bg-gray-550 mdl:flex-col mdl:bg-transparent mdl:p-0 mdl:dark:bg-transparent flex w-full items-center justify-between px-[15px] py-2.5 sm:px-5 lg:px-8" arial-label="" aria-label="Open text settings dropdown">
      <div class="flex items-center gap-2">
      <svg class="dark:text-gray-250 mdl:h-7 mdl:w-7 h-5 w-5 text-gray-300 group-hover:text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 43 43"><defs><clipPath id="text-settings_svg__a"><path fill="none" stroke-width="0" d="M0 0h43v43H0z"/></clipPath><clipPath id="text-settings_svg__b"><path fill="none" stroke-width="0" d="M0 0h43v43H0z"/></clipPath></defs><g clip-path="url(#text-settings_svg__a)"><g fill="currentColor" clip-path="url(#text-settings_svg__b)"><path d="M33.52 17.82c-.69-.27-1.55-.4-2.55-.4-.6 0-1.28.03-2.04.08-.76.06-1.52.12-2.28.21-.76.08-1.43.18-2.01.29l.34 2.38c.97-.06 1.92-.12 2.84-.16q1.38-.06 2.31-.06c.74 0 1.25.13 1.52.39s.4.67.4 1.24v.56h-4.34c-1.13 0-2.02.27-2.67.8s-.97 1.28-.97 2.23v1.24c0 .75.17 1.37.51 1.87q.51.75 1.38 1.14c.58.26 1.24.39 1.97.39s1.41-.12 1.99-.36a6.34 6.34 0 0 0 2.51-1.85l.38 1.92h2.86v-7.91c0-1.12-.18-1.99-.55-2.63a3 3 0 0 0-1.59-1.36m-1.49 8.42c-.06.04-.11.09-.17.13q-.735.48-1.47.75c-.49.18-.95.27-1.37.27-.5 0-.87-.11-1.09-.33-.23-.22-.34-.53-.34-.93v-.58c0-.36.09-.64.28-.85s.5-.31.94-.31l3.23-.02v1.87Zm-14.2-13q-.36-.27-.81-.27h-3.52q-.465 0-.81.27c-.23.18-.39.41-.47.7L7.35 29.72h3.81l1.23-4.42h5.77l1.23 4.42h3.79l-4.85-15.77a1.3 1.3 0 0 0-.47-.7m-4.71 9.27 1.42-5.1q.12-.405.21-.84c.06-.28.11-.55.16-.81h.65c.05.26.1.53.17.81s.13.56.19.84l1.42 5.1z"/><path d="M33.5 4.5c2.76 0 5 2.24 5 5v24.01c0 2.76-2.24 5-5 5h-24c-2.76 0-5-2.24-5-5V9.5c0-2.76 2.24-5 5-5zm0-3h-24c-4.42 0-8 3.58-8 8v24.01c0 4.42 3.58 8 8 8h24c4.42 0 8-3.58 8-8V9.5c0-4.42-3.58-8-8-8"/></g></g></svg>
      <span
        class="font-impact settings-text dark:text-gray-250 mdl:hidden text-xs font-semibold uppercase text-gray-300">Text
        settings</span>
    </div>
    <span class="settings-icon">
      <svg class="dark:text-gray-250 mdl:hidden h-4 w-4 text-gray-300" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 39.8 40"><defs><clipPath id="settings_svg__a"><path fill="none" d="M0 0h39.8v40H0z"/></clipPath><clipPath id="settings_svg__b"><path fill="none" d="M0 0h39.8v40H0z"/></clipPath></defs><g clip-path="url(#settings_svg__a)"><g fill="currentColor" clip-path="url(#settings_svg__b)"><path d="M17.4 3c-.8-1.8-2.5-3-4.5-3S9.1 1.2 8.3 3H0v4h8.3c.8 1.8 2.5 3 4.6 3s3.8-1.2 4.6-3h22.4V3H17.5Zm-4.6 4.5c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5M27 15c-2 0-3.8 1.2-4.6 3H0v4h22.4c.8 1.8 2.5 3 4.6 3s3.8-1.2 4.6-3h8.3v-4h-8.3c-.8-1.8-2.5-3-4.6-3m0 7.5c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5M12.9 30c-2 0-3.8 1.2-4.6 3H0v4h8.3c.8 1.8 2.5 3 4.6 3s3.8-1.2 4.6-3h22.4v-4H17.5c-.8-1.8-2.5-3-4.6-3m0 7.5c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5"/></g></g></svg>
      <svg class="dark:text-gray-250 mdl:block mt-[3px] hidden h-auto w-5 text-gray-300" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 25.17"><defs><clipPath id="settings-compact_svg__a"><path fill="none" stroke-width="0" d="M0 0h40v25.17H0z"/></clipPath><clipPath id="settings-compact_svg__b"><path fill="none" stroke-width="0" d="M0 0h40v25.17H0z"/></clipPath></defs><g clip-path="url(#settings-compact_svg__a)"><g fill="currentColor" clip-path="url(#settings-compact_svg__b)"><path d="M27.09.09c-2.05 0-3.81 1.24-4.58 3H0v4h22.51c.77 1.76 2.53 3 4.58 3s3.81-1.24 4.58-3H40v-4h-8.33c-.77-1.76-2.53-3-4.58-3m0 7.5a2.5 2.5 0 0 1 0-5 2.5 2.5 0 0 1 0 5m-14.18 7.58c-2.05 0-3.81 1.24-4.58 3H0v4h8.34c.77 1.76 2.53 3 4.58 3s3.81-1.24 4.58-3h22.51v-4H17.5c-.77-1.76-2.53-3-4.58-3m-.01 7.5a2.5 2.5 0 0 1 0-5 2.5 2.5 0 0 1 0 5"/></g></g></svg>
    </span>
    </button>

    <!-- Panel -->
    <div x-cloak x-ref="panel" x-show="open" x-transition.origin.top.center x-on:click.outside="close()"
      :id="$id('dropdown-button')" class="absolute overflow-hidden z-50 bg-gray-550 absolute left-0 top-0">
      <div class="text-settings">
      <div class="text-settings-menu bg-gray-550 w-60">
        <div class="flex items-center justify-between bg-gray-600 px-5 py-2">
          <div class="flex items-center gap-2">
            <svg class="h-5 w-5 text-green-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="text-settings-open_svg__a"><path fill="none" stroke-width="0" d="M0 0h40v40H0z"/></clipPath><clipPath id="text-settings-open_svg__b"><path fill="none" stroke-width="0" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#text-settings-open_svg__a)"><g fill="currentColor" clip-path="url(#text-settings-open_svg__b)"><path d="M26.38 23.2c-.19.21-.28.49-.28.85v.58c0 .4.11.72.34.93.23.22.59.33 1.09.33.42 0 .88-.09 1.37-.27q.735-.27 1.47-.75c.06-.04.11-.09.17-.13v-1.87h-3.23q-.66.015-.93.33"/><path d="M32 0H8C3.58 0 0 3.58 0 8v24.01C0 36.42 3.58 40 8 40h24c4.42 0 8-3.58 8-8V8c0-4.42-3.58-8-8-8M17.88 28.23l-1.23-4.42h-5.77l-1.23 4.42H5.84l4.88-15.77a1.316 1.316 0 0 1 1.28-.97h3.52q.465 0 .81.27c.23.18.39.41.47.7l4.85 15.77h-3.79Zm16.28 0H31.3l-.38-1.92c-.27.33-.59.65-.98.96-.44.35-.95.64-1.53.89-.58.24-1.25.36-1.99.36s-1.38-.13-1.97-.39q-.87-.39-1.38-1.14c-.34-.5-.51-1.12-.51-1.87v-1.24c0-.95.32-1.7.97-2.23s1.54-.8 2.67-.8h4.34v-.56c0-.57-.13-.98-.4-1.24s-.77-.39-1.52-.39c-.61 0-1.38.02-2.3.06s-1.87.09-2.84.16l-.34-2.38c.58-.11 1.25-.21 2.02-.29q1.14-.12 2.28-.21t2.04-.09c1 0 1.85.13 2.55.4.69.27 1.22.72 1.59 1.36.36.64.55 1.52.55 2.63v7.91Z"/><path d="M14.26 15.09c-.06-.28-.12-.55-.17-.81h-.65c-.05.26-.1.53-.16.81s-.12.56-.21.84l-1.42 5.1h4.22l-1.42-5.1c-.07-.27-.13-.55-.19-.84"/></g></g></svg>
            <span class="font-impact text-gray-350 text-base font-semibold uppercase">Story text</span>
          </div>
          <span class="text-settings-close" x-on:click="close();">
            <svg class="h-4 w-4 text-gray-300" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="close_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g fill="none" clip-path="url(#close_svg__a)"><path fill="currentColor" d="M34.3 0 20 14.3 5.7 0H0v5.7L14.3 20 0 34.3V40h5.7L20 25.7 34.3 40H40v-5.7L25.7 20 40 5.7V0z"/></g></svg>
          </span>
        </div>

        <div class="grid grid-cols-3 items-center gap-3 px-5 py-2">
          <label class="font-impact w-20 text-base font-semibold uppercase text-gray-100" for="text-settings-size">Size</label>
<select name="text-settings-size" class="text-settings-size col-span-2 bg-gray-600 text-sm text-gray-300">
  <option value="small">Small</option>
  <option value="standard" selected>Standard</option>
  <option value="large">Large</option>
</select>


<label class="font-impact hidden w-20 text-base font-semibold uppercase text-gray-100 md:block"
  for="text-settings-width">Width
      <span class="text-gray-400">*</span>
  </label>
<select name="text-settings-width"
  class="text-settings-width col-span-2 hidden bg-gray-600 text-sm text-gray-300 md:block">
  <option value="standard" selected>Standard</option>
  <option value="wide">Wide</option>
</select>


<label class="font-impact w-20 text-base font-semibold uppercase text-gray-100" for="text-settings-links">Links</label>
<select name="text-settings-links" class="text-settings-links col-span-2 bg-gray-600 text-sm text-gray-300">
  <option value="standard" selected>Standard</option>
  <option value="orange">Orange</option>
</select>


  <div class="font-impact col-span-3 hidden text-sm font-semibold uppercase text-gray-400 md:block">
    <span class="mb-0 italic">* Subscribers only</span><br>
    &nbsp;&nbsp;<a href="/store/product/subscriptions/" class="text-green-400">Learn more</a>
  </div>

          
          <button
            class="font-impact text-settings-position col-span-3 mx-auto my-3 block rounded-sm border-2 border-green-400 px-3 py-1 text-base font-semibold uppercase text-gray-100"
            value="nav">
            Minimize to nav
          </button>
        </div>
      </div>
    </div>
    </div>
  </div>
</div>

  

  
      
    
    <div
      class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0">
      <div class="relative lg:col-span-2">

        
        <div class="post-content post-content-double">
                      
                      
          <div class="page-anchor-wrapper"><a class="" name="page-1" data-page="1" data-url="https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/"></a></div>
<p>Large language models represent text using tokens, each of which is a few characters. Short words are represented by a single token (like "the" or "it"), whereas larger words may be represented by several tokens (GPT-4o represents "indivisible" with "ind," "iv," and "isible").</p>
<p>When OpenAI released ChatGPT two years ago, it had a memory—known as a context window—of just <a href="https://x.com/goodside/status/1598874674204618753">8,192 tokens</a>. That works out to roughly 6,000 words of text. This meant that if you fed it more than about 15 pages of text, it would “forget” information from the beginning of its context. This limited the size and complexity of tasks ChatGPT could handle.</p>
<p>Today’s LLMs are far more capable:</p>
<ul>
<li>OpenAI’s <a href="https://platform.openai.com/docs/models/gp" rel="">GPT-4o</a> can handle 128,000 tokens (about 200 pages of text).</li>
<li>Anthropic’s <a href="https://www.anthropic.com/news/claude-3-5-sonnet" rel="">Claude 3.5 Sonnet</a> can accept 200,000 tokens (about 300 pages of text).</li>
<li>Google’s <a href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" rel="">Gemini 1.5 Pro</a> allows 2 million tokens (about 2,000 pages of text).</li>
</ul>
<p>Still, it’s going to take a lot more progress if we want AI systems with human-level cognitive abilities.</p>
<p>Many people envision a future where AI systems are able to do many—perhaps most—of the jobs performed by humans. Yet many human workers read and hear hundreds of millions of words during our working years—and we absorb even more information from sights, sounds, and smells in the world around us. To achieve human-level intelligence, AI systems will need the capacity to absorb similar quantities of information.</p>
<p>Right now the most popular way to build an LLM-based system to handle large amounts of information is called retrieval-augmented generation (RAG). These systems try to find documents relevant to a user’s query and then insert the most relevant documents into an LLM’s context window.</p>
<p>This sometimes works better than a conventional search engine, but today’s RAG systems leave a lot to be desired. They only produce good results if the system puts the most relevant documents into the LLM’s context. But the mechanism used to find those documents—often, searching in a <a href="https://en.wikipedia.org/wiki/Vector_database" rel="">vector database</a>—is not very sophisticated. If the user asks a complicated or confusing question, there’s a good chance the RAG system will retrieve the wrong documents and the chatbot will return the wrong answer.</p>

          
                      <div class="ars-interlude-container in-content-interlude mx-auto max-w-xl">
            </div>
                  </div>

              </div>

      
      <div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end dark:bg-gray-50 lg:block">
        
                  <div class="ad-wrapper is-sticky is-rail">
        <div class="ad-wrapper-inner">
            <div class="ad ad--rail"></div>
        </div>
    </div>
              </div>
    </div>
                    
        <div class="ad-wrapper with-label is-fullwidth">
        <div class="ad-wrapper-inner">
            <div class="ad ad--mid-content">
          </div>
        </div>
    </div>
          
    
    <div
      class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0">
      <div class="relative lg:col-span-2">

        
        <div class="post-content post-content-double">
          
          
<p>And RAG doesn’t enable an LLM to reason in more sophisticated ways over large numbers of documents:</p>
<ul>
<li>A lawyer might want an AI system to review and summarize hundreds of thousands of emails.</li>
<li>An engineer might want an AI system to analyze thousands of hours of camera footage from a factory floor.</li>
<li>A medical researcher might want an AI system to identify trends in tens of thousands of patient records.</li>
</ul>
<p>Each of these tasks could easily require more than 2 million tokens of context. Moreover, we’re not going to want our AI systems to start with a clean slate after doing one of these jobs. We will want them to gain experience over time, just like human workers do.</p>
<p>Superhuman memory and stamina have long been key selling points for computers. We’re not going to want to give them up in the AI age. Yet today’s LLMs are distinctly subhuman in their ability to absorb and understand large quantities of information.</p>
<p>It’s true, of course, that LLMs absorb superhuman quantities of information at training time. The latest AI models have been trained on trillions of tokens—far more than any human will read or hear. But a lot of valuable information is proprietary, time-sensitive, or otherwise not available for training.</p>
<p>So we’re going to want AI models to read and remember far more than 2 million tokens at inference time. And that won’t be easy.</p>
<p>The key innovation behind transformer-based LLMs is attention, a mathematical operation that allows a model to “think about” previous tokens. (<a href="https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/" rel="">Check out our LLM explainer</a> if you want a detailed explanation of how this works.) Before an LLM generates a new token, it performs an attention operation that compares the latest token to every previous token. This means that conventional LLMs get less and less efficient as the context grows.</p>

          
                  </div>

              </div>

      
      <div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end dark:bg-gray-50 lg:block">
        
                  <div class="ad-wrapper is-sticky is-rail">
        <div class="ad-wrapper-inner">
            <div class="ad ad--rail"></div>
        </div>
    </div>
              </div>
    </div>
                    
        <div class="ad-wrapper with-label is-fullwidth">
        <div class="ad-wrapper-inner">
            <div class="ad ad--mid-content">
          </div>
        </div>
    </div>
          
    
    <div
      class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0">
      <div class="relative lg:col-span-2">

        
        <div class="post-content post-content-double">
          
          
<p>Lots of people are working on ways to solve this problem—I’ll discuss some of them later in this article. But first I should explain how we ended up with such an unwieldy architecture.</p>
<div class="page-anchor-wrapper"><a class="record-pageview" name="page-2" data-page="2" data-url="https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/"></a></div>
<h2 class="header-anchor-post">GPUs made deep learning possible</h2>
<p>The “brains” of personal computers are central processing units (CPUs). Traditionally, chipmakers made CPUs faster by increasing the frequency of the clock that acts as its heartbeat. But in the early 2000s, overheating forced chipmakers to mostly abandon this technique.</p>
<p>Chipmakers started making CPUs that could execute <a href="https://en.wikipedia.org/wiki/Multithreading_(computer_architecture)" rel="">more than one instruction at a time</a>. But they were held back by a programming paradigm that requires instructions to mostly be executed in order.</p>
<p>A new architecture was needed to take full advantage of <a href="https://en.wikipedia.org/wiki/Moore%27s_law" rel="">Moore’s Law</a>. Enter Nvidia.</p>
<p>In 1999, Nvidia started selling graphics processing units (GPUs) to speed up the rendering of three-dimensional games like <em>Quake III Arena</em>. The job of these PC add-on cards was to rapidly draw thousands of triangles that made up walls, weapons, monsters, and other objects in a game.</p>
<p>This is <em>not</em> a sequential programming task: triangles in different areas of the screen can be drawn in any order. So rather than having a single processor that executed instructions one at a time, Nvidia’s <a href="https://en.wikipedia.org/wiki/GeForce_256" rel="">first GPU</a> had a dozen specialized cores—effectively tiny CPUs—that worked in parallel to paint a scene.</p>
<p>Over time, Moore’s Law enabled Nvidia to make GPUs with tens, hundreds, and eventually thousands of computing cores. People started to realize that the massive parallel computing power of GPUs could be used for applications unrelated to video games.</p>
<p>In 2012, three University of Toronto computer scientists—Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton—used a pair of <a href="https://www.techpowerup.com/gpu-specs/geforce-gtx-580.c270" rel="">Nvidia GTX 580 GPUs</a> to train a neural network for recognizing images. The massive computing power of those GPUs, which had 512 cores each, allowed them to train a network with a then-impressive 60 million parameters. They <a href="https://arstechnica.com/ai/2024/11/how-a-stubborn-computer-scientist-accidentally-launched-the-deep-learning-boom/" rel="">entered ImageNet</a>, an academic competition to classify images into one of 1,000 categories, and <a href="https://arstechnica.com/science/2018/12/how-computers-got-shockingly-good-at-recognizing-images/3/" rel="">set a new record for accuracy</a> in image recognition.</p>

          
                  </div>

              </div>

      
      <div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end dark:bg-gray-50 lg:block">
        
                  <div class="ad-wrapper is-sticky is-rail">
        <div class="ad-wrapper-inner">
            <div class="ad ad--rail"></div>
        </div>
    </div>
              </div>
    </div>
                    
        <div class="ad-wrapper with-label is-fullwidth">
        <div class="ad-wrapper-inner">
            <div class="ad ad--mid-content">
          </div>
        </div>
    </div>
          
    
    <div
      class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0">
      <div class="relative lg:col-span-2">

        
        <div class="post-content post-content-double">
          
          
<p>Before long, researchers were applying similar techniques to a wide variety of domains, including natural language.</p>
<h2 class="header-anchor-post">Transformers removed a bottleneck for natural language</h2>
<div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent">
<div class="pencraft pc-display-contents pc-reset _pubTheme_c2zmd_1">In the early 2010s, recurrent neural networks (RNNs) were a popular architecture for understanding natural language. RNNs process language one word at a time. After each word, the network updates its hidden state, a list of numbers that reflects its understanding of the sentence so far.</div>
</div>
<p>RNNs worked fairly well on short sentences, but they struggled with longer ones—to say nothing of paragraphs or longer passages. When reasoning about a long sentence, an RNN would sometimes “forget about” an important word early in the sentence. In 2014, computer scientists Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio <a href="https://arxiv.org/pdf/1409.0473" rel="">discovered</a> they could improve the performance of a recurrent neural network by adding an attention mechanism that allowed the network to “look back” at earlier words in a sentence.</p>
<p>In 2017, Google published <a href="https://arxiv.org/abs/1706.03762" rel="">“Attention Is All You Need,”</a> one of the most important papers in the history of machine learning. Building on the work of Bahdanau and his colleagues, Google researchers dispensed with the RNN and its hidden states. Instead, Google’s model used an attention mechanism to scan previous words for relevant context.</p>
<p>This new architecture, which Google called the transformer, proved hugely consequential because it eliminated a serious bottleneck to scaling language models.</p>
<p>Here’s an animation illustrating why RNNs didn’t scale well:</p>
<div class="captioned-image-container">
<figure>
<div class="image2-inset">
<picture><source srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34b7514d-a8f6-450f-8adb-b9cea42c692e_960x635.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34b7514d-a8f6-450f-8adb-b9cea42c692e_960x635.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34b7514d-a8f6-450f-8adb-b9cea42c692e_960x635.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34b7514d-a8f6-450f-8adb-b9cea42c692e_960x635.gif 1456w" type="image/webp" sizes="100vw"></source><img decoding="async" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34b7514d-a8f6-450f-8adb-b9cea42c692e_960x635.gif" sizes="100vw" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34b7514d-a8f6-450f-8adb-b9cea42c692e_960x635.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34b7514d-a8f6-450f-8adb-b9cea42c692e_960x635.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34b7514d-a8f6-450f-8adb-b9cea42c692e_960x635.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34b7514d-a8f6-450f-8adb-b9cea42c692e_960x635.gif 1456w" alt="" width="960" height="635" data-attrs='{"src":"https://substack-post-media.s3.amazonaws.com/public/images/34b7514d-a8f6-450f-8adb-b9cea42c692e_960x635.gif","srcNoWatermark":null,"fullscreen":null,"imageSize":null,"height":635,"width":960,"resizeWidth":null,"bytes":null,"alt":null,"title":null,"type":null,"href":null,"belowTheFold":true,"topImage":false,"internalRedirect":null,"isProcessing":false}'></picture>
<div class="image-link-expand">
<div class="pencraft pc-display-flex pc-gap-8 pc-reset">
<div class="pencraft pc-reset icon-container view-image"></div>
</div>
</div>
</div>
</figure>
</div>
<p>This hypothetical RNN tries to predict the next word in a sentence, with the prediction shown in the top row of the diagram. This network has three layers, each represented by a rectangle. It is inherently linear: it has to complete its analysis of the first word, “How,” before passing the hidden state back to the bottom layer so the network can start to analyze the second word, “are.”</p>
<p>This constraint wasn’t a big deal when machine learning algorithms ran on CPUs. But when people started leveraging the parallel computing power of GPUs, the linear architecture of RNNs became a serious obstacle.</p>

          
                  </div>

              </div>

      
      <div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end dark:bg-gray-50 lg:block">
        
                  <div class="ad-wrapper is-sticky is-rail">
        <div class="ad-wrapper-inner">
            <div class="ad ad--rail"></div>
        </div>
    </div>
              </div>
    </div>
                    
        <div class="ad-wrapper with-label is-fullwidth">
        <div class="ad-wrapper-inner">
            <div class="ad ad--mid-content">
          </div>
        </div>
    </div>
          
    
    <div
      class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0">
      <div class="relative lg:col-span-2">

        
        <div class="post-content post-content-double">
          
          
<p>The transformer removed this bottleneck by allowing the network to “think about” all the words in its input at the same time:</p>
<div class="captioned-image-container">
<figure>
<div class="image2-inset">
<picture><source srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecedba87-ada6-49a1-8652-42f18e41fd55_1152x762.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecedba87-ada6-49a1-8652-42f18e41fd55_1152x762.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecedba87-ada6-49a1-8652-42f18e41fd55_1152x762.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecedba87-ada6-49a1-8652-42f18e41fd55_1152x762.gif 1456w" type="image/webp" sizes="100vw"></source><img decoding="async" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecedba87-ada6-49a1-8652-42f18e41fd55_1152x762.gif" sizes="100vw" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecedba87-ada6-49a1-8652-42f18e41fd55_1152x762.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecedba87-ada6-49a1-8652-42f18e41fd55_1152x762.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecedba87-ada6-49a1-8652-42f18e41fd55_1152x762.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecedba87-ada6-49a1-8652-42f18e41fd55_1152x762.gif 1456w" alt="" width="1152" height="762" data-attrs='{"src":"https://substack-post-media.s3.amazonaws.com/public/images/ecedba87-ada6-49a1-8652-42f18e41fd55_1152x762.gif","srcNoWatermark":null,"fullscreen":null,"imageSize":null,"height":762,"width":1152,"resizeWidth":null,"bytes":null,"alt":null,"title":null,"type":null,"href":null,"belowTheFold":true,"topImage":false,"internalRedirect":null,"isProcessing":false}'></picture>
</div>
</figure>
</div>
<p>The transformer-based model shown here does roughly as many computations as the RNN in the previous diagram. So it might not run any faster on a (single-core) CPU. But because the model doesn’t need to finish with “How” before starting on “are,” “you,” or “doing,” it can work on all of these words simultaneously. So it can run a <em>lot</em> faster on a GPU with many parallel execution units.</p>
<p>How much faster? The potential speed-up is proportional to the number of input words. My animations depict a four-word input that makes the transformer model about four times faster than the RNN. Real LLMs can have inputs thousands of words long. So, with a sufficiently beefy GPU, transformer-based models can be orders of magnitude faster than otherwise similar RNNs.</p>
<p>In short, the transformer unlocked the full processing power of GPUs and catalyzed rapid increases in the scale of language models. Leading LLMs grew from <a href="https://en.wikipedia.org/wiki/GPT-1" rel="">hundreds of millions of parameters</a> in 2018 to <a href="https://en.wikipedia.org/wiki/GPT-3" rel="">hundreds of billions of parameters</a> by 2020. Classic RNN-based models could not have grown that large because their linear architecture prevented them from being trained efficiently on a GPU.</p>
<div class="page-anchor-wrapper"><a class="record-pageview" name="page-3" data-page="3" data-url="https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/"></a></div>
<h2 class="header-anchor-post">Transformers have a scaling problem</h2>
<div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent">
<div class="pencraft pc-display-contents pc-reset _pubTheme_c2zmd_1">
<p>Earlier I said that the recurrent neural network in my animations did “roughly the same amount of work” as the transformer-based network. But they don’t do <em>exactly</em> the same amount of work. Let’s look again at the diagram for the transformer-based model:</p>
</div>
</div>
<div class="captioned-image-container">
<figure>
<div class="image2-inset">
<picture><source srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa1b2741-2309-4ff0-bc36-9c1f8be33c3a_1106x742.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa1b2741-2309-4ff0-bc36-9c1f8be33c3a_1106x742.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa1b2741-2309-4ff0-bc36-9c1f8be33c3a_1106x742.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa1b2741-2309-4ff0-bc36-9c1f8be33c3a_1106x742.png 1456w" type="image/webp" sizes="100vw"></source><img decoding="async" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa1b2741-2309-4ff0-bc36-9c1f8be33c3a_1106x742.png" sizes="100vw" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa1b2741-2309-4ff0-bc36-9c1f8be33c3a_1106x742.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa1b2741-2309-4ff0-bc36-9c1f8be33c3a_1106x742.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa1b2741-2309-4ff0-bc36-9c1f8be33c3a_1106x742.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa1b2741-2309-4ff0-bc36-9c1f8be33c3a_1106x742.png 1456w" alt="" width="1106" height="742" data-attrs='{"src":"https://substack-post-media.s3.amazonaws.com/public/images/aa1b2741-2309-4ff0-bc36-9c1f8be33c3a_1106x742.png","srcNoWatermark":null,"fullscreen":null,"imageSize":null,"height":742,"width":1106,"resizeWidth":null,"bytes":null,"alt":null,"title":null,"type":null,"href":null,"belowTheFold":true,"topImage":false,"internalRedirect":null,"isProcessing":false}'></picture>
</div>
</figure>
</div>
<p>See all those diagonal arrows between the layers? They represent the operation of the attention mechanism. Before a transformer-based language model generates a new token, it “thinks about” every previous token to find the ones that are most relevant.</p>
<p>Each of these comparisons is cheap, computationally speaking. For small contexts—10, 100, or even 1,000 tokens—they are not a big deal. But the computational cost of attention grows relentlessly with the number of preceding tokens. The longer the context gets, the more attention operations (and therefore computing power) are needed to generate the next token.</p>

          
                  </div>

              </div>

      
      <div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end dark:bg-gray-50 lg:block">
        
                  <div class="ad-wrapper is-sticky is-rail">
        <div class="ad-wrapper-inner">
            <div class="ad ad--rail"></div>
        </div>
    </div>
              </div>
    </div>
                    
        <div class="ad-wrapper with-label is-fullwidth">
        <div class="ad-wrapper-inner">
            <div class="ad ad--mid-content">
          </div>
        </div>
    </div>
          
    
    <div
      class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0">
      <div class="relative lg:col-span-2">

        
        <div class="post-content post-content-double">
          
          
<p>This means that the total computing power required for attention grows quadratically with the total number of tokens. Suppose a 10-token prompt requires 414,720 attention operations. Then:</p>
<ul>
<li>Processing a 100-token prompt will require 45.6 million attention operations.</li>
<li>Processing a 1,000-token prompt will require 4.6 billion attention operations.</li>
<li>Processing a 10,000-token prompt will require <em>460 billion</em> attention operations.</li>
</ul>
<p>This is probably why Google charges twice as much, per token, for Gemini 1.5 Pro once the context gets longer than 128,000 tokens. Generating token number 128,001 requires comparisons with all 128,000 previous tokens, making it significantly more expensive than producing the first or 10th or 100th token.</p>
<h2 class="header-anchor-post">Making attention more efficient and scalable</h2>
<p>A lot of effort has been put into optimizing attention. One line of research has tried to squeeze maximum efficiency out of individual GPUs.</p>
<p>As we saw earlier, a modern GPU contains thousands of execution units. Before a GPU can start doing math, it must move data from slow shared memory (called high-bandwidth memory) to much faster memory inside a particular execution unit (called SRAM). Sometimes GPUs spend more time moving data around than performing calculations.</p>
<p>In a <a href="https://arxiv.org/abs/2205.14135" rel="">series</a> <a href="https://arxiv.org/abs/2307.08691" rel="">of</a> <a href="https://arxiv.org/abs/2407.08608" rel="">papers</a>, Princeton computer scientist Tri Dao and several collaborators have developed FlashAttention, which calculates attention in a way that minimizes the number of these slow memory operations. Work like Dao’s has dramatically improved the performance of transformers on modern GPUs.</p>
<p>Another line of research has focused on efficiently scaling attention across multiple GPUs. One widely cited paper describes <a href="https://arxiv.org/abs/2310.01889" rel="">ring attention</a>, which divides input tokens into blocks and assigns each block to a different GPU. It’s called ring attention because GPUs are organized into a conceptual ring, with each GPU passing data to its neighbor.</p>
<p>I once attended a ballroom dancing class where couples stood in a ring around the edge of the room. After each dance, women would stay where they were while men would rotate to the next woman. Over time, every man got a chance to dance with every woman. Ring attention works on the same principle. The “women” are query vectors (describing what each token is “looking for”) and the “men” are key vectors (describing the characteristics each token has). As the key vectors rotate through a sequence of GPUs, they get multiplied by every query vector in turn.</p>

          
                  </div>

              </div>

      
      <div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end dark:bg-gray-50 lg:block">
        
                  <div class="ad-wrapper is-sticky is-rail">
        <div class="ad-wrapper-inner">
            <div class="ad ad--rail"></div>
        </div>
    </div>
              </div>
    </div>
                    
        <div class="ad-wrapper with-label is-fullwidth">
        <div class="ad-wrapper-inner">
            <div class="ad ad--mid-content">
          </div>
        </div>
    </div>
          
    
    <div
      class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0">
      <div class="relative lg:col-span-2">

        
        <div class="post-content post-content-double">
          
          
<p>In short, ring attention distributes attention calculations across multiple GPUs, making it possible for LLMs to have larger context windows. But it doesn’t make individual attention calculations any cheaper.</p>
<div class="page-anchor-wrapper"><a class="record-pageview" name="page-4" data-page="4" data-url="https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/"></a></div>
<h2 class="header-anchor-post">Could RNNs make a comeback?</h2>
<p>The fixed-size hidden state of an RNN means that it doesn’t have the same scaling problems as a transformer. An RNN requires about the same amount of computing power to produce its first, hundredth and millionth token. That’s a big advantage over attention-based models.</p>
<p>Although RNNs have fallen out of favor since the invention of the transformer, people have continued trying to develop RNNs suitable for training on modern GPUs.</p>
<p>In April, Google <a href="https://arxiv.org/abs/2404.07143" rel="">announced a new model</a> called Infini-attention. It’s kind of a hybrid between a transformer and an RNN. Infini-attention handles recent tokens like a normal transformer, remembering them and recalling them using an attention mechanism.</p>
<p>However, Infini-attention doesn’t try to remember every token in a model’s context. Instead, it stores older tokens in a “compressive memory” that works something like the hidden state of an RNN. This data structure can perfectly store and recall a few tokens, but as the number of tokens grows, its recall becomes lossier.</p>
<p>Machine learning YouTuber Yannic Kilcher <a href="https://www.youtube.com/watch?v=r_UBBfTPcF0&amp;t=2s" rel="">wasn’t too impressed</a> by Google’s approach.</p>
<p>“I’m super open to believing that this actually does work and this is the way to go for infinite attention, but I’m very skeptical,” Kilcher said. “It uses this compressive memory approach where you just store as you go along, you don’t really learn how to store, you just store in a deterministic fashion, which also means you have very little control over what you store and how you store it.”</p>
<h2 class="header-anchor-post">Could Mamba be the future?</h2>
<p>Perhaps the most notable effort to resurrect RNNs is Mamba, an architecture that was announced in a <a href="https://arxiv.org/abs/2312.00752" rel="">December 2023 paper</a>. It was developed by computer scientists Dao (who also did the FlashAttention work I mentioned earlier) and Albert Gu.</p>

          
                  </div>

              </div>

      
      <div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end dark:bg-gray-50 lg:block">
        
                  <div class="ad-wrapper is-sticky is-rail">
        <div class="ad-wrapper-inner">
            <div class="ad ad--rail"></div>
        </div>
    </div>
              </div>
    </div>
                    
        <div class="ad-wrapper with-label is-fullwidth">
        <div class="ad-wrapper-inner">
            <div class="ad ad--mid-content">
          </div>
        </div>
    </div>
          
    
    <div
      class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0">
      <div class="relative lg:col-span-2">

        
        <div class="post-content post-content-double">
          
          
<p>Mamba does not use attention. Like other RNNs, it has a hidden state that acts as the model’s “memory.” Because the hidden state has a fixed size, longer prompts do not increase Mamba’s per-token cost.</p>
<p>When I started writing this article in March, my goal was to explain Mamba’s architecture in some detail. But then in May, the researchers <a href="https://arxiv.org/abs/2405.21060" rel="">released Mamba-2</a>, which significantly changed the architecture from the original Mamba paper. I’ll be frank: I struggled to understand the original Mamba and have not figured out how Mamba-2 works.</p>
<p>But the key thing to understand is that Mamba has the potential to combine transformer-like performance with the efficiency of conventional RNNs.</p>
<p>In June, Dao and Gu <a href="https://arxiv.org/abs/2406.07887" rel="">co-authored a paper</a> with Nvidia researchers that evaluated a Mamba model with 8 billion parameters. They found that models like Mamba were competitive with comparably sized transformers in a number of tasks, but they “lag behind Transformer models when it comes to in-context learning and recalling information from the context.”</p>
<p>Transformers are good at information recall because they “remember” every token of their context—this is also why they become less efficient as the context grows. In contrast, Mamba tries to compress the context into a fixed-size state, which necessarily means discarding some information from long contexts.</p>
<p>The Nvidia team found they got the best performance from a hybrid architecture that interleaved 24 Mamba layers with four attention layers. This worked better than either a pure transformer model <em>or</em> a pure Mamba model.</p>
<p>A model needs <em>some</em> attention layers so it can remember important details from early in its context. But a few attention layers seem to be sufficient; the rest of the attention layers can be replaced by cheaper Mamba layers with little impact on the model’s overall performance.</p>

          
                  </div>

              </div>

      
      <div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end dark:bg-gray-50 lg:block">
        
                  <div class="ad-wrapper is-sticky is-rail">
        <div class="ad-wrapper-inner">
            <div class="ad ad--rail"></div>
        </div>
    </div>
              </div>
    </div>
                    
        <div class="ad-wrapper with-label is-fullwidth">
        <div class="ad-wrapper-inner">
            <div class="ad ad--mid-content">
          </div>
        </div>
    </div>
          
    
    <div
      class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0">
      <div class="relative lg:col-span-2">

        
        <div class="post-content post-content-double">
          
          
<p>In August, an Israeli startup called AI21 announced its <a href="https://arxiv.org/abs/2408.12570" rel="">Jamba 1.5 family</a> of models. The largest version had 398 billion parameters, making it comparable in size to Meta’s Llama 405B model. Jamba 1.5 Large has seven times more Mamba layers than attention layers. As a result, Jamba 1.5 Large requires far less memory than comparable models from Meta and others. For example, AI21 estimates that Llama 3.1 70B needs 80GB of memory to keep track of 256,000 tokens of context. Jamba 1.5 Large only needs 9GB, allowing the model to run on much less powerful hardware.</p>
<p>The Jamba 1.5 Large model gets an MMLU score of 80, significantly below the Llama 3.1 70B’s score of 86. So by this measure, Mamba doesn’t blow transformers out of the water. However, this may not be an apples-to-apples comparison. Frontier labs like Meta have invested heavily in training data and post-training infrastructure to squeeze a few more percentage points of performance out of benchmarks like MMLU. It’s possible that the same kind of intense optimization could close the gap between Jamba and frontier models.</p>
<p>So while the benefits of longer context windows is obvious, the best strategy to get there is not. In the short term, AI companies may continue using clever efficiency and scaling hacks (like FlashAttention and Ring Attention) to scale up vanilla LLMs. Longer term, we may see growing interest in Mamba and perhaps other attention-free architectures. Or maybe someone will come up with a totally new architecture that renders transformers obsolete.</p>
<p>But I am pretty confident that scaling up transformer-based frontier models isn’t going to be a solution on its own. If we want models that can handle billions of tokens—and many people do—we’re going to need to think outside the box.</p>
<p><i>Tim Lee was on staff at Ars from 2017 to 2021. Last year, he launched a newsletter, </i><a href="https://www.understandingai.org/" data-ml-dynamic="true" data-ml-dynamic-type="sl" data-orig-url="https://www.understandingai.org/" data-ml-id="1" data-ml="true" data-skimlinks-tracking="xid:fr1734637381939bhi" data-xid="fr1734637381939bhi"><i>Understanding AI,</i></a><i> that explores how AI works and how it's changing our world. You can subscribe </i><a href="https://www.understandingai.org/"><i>here</i></a><i>.</i></p>


          
                  </div>

                  
          <div class="-mx-2.5 sm:mx-0">
  </div>






  <div class="author-mini-bio">
    <div class="flex flex-col items-start gap-5 border-t-4 py-5 dark:border-gray-700 sm:flex-row">
  <div class="flex items-center gap-3">
          <a class="relative block aspect-square h-24 w-24 shrink-0 overflow-hidden rounded-full border-4 border-green-400"
        href="https://arstechnica.com/author/timlee/"><img class="absolute left-0 top-0 min-h-full min-w-full object-cover"
          src="/wp-content/uploads/2016/05/t.lee-26.jpg" alt="Photo of Timothy B. Lee"></a>
        <div class="font-impact mb-0 text-left text-base font-semibold uppercase sm:hidden">
      <a href="https://arstechnica.com/author/timlee/">Timothy B. Lee</a>
      <span class="block font-sans text-sm font-normal italic sm:inline-block">Senior tech policy reporter</span>
    </div>
  </div>

  <div class="">
    <div class="font-impact mb-0 hidden text-left text-base font-semibold uppercase sm:block">
      <a href="https://arstechnica.com/author/timlee/">Timothy B. Lee</a>
      <span class="block font-sans text-sm font-normal italic sm:ml-2 sm:inline-block">Senior tech policy reporter</span>
    </div>

    <div class="text-left text-base leading-5 text-gray-400" itemprop="description">
      Timothy is a senior reporter covering tech policy and the future of transportation. He lives in Washington DC.
    </div>
  </div>
</div>
  </div>


  <div
    class="story-tools flex items-center justify-between border-b-4 border-t-4 text-sm dark:border-gray-700 sm:text-lg">
    <a class="view-comments font-impact my-5 flex items-center gap-2 whitespace-nowrap font-semibold uppercase"
    href="https://arstechnica.com/ai/2024/12/why-ai-language-models-choke-on-too-much-text/#comments" title="107 comments">
    <svg class="text-gray-300 hover:text-gray-500 h-6 w-6" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"/></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"/></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"/><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"/></g></g></svg>
    107 Comments
  </a>
      </div>
              </div>

      
      <div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end dark:bg-gray-50 lg:block">
        
                  <div class="ad-wrapper is-sticky is-rail">
        <div class="ad-wrapper-inner">
            <div class="ad ad--rail"></div>
        </div>
    </div>
              </div>
    </div>
  </article>


  <div class="relative">
    <section class="dusk:bg-none bg-gray-100 dark:bg-gray-50" id="comments">
  <div
    class="comments-container mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-y-6 lg:px-8 xl:px-0">
        <div class="comments-wrapper col-span-3 hidden py-5">
      <div class="lg:grid lg:grid-cols-3 lg:gap-6">
        <div class="lg:col-span-2">
          <div class="wp-forum-connect-comments relative">
  <div
    class="comments-title font-impact xs:justify-center flex flex-row items-center gap-2 bg-gray-600 px-5 py-2 text-xl font-extrabold uppercase text-green-400 lg:text-2xl">
    <svg class="h-6 w-6 rotate-[-75deg] text-gray-100" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 49 49"><defs><clipPath id="bubble_svg__a"><path fill="none" d="M.011 10.382 38.648.029l10.353 38.637L10.364 49.02z"/></clipPath><clipPath id="bubble_svg__b"><path fill="none" d="M.011 10.382 38.648.029l10.353 38.637L10.364 49.02z"/></clipPath></defs><g clip-path="url(#bubble_svg__a)"><g fill="currentColor" clip-path="url(#bubble_svg__b)"><path d="M29.7 43.8C19 46.7 8.1 40.3 5.2 29.7S8.7 8.1 19.3 5.2s21.6 3.5 24.5 14.1c2.9 10.7-3.5 21.6-14.1 24.5"/><path d="M24.5 24.5 1.7 10.2c-.8-.4-1.7.3-1.5 1.1l3.3 12.2 1.7 6.2z"/></g></g></svg>
    Comments
  </div>

  <a class="font-impact absolute bottom-0 right-5 top-0 flex flex-row items-center gap-2 text-base font-semibold uppercase text-gray-300 hover:text-gray-200"
    href="https://arstechnica.com/civis/threads/why-ai-language-models-choke-on-too-much-text.1504692/" target="_blank">
    <svg class="h-5 w-5 text-gray-200" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="forum-arrow_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="forum-arrow_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#forum-arrow_svg__a)"><g fill="none" clip-path="url(#forum-arrow_svg__b)"><path fill="#ff4e00" d="M23 0c-1.1 0-2 .9-2 2s.9 2 2 2h10.2L16.6 20.6c-.8.8-.8 2 0 2.8.4.4.9.6 1.4.6s1-.2 1.4-.6L36 6.8V17c0 1.1.9 2 2 2s2-.9 2-2V0z"/><path fill="currentColor" d="M30 24v12H4V10h12l4-4H4c-2.2 0-4 1.8-4 4v26c0 2.2 1.8 4 4 4h26c2.2 0 4-1.8 4-4V20z"/></g></g></svg>
    <span class="hidden sm:inline">Forum view</span>
  </a>
</div>

<div class="xf_thread_iframe_wrapper relative min-h-screen">
  <div class="xf_thread_iframe_loading flex items-center justify-center">
    <div class="my-20">
      <img class="h-10 w-10" src="https://arstechnica.com/wp-content/themes/ars-v9/public/images/firework-loader.75ab30.gif" alt="Loading" />
      Loading comments...
    </div>
  </div>

  <div class="xf_thread_iframe_container" id="xf_thread_iframe_container" data-thread-id="1504692"
    data-url="https://arstechnica.com/civis/threads/why-ai-language-models-choke-on-too-much-text.1504692/unread?in_iframe=1&amp;theme=auto&amp;wp_data=eyJ1cmwiOiJodHRwczpcL1wvYXJzdGVjaG5pY2EuY29tXC9haVwvMjAyNFwvMTJcL3doeS1haS1sYW5ndWFnZS1tb2RlbHMtY2hva2Utb24tdG9vLW11Y2gtdGV4dFwvIiwib3Blbl9jb21tZW50cyI6ImNvbW1lbnRzPTEifQ==&amp;"
    data-open="0"
    data-open-default="0"></div>
</div>
        </div>
        
        <div class="dusk:bg-gray-100 row-span-2 hidden min-w-[300px] justify-self-end dark:bg-gray-50 lg:block">
          
                      <div class="ad-wrapper is-sticky is-rail">
        <div class="ad-wrapper-inner">
            <div class="ad ad--rail"></div>
        </div>
    </div>
                  </div>
      </div>
    </div>
  </div>
</section>
  </div>


  <div class="mx-auto mb-2.5 px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0">
    <div class="col-span-2 py-5">
      <div class="post-navigation">
  
  <div class="nav-previous post-navigation-link-wrapper">
          <a class="post-navigation-link" rel="nofollow" href="https://arstechnica.com/space/2024/12/were-about-to-fly-a-spacecraft-into-the-sun-for-the-first-time/"
        title="Go to: We’re about to fly a spacecraft into the Sun for the first time"><svg class="text-orange-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="arrow-blocks-right_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g fill="currentColor" clip-path="url(#arrow-blocks-right_svg__a)"><path d="M32 16h8v8h-8zm-8 8h8v8h-8zm-8 8h8v8h-8zm8-24h8v8h-8zm-8-8h8v8h-8zM0 16h16v8H0z"/></g></svg>
<span class="post-navigation-link-text">Prev story</span></a>
      </div>

  
  <div class="nav-next post-navigation-link-wrapper">
          <a class="post-navigation-link" rel="nofollow" href="https://arstechnica.com/security/2024/12/vpn-used-for-vr-game-cheat-sells-access-to-your-home-network/"
        title="Go to: VPN used for VR game cheat sells access to your home network"><span class="post-navigation-link-text">Next story</span><svg class="text-orange-400" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="arrow-blocks-right_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g fill="currentColor" clip-path="url(#arrow-blocks-right_svg__a)"><path d="M32 16h8v8h-8zm-8 8h8v8h-8zm-8 8h8v8h-8zm8-24h8v8h-8zm-8-8h8v8h-8zM0 16h16v8H0z"/></g></svg>
</a>
      </div>
</div>
    </div>
  </div>


  <div class="mx-auto -mt-2 mb-5 max-w-md sm:max-w-3xl sm:px-5 lg:grid lg:max-w-6xl lg:grid-cols-3 lg:gap-16 xl:px-0">
    <div class="single-most-read dusk:bg-gray-700 relative col-span-2 bg-gray-100 dark:bg-gray-700">
      <div
  class="component-most-read font-impact flex h-full min-h-[300px] flex-col flex-nowrap gap-5 pb-5 uppercase text-white">
  <div>
    <header class="flex flex-row flex-nowrap items-center justify-center gap-2 bg-gray-600 px-5 py-2">
      <svg class="h-[20px] w-[30px] text-gray-100" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 26"><defs><clipPath id="most-read_svg__a"><path fill="none" d="M0 0h40v26H0z"/></clipPath><clipPath id="most-read_svg__b"><path fill="none" d="M0 0h40v26H0z"/></clipPath></defs><g clip-path="url(#most-read_svg__a)"><g fill="none" clip-path="url(#most-read_svg__b)"><path fill="currentColor" d="M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1"/><path fill="#ff4e00" d="M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3"/></g></g></svg>
      <div class="font-impact inline text-xl font-extrabold uppercase text-green-400">
        Most Read</div>
    </header>
    <ol>
              <li class="group relative">
                      <a href="https://arstechnica.com/cars/2024/12/man-vs-ai-race-scrapped-after-ai-car-crashes-into-wall-on-warm-up-lap/">
              <img class="h-auto w-full rounded-sm group-hover:saturate-150"
                src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/1210_a2rl-12-768x432-1734453248.jpg"
                alt="Listing image for first story in Most Read: Human versus autonomous car race ends before it begins"
                decoding="async" loading="lazy">
            </a>
                    <div class="relative px-[15px] py-4 sm:px-5">
                          <div class="most-read-divider absolute left-5 top-[-3px] h-[5px] w-1/4 bg-green-400">
              </div>
              <span
                class="flex flex-row flex-nowrap items-start gap-4 font-serif text-xl font-bold normal-case leading-tight">
                <span class="shrink-0 text-green-400">1.</span>
                <a class="most-read-title text-gray-100 visited:text-gray-400 hover:text-orange-400"
                  href="https://arstechnica.com/cars/2024/12/man-vs-ai-race-scrapped-after-ai-car-crashes-into-wall-on-warm-up-lap/">Human versus autonomous car race ends before it begins</a>
              </span>
                      </div>
        </li>
                    <li class="group relative">
                    <div class="relative px-[15px] py-4 sm:px-5">
                          <div class="most-read-divider absolute left-5 top-0 h-[1px] w-1/4 bg-gray-400">
              </div>
              <span
                class="flex flex-row flex-nowrap items-start gap-4 font-serif text-xl font-bold normal-case leading-tight">
                <span class="shrink-0 text-green-400">2.</span>
                <a class="most-read-title text-gray-100 visited:text-gray-400 hover:text-orange-400"
                  href="https://arstechnica.com/science/2024/12/injured-green-sea-turtle-relearns-how-to-swim-thanks-to-3d-printed-harness/">Green sea turtle gets relief from “bubble butt” syndrome thanks to 3D printing</a>
              </span>
                      </div>
        </li>
                    <li class="group relative">
                    <div class="relative px-[15px] py-4 sm:px-5">
                          <div class="most-read-divider absolute left-5 top-0 h-[1px] w-1/4 bg-gray-400">
              </div>
              <span
                class="flex flex-row flex-nowrap items-start gap-4 font-serif text-xl font-bold normal-case leading-tight">
                <span class="shrink-0 text-green-400">3.</span>
                <a class="most-read-title text-gray-100 visited:text-gray-400 hover:text-orange-400"
                  href="https://arstechnica.com/gaming/2024/12/ars-technicas-top-20-video-games-of-2024/">Ars Technica’s top 20 video games of 2024</a>
              </span>
                      </div>
        </li>
                    <li class="group relative">
                    <div class="relative px-[15px] py-4 sm:px-5">
                          <div class="most-read-divider absolute left-5 top-0 h-[1px] w-1/4 bg-gray-400">
              </div>
              <span
                class="flex flex-row flex-nowrap items-start gap-4 font-serif text-xl font-bold normal-case leading-tight">
                <span class="shrink-0 text-green-400">4.</span>
                <a class="most-read-title text-gray-100 visited:text-gray-400 hover:text-orange-400"
                  href="https://arstechnica.com/health/2024/12/journal-that-published-faulty-black-plastic-study-removed-from-science-index/">Journal that published faulty black plastic study removed from science index</a>
              </span>
                      </div>
        </li>
                    <li class="group relative">
                    <div class="relative px-[15px] py-4 sm:px-5">
                          <div class="most-read-divider absolute left-5 top-0 h-[1px] w-1/4 bg-gray-400">
              </div>
              <span
                class="flex flex-row flex-nowrap items-start gap-4 font-serif text-xl font-bold normal-case leading-tight">
                <span class="shrink-0 text-green-400">5.</span>
                <a class="most-read-title text-gray-100 visited:text-gray-400 hover:text-orange-400"
                  href="https://arstechnica.com/science/2024/12/rocket-report-waiting-for-new-glenn-spacex-takes-a-launch-from-ula/">Rocket Report: ULA has a wild idea; Starliner crew will stay in orbit even longer</a>
              </span>
                      </div>
        </li>
                  </ol>
</div>
<div class="most-read-customize text-center">
  <button
    class="btn-customize font-impact mt-5 inline-flex flex-row flex-nowrap items-center justify-center gap-2 font-semibold uppercase text-gray-300 hover:text-gray-100"
    aria-label="Customize view settings" x-data x-on:click="$dispatch('view-settings-bar-open');">
    <svg class="h-5 w-5" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 39.8 40"><defs><clipPath id="settings_svg__a"><path fill="none" d="M0 0h39.8v40H0z"/></clipPath><clipPath id="settings_svg__b"><path fill="none" d="M0 0h39.8v40H0z"/></clipPath></defs><g clip-path="url(#settings_svg__a)"><g fill="currentColor" clip-path="url(#settings_svg__b)"><path d="M17.4 3c-.8-1.8-2.5-3-4.5-3S9.1 1.2 8.3 3H0v4h8.3c.8 1.8 2.5 3 4.6 3s3.8-1.2 4.6-3h22.4V3H17.5Zm-4.6 4.5c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5M27 15c-2 0-3.8 1.2-4.6 3H0v4h22.4c.8 1.8 2.5 3 4.6 3s3.8-1.2 4.6-3h8.3v-4h-8.3c-.8-1.8-2.5-3-4.6-3m0 7.5c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5M12.9 30c-2 0-3.8 1.2-4.6 3H0v4h8.3c.8 1.8 2.5 3 4.6 3s3.8-1.2 4.6-3h22.4v-4H17.5c-.8-1.8-2.5-3-4.6-3m0 7.5c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5"/></g></g></svg>
    <span>Customize</span>
  </button>
</div>
</div>
    </div>
  </div>


  <div
  class="taboola-container border-t-gray-250 mx-auto my-5 mt-10 max-w-md border-t-4 px-5 pt-10 dark:border-t-gray-600 sm:max-w-3xl lg:max-w-6xl xl:px-0"
>
  <div id="taboola-below-article-thumbnails---at"></div>
</div>
<script type="text/javascript">
  window._taboola = window._taboola || [];
  _taboola.push({
    mode: 'thumbnails-a-6x1',
    container: 'taboola-below-article-thumbnails---at',
    placement: 'Below Article Thumbnails - AT',
    target_type: 'mix'
  });
</script>
  </main>


<div class="ad-wrapper is-fullwidth">
        <div class="ad-wrapper-inner">
            <div class="ad ad--footer"></div>
        </div>
    </div>

<footer class="site-footer bg-black">
  <div class="mx-auto max-w-6xl px-4 text-gray-300">
    <div class="justify-between gap-10 py-8 md:flex">
      <div class="site-footer-statement text-center md:w-3/5 md:text-left">
        <svg class="mb-6 inline h-10 md:mb-4 md:h-12 lg:h-14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 436 144.1"><defs><clipPath id="ars-full-mono_svg__a"><path fill="none" d="M0 0h436v144.1H0z"/></clipPath><clipPath id="ars-full-mono_svg__b"><path fill="none" d="M0 0h436v144.1H0z"/></clipPath></defs><g clip-path="url(#ars-full-mono_svg__a)"><g fill="currentColor" clip-path="url(#ars-full-mono_svg__b)"><path d="M218.8 83.7c-4.4 3.7-8.4 5-12.8 5-7.7 0-12.7-5.3-13.5-14h24.8l.9-5.5h-25.7c.8-8.7 5.7-14.1 12.9-14.1s8.8 1.7 12.9 5.1l1-5.9c-4-2.9-8.8-4.4-13.7-4.3-10.7 0-19.2 7.8-19.2 21.9s8.3 21.9 18.9 21.9c5.2.1 10.2-1.6 14.3-4.8zm-48.7-27.5v36.9h-5.8V56.2h-13.4v-5.3H183l.9 5.3H170Zm74.5 37.6c-11.9 0-19.5-8.8-19.5-21.8s7.8-22 19.6-22c4.3-.1 8.5 1.1 12 3.5l-.9 5.9c-3.2-2.6-7.1-4-11.2-4.1-8.6 0-13.6 6.5-13.6 16.6s5.1 16.6 13.6 16.6c4.3 0 8.5-1.6 11.9-4.2l.9 5.4c-3.7 2.6-8.2 4.1-12.8 4.1M292 93V73.5h-21.4V93h-5.8V50.9h5.8v17.5H292V50.9h5.8V93zm42.9 0-23.2-32.8V93h-5.3V50.9h5.1l22.4 31.5V50.9h5.3V93zm13.4-42.1h5.8V93h-5.8zm32.6 42.9c-11.9 0-19.5-8.8-19.5-21.8s7.8-22 19.6-22c4.3-.1 8.5 1.1 12 3.5l-.9 5.9c-3.2-2.6-7.1-4-11.2-4.1-8.6 0-13.6 6.5-13.6 16.6s5.1 16.6 13.6 16.6c4.3 0 8.5-1.6 11.9-4.2l.9 5.4c-3.7 2.6-8.2 4.1-12.8 4.1m32.9-43.1h5.8l16.3 41.5-5.6 1.2-5-13.1h-17.4L403.1 93h-5.8zm-4 24.6h13.5l-6.8-17.9zM72 0C32.3 0 0 32.3 0 72.1s32.3 72.1 72 72.1 72.1-32.3 72.1-72.1S111.8 0 72 0M53 94h-6.6l-.9-5.9c-4 4.4-9.6 6.8-15.6 6.8-8 0-13-4.8-13-12.3 0-11 9.4-15.4 27.8-17.3v-1.9c0-5.6-3.3-7.5-8.4-7.5S25.8 57.6 21 59.7l-1.1-7.1c5.3-2.1 10.3-3.7 17.1-3.7 10.7 0 15.9 4.3 15.9 14.2v30.8Zm19.2-26v26H64V50h6.6l1.4 9c3.1-5 8.2-9.5 15.5-9.9l1.3 7.9c-7.4.3-13.6 5.2-16.6 11m37.2 26.9c-5.6-.1-11.1-1.6-16.1-4.2l1.2-7.8c4.6 3.2 10 5 15.6 5.1 5.6 0 9-2.1 9-5.8s-2.5-5.6-10.5-7.5C98.2 72.1 94.1 69 94.1 61.1s5.9-12.2 15.6-12.2c5 0 9.9 1 14.5 3l-1.3 7.8c-4.1-2.4-8.7-3.7-13.4-3.8-5 0-7.6 1.9-7.6 5.1s2.2 4.6 9.2 6.4c10.9 2.8 15.8 5.9 15.8 14.3s-6.1 13.2-17.5 13.2"/><path d="M25.2 82.2c0 4.6 2.4 5.9 6.6 5.9s9.4-2.4 13.1-6.2V71.6c-16.3 1.6-19.7 6-19.7 10.6"/></g></g></svg>
        <p>Ars Technica has been separating the signal from
          the noise for over 25 years. With our unique combination of
          technical savvy and wide-ranging interest in the technological arts
          and sciences, Ars is the trusted source in a sea of information. After
          all, you don’t need to know everything, only what’s important.</p>
        <p class="mt-4">
          <a href="https://bsky.app/profile/arstechnica.com" aria-label="Follow Ars Technica on Bluesky">
            <svg class="inline h-12 w-12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="bluesky-logo_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="bluesky-logo_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#bluesky-logo_svg__a)"><g clip-path="url(#bluesky-logo_svg__b)"><path fill="currentColor" d="M14.34 12.38c2.29 1.72 4.76 5.21 5.67 7.08.9-1.87 3.37-5.36 5.66-7.08 1.65-1.24 4.34-2.2 4.34.85 0 .61-.35 5.13-.56 5.86-.71 2.55-3.32 3.2-5.63 2.81 4.05.69 5.07 2.97 2.85 5.25-4.22 4.33-6.07-1.09-6.54-2.47-.09-.26-.13-.37-.13-.27 0-.1-.04.02-.13.27-.47 1.39-2.32 6.81-6.54 2.47-2.22-2.28-1.19-4.56 2.85-5.25-2.31.39-4.92-.26-5.63-2.81-.2-.73-.56-5.25-.56-5.86 0-3.06 2.68-2.1 4.34-.85Z"/></g></g></svg>
          </a>
          <a href="https://mastodon.social/@arstechnica" aria-label="Follow Ars Technica on Mastodon">
            <svg class="inline h-12 w-12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="mastodon-logo_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="mastodon-logo_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#mastodon-logo_svg__a)"><g clip-path="url(#mastodon-logo_svg__b)"><path fill="currentColor" d="M29.15 16.58c0-4.3-2.8-5.6-2.8-5.6-1.4-.7-3.9-.9-6.5-1-2.6 0-5 .3-6.4 1 0 0-2.8 1.3-2.8 5.6v3.4c.1 4.2.8 8.4 4.7 9.5 1.8.5 3.4.6 4.6.5 2.3-.1 3.5-.8 3.5-.8v-1.6s-1.7.5-3.5.4c-1.8 0-3.7-.2-4-2.4v-.6s1.8.4 4 .5c1.4 0 2.7 0 4-.2 2.5-.3 4.7-1.8 5-3.3.4-2.2.4-5.4.4-5.4zm-3.4 5.6h-2.1v-5.1c0-1.1-.5-1.6-1.4-1.6s-1.5.6-1.5 1.9v2.8h-2.1v-2.8c0-1.3-.5-1.9-1.5-1.9s-1.4.5-1.4 1.6v5.1h-2.1v-5.3c0-1.1.3-1.9.8-2.6.6-.6 1.3-1 2.2-1s1.9.4 2.4 1.2l.5.9.5-.9q.75-1.2 2.4-1.2c1.6 0 1.7.3 2.2 1 .6.6.8 1.5.8 2.6v5.3z"/></g></g></svg>
          </a>
          <a href="https://www.facebook.com/arstechnica" aria-label="Follow Ars Technica on Facebook">
            <svg class="inline h-12 w-12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="facebook-logo_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="facebook-logo_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#facebook-logo_svg__a)"><g clip-path="url(#facebook-logo_svg__b)"><path fill="currentColor" d="M17.3 13.8v2.8h-2V20h2v10h4.2V20h2.8s.3-1.6.4-3.4h-3.2v-2.3c0-.3.5-.8.9-.8h2.3V10h-3.1c-4.4 0-4.3 3.4-4.3 3.9"/></g></g></svg>
          </a>
          <a href="https://www.youtube.com/@arstechnica" aria-label="Follow Ars Technica on YouTube">
            <svg class="inline h-12 w-12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="youtube-logo_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="youtube-logo_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#youtube-logo_svg__a)"><g clip-path="url(#youtube-logo_svg__b)"><path fill="currentColor" d="M29.5 15.2c-.1-.4-.3-.8-.6-1.1s-.7-.5-1.1-.7C26.2 13 20 13 20 13s-6.3 0-7.8.4c-.4.1-.8.3-1.1.7-.3.3-.5.7-.6 1.1-.4 1.6-.4 4.8-.4 4.8s0 3.3.4 4.8c.1.4.3.8.6 1.1s.7.5 1.1.7c1.6.4 7.8.4 7.8.4s6.3 0 7.8-.4c.4-.1.8-.3 1.1-.7s.5-.7.6-1.1c.4-1.6.4-4.8.4-4.8s0-3.3-.4-4.8M17.9 23v-5.9l5.2 3-5.2 3z"/></g></g></svg>
          </a>
          <a href="https://www.instagram.com/arstechnica/" aria-label="Follow Ars Technica on Instagram">
            <svg class="inline h-12 w-12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="insta-logo_svg__a"><path fill="none" d="M0 0h40v40H0z"/></clipPath><clipPath id="insta-logo_svg__b"><path fill="none" d="M0 0h40v40H0z"/></clipPath></defs><g clip-path="url(#insta-logo_svg__a)"><g clip-path="url(#insta-logo_svg__b)"><path fill="currentColor" d="M20 10h4.1c1.1 0 1.8.2 2.4.5.7.3 1.2.6 1.8 1.2s.9 1.1 1.2 1.8c.2.6.4 1.4.5 2.4v8.2c0 1.1-.2 1.8-.5 2.4-.3.7-.6 1.3-1.2 1.8-.6.6-1.1.9-1.8 1.2-.6.2-1.4.4-2.4.5h-8.2c-1.1 0-1.8-.2-2.4-.5-.7-.3-1.3-.6-1.8-1.2q-.75-.75-1.2-1.8c-.2-.6-.4-1.4-.5-2.4v-8.2c0-1.1.2-1.8.5-2.4.3-.7.6-1.2 1.2-1.8s1.1-.9 1.8-1.2c.6-.2 1.4-.4 2.4-.5zm0 2.5h-3.7c-.9 0-1.4.2-1.7.3-.4.1-.8.4-1.1.7s-.5.6-.7 1.1c-.1.3-.3.8-.3 1.7v7.4c0 .9.2 1.4.3 1.7.2.4.4.7.7 1.1.3.3.6.5 1.1.7.3.1.8.3 1.7.3h7.4c.9 0 1.4-.2 1.7-.3.4-.2.7-.4 1.1-.7.3-.3.5-.6.7-1.1.1-.3.3-.8.3-1.7v-7.4c0-.9-.2-1.4-.3-1.7-.1-.4-.4-.8-.7-1.1s-.7-.5-1.1-.7c-.3-.1-.8-.3-1.7-.3zm0 2.2c.7 0 1.4.1 2 .4s1.2.7 1.7 1.1c.5.5.9 1.1 1.1 1.7.3.6.4 1.3.4 2s-.1 1.4-.4 2-.7 1.2-1.1 1.7c-.5.5-1.1.9-1.7 1.1-.6.3-1.3.4-2 .4-1.4 0-2.7-.6-3.7-1.5-1-1-1.5-2.3-1.5-3.7s.6-2.7 1.5-3.7 2.3-1.5 3.7-1.5m0 8.3q1.2 0 2.1-.9T23 20c0-1.2-.3-1.5-.9-2.1S20.8 17 20 17c-1.2 0-1.5.3-2.1.9q-.9.9-.9 2.1c0 1.2.3 1.5.9 2.1q.9.9 2.1.9m6.6-8.1c0 .4-.2.7-.4 1s-.6.4-1 .4-.7-.2-1-.4c-.3-.3-.4-.6-.4-1s.2-.7.4-1c.3-.3.6-.4 1-.4s.7.2 1 .4c.3.3.4.6.4 1"/></g></g></svg>
          </a>
        </p>
      </div>
      <div class="text-center md:w-1/5 md:text-left">
        <span class="font-impact mb-4 mt-6 block font-semibold uppercase">More
          from Ars
        </span>
        <ul id="menu-more_navigation" class="menu"><li id="menu-item-1971876" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1971876"><a href="https://arstechnica.com/about-us/">About Us</a></li>
<li id="menu-item-1971877" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1971877"><a href="https://arstechnica.com/staff-directory/">Staff Directory</a></li>
<li id="menu-item-1971878" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1971878"><a href="https://arstechnica.com/newsletters/">Newsletters</a></li>
<li id="menu-item-1980432" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-1980432"><a href="https://arstechnica.com/video/">Ars Videos</a></li>
<li id="menu-item-1971879" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1971879"><a href="https://arstechnica.com/general-faq/">General FAQ</a></li>
<li id="menu-item-1971880" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1971880"><a href="https://arstechnica.com/rss-feeds/">RSS Feeds</a></li>
</ul>
      </div>
      <div class="text-center md:w-1/5 md:text-left">
        <span class="font-impact mb-4 mt-6 block font-semibold uppercase">Contact</span>
        <ul id="menu-contact_navigation" class="menu"><li id="menu-item-1971881" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1971881"><a href="https://arstechnica.com/contact-us/">Contact us</a></li>
<li id="menu-item-1971884" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-1971884"><a target="_blank" href="https://www.condenast.com/brands/ars-technica">Advertise with us</a></li>
<li id="menu-item-1971882" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1971882"><a href="https://arstechnica.com/reprints/">Reprints</a></li>
</ul>
      </div>
    </div>

    <div class="pb-10 pt-5" id="copyright-terms">
              <div class="mb-4 flex flex-row flex-nowrap items-center gap-2">
          <svg class="h-4" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 30 14"><path d="M7.4 12.8h6.8l3.1-11.6H7.4C4.2 1.2 1.6 3.8 1.6 7s2.6 5.8 5.8 5.8" style="fill-rule:evenodd;clip-rule:evenodd;fill:#fff"/><path d="M22.6 0H7.4c-3.9 0-7 3.1-7 7s3.1 7 7 7h15.2c3.9 0 7-3.1 7-7s-3.2-7-7-7m-21 7c0-3.2 2.6-5.8 5.8-5.8h9.9l-3.1 11.6H7.4c-3.2 0-5.8-2.6-5.8-5.8" style="fill-rule:evenodd;clip-rule:evenodd;fill:#06f"/><path d="M24.6 4c.2.2.2.6 0 .8L22.5 7l2.2 2.2c.2.2.2.6 0 .8s-.6.2-.8 0l-2.2-2.2-2.2 2.2c-.2.2-.6.2-.8 0s-.2-.6 0-.8L20.8 7l-2.2-2.2c-.2-.2-.2-.6 0-.8s.6-.2.8 0l2.2 2.2L23.8 4c.2-.2.6-.2.8 0" style="fill:#fff"/><path d="M12.7 4.1c.2.2.3.6.1.8L8.6 9.8c-.1.1-.2.2-.3.2-.2.1-.5.1-.7-.1L5.4 7.7c-.2-.2-.2-.6 0-.8s.6-.2.8 0L8 8.6l3.8-4.5c.2-.2.6-.2.9 0" style="fill:#06f"/></svg>
          <a class="ot-sdk-show-settings" id="ot-sdk-btn">Do Not Sell My Personal
            Information</a>
        </div>
      
      © 2024 Condé Nast. All rights reserved. Use of and/or
      registration on any portion of this site constitutes acceptance of our <a
        href="https://www.condenast.com/user-agreement/">User Agreement</a> and
      <a href="https://www.condenast.com/privacy-policy/">Privacy Policy and
        Cookie Statement</a> and <a href="/amendment-to-conde-nast-user-agreement-privacy-policy/">Ars
        Technica Addendum</a> and <a href="https://www.condenast.com/privacy-policy/#california">Your
        California Privacy Rights</a>. Ars Technica may earn compensation on
      sales from links on this site. <a href="/affiliate-link-policy/">Read our
        affiliate link policy</a>. The material on this site may not be
      reproduced, distributed, transmitted, cached or otherwise used, except
      with the prior written permission of Condé Nast. <a href="https://www.aboutads.info/">Ad
        Choices</a>
    </div>
  </div>
</footer>
  </div>

    <script type="text/javascript" src="https://s.skimresources.com/js/100098X1555750.skimlinks.js"></script>
<script>
  (function() {
    const div = document.querySelector('.ars-interlude-container');
    if (!div) {
      return;
    }

    // Exclude on sponsored posts
    if (document.querySelector('.single-ars_sponsored_post')) {
      return;
    }

    // If on an article page and the interlude container exists
    if (document.querySelector('body.single')) {
      const parent = div.parentElement;

      // Get all the top level elements in the parent that aren't the interlude container
      const elems = Array.from(parent.children).filter((elem) => elem !== div);
      // Loop over the elements in reverse order
      for (let i = elems.length - 1; i >= 0; i--) {
        const elem = elems[i];
        // If the next element isn't one of: h1, h2, h3, h4, h5, h6, or div, insert the interlude container before it
        const nextElem = elems[i - 1];
        if (nextElem && !['H1', 'H2', 'H3', 'H4', 'H5', 'H6', 'DIV'].includes(nextElem.tagName)) {
          // Add .my-5 to the interlude container
          div.classList.add('my-5');
          parent.insertBefore(div, elem);
          break;
        }
      }
    }
    const src =
      'https://player.cnevids.com/interlude/arstechnica.js';
    const s = document.createElement('script');
    s.setAttribute('async', true);
    s.setAttribute('src', src);
    document.body.appendChild(s);
  })();
</script>
<!-- Parse.ly start -->
<script type="text/plain" class="optanon-category-C0002" id="parsely-cfg" src="//fpa-cdn.arstechnica.com/keys/arstechnica.com/p.js"></script>
<!-- Parse.ly end -->
<script id="snowplow-js-before">
window.snowplowQueue = window.snowplowQueue || []; window.snowplowContexts = {"site":{"orgId":"4gKgcFGUFUvCGFzHakTPfYp85Yi8","orgAppId":null,"appVersion":null,"env":"production"},"content":{"functionalTags":null,"hasBuyButtons":null,"noOfRevisions":null,"editorNames":null,"author_name":"Timothy B. Lee","contentId":"2067918","contentLength":4,"contentTitle":"Why AI language models choke on too much text","contentSource":"web","authorIds":"45993","publishDate":"2024-12-20T13:00:56Z","modifiedDate":"2024-12-19T22:21:38Z","tags":"AI|Anthropic|context windows|google deepmind|LLMs|openai","contentLang":"en-US","galleryName":null,"totalGalleryImages":null,"wordCount":3035,"contentType":null,"templateType":"article_standard_two_column","primaryTag":null,"contentFlag":"news","isCommerceContent":null,"pageTypeProperties":null,"section":"ai","subsection":null,"subsection2":null,"dataSource":"web","content_type":"article"},"syndication":{"content":null,"originalSource":null,"originalContentLanguage":null},"page":{"canonical":"https:\/\/arstechnica.com\/ai\/2024\/12\/why-ai-language-models-choke-on-too-much-text\/","syndicatorUrl":null},"user":{"amguuid":null}}; window.snowplowConfig = {"SNOWPLOW_COLLECTOR":"c.arstechnica.com","SNOWPLOW_SCRIPT":"https:\/\/globalservices.conde.digital\/p77xzrbz9z.js","AVO_API_KEY":"FTJO6mVPBIzdGhjn2Ruy","APP_ID":"ars-technica","APP_NAME":"ars-technica","APP_ENV":"production","APP_VERSION":"1.0.0","COOKIE_DOMAIN":".arstechnica.com"};
</script>
<script src="https://cdn.arstechnica.net/wp-content/mu-plugins/ars-snowplow/ars-snowplow-js/dist/main-1-0-4.js?ver=1.0.4" id="snowplow-js"></script>
<script src="https://cdn.arstechnica.net/wp-content/plugins/article-forum-connect/public/js/iframe-resizer.parent.js?ver=5.3.1" id="article_forum_connect_iframe_resizer-js"></script>
<script src="https://cdn.arstechnica.net/wp-content/plugins/article-forum-connect/public/js/iframe.js?ver=1.2.4" id="article_forum_connect_iframe-js"></script>
<script id="app/0-js-before">
(()=>{"use strict";var r,e={},o={};function t(r){var a=o[r];if(void 0!==a)return a.exports;var n=o[r]={exports:{}};return e[r](n,n.exports,t),n.exports}t.m=e,r=[],t.O=(e,o,a,n)=>{if(!o){var i=1/0;for(v=0;v<r.length;v++){for(var[o,a,n]=r[v],s=!0,l=0;l<o.length;l++)(!1&n||i>=n)&&Object.keys(t.O).every((r=>t.O[r](o[l])))?o.splice(l--,1):(s=!1,n<i&&(i=n));if(s){r.splice(v--,1);var u=a();void 0!==u&&(e=u)}}return e}n=n||0;for(var v=r.length;v>0&&r[v-1][2]>n;v--)r[v]=r[v-1];r[v]=[o,a,n]},t.d=(r,e)=>{for(var o in e)t.o(e,o)&&!t.o(r,o)&&Object.defineProperty(r,o,{enumerable:!0,get:e[o]})},t.o=(r,e)=>Object.prototype.hasOwnProperty.call(r,e),(()=>{var r={121:0};t.O.j=e=>0===r[e];var e=(e,o)=>{var a,n,[i,s,l]=o,u=0;if(i.some((e=>0!==r[e]))){for(a in s)t.o(s,a)&&(t.m[a]=s[a]);if(l)var v=l(t)}for(e&&e(o);u<i.length;u++)n=i[u],t.o(r,n)&&r[n]&&r[n][0](),r[n]=0;return t.O(v)},o=globalThis.webpackChunk_roots_bud_sage=globalThis.webpackChunk_roots_bud_sage||[];o.forEach(e.bind(null,0)),o.push=e.bind(null,o.push.bind(o))})()})();
</script>
<script src="https://cdn.arstechnica.net/wp-content/themes/ars-v9/public/js/app.3d0053.js" id="app/0-js"></script>
<script src="https://cdn.arstechnica.net/wp-content/themes/ars-v9/public/js/ads.ae0b0b.js" id="ads/0-js"></script>
<script src="https://cdn.arstechnica.net/wp-content/themes/ars-v9/public/js/stats.ff665f.js" id="stats/0-js"></script>
</body>

</html>