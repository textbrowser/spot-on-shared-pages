New LLM Jailbreak Uses Models' Evaluation Skills Against Them