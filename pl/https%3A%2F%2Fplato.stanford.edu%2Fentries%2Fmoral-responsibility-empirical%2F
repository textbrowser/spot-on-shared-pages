<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html lang="en"> <!-- <![endif]-->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Empirical Approaches to Moral Responsibility (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Empirical Approaches to Moral Responsibility" />
<meta property="citation_author" content="Sripada, Chandra" />
<meta property="citation_publication_date" content="2025/06/11" />
<meta name="DC.title" content="Empirical Approaches to Moral Responsibility" />
<meta name="DC.creator" content="Sripada, Chandra" />
<meta name="DCTERMS.issued" content="2025-06-11" />
<meta name="DCTERMS.modified" content="2025-06-11" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP home page" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
                    <li role="menuitem"><a href="../../new.html">What's New</a></li>
                    <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li role="menuitem"><a href="../../published.html">Chronological</a></li>
                    <li role="menuitem"><a href="../../archives/">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
                    <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
                    <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
                    <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
                    <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
                    <li role="menuitem"><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
                    <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
                    <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="../../search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit" aria-label="search"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/moral-responsibility-empirical/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=moral-responsibility-empirical">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Empirical Approaches to Moral Responsibility</h1><div id="pubinfo"><em>First published Wed Jun 11, 2025</em></div>

<div id="preamble">

<p>
What are the conditions under which an agent is morally responsible
for some action that they have performed? Put another way, and
acknowledging that this rephrasing might be contentious, what are the
conditions under which it would be appropriate to praise or blame the
agent for something they have done? (Strawson 1962; Wallace 1998;
Coates &amp; Tognazzini 2013). An account of moral responsibility
supplies answers to these questions. (See the entry on
 <a href="../moral-responsibility/" target ="other">&ldquo;Moral Responsibility&rdquo;</a>).</p>
 
<p>
Most theorists agree that moral responsibility requires satisfying at
least two core conditions. The first is a <em>control</em> condition;
the agent must have the right sort of control over what they do
(Dennett 1984; Fischer &amp; Ravizza 1998; Shepherd 2014). Such
control would be lacking in cases involving force or coercion. The
second is an <em>epistemic condition</em>; the agent must know certain
things, such as what they are doing and the moral reasons that bear on
their actions (Wieland &amp; Robichaud 2017; Zimmerman 1997). The
epistemic condition would be violated if a person does something out
of ignorance, especially if their ignorance is itself non-culpable.
See the entry by Fernando Rudy-Hiller on &ldquo;The Epistemic
Condition for Moral Responsibility&rdquo; in this encyclopedia.</p>

<p>
Some of the work in constructing an account of moral responsibility is
conducted from the &ldquo;armchair&rdquo; (Daniels 1979; Williamson
2007). Theorists put forward plausible principles for when an agent is
morally responsible for what they do. They check these principles for
consistency with other principles and with reactions to specific
hypothetical cases. They revise these principles and reactions to
cases in the direction of greater coherence, simplicity,
explanatoriness, elegance, and so forth.</p>

<p>
Yet, consistent with the view that there is no sharp demarcation
between philosophical and scientific inquiry (Quine 1957; Stich 1996),
there could be many ways empirical evidence might be relevant to the
task of constructing an account of moral responsibility. For example,
we might believe that ordinary adults have the kind of control that is
needed to satisfy the control condition for moral responsibility,
while individuals with certain mental disorders, such as addiction,
lack this kind of control. Empirical investigations might help
identify what is possessed by the former and lacked by the latter.</p>

<p>
This example, and others to be discussed below, highlight that
findings from the natural sciences, especially about reasoning,
deliberation, belief formation, action selection, and self-control,
among other topics, can potentially inform accounts of moral
responsibility and application of these accounts to difficult
real-world cases.</p>

<p>
This entry examines four areas in which empirical insights have been
fruitful aids in constructing and applying theories of moral
responsibility. The focus is on work in empirical fields examining the
mechanisms of agency, especially psychology, neuroscience,
computational cognitive science, and artificial intelligence.</p>

<p>
Of note, this entry does not take up findings from experimental
philosophy, understood as the study of folk judgments about
philosophically relevant cases (Mallon 2016). Experimental philosophy
understood this way is about ordinary attributions of moral
responsibility, especially ordinary intuitive judgments. The focus of
this entry is, instead, on actual mechanisms of mind and agency, as
revealed by empirical sciences, that have relevance for constructing
and applying theories of moral responsibility.</p>

<p>
Also, two topics are not discussed here: situationism and implicit
bias. These topics fall within the scope of this entry, but they are
covered at length in the entries in this encyclopedia by Christian
Miller on &ldquo;Empirical Approaches to Moral Character&rdquo; and by
Michael Brownstein on &ldquo;Implicit Bias&rdquo;.</p>
</div> 

<div id="toc"><!--Entry Contents-->
<ul>
	<li><a href="#AddImpCon">1. Addiction and Impaired Control</a>

	<ul>
		<li><a href="#WhaAdd">1.1 What is Addiction?</a></li>
		<li><a href="#AddInvIrrDes">1.2 Addiction Involves Irresistible Desires</a></li>
		<li><a href="#AddInvDesVerHarRes">1.3 Addiction Involves Desires That Are Very Hard to Resist</a></li>
		<li><a href="#PeoWhoUseDruDoNotHavImpCon">1.4 People Who Use Drugs Do Not Have Impaired Control</a></li>
		<li><a href="#WhaStaDeb">1.5 What Is at Stake in the Debate?</a></li>
	</ul>
	</li>
	<li><a href="#ResForSpoCon">2. Responsibility for Spontaneous Conduct</a>
	<ul>
		<li><a href="#CasFor">2.1 A Case of Forgetting</a></li>
		<li><a href="#OpeUpBlaBox">2.2 Opening Up the Black Box</a></li>
		<li><a href="#HowFinCogSciInfAssMorRes">2.3 How Findings from Cognitive Science Inform Assessments of Moral Responsibility</a></li>
	</ul>
	</li>
	<li><a href="#MorResEtiIgn">3. Moral Responsibility and the Etiology of Ignorance</a>
	<ul>
		<li><a href="#EpiConCulIgn">3.1 The Epistemic Condition and Culpable Ignorance</a></li>
		<li><a href="#CulMorIgn">3.1 Culture and Moral Ignorance</a></li>
		<li><a href="#SocNetBadBel">3.2 Social Networks and &ldquo;Bad Beliefs&rdquo;</a></li>
	</ul>
	</li>
	<li><a href="#MorResArtAge">4. Moral Responsibility and Artificial Agents</a>
	<ul>
		<li><a href="#AgeMod">4.1 The Agent Model</a></li>
		<li><a href="#WhaNeeForArtAgeMorResForWhaTheDo">4.2 What Is Needed for Artificial Agents to be Morally Responsible for What They Do?</a>
		<ul>
			<li><a href="#TemExtProPla">4.2.1 Temporally Extended Projects and Plans</a></li>
			<li><a href="#MorSenAccMorRea">4.2.2 A Moral Sense and Access to Moral Reasons</a></li>
			<li><a href="#Con">4.2.3 Consciousness</a></li>
			<li><a href="#UltCon">4.2.4 &ldquo;Ultimate&rdquo; Control</a></li>
		</ul>
		</li>
		<li><a href="#FutMorRes">4.3 The Future of Moral Responsibility</a></li>
	</ul>
	</li>
	<li><a href="#Bib">Bibliography</a></li>
	<li><a href="#Aca">Academic Tools</a></li>
	<li><a href="#Oth">Other Internet Resources</a></li>
	<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->

<hr /></div>

<div id="main-text">

<h2 id="AddImpCon">1. Addiction and Impaired Control</h2>

<p>
Addiction figures frequently in contemporary works on moral
responsibility because it is supposed to illustrate a canonical way
that agency goes awry. We are usually authors of our actions; what we
do is up to us. Many philosophers and other theorists claim that this
is not so for individuals addicted to drugs. These theorists claim
that these individuals are not morally responsible for their
drug-directed actions, or else responsibility is to an important
degree mitigated.</p>

<p>
To better understand and assess these claims, we must get clear on a
number of empirical questions about the nature of addiction and the
ways it impacts agency&mdash;specifically addiction to drugs such as
alcohol or opiates, which have been the focus of philosophical
interest.</p>

<h3 id="WhaAdd">1.1 What is Addiction?</h3>

<p>
Addiction is a complex and heterogeneous phenomenon (Glackin et al.
2021), and it is best conceptualized as encompassing several
importantly distinct components (Griffiths 2005; Sussman &amp; Sussman
2011; Sinnott-Armstrong &amp; Pickard 2013). These components include
excessive use despite deleterious consequences, physiological changes
including tolerance and withdrawal, and excessive time spent on
drug-related activities, which crowds out other aspects of life. These
components are reflected in the criteria for substance use disorders
in the Diagnostic and Statistical Manual of Mental Disorders (American
Psychiatric Association &amp; DSM-5 Task Force 2013), a widely used
text for psychiatric diagnosis and classification.</p>

<p>
Impaired control is another important component of addiction that is
conceptually distinct from the previous three (Heather 1998, 2020;
Sripada 2022). The hallmark of impaired control is that a person with
(sincerely held) goals to cut down or quit has an inability to get
themselves to reach or maintain these goals. As noted earlier, control
is a core condition for moral responsibility. Naturally, then, this
fourth component of addiction, impaired control, has garnered the most
philosophical attention, and it shall be our focus. What is the nature
of impaired control in addiction?</p>

<h3 id="AddInvIrrDes">1.2 Addiction Involves Irresistible Desires</h3>

<p>
One possibility is that impaired control in addiction arises from
irresistible desires. Very roughly, a desire is irresistible if it is
so strong that the person cannot resist it no matter how hard they
try, though pinning down the idea with more precision is challenging
(Mele 1990; Pickard 2015). A particularly vivid depiction of
irresistible addictive desires comes from Harry Frankfurt, who gives
us the haunting figure of the unwilling addict:</p>

<p>
[The man] hates his addiction and always struggles desperately,
although to no avail, against its thrust. He tries everything that he
thinks might enable him to overcome his desires for the drug. But
these desires are too powerful for him to withstand, and invariably,
in the end, they conquer him. He is an unwilling addict, helplessly
violated by his own desires. (Frankfurt 1971, p. 12)</p>

<p>
The idea that addiction involves irresistible desires was famously
endorsed by William James (James 1890) and has been widespread in
philosophy, for example, in Fischer (2012, Section 2.2), Fischer and
Ravizza (1998, p. 82), Wolf (1993, Chapter 2), Scanlon (1998, p. 290),
and Wallace (1998, Chapter 5), among others. But is the idea accurate?
Does impaired control in addiction typically take the form of desires
too powerful for a person to withstand?</p>

<p>
The answer appears to be, fairly clearly, no. Hanna Pickard provides
an influential critique of the idea that that conditions such as
addiction involve motives so strong that the person &ldquo;cannot do
otherwise&rdquo; (Pickard 2015). A key observation is that individuals
with addictions display substantial &ldquo;incentive
sensitivity&rdquo;: they both act and withhold actions related to drug
use based on incentives and disincentives for doing so (Pickard 2012;
Hart 2013; Husak 1992; Heyman 2009; Sripada 2022). So, for example,
they avoid drug use when negative consequences are clearly and
saliently present, for example when a police officer is &ldquo;at the
elbow&rdquo; (Morse 2000; Caplan 2006), and they choose to forsake
using drugs if offered only modest-sized incentives (Hart et al. 2000;
Higgins &amp; Petry 1999). Additionally, many individuals with
addictions routinely attempt to quit, and typically manage to maintain
sobriety for days and weeks, something that would not be possible if
drug-directed desires are literally irresistible (Pickard 2015).</p>

<h3 id="AddInvDesVerHarRes">1.3 Addiction Involves Desires That Are Very Hard to Resist</h3>

<p>
Faced with the preceding observations, many theorists retreat to a
weaker claim: In addiction, drug-directed desires are not literally
irresistible, but they are somehow uniquely <em>hard</em> or
<em>difficult</em> to resist (claims along these lines are found in
Watson 1999; Wallace 1999; Kennett 2013; Levy 2006; Henden, Melberg,
and Rogeberg 2013; Morse 2002; Holton and Berridge 2013 and Burdman
2022). There are several potential problems for these &ldquo;hard to
resist&rdquo; views.</p>

<p>
First of all, there are active philosophical disagreements about how
best to understand the notion of &ldquo;hard&rdquo; or
&ldquo;difficult&rdquo; (Bradford 2015). One sense of
something&rsquo;s being hard emphasizes subjective effort
(Berm&uacute;dez &amp; Massin 2023). This sense seems to be at work
when it is said that it is hard to lift a hefty but ultimately
manageable weight, say 50 pounds. The weight is not unliftable, but it
is not easy to lift&mdash;it takes some effort and feels somewhat
aversive to do it.</p>

<p>
But if this is the sense of &ldquo;hard&rdquo; at issue, it is not
clear that something&rsquo;s being hard or difficult counts as a form
of impaired control that contributes to an excuse from moral
responsibility. For example, here are some things that are hard in
this effortful sense: going to work early in the morning, grading
poorly written student papers, and cleaning up a baby&rsquo;s messy
diaper. Though these things are hard to do, it is a leap to say that
we have impaired control over these things, or that we are excused
from moral responsibility if we fail to do these things.</p>

<p>
There is, in addition, an empirical problem for this &ldquo;hard to
resist&rdquo; view under consideration. A number of studies have asked
people to rate the strength of their drug-directed desires. These
studies typically find that these desires are rated fairly moderately;
notably, people almost never rate them using whatever is the highest
rating the survey allows (Hofmann, Baumeister, et al. 2012; Hofmann,
Vohs, et al. 2012; Preston et al. 2009).</p>

<p>
Perhaps, then, one might offer an alternative analysis of what it
means for one&rsquo;s drug-directed desires to be &ldquo;hard&rdquo;
to resist or otherwise control. Drawing on a picture rooted in
cognitive behavioral therapy, Sripada (2021) proposes that many
individuals with addiction experience distorted automatic impressions
and evaluations. They inaccurately &ldquo;see&rdquo; their self as
inadequate, the world as harsh, their future as bleak, their ability
to cope without drugs as limited, their relief from using drugs as
substantial, and so on. As a result, they engage in drug use (see
Pickard (2016) and Flanagan (2013) for additional perspectives on
distortions in addiction). These distortions that lie at the root of
drug seeking are &ldquo;hard&rdquo; to control in the sense that they
are difficult for the person to recognize and correct. More
specifically, people are highly <em>unreliable</em>, in a statistical
sense, at recognizing and correcting distorted impressions&mdash;they
succeed sometimes but many times they don&rsquo;t. On this model, the
person has impaired control not over their drug-directed desires
directly, but rather over their distorted impressions and evaluations,
which in turn are the source of their seeking to use drugs.</p>

<h3 id="PeoWhoUseDruDoNotHavImpCon">1.4 People Who Use Drugs Do Not Have Impaired Control</h3>

<p>
Thus far we have been assuming that addiction involves some kind of
impaired control over use of drugs and have examined several accounts
of what this impaired control amounts to. Not everyone, however,
subscribes to this assumption. Some theorists have been attracted to
the position that people who use drugs heavily (and meet many of the
conventional criteria for the diagnosis of addiction) do not genuinely
have impaired control at all (Foddy &amp; Savulescu 2007, 2010; Hart
2013; Heyman 2009). See also Pickard 2012, for a nuanced related
position.</p>

<p>
On these views, choices to use drugs, even substantial quantities of
drugs, are made freely, rationally, and with full control. We may
disagree morally with the choices these individuals make. We may not
be privy to some of the instrumental goals that they are trying to
achieve. But they choose rationally and their control is
unimpaired.</p>

<p>
There are, however, some serious problems with these &ldquo;purposive
choice&rdquo; views. A typical pattern in addiction is that the person
attempts to cut back or quit and has some temporary success (i.e.,
often days to weeks), but eventually resumes regular patterns of use,
with this cycle typically repeating multiple times (Dennis et al.
2007; Hunt et al. 1971; Kirshenbaum et al. 2009; McLellan et al.
2000). Also, in order to maintain sobriety, people with addiction
frequently undertake interventions that are costly in terms of time,
money, and other burdens and risks. For example, they join therapeutic
communities (requiring meetings multiple times a week), attend
counseling sessions, and undertake onerous drug treatments that
require close clinical supervision. These observations seem
inconsistent with the claim that drug use is chosen freely,
purposively, and with full control.</p>

<h3 id="WhaStaDeb">1.5 What Is at Stake in the Debate?</h3>

<p>
Philosophers frequently assert that addiction is a paradigmatic
real-world case in which individuals fail to meet the control
condition for moral responsibility. But the empirical literature is
far more tentative and unsure. Claims that addiction involves impaired
control face serious challenges, and theorists have struggled to
specify in detail the nature of the supposed control impairments. But
claims that addiction does not involve impaired control also face
serious difficulties. Work on the issue is ongoing, but meanwhile
questions of moral responsibility for individuals with addiction hang
in the balance. Whether and to what degree individuals with addiction
are morally responsible depend importantly on exactly how the
empirical cards get settled.</p>

<h2 id="ResForSpoCon">2. Responsibility for Spontaneous Conduct</h2>

<p>
Suppose a person does something morally criticizable. They deliberate
carefully. They reflect on and endorse their relevant (morally flawed)
motives. They form a judgment about what to do and follow through on
it. Putting global forms of skepticism aside, assessing moral
responsibility is relatively straightforward in cases like these, and
most theories deliver similar verdicts. Assuming no defeaters are
present, the person is morally responsible for their morally
criticizable actions.</p>

<p>
But many of our actions, in fact most, do not arise from deliberation;
they arise spontaneously and unreflectively. A number of authors,
including George Sher, Tim Scanlon, Angela Smith, and Santiago Amaya
have pointed out that we can be morally responsible for various kinds
of spontaneous conduct, including how we direct attention, what we
notice and fail to notice, what we remember and forget, what we dwell
on or ignore, our spur-of-the-moment actions (e.g., blurting something
out), our momentary slips or lapses, our unwitting omissions, and so
forth (Sher 2006, 2009; Scanlon 1998; A. Smith 2005, 2008; Amaya 2013;
Amaya &amp; Doris 2015; Nelkin &amp; Rickless 2017).</p>

<h3 id="CasFor">2.1 A Case of Forgetting</h3>

<p>
To make matters more concrete, consider a case from Samuel Murray and
Manuel Vargas that they call &ldquo;Bourbon.&rdquo;</p>

<p>
As Randy is about to leave his home for the office, Al calls to tell
him that they are out of bourbon. His regular route to the office
takes him right by a liquor store, and Randy tells Al he&rsquo;ll buy
some. Between his home and the liquor store, Randy starts thinking
about a paper he is writing on omissions. He continues thinking about
his work until he arrives at the department, where he realizes that he
has forgotten the bourbon. (Murray &amp; Vargas 2020, p. 826)</p>

<p>
Randy did not step back, reflect, and then deliberately violate his
promise to bring the bourbon. Yet he is, it seems, morally responsible
for what he did, or in this case, what he failed to do (Nelkin &amp;
Rickless 2017; Clarke 2014; Amaya &amp; Doris 2015; Murray &amp;
Vargas 2020). Notice that it seems appropriate for Randy to apologize
to Al, and that he might perhaps be forgiven, which further support
this impression.</p>

<p>
Yet, even if we are inclined to say that Randy is morally responsible,
it is not at all clear how he could be because it is hard to see how
he can satisfy the control and epistemic conditions for moral
responsibility. After all, it seems odd to say that Randy was <em>in
control</em> of his forgetting or that he <em>knew</em> he was
forgetting (Murray &amp; Vargas 2020; Nelkin &amp; Rickless 2017).</p>

<p>
Notice further that whatever the psychological processes that led to
Randy&rsquo;s forgetting, they don&rsquo;t seem to resemble very much
the processes at work in producing deliberative actions, the more
familiar case studied in the moral responsibility literature. As
Murray and Vargas put the point:</p>

<p>
The problem is that in <em>Bourbon</em>&mdash;and relevantly similar
cases&mdash;the offending agent&rsquo;s conduct lacks all familiar
actional and valuative antecedents that might ground responsibility.
There is no decision, volition, intention, belief, desire, choice, or
judgment (among other things). (Murray &amp; Vargas, 2020, p. 826)</p>

<p>
When confronted with cases such as <em>Bourbon</em>, an important yet
underexplored next question is this: What exactly <em>are</em> the
processes that generate spontaneous conduct? Are these processes
simple and reflex-like? Or do they reflect more sophisticated forms of
agency?</p>

<p>
In asking these questions, we are acknowledging that it is implausible
that we can simply treat the mechanisms that produce spontaneous
conduct as a black box. Instead, it is likely that we need to get
clear on the mechanistic underpinnings of why Randy did what he did
before we can decide if he is morally responsible for his conduct.</p>

<h3 id="OpeUpBlaBox">2.2 Opening Up the Black Box</h3>

<p>
A first step is to map the language of the <em>Bourbon</em> case into
more precise, empirically tractable constructs. We are told that Randy
&ldquo;starts thinking&rdquo; about omissions during the trip. This in
turn might plausibly be understood in terms of the allocation of
attention: Randy attends to an internally generated stream of thought
that pertains to omissions rather than other things that he could be
attending to, such as thoughts about getting the bourbon. His
allocation of attention to omissions is harmless until he is near the
store. Unfortunately, he continues to allocate attention to omissions
rather than the goal of getting bourbon, and so he passes by the store
and arrives to his destination empty handed.</p>

<p>
Having reconstructed the <em>Bourbon</em> case in terms of attention
allocation, we can next turn to the substantial body of empirical work
that illuminates how attention allocation works. Much of this work
specifically studies allocation of visual attention to spatially
arrayed external targets. Nonetheless, it is widely thought that
allocation of attention to candidate internal targets&mdash;for
example, thoughts or memory items&mdash;follows similar principles
(Chun et al. 2011; Kiyonaga &amp; Egner 2013).</p>

<p>
According to a leading model, choices to allocate attention to
candidate targets arise from integrated priority maps (Fecteau &amp;
Munoz 2006; Zelinsky &amp; Bisley 2015; Theeuwes et al. 2022). These
are maps that assign to each candidate attentional target a scalar
score that represents the expected value of attending to that target.
On the basis of these priority maps, the person chooses to attend to
the target with highest value. Of course, due to the selectivity of
attention, this implies the person is not attending (or perhaps not
attending sufficiently) to the other candidate targets of
attention.</p>

<p>
The priority map model of attention allocation fits nicely with a much
broader picture of the etiology of spontaneous conduct that has
emerged in computational cognitive science (Rangel et al. 2008; Rangel
&amp; Hare 2010; Busemeyer &amp; Townsend 1993; Carruthers 2018;
Railton 2017a; Haas 2022, forthcoming; Sripada, 2025). According to
this model, the mind houses an extensive set of algorithms for the
ongoing calculation of the expected value of one&rsquo;s actional
options, where the value at issue is instrumental value relative to a
person&rsquo;s more basic aims, goals, and priorities. On this
picture, one&rsquo;s spontaneous conduct, which can sometimes feel
reflexive or automatic, is actually the product of rapid decisions
made on the basis of representations of the expected value of the
options.</p>

<p>
We can distinguish two kinds of processes operative in the priority
map model of attention allocation. First, there is a set of processes
that leads to the construction of priority maps. These are
<em>subpersonal</em> processes that integrate a number of cues into an
overall expected value representation that attaches to each
attentional target (Anderson &amp; Kim 2018; Failing &amp; Theeuwes
2018). Second, there is a set of rapid decision processes that
translate priority map value representations into actual choices about
the target to which attention is in fact allocated (Forstmann et al.
2016; Ratcliff &amp; McKoon 2007). Importantly, the rapid decisions
implemented by this second set of processes are <em>person-level</em>
events. This accords well with first person phenomenology. Allocations
of attention aren&rsquo;t simply happenings within one&rsquo;s
psychology; they are something that the <em>person</em> does (Watzl
2017; Wu 2023).</p>

<p>
Adopting this overall priority map model, we get the following
detailed account of what unfolds in the <em>Bourbon</em> case. At the
start of the trip, Randy allocates attention to omission thoughts. He
does so based on an attentional priority map that assigns omission
thoughts a higher value than alternatives including bourbon thoughts.
This makes sense&mdash;Randy is highly interested in omissions, so it
is natural that his attentional priority map would reflect this. As he
passes the store, however, there appears to be a missed opportunity:
the subpersonal processes that construct and update priority maps
could have been sensitive to his current store-adjacent location and
shifted the priority map to place higher value on bourbon thoughts
rather than omission thoughts. But this shift did not occur&mdash;his
priority map continued to place higher value on omission thoughts
rather than bourbon thoughts, and thus Randy continued to choose to
attend to omission thoughts. And due to the limited capacity of
attention, in attending to omission thoughts, he was not attending to
bourbon thoughts&mdash;that is, he forgot about the bourbon.</p>

<h3 id="HowFinCogSciInfAssMorRes">2.3 How Findings from Cognitive Science Inform Assessments of Moral Responsibility</h3>

<p>
With these empirical details filled in, what then about moral
responsibility?</p>

<p>
One approach holds that the kinds of mechanisms that underwrite
attention allocation in our empirically-detailed reconstruction of the
<em>Bourbon</em> case do in fact confer the kind of <em>control</em>
that is required for moral responsibility. This is broadly the tack
taken by Murray and Vargas (2020). A hallmark of mechanisms that
confer control is that they are reasons-responsive&mdash;they flexibly
issue in different responses when there are sufficient reasons to do
so (Vargas 2013; Fischer &amp; Ravizza 1998; Dennett 1984; Shepherd
2014). The priority map-based mechanisms that underpin attention
allocation appear to be reasons-responsive in just this way&mdash;a
suite of learning algorithms and other mechanisms help to make sure
priority maps track the things that promote one&rsquo;s aims and
priorities (Haas 2022; Railton 2017a). On this
 approach<sup>[<a href="notes.html#note-1" id="ref-1">1</a>]</sup>,
 since Randy satisfies the conditions for control, he is morally
responsible for forgetting the bourbon, vindicating ordinary
opinion.</p>

<p>
Another position focuses on the <em>epistemic</em> condition for moral
responsibility. Recall that priority maps are generated by subpersonal
algorithms that are sensitive to the agent&rsquo;s more basic aims and
interests. Now, these algorithms work well most of the time, but they
aren&rsquo;t perfect. Like everything else in our psychology, they are
only boundedly rational (Simon 1990; Lewis et al. 2014; Lieder &amp;
Griffiths 2020), and thus, inevitably, there will be many situations
in which priority maps associated with candidate attentional targets
are inaccurate. That is, there are many situations in which these maps
will ascribe higher value to some candidate attentional target
<em>A</em> rather than some target <em>B</em>, when, in fact, the
actual value, relative to the agent&rsquo;s own aims and priorities,
favors <em>B</em> over <em>A</em>.</p>

<p>
Suppose that, at the point when he is near the store, Randy&rsquo;s
priority map is in fact inaccurate. That is, the map assigns higher
value to omission thoughts rather than bourbon thoughts when in fact
the reverse should be the case, given Randy&rsquo;s own more basic
aims and priorities. If Randy allocates his attention on the basis of
an inaccurate priority map and this is why he forgets to bring the
bourbon, then he may have done what he did under ignorance. That is,
he may fail the epistemic condition for moral responsibility, and thus
he would not be morally responsible for his conduct (assuming, that
is, that his ignorance is itself non-culpable&mdash;see the following
section). This position revises folk opinion in the <em>Bourbon</em>
case, identifying a potential excusing condition, i.e., ignorance,
that might have otherwise gone unnoticed or been
 unappreciated.<sup>[<a href="notes.html#note-2" id="ref-2">2</a>]</sup></p>
 
<p>
Stepping back a bit, the larger point is that we appear to have made
some progress. At the start, it was noted that most theorists treat
the mechanisms that produce spontaneous conduct in cases like
<em>Bourbon</em> as a black box. By consulting the empirical
literature, we have been able to offer up one version of what happens
in the case with the box meaningfully filled in. We can next ask,
given this picture of the mechanisms that operate to produce the
relevant instance of spontaneous conduct, whether the control
condition is satisfied, whether the epistemic condition is satisfied,
and so on for other conditions relevant for moral responsibility.
Empirical considerations have not settled the question of whether and
why agents are morally responsible for spontaneous conduct. But they
have brought to bear additional resources that clarify the debate and
move it forward.</p>

<h2 id="MorResEtiIgn">3. Moral Responsibility and the Etiology of Ignorance</h2>

<h3 id="EpiConCulIgn">3.1 The Epistemic Condition and Culpable Ignorance</h3>

<p>
When assessing the epistemic condition for moral responsibility, most
theorists agree that it is not enough to check whether the agent acts
under ignorance. We must further assess whether the agent is culpable
for bringing about their ignorance&mdash;whether they did something
that led to their own &ldquo;benighting&rdquo; (H. Smith 1983;
Zimmerman 1997; Rosen 2004; Wieland &amp; Robichaud 2017).</p>

<p>
Consider the case of a doctor who infuses the wrong type of blood into
a patient who then has a severe reaction (the case is loosely drawn
from Rosen 2004). The doctor does this out of ignorance; she thinks
the patient has one blood type when in fact the patient has an
incompatible one. She has this mistaken impression, however, because
she does not doublecheck the chart, something all doctors are supposed
to do. She does not doublecheck because she is in a rush to get to her
tee time at a golf club, the most exclusive in the city, and chooses
to skip portions of the usual protocol. Here, her ignorance plausibly
does not excuse moral responsibility as she is culpable for bringing
it about.</p>

<p>
Now consider a second case in which the doctor <em>does</em>
doublecheck the chart. The chart itself is wrong because of a rare
mistake&mdash;the laboratory procedure that establishes a
patient&rsquo;s blood type is nearly always accurate, but in this
particular case, the procedure has assigned the wrong blood type. The
doctor acts under ignorance, but she is plausibly excused from moral
responsibility because her ignorance itself arises non-culpably.</p>

<p>
In the preceding examples, we were able to stipulate key features of
how the respective agents come to falsely believe certain things. In
many interesting real-world cases, we cannot rely on stipulation. We
must go out and investigate the pathways by which the agent came to be
ignorant. Armed with this etiological information, we can make better
assessments of whether the agent&rsquo;s ignorance is culpable or
non-culpable and thus whether they might receive an excuse from moral
responsibility.</p>

<p>
One place where this kind of empirical etiological inquiry is
important is in assessing the role of culture and socialization in
creating impediments to knowledge, especially moral knowledge,
impediments that bear on questions of moral responsibility (Wolf
2012).</p>

<p>
One note before proceeding. Our focus in what follows is on empirical
questions about how certain forms of ignorance, especially moral
ignorance, arise. In putting the focus here, we are passing over
important conceptual questions that remain unsettled about such things
as whether moral ignorance excuses at all (we are assuming, in
agreement with the weight of philosophical opinion, that it does), and
if so, precisely which forms of moral ignorance are excusing.
Weatherson 2019, Chapter 5 provides a helpful overview of the
literature on these questions.</p>

<h3 id="CulMorIgn">3.1 Culture and Moral Ignorance</h3>

<p>
Michael Slote observes that though slavery is viewed as morally
repugnant today, it was widespread in the ancient world (Slote 1982).
So, can we blame Greek slave owners for their wrongdoing or their acts
of vice? Slote thinks we cannot, because Greek slave owners were
simply unable to see what virtue required regarding slavery. The
reason, he believes, is that slavery was too much of a
<em>universal</em> phenomenon, constraining people&rsquo;s ability to
conceive of alternatives. He writes:</p>

<p>
Just as the alternative terms used by other languages can seem to make
linguistic conventions seem like inevitable facts of nature, so too
ignorance of alternatives to a given social arrangement can instill
the belief that the arrangement is natural and inevitable and thus
beyond the possibility of radical criticism. So, if the ancients were
unable to see what virtue required in regard to slavery, that &hellip;
requires some explanation by social and historical forces, by cultural
limitations if you will. (Slote 1982, p. 72)</p>

<p>
Michelle Moody-Adams agrees with Slote that whether culturally
acquired beliefs defeat moral responsibility depends importantly on
the empirical details of how they were acquired and sustained
(Moody-Adams 1994). But she disagrees with Slote&rsquo;s particular
etiological story: &ldquo;I challenge the empirical credentials of
those views which attempt to exempt historical agents from
responsibility on the grounds that they suffer from some presumed
culturally generated inability to avoid wrongdoing&rdquo; (Moody-Adams
1994, p. 293).</p>

<p>
According to Moody-Adams, a better explanation of culturally
sanctioned immoral practices and institutions is that individuals
choose to participate in these practices and perpetuate them.</p>

<p>
Our failure to see this as the correct etiological story owes to
underappreciation of two facts about human psychology that are,
according to Moody-Adams, well attested to in anthropology, social
psychology, and case reports. The first fact is the &ldquo;banality of
evil,&rdquo; the observation that ordinary humans are regularly and
routinely able to inflict great cruelty on their fellows if there are
incentives to do so. Moody-Adams cites Stanley Milgram&rsquo;s famous
experiments on obedience (Milgram 1965), among other empirical data,
in support. The second fact is our proclivity towards &ldquo;affected
ignorance,&rdquo; in which individuals engage in subtle forms of
self-deception and motivated evidence seeking. Slavery was maintained
as an institution, Moody-Adams surmises, because people made choices
that were in part cruel and in part affectedly ignorant. See also
Calhoun 1989 and Mills 2007, for influential related arguments.</p>

<h3 id="SocNetBadBel">3.2 Social Networks and &ldquo;Bad Beliefs&rdquo;</h3>

<p>
Neil Levy offers a contrasting perspective in investigating a related
phenomenon, the acquisition of &ldquo;bad beliefs&rdquo; among members
of certain political or ideological subcultures, for example,
communities of climate change deniers, vaccination skeptics, or
supporters of demagogic political figures (Levy 2021).</p>

<p>
Levy&rsquo;s argument relies heavily on the ideas of bounded
rationality and epistemic deference. He notes that the evidence that
bears on most complex scientific matters (climate, evolution) is so
extensive and abstruse, it is simply not feasible or rationally
advisable for ordinary people to evaluate all this evidence for
themselves. Drawing on the work of quantitative biologists and social
scientists working in the &ldquo;dual-inheritance&rdquo; framework
(Boyd &amp; Richerson 1988; Henrich 2016), Levy argues that people
instead make heavy use of the strategy of deferring to the beliefs
that prevail in their community. This strategy works because there are
a number of features of human belief networks that jointly make it the
case that the fact that others around you believe that <em>p</em> is
in fact, on average, evidence for <em>p</em>. Levy argues that from
these observations, it follows that those who hold beliefs that run
counter to scientific consensuses are very often just engaging in
rational deference&mdash;the problem is not in the way they form their
beliefs but in the epistemic environment in which they are formed. See
also Rini 2017, O&rsquo;Connor &amp; Weatherall 2019, Nguyen 2020,
Dorst 2023, for importantly different arguments that reach similar
conclusions.</p>

<p>
A striking aspect of Levy&rsquo;s picture is that those who hold
&ldquo;good&rdquo; beliefs that are in line with the scientific
consensus and those who hold &ldquo;bad&rdquo; beliefs that deviate
from this consensus typically don&rsquo;t differ much in terms of
their respective methods of belief formation. The former just happen
to be in a less favorable epistemic environment than the latter (see
Worsnip 2022, for a helpful discussion of this point). Levy&rsquo;s
picture furthermore suggests that the ignorance of those who hold bad
beliefs is often non-culpable. A parent who fails to vaccinate their
child may not be morally responsible for the damage inflicted because
they may be non-culpably ignorant of the balance of risks and
benefits. The fault lies not with them but with the unlucky fact that
their epistemic environment is polluted.</p>

<p>
A key empirical assumption in Levy&rsquo;s account is that taking on
the beliefs of those around you is done solely, or even mostly, for
epistemic reasons. But there is considerable evidence that people
often adopt views, especially counternormative ones, that serve as
&ldquo;cultural badges&rdquo; that identify the members of a moral,
political, or ideological community and demarcate the
community&rsquo;s boundaries (Boyd &amp; Richerson 1987; McElreath et
al. 2003). These views are held on to tenaciously in the face of
strong and persistent counterevidence because the epistemic costs are
more than made up by personal, prudential gains. Membership in the
group is valuable and deviations from orthodoxy are punished so the
person has strong social incentives to endorse whatever is the
&ldquo;tribal&rdquo; creed (Williams 2023, 2021; Kahan 2017;
Funkhouser 2022).</p>

<p>
But notice that at this turn in the discussion, it is not at all clear
that we are still talking about the attitude of <em>belief</em>
anymore, which was our original topic. The present claim under
consideration is that people express support for certain views for
prudential reasons: personal gain, social status, avoiding ostracism,
and so forth. None of this requires the person actually to believe the
relevant claims for which they are expressing support. Recall the
original issue that we were aiming to address: When is a person
excused from moral responsibility due to ignorance and when are they
not excused because they culpably brought about their ignorance? If
the claims currently under consideration are correct, then some cases
that appear overtly to be ignorance may turn out to be no such thing;
they are simply cases of people expressing social support for certain
false propositions without actually believing them. Such expressions
of social support, it would seem, are not forms of ignorance and are
no shield from moral responsibility.</p>

<p>
We have considered several alternative explanations for the etiology
of ignorance, or related attitudes. It should be emphasized that there
is one sense in which they don&rsquo;t necessarily compete: each
explanation might be true of different sets of cases. That is, it
might be true that Slote&rsquo;s explanation invoking cultural
inability is applicable to some cases, Levy&rsquo;s view invoking
rational deference is applicable to others, and the views of
Moody-Adams and other critics are applicable in still other cases (see
Benson 2001, which makes a related point). It is ultimately an
empirical question which of the preceding etiological explanations
best fits the particular case at hand, if any. It follows that when
dealing with complex, real-world cases, as opposed to stipulated
hypothetical cases, assessing whether agents exhibit culpable versus
non-culpable ignorance cannot generally be accomplished from the
armchair alone. Such assessment will additionally require careful
empirical inquiry into the etiology of how the relevant agents came to
believe what they do.</p>

<h2 id="MorResArtAge">4. Moral Responsibility and Artificial Agents</h2>

<p>
<em>Agents</em>, we have been saying, can be morally responsible for
what they do. But what is an agent? Conceptual work is certainly
needed to answer this question, but empirical work can make key
contributions. An empirical field of particular interest is artificial
intelligence (AI). As AI gallops forward, questions arise about
whether machines of various kinds might be morally responsible for
what they do.</p>

<h3 id="AgeMod">4.1 The Agent Model</h3>

<p>
To get us going in thinking about this issue, a useful starting place
is a framework for understanding agency developed in computer science
and artificial intelligence called the &ldquo;agent model&rdquo;
(Russell &amp; Norvig 2020; Sutton &amp; Barto 1998; Haas 2022). A
standard formulation of the model considers an agent who interacts
with an environment partitioned into a set of states, with various
actions available at each state. The agent also has a function that
assigns to each state a degree of intrinsic value to the agent; these
assignments of intrinsic value capture the agent&rsquo;s
&ldquo;goals&rdquo;. Agency involves a loop. In the first step, the
agent receives perceptual input regarding the current state and also
receives the intrinsic value of that state. Next, the agent makes a
selection from the actions available in that state. Based on that
action, the agent enters a new state, and the loop starts again. The
key task of agency involves learning over time to behave in ways that
maximize cumulative, long-term achievement of intrinsic value.</p>

<p>
Much of the excitement in the study of artificial agents is due to the
development of a wide assortment of algorithms that explain how agents
embedded in the above setup can learn what are the best actions
(Sutton &amp; Barto 1998; Haas 2022; Solway &amp; Botvinick 2012).
These algorithms take a variety of forms. Some learn directly from
experience, while others learn a model of the workings of the world
and consequences of one&rsquo;s actions and leverage this information
to guide the selection of actions. And though the agent model is
relatively spartan in its setup, it has been shown to be
extraordinarily powerful. Recent milestones in AI, such as machines
that achieve expert-level performance at chess, Go, and Atari video
games, have been achieved within the agent model framework (Campbell
et al. 2002; Mnih et al. 2015).</p>

<p>
The agent model might also serve as a tool to probe a space of
possible agents, each with varying capacities, some of which might
potentially be morally responsible for what they do. Recall the two
core conditions for moral responsibility. It seems at least some
artificial agents of the type envisioned in the agent model (hereafter
just &ldquo;artificial agent&rdquo;) might be able satisfy these two
conditions (Nyholm, 2018; Menges &amp; Altehenger 2024).</p>

<p>
An artificial agent flexibly adjusts its actions based on the current
circumstances in order to maximize attainment of its aims. This kind
of behavioral flexibility in pursuit of goals is widely thought to be
the central element of control (Dennett 1984; Fischer &amp; Ravizza
1998; Shepherd 2014). Moreover, an artificial agent selects its
actions based on various kinds of knowledge. For example, it knows
what actions are available in the current situation, which of these
actions are most likely to achieve its goals, and so forth. Thus, it
is at least prima facie plausible that an artificial agent might be
able to satisfy moral responsibility&rsquo;s epistemic condition.</p>

<p>
And yet, suppose an Atari game-playing artificial agent is playing the
game <em>Space Invaders</em>. It fends off wave after wave of aliens
and thus saves the Earth&rsquo;s cities from destruction. Putting
aside the question of moral responsibility in fictional scenarios, it
seems deeply implausible that the artificial agent should be
considered morally responsible for what it does, or that it should be
somehow praised (Nyholm 2022, Chapter 6). So, questions naturally
arise about what is missing for moral responsibility.</p>

<h3 id="WhaNeeForArtAgeMorResForWhaTheDo">4.2 What Is Needed for Artificial Agents to be Morally Responsible for What They Do?</h3>

<p>
What capacities do ordinary unimpaired adult humans have that are
relevant for moral responsibility that seem to be missing in
relatively simple artificial agents such as an Atari-playing machine?
Here are a few candidates.</p>

<h4 id="TemExtProPla">4.2.1 Temporally Extended Projects and Plans</h4>

<p>
The Atari-playing artificial agent has just a single goal that it
reaches fairly quickly: win the Atari game. Humans have a much richer,
interlocking set of things that they care about&mdash;health, success,
relationships, cultivating one&rsquo;s talents, and so forth (Jaworska
2007; Shoemaker 2003). These things can typically be accomplished only
through endeavors and projects that unfold over years and even
decades. Moral responsibility, one might argue, requires an agent with
a rich and complex evaluative point of view and capacities for
long-term planning agency (Bratman 2000) to bring about those things
the agent cares about.</p>

<h4 id="MorSenAccMorRea">4.2.2 A Moral Sense and Access to Moral Reasons</h4>

<p>
The Atari-playing artificial agent has no sense of what is right or
wrong, fair or unfair, good or bad, and what kinds of actions manifest
vices or virtues. To be morally responsible, one might argue, an agent
needs to be outfitted with a moral sense, have access to moral reasons
(Wolf 2012; Wallace 1998; Shoemaker 2011), or be able to engage in
moral learning (Railton 2017b). Only then can the agent be blamed for
failing to do what morality demands.</p>

<h4 id="Con">4.2.3 Consciousness</h4>

<p>
Suppose a person acts based on motives that are entirely unconscious;
they do what they do without awareness of why they are doing it. This
is in fact what may happen in, for instance, certain kinds of
sleepwalking (Levy 2014). Reflecting on cases such as these, some
philosophers have claimed that consciousness is required for moral
responsibility (Levy 2014; King &amp; Carruthers 2012).</p>

<p>
But why specifically might moral responsibility depend on
consciousness? One influential view is that consciousness is required
for, or else closely associated with, the widespread sharing of
information throughout the agent&rsquo;s psychology (King &amp;
Carruthers 2012; Levy 2014; Nahmias et al. 2020). In the conscious
waking state, information is widely broadcast to diverse consumer
systems, rendering the agent responsive to a wide range of reasons
(Fischer &amp; Ravizza 1998) and rendering their actions reflective of
their full evaluative point of view (Wolf 1993). The problem with the
sleepwalker, it is argued, is that low-level modules produce their
behavior. These modules are unlikely to be flexibly responsive to a
broad range of reasons, and the agent&rsquo;s actions correspondingly
won&rsquo;t (typically) be reflective of their motives and
evaluations, thus explaining why the absence of consciousness
undermines moral responsibility.</p>

<h4 id="UltCon">4.2.4 &ldquo;Ultimate&rdquo; Control</h4>

<p>
Our Atari-playing artificial agent comes pre-programmed with its aims,
in this case, a single aim to win the game. It learns over time to
choose actions that bring it closer and closer to fulfillment of this
externally installed aim. More generally, for an artificial agent like
the Atari-playing machine, the moral quality of its actions depends
strictly on what aims were prespecified. If these aims are morally
commendable, the agent will act in the service of the good; if these
aims are morally reprehensible, so too will be agent&rsquo;s
actions.</p>

<p>
It might be argued that for genuine moral responsibility, agents
cannot simply act on the basis of fixed, externally installed aims.
The agents themselves must somehow have control over what they are
aiming for, something we might term &ldquo;ultimate
control.&rdquo;</p>

<p>
What ultimate control amounts to is itself controversial. For some
theorists, it only requires criticizability and
revisability&mdash;whatever aims an agent has, there must be ways for
the agent to reflectively criticize them (Frankfurt 1971) or revise
them (Mele 2001, 2006), or at least change them were they to conflict
with certain standards of correctness (Wolf 1980, 1993; Nelkin
2011).</p>

<p>
For other theorists, the agent must be the &ldquo;root&rdquo; source
of their own aims or other elements of their evaluative point of view.
For example, one formulation goes like this: To be responsible for
what one chooses at some time <em>t</em>, the elements of one&rsquo;s
evaluative point of view that are the basis for what one chooses at
<em>t</em> must themselves be the products of the agent&rsquo;s own
prior choices. This formulation appears to set up an infinite regress.
This this way of understanding ultimate control may be so demanding,
it makes moral responsibility essentially impossible (G. Strawson
1994). But notice that it is impossible irrespective of whether the
agent in question is human or artificial.</p>

<h3 id="FutMorRes">4.3 The Future of Moral Responsibility</h3>

<p>
We have identified several gaps that separate a fairly simple
artificial agent from typical human agents. Looking to the future,
some of these gaps are likely to shrink. For example, there are
research programs trying to outfit artificial agents with abilities
for long-term planning, leveraging sophisticated causal models of the
world (Malinsky &amp; Danks 2018; Steyvers et al. 2003). There is also
great interest in building artificial agents that can engage in moral
learning (Railton 2017b) and moral reasoning (Awad et al. 2022;
Sinnott-Armstrong &amp; Skorburg 2021).</p>

<p>
Interestingly, in some cases, gaps between humans and artificial
agents may emerge and grow in the opposite direction. That is,
artificial agents may exhibit responsibility-relevant abilities that
exceed our own. For example, in humans, information sharing is
importantly limited by the capacity of working memory (Baddeley 2019;
Carruthers 2015; Persuh et al. 2018), which is thought to be limited
to roughly seven chunks of information at a time (Miller 1956). In
artificial systems, components that play an analogous role to working
memory need not be so constrained; dozens, hundreds, or even thousands
of pieces of information may be simultaneously activated and available
for the purposes of reasoning and inference.</p>

<p>
Accounts of moral responsibility have primarily been developed by
considering ordinary adult humans as the targets for the theory. In
the future, a menagerie of distinctive artificial agents might arise,
each outfitted with different sets of abilities and exhibiting
different limitations. The targets that a theory of moral
responsibility must be sensitive to are likely to commensurably
expand. Theories of moral responsibility may need to be amended,
refined, or otherwise rethought to accommodate these developments.</p>
</div>

<div id="bibliography">

<h2 id="Bib">Bibliography</h2>

<ul class="hanging">

<li>Amaya, S., 2013, &ldquo;Slips&rdquo;, <em>No&ucirc;s</em>, 47(3):
559&ndash;576. doi:10.1111/j.1468-0068.2011.00838.x</li>

<li>Amaya, S., &amp; Doris, J. M., 2015, &ldquo;No excuses:
Performance mistakes in morality&rdquo;, in J. Clausen &amp; N. Levy
(eds.), <em>Handbook of Neuroethics</em>, pp. 253&ndash;272, Springer
Netherlands.</li>

<li>American Psychiatric Association &amp; DSM-5 Task Force, 2013,
<em>Diagnostic and statistical manual of mental disorders: DSM-5</em>,
American Psychiatric Association.</li>

<li>Anderson, B. A., &amp; Kim, H., 2018, &ldquo;Mechanisms of
value-learning in the guidance of spatial attention&rdquo;,
<em>Cognition</em>, 178: 26&ndash;36.</li>

<li>Awad, E., Levine, S., Anderson, M., Anderson, S. L., Conitzer, V.,
Crockett, M. J., Everett, J. A., Evgeniou, T., Gopnik, A., &amp;
Jamison, J. C., 2022, &ldquo;Computational ethics&rdquo;, <em>Trends
in Cognitive Sciences</em>, 26(5): 388&ndash;405.</li>

<li>Baddeley, A., 2019, &ldquo;Working memory and conscious
awareness&rdquo;, in A.F. Colins, S.E. Gathercole, M.A. Conway, and
P.E. Morris (eds.), <em>Theories of memory</em>, pp. 11&ndash;28,
Hillsdale, NJ: Lawrence Erlbaum Associates.</li>

<li>Benson, P., 2001, &ldquo;Culture and responsibility: A reply to
Moody-Adams&rdquo;, <em>Journal of Social Philosophy</em>, 32(4):
610&ndash;620.</li>

<li>Berm&uacute;dez, J. P., &amp; Massin, O., 2023, &ldquo;Efforts and
their feelings&rdquo;, <em>Philosophy Compass</em>, 18(1):
e12894.</li>

<li>Boyd, R., &amp; Richerson, P. J., 1987, &ldquo;The evolution of
ethnic markers&rdquo;, <em>Cultural Anthropology</em>, 2(1):
65&ndash;79.</li>

<li>&ndash;&ndash;&ndash;, 1988, <em>Culture and the evolutionary
process</em>, Chicago: University of Chicago Press.</li>

<li>Bradford, G., 2015, <em>Achievement</em>, Oxford: Oxford
University Press.</li>

<li>Bratman, M. E., 2000, &ldquo;Reflection, planning, and temporally
extended agency&rdquo;, <em>Philosophical Review</em>, 109(1):
35&ndash;61. doi:10.1215/00318108-109-1-35</li>

<li>Burdman, F., 2022, &ldquo;A pluralistic account of degrees of
control in addiction&rdquo;, <em>Philosophical Studies</em>, 179(1):
197&ndash;221.</li>

<li>Busemeyer, J. R., &amp; Townsend, J. T., 1993, &ldquo;Decision
field theory: A dynamic-cognitive approach to decision making in an
uncertain environment&rdquo;, <em>Psychological Review</em>, 100(3):
432&ndash;459.</li>

<li>Calhoun, C., 1989, &ldquo;Responsibility and reproach&rdquo;,
<em>Ethics</em>, 99(2): 389&ndash;406.</li>

<li>Campbell, M., Hoane Jr, A. J., &amp; Hsu, F., 2002, &ldquo;Deep
blue&rdquo;, <em>Artificial Intelligence</em>, 134(1&ndash;2):
57&ndash;83.</li>

<li>Caplan, B., 2006, &ldquo;The economics of szasz: Preferences,
constraints and mental illness&rdquo;, <em>Rationality and
Society</em>, 18(3): 333&ndash;366.</li>

<li>Carruthers, P., 2015, <em>The centered mind: What the science of
working memory shows us about the nature of human thought</em>,
Oxford: Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2018, &ldquo;Valence and value&rdquo;,
<em>Philosophy and Phenomenological Research</em>, 97(3):
658&ndash;680.</li>

<li>Chun, M. M., Golomb, J. D., &amp; Turk-Browne, N. B., 2011,
&ldquo;A taxonomy of external and internal attention&rdquo;,
<em>Annual Review of Psychology</em>, 62(1): 73&ndash;101.</li>

<li>Clarke, R., 2014, <em>Omissions: Agency, metaphysics, and
responsibility</em>, Oxford: Oxford University Press.</li>

<li>Coates, D. J., &amp; Tognazzini, N. A., 2013, <em>Blame: Its
nature and norms</em>, Oxford: Oxford University Press.</li>

<li>Daniels, N., 1979, &ldquo;Wide reflective equilibrium and theory
acceptance in ethics&rdquo;, <em>The Journal of Philosophy</em>,
76(5): 256&ndash;282.</li>

<li>Dennett, D. C., 1984, <em>Elbow room: The varieties of free will
worth wanting</em>, Cambridge: The MIT Press.</li>

<li>Dennis, M. L., Foss, M. A., &amp; Scott, C. K., 2007, &ldquo;An
eight-year perspective on the relationship between the duration of
abstinence and other aspects of recovery&rdquo;, <em>Evaluation
Review</em>, 31(6): 585&ndash;612. doi:10.1177/0193841X07307771</li>

<li>Dorst, K., 2023, &ldquo;Rational polarization&rdquo;,
<em>Philosophical Review</em>, 132(3): 355&ndash;458.</li>

<li>Failing, M., &amp; Theeuwes, J., 2018, &ldquo;Selection history:
How reward modulates selectivity of visual attention&rdquo;,
<em>Psychonomic Bulletin &amp; Review</em>, 25(2): 514&ndash;538.</li>

<li>Fecteau, J. H., &amp; Munoz, D. P., 2006, &ldquo;Salience,
relevance, and firing: A priority map for target selection&rdquo;,
<em>Trends in Cognitive Sciences</em>, 10(8): 382&ndash;390.</li>

<li>Fischer, J. M., 2012, &ldquo;Semicompatibilism and its
rivals&rdquo;, <em>The Journal of Ethics</em>, 16(2): 117&ndash;143.
doi:10.1007/s10892-012-9123-9</li>

<li>Fischer, J. M., &amp; Ravizza, M., 1998, <em>Responsibility and
control: A theory of moral responsibility</em>, Cambridge: Cambridge
University Press.</li>

<li>Flanagan, O., 2013, &ldquo;The shame of addiction&rdquo;,
<em>Frontiers in Psychiatry</em>, 4: 120.</li>

<li>Foddy, B., &amp; Savulescu, J., 2007, &ldquo;Addiction is not an
affliction: Addictive desires are merely pleasure-oriented
desires&rdquo;, <em>The American Journal of Bioethics</em>, 7(1):
29&ndash;32.</li>

<li>&ndash;&ndash;&ndash;, 2010, &ldquo;A liberal account of
addiction&rdquo;, <em>Philosophy, Psychiatry, &amp; Psychology:
PPP</em>, 17(1): 1&ndash;22. doi:10.1353/ppp.0.0282</li>

<li>Forstmann, B. U., Ratcliff, R., &amp; Wagenmakers, E.-J., 2016,
&ldquo;Sequential sampling models in cognitive neuroscience:
Advantages, applications, and extensions&rdquo;, <em>Annual Review of
Psychology</em>, 67: 641&ndash;666.</li>

<li>Frankfurt, H., 1971, &ldquo;Freedom of the will and the concept of
a person&rdquo;, <em>The Journal of Philosophy</em>, 68(1):
5&ndash;20. doi:10.2307/2024717</li>

<li>Funkhouser, E., 2022, &ldquo;A tribal mind: Beliefs that signal
group identity or commitment&rdquo;, <em>Mind &amp; Language</em>,
37(3): 444&ndash;464.</li>

<li>Glackin, S. N., Roberts, T., &amp; Krueger, J., 2021, &ldquo;Out
of our heads: Addiction and psychiatric externalism&rdquo;,
<em>Behavioural Brain Research</em>, 398: 112936.</li>

<li>Griffiths, M., 2005, &ldquo;A &lsquo;components&rsquo; model of
addiction within a biopsychosocial framework&rdquo;, <em>Journal of
Substance Use</em>, 10(4): 191&ndash;197.</li>

<li>Haas, J., 2022, &ldquo;Reinforcement learning: A brief guide for
philosophers of mind&rdquo;, <em>Philosophy Compass</em>, e12865.
doi:10.1111/phc3.12865</li>

<li>&ndash;&ndash;&ndash;, forthcoming, &ldquo;The evaluative
mind&rdquo;, in <em>Mind Design III</em>, Cambridge: MIT Press.
 [<a href="https://philpapers.org/archive/HAATEM-2.pdf" target="other">Haas forthcoming available online</a>]</li>
 
<li>Hart, C., 2013, <em>High price: A neuroscientist&rsquo;s journey
of self-discovery that challenges everything you know about drugs and
society</em>, London: Penguin Books.</li>

<li>Hart, C., Haney, M., Foltin, R. W., &amp; Fischman, M. W., 2000,
&ldquo;Alternative reinforcers differentially modify cocaine
self-administration by humans&rdquo;, <em>Behavioural
Pharmacology</em>, 11(1): 87&ndash;91.</li>

<li>Heather, N., 1998, &ldquo;A conceptual framework for explaining
drug addiction&rdquo;, <em>Journal of Psychopharmacology</em>, 12(1):
3&ndash;7.</li>

<li>&ndash;&ndash;&ndash;, 2020, &ldquo;The concept of akrasia as the
foundation for a dual systems theory of addiction&rdquo;,
<em>Behavioural Brain Research</em>, 390: 112666.</li>

<li>Henden, E., Melberg, H.-O., &amp; Rogeberg, O., 2013,
&ldquo;Addiction: Choice or compulsion?&rdquo; <em>Frontiers in
Psychiatry</em>, 4. doi:10.3389/fpsyt.2013.00077</li>

<li>Henrich, J., 2016, <em>The secret of our success: How culture is
driving human evolution, domesticating our species, and making us
smarter</em>, Princeton: Princeton University Press.</li>

<li>Heyman, G. M., 2009, <em>Addiction: A disorder of choice</em>
(Reprint edition). Cambridge: Harvard University Press.</li>

<li>Higgins, S. T., &amp; Petry, N. M., 1999, &ldquo;Contingency
management. Incentives for sobriety&rdquo;, <em>Alcohol Research &amp;
Health: The Journal of the National Institute on Alcohol Abuse and
Alcoholism</em>, 23(2): 122&ndash;127.</li>

<li>Hofmann, W., Baumeister, R. F., F&ouml;rster, G., &amp; Vohs, K.
D., 2012, &ldquo;Everyday temptations: An experience sampling study of
desire, conflict, and self-control&rdquo;, <em>Journal of Personality
and Social Psychology</em>, 102(6): 1318&ndash;133OB5.</li>

<li>Hofmann, W., Vohs, K. D., &amp; Baumeister, R. F., 2012,
&ldquo;What people desire, feel conflicted about, and try to resist in
everyday life&rdquo;, <em>Psychological Science</em>, 23(6):
582&ndash;588.</li>

<li>Holton, R., &amp; Berridge, K., 2013, &ldquo;Addiction between
compulsion and choice&rdquo;, in N. Levy (ed.), <em>Addiction and
self-control: Perspectives from philosophy, psychology, and
neuroscience</em>, pp. 239&ndash;268, New York: Oxford University
Press.</li>

<li>Hunt, W. A., Barnett, L. W., &amp; Branch, L. G., 1971,
&ldquo;Relapse rates in addiction programs&rdquo;, <em>Journal of
Clinical Psychology</em>, 27(4): 455&ndash;456.
doi:10.1002/1097-4679(197110)27:4&lt;455::AID-JCLP2270270412&gt;3.0.CO;2-R</li>

<li>Husak, D. N., 1992, <em>Drugs and rights</em>, Cambridge:
Cambridge University Press.</li>

<li>James, W., 1890, <em>Principles of psychology</em>, Henry Holt
&amp; Company.</li>

<li>Jaworska, A., 2007, &ldquo;Caring and internality&rdquo;,
<em>Philosophy and Phenomenological Research</em>, 74(3):
529&ndash;568. doi:10.1111/j.1933-1592.2007.00039.x</li>

<li>Kennett, J., 2013, &ldquo;Addiction, choice, and disease: How
voluntary is voluntary action in addiction?&rdquo; in N. Vincent
(ed.), <em>Neuroscience and Legal Responsibility</em>, pp.
257&ndash;278, Oxford: Oxford University Press.</li>

<li>King, M., &amp; Carruthers, P., 2012, &ldquo;Moral responsibility
and consciousness&rdquo;, <em>Journal of Moral Philosophy</em>, 9(2):
200&ndash;228. doi:10.1163/174552412X625682</li>

<li>Kirshenbaum, A. P., Olsen, D. M., &amp; Bickel, W. K., 2009,
&ldquo;A quantitative review of the ubiquitous relapse curve&rdquo;,
<em>Journal of Substance Abuse Treatment</em>, 36(1): 8&ndash;17.
doi:10.1016/j.jsat.2008.04.001</li>

<li>Kiyonaga, A., &amp; Egner, T., 2013, &ldquo;Working memory as
internal attention: Toward an integrative account of internal and
external selection processes&rdquo;, <em>Psychonomic Bulletin &amp;
Review</em>, 20, 228&ndash;242.</li>

<li>Levy, N., 2006, &ldquo;Addiction, autonomy and ego-depletion: A
response to Bennett Foddy and Julian Savulescu&rdquo;,
<em>Bioethics</em>, 20(1): 16&ndash;20.
doi:10.1111/j.1467-8519.2006.00471.x</li>

<li>&ndash;&ndash;&ndash;, 2014, <em>Consciousness and moral
responsibility</em>, New York: Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2021, <em>Bad beliefs: Why they happen to
good people</em>. Oxford: Oxford University Press.
doi:10.1093/oso/9780192895325.001.0001</li>

<li>Lewis, R. L., Howes, A., &amp; Singh, S., 2014,
&ldquo;Computational rationality: Linking mechanism and behavior
through bounded utility maximization&rdquo;, <em>Topics in Cognitive
Science</em>, 6(2): 279&ndash;311.</li>

<li>Lieder, F., &amp; Griffiths, T. L., 2020, &ldquo;Resource-rational
analysis: Understanding human cognition as the optimal use of limited
computational resources&rdquo;, <em>Behavioral and Brain
Sciences</em>, 43: e1.</li>

<li>Malinsky, D., &amp; Danks, D., 2018, &ldquo;Causal discovery
algorithms: A practical guide&rdquo;, <em>Philosophy Compass</em>,
13(1): e12470.</li>

<li>Mallon, R., 2016, &ldquo;Experimental philosophy&rdquo;, in Herman
Cappelen, Tamar Gendler, &amp; John Hawthorne (eds.), <em>Oxford
Handbook of Philosophical Methodology</em>, pp. 410&ndash;433, Oxford:
Oxford University Press.</li>

<li>McElreath, R., Boyd, R., &amp; Richerson, P., 2003, &ldquo;Shared
norms and the evolution of ethnic markers&rdquo;, <em>Current
Anthropology</em>, 44(1): 122&ndash;130.</li>

<li>McLellan, A. T., Lewis, D. C., O&rsquo;Brien, C. P., &amp; Kleber,
H. D., 2000, &ldquo;Drug dependence, a chronic medical illness:
Implications for treatment, insurance, and outcomes evaluation&rdquo;,
<em>JAMA</em>, 284(13): 1689&ndash;1695.
doi:10.1001/jama.284.13.1689</li>

<li>Mele, A., 1990, &ldquo;Irresistible desires&rdquo;,
<em>No&ucirc;s</em>, 24(3): 455&ndash;472. doi:10.2307/2215775</li>

<li>&ndash;&ndash;&ndash;, 2001, <em>Autonomous agents: From
self-control to autonomy</em>, New York: Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2006, <em>Free will and luck</em>. New
York: Oxford University Press.</li>

<li>Menges, L., &amp; Altehenger A., 2024, &ldquo;The point of blaming
AI systems&rdquo;, <em>Journal of Ethics and Social Philosophy</em>,
27(2): 287&ndash;314.</li>

<li>Milgram, S., 1965, &ldquo;Some conditions of obedience and
disobedience to authority&rdquo;, <em>Human Relations</em>, 18(1):
57&ndash;76.</li>

<li>Miller, G. A., 1956, &ldquo;The magical number seven, plus or
minus two: Some limits on our capacity for processing
information&rdquo;, <em>Psychological Review</em>, 63(2): 81.</li>

<li>Mills, C., 2007, &ldquo;White ignorance&rdquo;, <em>Race and
Epistemologies of Ignorance</em>, 247: 26&ndash;31.</li>

<li>Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J.,
Bellemare, M. G., Graves, A., Riedmiller, M., Fidjeland, A. K., &amp;
Ostrovski, G., 2015, &ldquo;Human-level control through deep
reinforcement learning&rdquo;, <em>Nature</em>, 518(7540):
529&ndash;533.</li>

<li>Moody-Adams, M. M., 1994, &ldquo;Culture, responsibility, and
affected ignorance&rdquo;, <em>Ethics</em>, 104(2):
291&ndash;309.</li>

<li>Morse, S. J., 2000, &ldquo;Hooked on hype: Addiction and
responsibility&rdquo;, <em>Law and Philosophy</em>, 19:
3&ndash;49.</li>

<li>&ndash;&ndash;&ndash;, 2002, &ldquo;Uncontrollable urges and
irrational people&rdquo;, <em>Virginia Law Review</em>, 88:
1025&ndash;1078.</li>

<li>Murray, S., &amp; Vargas, M., 2020, &ldquo;Vigilance and
control&rdquo;, <em>Philosophical Studies</em>, 177:
825&ndash;843.</li>

<li>Nahmias, E., Allen, C. H., &amp; Loveall, B., 2020, &ldquo;When do
robots have free will? Exploring the relationships between
(attributions of) consciousness and free will&rdquo;, <em>Free Will,
Causality, and Neuroscience</em>, 338: 57&ndash;80.</li>

<li>Nelkin, D. K., 2011, <em>Making sense of freedom and
responsibility</em>. Oxford: Oxford University Press.</li>

<li>Nelkin, D. K., &amp; Rickless, S. C., 2017, &ldquo;Moral
responsibility for unwitting omissions: A new tracing view&rdquo;,
<em>The Ethics and Law of Omissions</em>, pp. 106&ndash;129.</li>

<li>Nguyen, C. T., 2020, &ldquo;Echo chambers and epistemic
bubbles&rdquo;, <em>Episteme: A Journal of Individual and Social
Epistemology</em>, 17(2): 141&ndash;161.</li>

<li>Nyholm, S., 2018, &ldquo;Attributing agency to automated systems:
Reflections on human&ndash;robot collaborations and
responsibility-loci&rdquo;, 24(4): 1201&ndash;1219.</li>

<li>&ndash;&ndash;&ndash;, 2022, <em>This is technology ethics: An
introduction</em>, Hoboken, NJ: John Wiley &amp; Sons.</li>

<li>O&rsquo;Connor, C., &amp; Weatherall, J. O., 2019, <em>The
misinformation age: How false beliefs spread</em>. Yale University
Press.</li>

<li>Persuh, M., LaRock, E., &amp; Berger, J., 2018, &ldquo;Working
memory and consciousness: The current state of play&rdquo;,
<em>Frontiers in Human Neuroscience</em>, 12: 78.</li>

<li>Pickard, H., 2012, &ldquo;The purpose in chronic addiction&rdquo;,
<em>AJOB Neuroscience</em>, 3(2): 40&ndash;49.
doi:10.1080/21507740.2012.663058</li>

<li>&ndash;&ndash;&ndash;, 2015, &ldquo;Psychopathology and the
ability to do otherwise&rdquo;, <em>Philosophy and Phenomenological
Research</em>, 90(1): 135&ndash;163. doi:10.1111/phpr.12025</li>

<li>&ndash;&ndash;&ndash;, 2016, &ldquo;Denial in addiction&rdquo;,
<em>Mind &amp; Language</em>, 31(3): 277&ndash;299.</li>

<li>Preston, K. L., Vahabzadeh, M., Schmittner, J., Lin, J.-L.,
Gorelick, D. A., &amp; Epstein, D. H., 2009, &ldquo;Cocaine craving
and use during daily life&rdquo;, <em>Psychopharmacology</em>, 207(2):
291. doi:10.1007/s00213-009-1655-8</li>

<li>Quine, W. V., 1957, &ldquo;The scope and language of
science&rdquo;, <em>The British Journal for the Philosophy of
Science</em>, 8(29): 1&ndash;17.</li>

<li>Railton, P., 2017a, &ldquo;At the core of our capacity to act for
a reason: The affective system and evaluative model-based learning and
control&rdquo;, <em>Emotion Review</em>, 9(4): 335&ndash;342.</li>

<li>&ndash;&ndash;&ndash;, 2017b, &ldquo;Moral learning: Conceptual
foundations and normative relevance&rdquo;, <em>Cognition</em>, 167:
172&ndash;190.</li>

<li>Rangel, A., Camerer, C., &amp; Montague, P. R., 2008, &ldquo;A
framework for studying the neurobiology of value-based decision
making&rdquo;, <em>Nat Rev Neurosci</em>, 9: 545&ndash;556.
doi:10.1038/nrn2357</li>

<li>Rangel, A., &amp; Hare, T., 2010, &ldquo;Neural computations
associated with goal-directed choice&rdquo;, <em>Current Opinion in
Neurobiology</em>, 20(2): 262&ndash;270.</li>

<li>Ratcliff, R., &amp; McKoon, G., 2007, &ldquo;The diffusion
decision model: Theory and data for two-choice decision tasks&rdquo;,
<em>Neural Computation</em>, 20(4): 873&ndash;922.
doi:10.1162/neco.2008.12-06-420</li>

<li>Rini, R., 2017, &ldquo;Fake news and partisan epistemology&rdquo;,
<em>Kennedy Institute of Ethics Journal</em>, 27(2):
E-43&ndash;E-64.</li>

<li>Rosen, G., 2004, &ldquo;Skepticism about moral
responsibility&rdquo;, <em>Philosophical Perspectives</em>, 18:
295&ndash;313.</li>

<li>Russell, S., &amp; Norvig, P., 2020, <em>Artificial intelligence:
A modern approach</em>, 4th Edition, Boston: Pearson Education,
Inc.</li>

<li>Scanlon, T., 1998, <em>What We Owe Each Other</em>, Cambridge:
Harvard University Press.</li>

<li>Shepherd, J., 2014, &ldquo;The contours of control&rdquo;,
<em>Philosophical Studies</em>, 170: 395&ndash;411.</li>

<li>Sher, G., 2006, &ldquo;Out of control&rdquo;, <em>Ethics</em>,
116(2): 285&ndash;301. doi:10.1086/et.2006.116.issue-2</li>

<li>&ndash;&ndash;&ndash;, 2009, <em>Who knew?: Responsibility without
awareness</em>. Oxford: Oxford University Press.</li>

<li>Shoemaker, D., 2003, &ldquo;Caring, identification, and
agency&rdquo;, <em>Ethics</em>, 114(1): 88&ndash;118.
doi:10.1086/376718</li>

<li>&ndash;&ndash;&ndash;, 2011, &ldquo;Psychopathy, responsibility,
and the moral/conventional distinction&rdquo;, <em>The Southern
Journal of Philosophy</em>, 49: 99&ndash;124.</li>

<li>Simon, H. A., 1990, &ldquo;Bounded rationality&rdquo;, <em>Utility
and Probability</em>, 15&ndash;18.</li>

<li>Sinnott-Armstrong, W., &amp; Pickard, H., 2013, &ldquo;What is
addiction?&rdquo; in K.W.M. Fulford et al. (eds.), <em>The Oxford
Handbook of Philosophy and Psychiatry</em>. pp. 851&ndash;864, Oxford:
Oxford University Press.
doi:10.1093/oxfordhb/9780199579563.013.0050</li>

<li>Sinnott-Armstrong, W., &amp; Skorburg, J. A., 2021, &ldquo;How AI
can AID bioethics&rdquo;, <em>Journal of Practical Ethics</em>, 9(1).
doi:10.3998/jpe.1175</li>

<li>Slote, M., 1982, &ldquo;Is virtue possible?&rdquo;
<em>Analysis</em>, 42(2): 70&ndash;76.</li>

<li>Smith, A., 2005, &ldquo;Responsibility for attitudes: Activity and
passivity in mental life&rdquo;, <em>Ethics</em>, 115:
236&ndash;271.</li>

<li>&ndash;&ndash;&ndash;, 2008, &ldquo;Control, responsibility, and
moral assessment&rdquo;, <em>Philosophical Studies</em>, 138:
367&ndash;392.</li>

<li>Smith, H., 1983, &ldquo;Culpable ignorance&rdquo;, <em>The
Philosophical Review</em>, 92(4): 543&ndash;571.</li>

<li>Solway, A., &amp; Botvinick, M. M., 2012, &ldquo;Goal-directed
decision making as probabilistic inference: A computational framework
and potential neural correlates&rdquo;, <em>Psychological Review</em>,
119(1): 120&ndash;154.</li>

<li>Sripada, C., 2021, &ldquo;Impaired control in addiction involves
cognitive distortions and unreliable self-control, not compulsive
desires and overwhelmed self-control&rdquo;, <em>Behavioural Brain
Research</em>, 418: 113639.</li>

<li>&ndash;&ndash;&ndash;, 2022, &ldquo;Loss of control in addiction:
The search for an adequate theory and the case for intellectual
humility&rdquo;, In M. Vargas &amp; J. M. Doris (eds.), <em>Oxford
Handbook of Moral Psychology</em>, Oxford: Oxford University
Press.</li>

<li>&ndash;&ndash;&ndash;, 2025, &ldquo;The valuationist model of
human agent architecture&rdquo;, <em>Philosophical Psychology</em>,
first online 06 April 2025. doi:10.1080/09515089.2025.2485323</li>

<li>Steyvers, M., Tenenbaum, J. B., Wagenmakers, E.-J., &amp; Blum,
B., 2003, &ldquo;Inferring causal networks from observations and
interventions&rdquo;, <em>Cognitive Science</em>, 27(3):
453&ndash;489.</li>

<li>Stich, S., 1996, <em>Deconstructing the mind</em>. New York:
Oxford University Press on Demand.</li>

<li>Strawson, G., 1994, &ldquo;The impossibility of moral
responsibility&rdquo;, <em>Philosophical Studies</em>, 75:
5&ndash;24.</li>

<li>Strawson, P., 1962, &ldquo;Freedom and resentment&rdquo;,
<em>Proceedings of the British Academy</em>, 48: 187&ndash;211.</li>

<li>Sussman, S., &amp; Sussman, A. N., 2011, &ldquo;Considering the
definition of addiction&rdquo;, <em>International Journal of
Environmental Research and Public Health</em>, 8(10):
4025&ndash;4038.</li>

<li>Sutton, R. S., &amp; Barto, A. G., 1998, <em>Reinforcement
Learning: An Introduction</em>, Cambridge: Bradford.</li>

<li>Theeuwes, J., Bogaerts, L., &amp; van Moorselaar, D., 2022,
&ldquo;What to expect where and when: How statistical learning drives
visual selection&rdquo;, <em>Trends in Cognitive Sciences</em>,
26(10): 860&ndash;872.</li>

<li>Vargas, M., 2013, <em>Building better beings: A theory of moral
responsibility</em>, Oxford: Oxford University Press.</li>

<li>Wallace, R. J., 1998, <em>Responsibility and the moral
sentiments</em>, Cambridge: Harvard University Press.</li>

<li>&ndash;&ndash;&ndash;, 1999, &ldquo;Addiction as defect of the
will: Some philosophical reflections&rdquo;, <em>Law and
Philosophy</em>, 18(6): 621&ndash;654.
doi:10.1023/A:1006315614953</li>

<li>Watson, G., 1999, &ldquo;Disordered appetites: Addiction,
compulsion, and dependence&rdquo;, in <em>Addiction: Entries and
exits</em>, pp. 3&ndash;28, New York: Russell Sage Foundation.</li>

<li>Watzl, S., 2017, <em>Structuring mind: The nature of attention and
how it shapes consciousness</em>. Oxford University Press.</li>

<li>Weatherson, B., 2019, <em>Normative ignorance</em>. Oxford: Oxford
University Press.</li>

<li>Wieland, J. W., &amp; Robichaud, P., 2017, <em>Responsibility: The
epistemic condition</em>. Oxford: Oxford University Press.</li>

<li>Williams, D., 2021, &ldquo;Socially adaptive belief&rdquo;,
<em>Mind &amp; Language</em>, 36(3): 333&ndash;354.</li>

<li>&ndash;&ndash;&ndash;, 2023, &ldquo;Bad beliefs: Why they happen
to highly intelligent, vigilant, devious, self-deceiving, coalitional
apes&rdquo;, <em>Philosophical Psychology</em>, 36(4):
819&ndash;833.</li>

<li>Williamson, T., 2007, <em>The philosophy of philosophy</em>.
Oxford: Blackwell Publishing.</li>

<li>Wolf, S., 1980, &ldquo;Asymmetrical freedom&rdquo;, <em>The
Journal of Philosophy</em>, 77(3): 151&ndash;166.
doi:10.2307/2025667</li>

<li>&ndash;&ndash;&ndash;, 1993, <em>Freedom within reason</em>.
Oxford: Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2012, &ldquo;Sanity and the metaphysics of
responsibility&rdquo;, in R. Shafer-Landau (ed.), <em>Ethical Theory:
An Anthology</em>. New York: John Wiley &amp; Sons.</li>

<li>Worsnip, A., 2022, &ldquo;Review of Bad beliefs: Why they happen
to good people&rdquo;, <em>Notre Dame Philosophical Reviews</em>,
2022.11.02.
 [<a href="https://ndpr.nd.edu/reviews/bad-beliefs-why-they-happen-to-good-people/" target="other">Worsnip 2022 available online</a>]</li>
 
<li>Wu, W., 2023, <em>Movements of the mind: A theory of attention,
intention and action</em>. Oxford: Oxford University Press.</li>

<li>Zelinsky, G. J., &amp; Bisley, J. W., 2015, &ldquo;The what,
where, and why of priority maps and their interactions with visual
working memory&rdquo;, <em>Annals of the New York Academy of
Sciences</em>, 1339(1): 154&ndash;164.</li>

<li>Zimmerman, M. J., 1997, &ldquo;Moral responsibility and
ignorance&rdquo;, <em>Ethics</em>, 107(3): 410&ndash;426.</li>
</ul>
</div> 

<div id="academic-tools">
<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=moral-responsibility-empirical" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/moral-responsibility-empirical/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=moral-responsibility-empirical&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="https://philpapers.org/sep/moral-responsibility-empirical/" target="other">Enhanced bibliography for this entry</a>
at <a href="https://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>
</div>

<div id="other-internet-resources">

<h2 id="Oth">Other Internet Resources</h2>

<ul>

<li>Kahan, D. M., 2017,
 <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2973067" target="other"><em>Misconceptions, misinformation, and the logic of identity-protective cognition</em></a>.
 SSRN. doi:10.2139/ssrn.2973067</li>
</ul>

<p>
[Please contact the author with suggestions.]</p>
</div>

<div id="related-entries">

<h2 id="Rel">Related Entries</h2>

<p>

 <a href="../attention/">attention</a> |
 <a href="../blame/">blame</a> |
 <a href="../bounded-rationality/">bounded rationality</a> |
 <a href="../computing-responsibility/">computing: and moral responsibility</a> |
 <a href="../moral-psych-emp/">moral psychology: empirical approaches</a> |
 <a href="../moral-responsibility/">moral responsibility</a> |
 <a href="../moral-responsibility-epistemic/">moral responsibility: the epistemic condition</a>

 </p>
</div> 

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2025</a> by

<br />
Chandra Sripada
&lt;<a href="m&#97;ilto:sripada&#37;40umich&#37;2eedu"><em>sripada<abbr title=" at ">&#64;</abbr>umich<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
            <li role="menuitem"><a href="../../new.html">What's New</a></li>
            <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li role="menuitem"><a href="../../published.html">Chronological</a></li>
            <li role="menuitem"><a href="../../archives/">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
            <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
            <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
            <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
            <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
            <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
            <li role="menuitem"><a href="../../accessibility.html">Accessibility</a></li>
            <li role="menuitem"><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
            <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
            <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2025</a> by <a href="https://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>
</html>
