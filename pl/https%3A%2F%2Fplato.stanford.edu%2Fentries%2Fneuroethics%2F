<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html lang="en"> <!-- <![endif]-->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Neuroethics (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Neuroethics" />
<meta property="citation_author" content="Roskies, Adina" />
<meta property="citation_publication_date" content="2016/02/10" />
<meta name="DC.title" content="Neuroethics" />
<meta name="DC.creator" content="Roskies, Adina" />
<meta name="DCTERMS.issued" content="2016-02-10" />
<meta name="DCTERMS.modified" content="2025-09-02" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP home page" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
                    <li role="menuitem"><a href="../../new.html">What's New</a></li>
                    <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li role="menuitem"><a href="../../published.html">Chronological</a></li>
                    <li role="menuitem"><a href="../../archives/">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
                    <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
                    <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
                    <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
                    <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
                    <li role="menuitem"><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
                    <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
                    <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="../../search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit" aria-label="search"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/neuroethics/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=neuroethics">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Neuroethics</h1><div id="pubinfo"><em>First published Wed Feb 10, 2016; substantive revision Tue Sep 2, 2025</em></div>

<div id="preamble">

<p>
Neuroethics is an interdisciplinary field focusing on ethical issues
raised by our increased and constantly improving understanding of the
brain and our ability to monitor and influence it.</p>
</div> 

<div id="toc"><!--Entry Contents-->
<ul>
<li><a href="#RiseScopNeur">1. The rise and scope of neuroethics</a></li>
<li><a href="#EthiNeur">2. The ethics of neuroscience</a>
   <ul>
   <li><a href="#EthiEnha">2.1 The ethics of enhancement</a>
      <ul>
      <li><a href="#ArguForEnha">2.1.1 Arguments for Enhancement</a></li>
      <li><a href="#ArguAgaiEnha">2.1.2 Arguments against Enhancement</a></li>
      </ul></li>
   <li><a href="#CognLibe">2.2 Cognitive liberty</a>
      <ul>
      <li><a href="#Priv">2.2.1 Privacy</a></li>
      </ul></li>
   <li><a href="#InteCont">2.3 Intervention and control</a>
      <ul>
      <li><a href="#Auto">2.3.1 Autonomy</a></li>
      <li><a href="#AgenIden">2.3.2 Agency and Identity</a></li>
      </ul></li>
   <li><a href="#ConsLifeDeat">2.4 Consciousness, life, and death</a>
      <ul>
      <li><a href="#DisoCons">2.4.1 Disorders of Consciousness</a></li>
      <li><a href="#BraiOrga">2.4.2 Brain Organoids</a></li>
      </ul></li>
   <li><a href="#PracNeur">2.5 Practical neuroethics</a></li>
   <li><a href="#PublPercNeur">2.6 Public perception of neuroscience</a>
      <ul>
      <li><a href="#SeduAllu">2.6.1 The seductive allure</a></li>
      <li><a href="#MediHype">2.6.2 Media Hype</a></li>
      </ul></li>
   <li><a href="#NeurJust">2.7 Neuroscience and justice</a></li>
   </ul></li>
<li><a href="#NeurEthi">3. The Neuroscience of Ethics</a></li>
<li><a href="#LookForwNewNeur">4. Looking forward: New neurotechnologies</a></li>
<li><a href="#Bib">Bibliography</a></li>
<li><a href="#Aca">Academic Tools</a></li>
<li><a href="#Oth">Other Internet Resources</a></li>
<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->

<hr /></div>

<div id="main-text">

<h2 id="RiseScopNeur">1. The rise and scope of neuroethics</h2>

<p>
Neuroethics focuses on ethical issues raised by our continually
improving understanding of the brain, and by consequent improvements
in our ability to monitor and influence brain function. Significant
attention to neuroethics can be traced to 2002, when the Dana
Foundation organized a meeting of neuroscientists, ethicists, and
other thinkers, entitled <em>Neuroethics: Mapping the Field</em>. A
participant at that meeting, columnist and wordsmith William Safire,
is often credited with introducing and establishing the meaning of the
term &ldquo;neuroethics&rdquo;, defining it as &lsquo;the examination
of what is right and wrong, good and bad about the treatment of,
perfection of, or unwelcome invasion of and worrisome manipulation of
the human brain&rsquo; (Marcus 2002, p.5). Others contend that the
word &ldquo;neuroethics&rdquo; was in use prior to this (Illes 2006;
Racine 2010), although all agree that these earlier uses did not
employ it in a disciplinary sense, or to refer to the entirety of the
ethical issues raised by neuroscience.</p>

<p>
Another attendee at that initial meeting, Adina Roskies, in response
to a perceived lack of recognition of the potential novelty of
neuroethics, penned &ldquo;Neuroethics for the new millennium&rdquo;
(Roskies 2002), an article in which she proposed a bipartite division
of neuroethics into the &ldquo;ethics of neuroscience&rdquo;, which
encompasses the kinds of ethical issues raised by Safire, and
&ldquo;the neuroscience of ethics&rdquo;, thus suggesting an extension
of the scope of neuroethics to encompass our burgeoning understanding
of the biological basis of ethical thought and behavior and the ways
in which this could itself influence and inform our ethical thinking.
This broadening of the scope of neuroethics highlights the obvious and
not-so-obvious ways that understanding our own moral thinking and
behavior might affect our moral views; it is one aspect of neuroethics
that distinguishes it from traditional bioethics. Another way of
characterizing the field is as a study of ethical issues arising from
what we can do to the brain (e.g. with neurotechnologies) and from
what we know about it (including, for example, understanding the basis
of ethical behavior).</p>

<p>
Although Roskies&rsquo; definition remains influential, it has been
challenged in various ways. Some have argued that neuroethics should
not be limited to the neuroscience of ethics, but rather be broadened
to the cognitive science of ethics (Levy, personal communication),
since so much work that enables us to understand the brain takes place
in disciplines outside of neuroscience, strictly defined. This is in
fact in the spirit of the original proposal, since it has been widely
recognized that the brain sciences encompass a wide array of
disciplines, methods, and questions. However, the most persistent
criticisms have been from those who have questioned whether the
neuroscience of ethics should be considered a part of neuroethics at
all: they argue that understanding our ethical faculties is a
scientific and not an ethical issue, and thus should not be part of
neuroethics. This argument is usually followed by a denial that
neuroethics is sufficiently distinct from traditional bioethics to
warrant being called a discipline in its own right.</p>

<p>
The response to these critics is different: Whether or not these
various branches of inquiry form a natural kind or are themselves a
focus of ethical analysis is quite beside the point. Neuroethics is
porous. One cannot successfully engage with many of the ethical issues
without also understanding the science. In addition, academic or
intellectual disciplines are at least in part (if not entirely) social
constructs. And in this case the horse is out of the barn: It is clear
that interesting and significant work is being pursued regarding the
brain bases of ethical thought and behavior, and that this theoretical
understanding has influenced, and has the potential to influence, our
own thinking about ethics and our ethical practices. That neuroethics
exists is undeniable: Neuroethical lines of research have borne
interesting fruit over the last 20-plus years; neuroethics is now
recognized as an area of study both nationally and internationally;
neuroethics courses are taught at many universities; and training
programs, professional societies, and research centers for neuroethics
have already been established. The NIH BRAIN Initiative has devoted
considerable resources to encouraging neuroscientific projects that
incorporate neuroethical projects and analyses. Neuroethics is a
discipline in its own right in part because we already structure our
practices in ways that recognize it as such. What is most significant
about neuroethics is not whether both the ethics of neuroscience and
the neuroscience of ethics are given the same overarching disciplinary
name, but that there are people working on both endeavors and that
they are in dialogue. Indeed, sometimes the very same people do
both.</p>

<p>
Of course, to the extent that neuroethicists ask questions about
disease, treatment, and so on, the questions will look familiar, and
for answers they can and should look to extant work in traditional
bioethics so as not to reinvent the wheel. But, ultimately, Farah is
correct in saying that &ldquo;New ethical issues are arising as
neuroscience gives us unprecedented ways to understand the human mind
and to predict, influence, and even control it. These issues lead us
beyond the boundaries of bioethics into the philosophy of mind,
psychology, theology, law and neuroscience itself. It is this larger
set of issues that has&hellip;earned it a name of its own&rdquo;
(Farah 2010, p. 2).</p>

<h2 id="EthiNeur">2. The ethics of neuroscience</h2>

<p>
Neuroethics is driven by neurotechnologies: it is concerned with the
ethical questions that attend the development and effects of novel
neurotechnologies, as well as other ethical and philosophical issues
that arise from our growing understanding of how brains give rise to
the people that we are and the social structures that we inhabit and
create. These questions are intimately bound up with scientific
questions about what kinds of knowledge can be acquired with
particular techniques: what are the scope and limits of what a
technique can tell us? With many new techniques, answers to these
questions are obscure not only to the lay public, but often to the
scientists and clinicians themselves. The uncertainty about the reach
of these technologies, their limits, and the unforeseen consequences
of their use adds to the challenge of grappling with the ethical
issues raised.</p>

<p>
Many new neurotechnologies enable us to monitor brain processes and
increasingly, to understand how the brain gives rise to certain
behaviors; others enable us to intervene in these processes, to change
and perhaps to control behaviors, traits, or abilities. Recent
advances in machine learning and the ubiquity of artificial
intelligence promise to increasingly inflect many of the extant issues
and to introduce some novel ones (Ienca and Ignatiadis 2020; Friedrich
et al. 2021). Although it will be impossible to fully canvass the
range of questions neuroethics has thus far contemplated, discussion
of the issues raised by a few neurotechnologies will allow me to
illustrate the range of questions neuroethics entertains. The
following is a not-exhaustive list of topics that fall under the
general rubric of neuroethics.</p>

<h3 id="EthiEnha">2.1 The ethics of enhancement</h3>

<p>
Medicine&rsquo;s traditional goal of treating illness is pursued by
the development of drugs and other treatments that counteract the
detrimental effects of disease or insult, and ethical questions arise
regarding how to weigh the risks and benefits of treatment. However,
the same kinds of compounds and methods that are being developed to
treat disease may also enhance normal cognitive functioning. We
already possess the ability to improve some aspects of cognition above
baseline, and will certainly develop other ways of doing so. Although
many neurotechnologies are responsive to clinical needs, some
potential forms of enhancement may be readily available, such as
transcranial direct current stimulation (tDCS) or certain
pharmaceuticals while other forms may be quite invasive and/or
expensive, as with many BCIs, such as the brain implants being
developed by Neuralink. Thus, a prominent topic in neuroethics is the
ethics of neuroenhancement (see e.g. Jotterand and Ienca, 2023): What
are the arguments for and against the use of neurotechnologies to
enhance one&rsquo;s brain&rsquo;s capacities and functioning? Under
what conditions, if any, is enhancement permissible?</p>

<p>
Proponents of enhancement are sometimes called
&ldquo;transhumanists,&rdquo; and opponents are identified as
&ldquo;bioconservatives&rdquo;. These value-laden appellations may
unnecessarily polarize a debate that need not pit extreme viewpoints
against each other, and that offers many nuanced intermediate
positions that recognize shared values (Parens 2005) and make room for
embracing the benefits of enhancement while recognizing the need for
some type of regulation (e.g. Lin and Alhoff 2008). The relevance of
this debate itself depends to some extent upon a philosophical issue
familiar to traditional bioethicists: the notorious difficulty of
identifying the line between disease and normal function, and the
corresponding difference between treatment and enhancement. However,
despite the difficulty attending the principled drawing of this line,
there are already clear instances in which a technology such as a drug
is used with the aim of improving a capacity or behavior that is by no
means clinically dysfunctional, or with the goal of improving a
capacity beyond the range of normal functioning. One common example is
the use, now widespread on college campuses and beyond, of
methylphenidate, a stimulant typically prescribed for the treatment of
ADHD. Known by the brand name Ritalin, methylphenidate has been shown
to improve performance on working memory, episodic memory and
inhibitory control tasks. Many students use it as a study aid, and the
ethical standing of such off-label use is a focus of debate among
neuroethicists (Sahakian and Morein-Zamir 2007; Greely et al.,
2008).</p>

<p>
As in the example above, the enhancements neuroethicists most often
discuss are <em>cognitive</em> enhancements: technologies that allow
normal people to function cognitively at a higher level than they
might without use of the technology (Knafo and Venero 2015). These may
include, for example, pharmacological enhancements of attention or
cognitive control, or targeted neurotechnologies for the modification
of memory, such as optogenetics (Zawadzki &amp; Adamczyk 2021). One
standing theoretical issue for neuroethics is a careful and precise
articulation of whether, how and why cognitive enhancement has a
philosophical status different than any other kind of enhancement,
such as enhancement of physical capacities by the use of steroids
(Dresler 2019).</p>

<p>
Often overlooked are other interesting potential neuroenhancements.
These are less frequently discussed than cognitive enhancements, but
just as worthy of consideration. They include social/moral
enhancements, such as the use of oxytocin to enhance pro-social
behavior, and other noncognitive but biological enhancements, such as
potential physical performance enhancers controlled by brain-computer
interfaces (BCIs) (see, e.g., Savulescu &amp; Persson 2012; Douglas
2008; Dubljev&iacute;c &amp; Racine 2017; Gordon &amp; Seth 2024). In
many ways, discussions regarding these kinds of enhancement
effectively recapitulate the cognitive enhancement debate, but in some
respects they raise different concerns and prompt different
arguments.</p>

<h4 id="ArguForEnha">2.1.1 Arguments for Enhancement</h4>

<p>
Naturalness: Although the aim of cognitive enhancement may at first
seem ethically questionable at best, it is plausible that humans
naturally engage in many forms of enhancement, including cognitive
enhancement. Indeed, we typically applaud and value these efforts.
After all, the aim of education is to cognitively enhance students
(which, we now understand, occurs by changing their brains), and we
look askance at those who devalue this particular enhancement, rather
than at those who embrace it. So some kinds of cognitive enhancement
are routine and unremarkable. Proponents of neuroenhancement will
argue that there is no principled difference between the enhancements
we routinely engage in, and enhancement by use of drugs or other
neurotechnologies. Many in fact argue that we are a species whose
nature it is to develop and use technology for augmenting our
capacities, and that continual pursuit of enhancement is a mark of the
human.</p>

<p>
Cognitive liberty: Those who believe that &ldquo;cognitive
liberty&rdquo; (see
 <a href="#CognLibe">section</a>
 2.2 below) is a fundamental right argue that an important element of
the autonomy at stake in cognitive liberty is the liberty to determine
for ourselves what to do with our minds and to them, including
cognitive enhancement, if we so choose. Although many who champion
&ldquo;cognitive liberty&rdquo; do so in the context of a strident
political libertarianism (e.g. Boire 2001), one can recognize the
value of cognitive liberty without swallowing an entire political
agenda. So, for example, even if we think that there is a <em>prima
facie</em> right to determine our own cognitive states, there may be
justifiable limits to that right. More work needs to be done to
establish the boundaries of the cognitive liberty we ought to
safeguard.</p>

<p>
Utilitarian arguments: Many proponents of cognitive enhancement point
to the positive effects of enhancement and argue that the benefits
outweigh the costs. In these utilitarian arguments it is important to
consider the positive and negative effects not only for individuals,
but also for society more broadly (see, e.g. Selgelid 2007).</p>

<p>
Deontological arguments: Sometimes enhancements are argued to be an
avenue for leveling the playing field, in pursuit of fairness and
equity. Such arguments are bolstered by the finding that at least for
some interventions, enhancement effects are greater for those who have
lower baseline functioning than those starting with a higher baseline
(President&rsquo;s Commission on Bioethics 2015).</p>

<p>
Practical arguments: These often point to the difficulty in enforcing
regulations of extant technology, or the detrimental effects of trying
to do so. They tend to be not really arguments in favor of
enhancement, but rather reasons not to oppose its use.</p>

<h4 id="ArguAgaiEnha">2.1.2 Arguments against Enhancement</h4>

<p>
There are a variety of arguments against enhancement. Most fall into
the following types:</p>

<p>
Harms: The simplest and most powerful argument against enhancement is
the claim that brain interventions carry with them the risk of harm,
risks that make the use of these interventions unacceptable. The low
bar for acceptable risk is an effect of the context of enhancement:
risks deemed reasonable to incur when treating a deficiency or disease
with the potential benefit of restoring normal function may be deemed
unreasonable when the payoff is simply augmenting performance above a
normal baseline. Some suggest that no risk is justified for
enhancement purposes. In evaluating the strength of a harm-based
argument against enhancement, several points should be considered:</p>

<ol>

<li>What are the actual and potential harms and benefits (medical and
social) of a given enhancement (see, e.g., Urban et al. 2014)?</li>

<li>Who should make the judgments about appropriate tradeoffs?
Different individuals may judge differently at what point the
risk/benefit threshold occurs, and their judgments may depend upon the
precise natures of the risks and benefits.</li>
</ol>

<p>
Notice, too, the harm argument is toothless against enhancements that
don&rsquo;t pose any risks.</p>

<p>
Unnaturalness: A number of thinkers argue, in one form or another,
that use of drugs or technologies to enhance our capacities is
unnatural, and the implication is that <em>unnatural</em> implies
<em>immoral</em>. Of course, to be a good argument, more reason has to
be given both for why it is unnatural (see an argument for
naturalness, above), and for why naturalness and morality align. Some
arguments suggest that manipulating our cognitive machinery amounts to
tinkering with &ldquo;God-given&rdquo; capacities, and usurping the
role of God as creator can be easily understood as transgressive in a
religious-moral framework. Despite its appeal to religious
conservatives, a neuroethicist may want to offer a more ecumenical or
naturalistic argument to support the link between <em>unnatural</em>
and <em>immoral</em>, and will have to counter the claim, above, that
it is natural for humans to enhance themselves.</p>

<p>
Diminishing human agency: Another argument suggests that the effect of
enhancement will be to diminish human agency by undermining the need
for real effort, and allowing for success with morally meaningless
shortcuts. Human life will lose the value achieved by the process of
striving for a goal and will be belittled as a result (see, e.g.
Schermer 2008; Kass 2003). Although this is a promising form of
argument, more needs to be done to undergird the claims that effort is
intrinsically valuable. Recent work suggests no general argument to
this effect is forthcoming (Douglas 2019). After all, few find
compelling the argument that we ought to abandon transportation by car
for horses, walking, or bicycling, because these require more effort
and thus have more moral value. On the other hand, the cognitive
off-loading that is now conceivable given the functionality of various
forms of AI raises the prospect of some &ldquo;enhancements&rdquo;
resulting in a wide-ranging cognitive passivity that may well be
destabilizing to the mental health of individuals and to entire
societies. Thus, recent technological developments may prompt renewed
attention to the importance of human agency and a more nuanced view of
what constitutes enhancement.</p>

<p>
The hubris objection: This interesting argument holds that the type of
attitude that seems to underlie pursuit of such interventions is
morally defective in some way, or is indicative of a morally defective
character trait. So, for example, Michael Sandel suggests that the
attitude underlying the attempt to enhance ourselves is a
&ldquo;Promethean&rdquo; attitude of mastery that overlooks or
underappreciates the &ldquo;giftedness of human life.&rdquo; It is the
expression and indulgence of a problematic attitude of dominion toward
life to which Sandel primarily objects: &ldquo;The moral problem with
enhancement lies less in the perfection it seeks than in the human
disposition it expresses and promotes&rdquo; (Sandel 2002). Others
have pushed back against this tack, arguing that the hubris objection
against enhancement is at base a religious one, or that it
fundamentally misunderstands the concepts it relies upon (Kahane,
2011).</p>

<p>
Equality and Distributive Justice: One question that routinely arises
with new technological advances is &ldquo;who gets to benefit from
them?&rdquo; As with other technologies, neuroenhancements are not
free. However, worries about access are compounded in the case of
neuroenhancements (as they may also be with other learning
technologies). As enhancements increase capacities of those who use
them, they are likely to further widen the already unconscionable gap
between the haves and have-nots: We can foresee that those already
well-off enough to afford enhancements will use them to increase their
competitive advantage against others, leaving further behind those who
cannot afford them. Not all arguments in this vein militate against
enhancement. For example, the finding mentioned above &ndash; that at
least with some cognitive enhancement technologies, those who have
lower baseline functioning experience greater improvements than those
starting at a higher level &ndash; could ground pro-enhancement
fairness and equity arguments for leveling the playing field
(President&rsquo;s Commission on Bioethics 2015). As public
consciousness about racial and economic disparities increases, we
should expect more neuroethical work on this topic. Although one can
imagine policy solutions to distributive justice concerns, such as
having enhancements covered by health insurance, having the state
distribute them to those who cannot afford them, etc., widespread
availability of neuroenhancements will inevitably raise questions
about coercion.</p>

<p>
Coercion: The prospect of coercion is raised in several ways.
Obviously, if the state decides to mandate an enhancement, treating
its beneficial effects as a public health issue, this is effectively
coercion. We see this currently in the backlash against vaccinations:
they are mandated with the aim of promoting public health, but in some
minds the mandate raises concerns about individual liberty. I would
submit that the vaccination case demonstrates that at least on some
occasions coercion is justified. The question is whether coercion
could be justifiable for enhancement, rather than for harm prevention.
Although some coercive ideas, such as the suggestion that we put
Prozac or other enhancers in the water supply, are unlikely to be
taken seriously as a policy issue (however, see Appel 2010), less
blatant forms of coercion are more realistic. For example, if people
immersed in tomorrow&rsquo;s competitive environment are in the
company of others who are reaping the benefits from cognitive
enhancement, they may feel compelled to make use of the same
techniques just to remain competitive, even though they would rather
not use enhancements. The danger is that respecting the autonomy of
some may put pressure on the autonomy of others.</p>

<p>
There is unlikely to be any categorical resolution of the ethics of
enhancement debate. The details of a technology will be relevant to
determining whether a technology ought to be made available for
enhancement purposes: we ought to treat a highly enhancing technology
that causes no harm differently from one that provides some benefit at
noticeable cost. Moreover, the magnitude of some of the
equality-related issues will depend upon empirical facts about the
technologies. Are neurotechnologies equally effective for everyone? As
mentioned, there is evidence that some known enhancers such as the
psychostimulants are more effective for those with deficiencies than
for the unimpaired: studies suggest the beneficial effects of these
drugs are proportional to the degree to which a capacity is impaired
(Husain and Mehta 2011). Other reports claim that normal
subjects&rsquo; capacities are not actually enhanced by these drugs,
and some aspects of functioning may actually be impaired (Mattay, et
al. 2000; Ileva et al. 2013). If this is a widespread pattern, it may
alleviate some worries about distributive justice and contributions to
social and economic stratification, since people with a deficit will
benefit proportionately more than those using the drug for enhancement
purposes. Bear in mind, however, that biology is rarely that
equitable, and it would be surprising if this pattern turned out to be
the norm. Since the technologies that could provide enhancements are
extremely diverse, ranging from drugs to implants to genetic
manipulations, assessment of the risks and benefits and the way in
which these technologies bear upon our conception of humanity will
have to be empirically grounded.</p>

<h3 id="CognLibe">2.2 Cognitive liberty</h3>

<p>
Freedom is a cornerstone value in a democracy, and one of the most
cherished kinds of freedom is freedom of thought. The main elements of
freedom of thought, or &ldquo;cognitive liberty&rdquo; as it is
sometimes called (Sententia 2013), include privacy and autonomy. Both
of these can be challenged by the new developments in neuroscience.
The value of, potential threat to, and ways to protect these aspects
of freedom are a concern for neuroethics. Several recent papers have
posited novel rights in this realm, such as rights to cognitive
liberty, to mental privacy, to mental integrity, and to psychological
continuity (Ienca &amp; Andorno 2017; see also Ligthart et al. 2023),
or alternatively, to psychological integrity and mental
self-determination (Bublitz 2020). Indeed, there is a recent
international movement to codify new neurorights, and to enact
regulations to legally protect the human mind from infringement by
various potential bad actors. Chile, for example, is the first nation
to enshrine neurorights in its constitution, with consequences not
uniformly seen as positive (Ruiz et al. 2023).</p>

<p>
While there is undoubtedly a greater threat to cognitive liberty with
modern neurotechnologies than previously, there is disagreement about
how such threats should be addressed (Ienca 2021). Do they call for
legal protections and/or explicit regulation? Must we enshrine novel
neurorights, or can cognitive liberty be adequately protected under
the umbrella of current human rights protections, either as they stand
or with modest extensions? While some argue that protecting the mind
and brain will require specially crafted policy, others worry that the
liberty of persons generally conceived is more fundamental, and
encompassing of the mental protections we want. They maintain that
devising a separate law for the mind and brain will shift attention
away from, and possibly defang, protections from assaults on privacy
and autonomy in other realms that &ndash; while less sexy &ndash; are
more prevalent and insidious, such as widespread data gathering on
individual behavior that cedes information to and empowers corporate
interests at the expense of individuals.</p>

<h4 id="Priv">2.2.1 Privacy</h4>

<p>
As the framers of our constitution were well aware, freedom is
intimately linked with privacy: even being monitored is considered
potentially &ldquo;chilling&rdquo; to the kinds of freedoms our
society aims to protect. One type of freedom that has been championed
in American jurisprudence is &ldquo;the right to be let alone&rdquo;
(Warren and Brandeis, 1890), to be free from government or other
intrusion in our private lives.</p>

<p>
In the past, mental privacy could be taken for granted: the
first-person accessibility of the contents of consciousness ensured
that the contents of one&rsquo;s mind remained hidden to the outside
world, until and unless they were voluntarily disclosed. Instead, the
battles for freedom of thought were waged at the borders where thought
meets the outside world &ndash; in expression &ndash; and were won
with the First Amendment&rsquo;s protections for those freedoms (note,
however, that these protections are only against government
infringement, and now even these are under threat). Over the last half
century, technological advances have eroded or impinged upon many
traditional realms of worldly privacy. Most of the avenues for
expression can be (and increasingly are) monitored by third parties.
It is tempting to think that the inner sanctum of the mind remains the
last bastion of real privacy.</p>

<p>
This may still be largely true, but even the privacy of the mind can
no longer to be taken for granted. Our neuroscientific achievements
have already made significant headway in allowing others to discern
some aspects of our mental content through neurotechnologies.
Noninvasive methods of brain imaging have revolutionized the study of
human cognition and have dramatically altered the kinds of knowledge
we can acquire about people and their minds. Neither is the threat to
mental privacy as simple as the naive claim that neuroimaging can read
our thoughts, nor are the capabilities of imaging so innocuous and
blunt that we needn&rsquo;t worry about that possibility. A focus of
neuroethics is to determine the real nature of the threat to mental
privacy, and to evaluate its ethical implications, many of which are
relevant to legal, medical, and other social issues (Shen 2013). For
example, in a world in which the bastion of the mind may be lowering
its drawbridges, do we need extra protections? Doing so effectively
will require both a solid understanding of the neuroscientific
technologies and the neural bases of thought, as well as a sensitivity
to the ethical problems raised by our growing knowledge and
ever-more-powerful neurotechnologies. These dual necessities
illustrate why neuroethicists must be trained both in neuroscience and
in ethics. In what follows I briefly discuss the most relevant
neurotechnology and its limitations and then canvas a few ways in
which privacy may be infringed by it.</p>

<h5>2.2.1.1 An illustration: Potential threats to privacy with Functional MRI</h5>

<p>
One of the most prominent neurotechnologies poised to pose a threat to
privacy is Magnetic Resonance Imaging, or MRI. MRI can provide both
structural and functional information about a person&rsquo;s brain
with minimal risk and inconvenience. In general, MRI is a tool that
allows researchers noninvasively to examine or monitor brain structure
and activity, and to correlate that structure or function with
behavior. Structural or anatomical MRI provides high-resolution
structural images of the brain. While structural imaging in the
biosciences is not new, MRI provides much higher resolution and better
ability to differentiate tissues than prior techniques such as x-rays
or CT scans.</p>

<p>
However, it is not structural but functional MRI (fMRI) that has
revolutionized the study of human cognition. fMRI provides information
about correlates of neuronal activity, from which neural activity can
be inferred. Recent advances in analysis methods for neuroimaging data
such as multi-voxel pattern analysis and related techniques now allow
relatively fine-grained &ldquo;decoding&rdquo; of brain activity.
Decoding involves probabilistic matching, using machine learning, of
an observed pattern of brain activation with experimentally
established correlations between activity patterns and some kind of
functional variable, such as task, behavior, or content. The kind of
information provided by functional imaging promises to provide
important evidence useful for three goals: Decoding mental content,
diagnosis, and prediction. Neuroethical questions arise in all these
areas.</p>

<p>
Before discussing these issues, it is important to remember that
neuroimaging is a technology that is subject to a number of
significant limitations, and these technical issues limit how precise
the inferences can be. For example:</p>

<ul class="jfy">

<li>The correlations between the fMRI signal and neural activity are
rough: the signal is delayed in time from the neuronal activity, and
spatially smeared, thus limiting the spatial and temporal precision of
the information that can be inferred.</li>

<li>A number of dynamic factors relate the fMRI signal to activity,
and the precise underlying model is not yet well-understood.</li>

<li>There is relatively low signal-to-noise, necessitating averaging
across trials and often across people.</li>

<li>Individual brains differ both in brain structure and in function.
Variability makes determining when differences are clinically or
scientifically relevant difficult, and leads to noisy data. Due to
natural individual variability in structure and function, and brain
plasticity (especially during development), even large differences in
structure or deviation from the norm may not be indicative of any
functional deficiency. Cognitive strategies can also affect
variability in the data. These sources of variability can complicate
the analysis of data and provide even more leeway for differences to
exist without implying dysfunction. However, numerous studies show
that despite variability, to some degree, semantic decoding is
possible across individuals (Tang and Huth 2025).</li>

<li>Activity in a brain area does not entail that the region is
necessary for performance of the task.</li>

<li>fMRI is so sensitive to motion that it would be virtually
impossible to get information from a noncompliant subject. This makes
the prospect of reading content from an unwilling mind virtually
impossible.</li>
</ul>

<p>
Without appreciating these technical issues and the resulting limits
to what can legitimately be inferred from fMRI, one is likely to
overestimate or mischaracterize the potential threat that it poses. In
fact, the threat is often sensationalized and overestimated: much of
the fear of mindreading expressed in non-scientific publications stems
from a lack of understanding or lack of attention to the limitations
of the science (Racine 2015). Ethical considerations should be
contextualized in terms of the actual and realistically foreseeable
capabilities and limitations of the neurotechnologies. For example,
there is no scientific basis to the worry that imaging would enable
the reading of mental content without our knowing it. Thus, fears that
the government is able to remotely or covertly monitor the thoughts of
citizens are unfounded. Different imaging technologies, such as EEG,
direct cortical recordings with implanted electrodes (ECOG), or Near
Infrared Spectroscopy (NIRS) each have their own set of suitable
applications, constraints and limitations.</p>

<h5>2.2.1.2 Decoding of mental content</h5>

<p>
Noninvasive ways of inferring neural activity have led many to worry
that mindreading is possible, not just in theory, but even now. Using
decoding techniques fMRI can be used, for example, to reconstruct a
visual stimulus from activity of the visual cortex while a subject is
looking at a scene or to determine whether a subject is looking at a
familiar face, or hearing a particular sound. If mental content
supervenes on the physical structure and function of our brains, as
most philosophers and neuroscientists think it does, then in principle
it should be possible to read minds by reading brains. Because of the
potential to identify mental content, decoding raises issues about
mental privacy.</p>

<p>
When it comes to mental content, our current abilities to
&ldquo;mind-read&rdquo; are still somewhat limited, but continually
improving (see, e.g. Roskies 2015b, 2020). In the last decade,
significant advances in decoding mental content have been made,
especially in conjunction with the development of generative models of
language (Tang et al. 2023; Silva et al. 2024). Until recently,
aspects of content decoded from neural data tended to be relatively
general and nonpropositional in character, and inferring semantic
meaning from ideation or visual stimulation worked best when the realm
of possible contents were quite constrained. However, with the advent
of Large Language Models (LLMs) and with improvements in brain
registration, reasonable estimations of propositional content can
sometimes be achieved. It is important to bear in mind that these are
merely estimations: they anchor best on concrete semantic atoms and
are informed by statistical regularities in the training set. Until we
understand how sensitive these techniques are to minor grammatical and
phonological differences that can completely change the meaning of a
sentence, we ought to be quite skeptical of the accuracy of any given
output. Ethical worries about privacy are also alleviated by data
suggesting that decoding only appears feasible with a cooperative
subject, both for training and decoding purposes (Tang et al.
2023).</p>

<p>
Even if neuroimaging is not at the stage where mindreading is
possible, it can nonetheless threaten aspects of privacy in ways that
should give us pause. Surprisingly, it is possible to identify
individuals on the basis of their brain scans (Finn et al. 2015;
Valizadeh et al. 2018), which raises questions about the
identifiability of health or other information. In addition,
neuroimaging can provide some insights into attributes of people that
they may not want known or disclosed. In some cases, subjects may not
even know that these attributes are being probed, thinking they are
being scanned for other purposes. A willing subject may not want
certain things to be monitored. In what follows, I consider a few of
these more realistic worries.</p>

<p>
Implicit bias: Although explicitly acknowledged racial biases are
declining, this may be due to a reporting bias attributable to the
increased negative social valuation of racial prejudice. Much
contemporary research now focuses on examining implicit racial biases,
which are automatic or unconscious reflections of racial bias. With
fMRI and EEG, it is possible to interrogate implicit biases, sometimes
without the subject&rsquo;s awareness that that is what is being
measured (Checkroud et al. 2014). While there is disagreement about
how best to interpret implicit bias results (e.g., as a measure of
perceived threat, as in-group/out-group distinctions, etc.), and what
relevance they have for behavior, the possibility that implicit biases
can be measured, either covertly or overtly, raises scientific and
ethical questions (Molenberghs and Louis 2018). When ought this
information be collected? What procedures must be followed for
subjects legitimately to consent to implicit measures? What
significance should be attributed to evidence of biases? What kind of
responsibility should be attributed to people who hold them? What
predictive power might they hold? Should they be used for practical
purposes? One can imagine obvious but controversial potential uses for
implicit bias measures in legal situations, in employment contexts, in
education, and in policing, all areas in which concerns of social
justice are significant.</p>

<p>
Lie detection: Several neurotechnologies are being used to detect
deception or neural correlates of lying or concealing information in
experimental situations. For example, both fMRI measures and EEG
analysis techniques relying on the P300 signal have been used in the
laboratory to detect deception with varying levels of success. These
methods are subject to a variety of criticisms (Farah et al. 2014).
For example, almost all experimental studies fail to study
<em>real</em> lying or deception, but instead investigate some version
of instructed misdirection. The context, tasks, and motivations differ
greatly between actual instances of lying and these experimental
analogs, calling into question the ecological validity of these
experimental techniques. Moreover, accuracy, though significantly
higher than chance, is far from perfect, and because of the inability
to determine base rates of lying, error rates cannot be effectively
assessed. Thus, we cannot establish their reliability for real-world
uses. Finally, both physical and mental countermeasures decrease the
accuracy of these methods (Hsu et al. 2019). Despite these
limitations, several companies have marketed neurotechnologies for
this purpose.</p>

<p>
Character traits: Neurotechnologies have shown some promise in
identifying or predicting aspects of personality or character. In an
interesting study aimed at determining how well neuroimaging could
detect lies, Greene and colleagues gave subjects in the fMRI scanner a
prediction task in a game of chance that they could easily cheat on.
By using statistical analysis the researchers could identify a group
of subjects who clearly cheated and others who did not (Greene and
Paxton 2009). Although they could not determine with neuroimaging on
which trials subjects cheated, there were overall differences in brain
activation patterns between cheaters and those who played fair and
were at chance in their predictions. Moreover, Greene and colleagues
repeated this study at several months remove, and found that the
character trait of honesty or dishonesty was stable over time:
cheaters the first time were likely to cheat (indeed, cheated even
more the second time), and honest players remained honest the second
time around. Also interesting was the fact that the brain patterns
suggested that cheaters had to activate their executive control
systems more than noncheaters, not only when they cheated, but also
when deciding not to cheat. While the differential activations cannot
be linked specifically to the propensity to cheat rather than to the
act of cheating, the work suggests that these task-related activation
patterns may reflect correlates of trustworthiness.</p>

<p>
The prospect of using methods for detecting these sorts of traits or
behaviors in real-world situations raises a host of thorny issues.
What level of reliability should be required for their employment? In
what circumstances should they be admissible as evidence in the
courtroom? For other purposes? Using lie detection or decoding
techniques from neuroscience in legal contexts may raise
constitutional concerns: Is brain imaging a search or seizure as
protected by the 4<sup>th</sup> Amendment? Would its forcible use be
precluded by 5<sup>th</sup> Amendment rights? These questions, though
troubling, might not be immediately pressing: in a landmark case
(<em>US v. Semrau,</em> 2012) the court ruled that fMRI lie detection
is inadmissible, given its current state of development. However, the
opinion left open the possibility that it may be admissible in the
future, if methods improve. Finally, to the extent that relevant
activation patterns may be found to correlate significantly with
activation patterns on other tasks, or with a task-free measure such
as default-network activity, it raises the possibility that
information about character could be inferred merely by scanning them
doing something innocuous, without their knowledge of the kind of
information being sought. Thus, there are multiple dimensions to the
threat to privacy posed by imaging techniques.</p>

<h5>2.2.1.3 Diagnosis</h5>

<p>
Increasingly, neuroimaging information can bear upon diagnoses for
diseases, and in some instances may provide predictive information
prior to the onset of symptoms (Sui et al. 2020). Work on the default
network is promising for improving diagnosis in certain diseases
without requiring that subjects perform specific tasks in the scanner
(Buckner et al. 2008). For some diseases, such as in Alzheimer&rsquo;s
disease, MRI promises to provide diagnostic information that
previously could only be established at autopsy (Liu et al. 2018).
fMRI signatures have also been linked to a variety of psychiatric
diseases, although not yet with the reliability required for clinical
diagnosis (Aydin et al. 2019). Neuroethical issues also arise
regarding ways to handle incidental findings, that is, evidence of
unsymptomatic tumors or potentially benign abnormalities that appear
in the course of scanning research subjects for non-medical purposes
(Illes et al. 2006; Illes and Sahakian 2011).</p>

<p>
The ability to predict future functional deficits raises a host of
issues, many of which have been previously addressed by genethics (the
ethics of genetics), since both provide information about future
disease risk. What may be different is that the diseases for which
neurotechnologies are diagnostically useful are those that affect the
brain, and thus potentially mental competence, mood, personality, or
sense of self. As such they may raise peculiarly neuroethical
questions (see below).</p>

<h5>2.2.1.4 Prediction</h5>

<p>
As discussed, decoding methods allow one to associate observed brain
activity with previously observed brain/behavior correlations. In
addition, such methods can also be used to predict future behaviors,
insofar as these are correlated with observations of brain activity
patterns. Some studies have already reported predictive power over
upcoming decisions (Soon et al. 2008). Increasingly, artificial
intelligence using predictive algorithms is integrated into our
neurotechnologies. It is inevitable that we will see neuroscience or
neuroimaging data that will give us some predictive power over
longer-range future behaviors. For example, brain imaging may allow us
to predict the onset of psychiatric symptoms such as psychotic or
depressive episodes. In cases in which this behavior is indicative of
mental dysfunction it raises questions about stigma, but also may
allow more effective interventions.</p>

<p>
One confusion regarding neuro prediction should be clarified
immediately: When neuroimages are said to &ldquo;predict&rdquo; future
activity, it means they provide <em>some</em> statistical information
regarding likelihood. Prediction in this sense does not imply that the
predicted behavior necessarily will come to pass; it does not mean a
person&rsquo;s future is fated or determined. Although scientists
occasionally make this mistake when discussing their results, the fact
that brain function or structure may give us some information about
future behaviors should not be interpreted as a strong challenge to
free will. The prevalence of this mistake among both philosophers and
scientists again illustrates the importance for neuroethicists of
sophistication in both neuroscience and philosophy.</p>

<p>
Perhaps the most consequential and most ethically difficult potential
use of predictive information is in the criminal justice system. For
example, there is evidence that structural brain differences are
predictive of scores on the PCL-R, a tool developed to diagnose
psychopathy. It is also well-established that psychopaths have high
rates of recidivism for violent offenses. Thus, in principle
neuroimaging could be used to provide information about an
individual&rsquo;s likelihood of recidivism. Indeed, brain information
appears to offer some predictive value when combined with other
factors (Poldrack et al. 2018; Delfin et al. 2019). One cautionary
tale comes from a recent exchange in the literature: A report
suggested that brain activity on a cognitive task predicts recidivism
(Aharoni et al. 2013), but a critical reanalysis of the data suggests
that methodological concerns led to an overestimate of the predictive
value of the neural data (Poldrack et al. 2018; Aharoni et al., 2014),
highlighting the importance of technical expertise in assessing the
findings and for translating the results of scientific experiments for
practical purposes and ethical analysis.</p>

<p>
Neuroethical analysis here is essential. Should neural data be
admissible for determining sentences or parole decisions? Would that
be equivalent to punishing someone for crimes they have not committed?
Or is it just a neutral extension of current uses of actuarial
information, such as age, gender, and income level? At an extreme, one
could imagine using predictive information to detain people who have
not yet committed a crime, arresting them before they do. This
dystopian scenario, portrayed in the film Minority Report (Spielberg,
2002), also illustrates how our abilities to predict can raise
difficult ethical and policy questions when they collide with
intuitions about and the value of free will and autonomy. More
generally, work in neuroethics could be of significant practical use
for the law (Jones et al. 2009), and indeed is often called by another
moniker, &ldquo;neurolaw&rdquo; (see section 2.7).</p>

<p>
In sum, neuroimaging techniques raise a number of neuroethical issues.
The ones discussed above pertain to the use of fMRI, currently an
expensive and cumbersome technique. But other imaging methods exist
that could be far more widespread. If car companies install imaging
methods, for example using NIRS (near infrared spectroscopy), which is
an imaging method that could be used at a distance and without the
subject&rsquo;s knowledge, or some other form of
 <a href="https://www.jaguarlandrover.com/news/2015/06/jaguar-land-rover-road-safety-research-includes-brain-wave-monitoring-improve-driver" target="other">brain monitoring to monitor levels of attention in order to alert drivers</a>
 who begin to doze off, could that data be used in a court of law in
the event of an accident? Even though the kind of information these
methods provide is very crude and generally unsuitable for decoding
mental content, there are conceivable everyday situations on the
horizon in which issues of mental privacy and neurotechnology might
arise.</p>

<h3 id="InteCont">2.3 Intervention and control</h3>

<p>
In addition to allowing us to monitor and predict what brains will do,
some neurotechnologies allow us to intervene on the nervous system and
affect behavior. This ability to alter and control action raises
numerous philosophical problems that are loosely related to questions
about agency and responsibility. In particular, important but not
well-defined constructs such as autonomy, authenticity, identity, and
personhood, may be impacted by neurointerventions.</p>

<h4 id="Auto">2.3.1 Autonomy</h4>

<p>
Cognitive liberty can also be impacted by limiting a person&rsquo;s
autonomy. Autonomy is the freedom to be the person one wants to be, to
pursue one&rsquo;s own goals without unjustifiable hindrances or
interference, to be self-governing. Although definitions of autonomy
differ, it is widely appreciated as a valuable aspect of personhood. A
closely related construct, authenticity, is roughly being able to be
and express one&rsquo;s true self. Autonomy and authenticity can be
impacted in a number of ways. Here are several:</p>

<p>
Direct interventions: The ability to directly manipulate our brains to
control our thoughts or behavior is an obvious threat to our autonomy
(Gilbert 2015; Walker and Mackenzie 2020). Some of our
neurotechnologies offer that potential, although these sorts of
neurotechnologies are invasive and used only in cases where they are
medically justified. Other types of interventions, such as the
administration of drugs to calm a psychotic person, may also impact
autonomy.</p>

<p>
We know that stimulating certain brain areas in animals will lead to
repetitive and often stereotyped behaviors. Scientists have implanted
rats with electrodes and have been able to control their foraging
behaviors by stimulating their cortex. In theory we could control a
person&rsquo;s behavior by implanting electrodes in the relevant
regions of cortex. In practice, we have a few methods that can do
this, but only in a limited way. For example, Transcranial Magnetic
Stimulation (TMS) applied to motor cortex can elicit involuntary
movements in the part of the body controlled by the cortical area
affected, or when repetitively administered it can inhibit activity
for a period of time, acting as a temporary lesion. Effects will vary
depending on what area of the brain is stimulated; higher cognitive
functions can be impacted as well. Relatively invasive methods, such
as Deep Brain Stimulation (DBS, discussed below) and
electrocorticography (ECOG), both techniques requiring brain surgery,
demonstrate that direct interventions can affect cognition, action,
and emotion, often in very particular and predictable ways.</p>

<p>
However much of a threat to autonomy these methods pose in theory,
they are rarely used with the aim of compromising autonomy. On the
contrary, direct brain interventions, when used in the context of
treatment, are largely aimed at augmenting or restoring rather than
bypassing or diminishing autonomy (Roskies 2015; Brown, 2015).</p>

<p>
Neural prostheses and brain computer interfaces: A rapidly advancing
field in neuroscience is the area of neural prostheses and brain
computer interfaces (Jebari 2013; Klein et al. 2015; Lebedev and
Nicolelis 2017). Neural prostheses are artificial systems that replace
defective neural ones, usually of sensory systems. Some of the more
advanced and widely-known are artificial cochleas. Other systems have
been developed that allow vision-like information to feed to
touch-specific receptors, enabling blind people to navigate the visual
world. Brain computer interfaces, on the other hand, are systems that
read brain activity and use it to guide robotic prostheses for limbs,
or to move a cursor on a video screen. Prosthetic limbs that are
guided by neural signals have restored motor agency to paraplegics and
quadriplegics, and other BCIs have been used to help people who are
&ldquo;locked in&rdquo; and cannot move their bodies to communicate
(Abbott and Peck 2017). Advisory and predictive implants use neural
information to warn patients about the risk of, for example, an
upcoming seizure, allowing them to prophylactically self-medicate
(Brown 2015; Lazaro-Munoz et al. 2017).</p>

<p>
Great strides have also been made in the development of prostheses to
restore speech in patients with communicative disabilities (Silva et
al. 2024; Littlejohn et al. 2024). These systems restore autonomy by
enabling patients to communicate more effectively, and in general they
increase autonomy. However, they also raise issues about mental
privacy, and in some circumstances may pose a risk to autonomy and
authenticity if they output information the patient does not wishes to
disclose, or when they do not accurately reflect the patient&rsquo;s
intent (Chandler et al. 2022). Nonetheless, their great promise lies
in their ability to restore function and autonomy to users. Thus,
although in principle brain interventions could be used to control
people and diminish their autonomy, in general, direct interventions
aim to restore and enhance it (Lavazza 2018). Complicating this is the
fact that BCIs increasingly employ machine learning algorithms to
decode or classify brain activity to control behavior. These systems
are not transparent to the user and often not transparent to the
researchers either, and increasingly they operate without the user in
the loop. The transfer of control from the person to AI raises complex
issues about autonomy, authenticity and responsibility.</p>

<p>
Indirect coercion: The more we understand about how the brain works,
the more potential there is for coercion or distortion of control.
Beyond directly intervening on brain activity, and causing subjects to
think or act in ways they otherwise would not, there are less direct
ways in which users of neurotechnologies can be coerced. Worrisome
prospects for coercion arise from the proliferation of BCIs and the
integration of algorithms from AI in their operation. These
technologies often require that users allow the company to record and
use their brain data. Consumer neurotechnologies will deliver troves
of brain data to corporations that can use them to influence
individual behavior, and even clinical neurotechnologies like
neurally-controlled bodily prostheses, which may not be data-mined for
profit, still raise the prospect of actions being taken on the basis
of decisions made by algorithms that may not accord with the will or
wishes of the subject. Apportioning responsibility in these cases will
be difficult.</p>

<p>
Neuroeconomics and neuromarketing: There are more subtle ways to
impact autonomy than through direct brain manipulations, or even brain
monitoring, and these are well within our grasp: Our thoughts can be
manipulated indirectly: old worries prompted by propaganda and
subliminal advertising have taken on a renewed currency with the
advent of neuroeconomics and neuromarketing (Spence 2020). Using
neuroscience information to inform marketing may walk a thin line
between an unproblematic avenue to design and market products that
appeal to people&rsquo;s desires and problematic manipulation of their
beliefs and desires (see, e.g. Ferrell et al. 2025). By better
understanding how we process reward, how we make decisions more
generally, and how we can bias or influence that process, we open the
door to more effective external indirect manipulations. Indeed, social
psychology has been showing how subtle alterations to our external
environment can affect beliefs, moods, and behaviors. The precise
threats posed by understanding the neural mechanisms of decision
making have yet to be fully articulated (Stanton et al. 2017). Is
neuromarketing being used merely to design products that satisfy our
desires more fully or is it being used to manipulate us? Depending on
how you see it, it could be construed as a good or an evil. Does
understanding the neural substrates of choice and reward provide
advertisers more effective tools than they had merely by using
behavioral data, or just more costly ones? Do consumers consequently
have less autonomy? How can we compensate for or counteract these
measures? Can we use our knowledge of the brain bases of human
behavior to benefit organizations more generally (Martineau and Racine
2020)? These questions have yet to be adequately addressed.</p>

<p>
Regulation: Yet another way that autonomy can be impacted is by
restricting the things that a person can do with and to her own mind
(see section on Cognitive Liberty). For instance, banning
mind-altering drugs is an externally imposed restraint on
people&rsquo;s ability to choose their states of consciousness (Biore,
2001). The degree to which a person should be prevented from doing
what he wishes to his or her self, body or mind, is an ethical issue
on which people have differing opinions. Some claim this kind of
regulation is a problematic infringement of autonomy, but certain
regulations of this type are already largely accepted in our society.
Regulation of drugs does impact our autonomy, but it arguably averts
potentially great harms. Allowing cognitive enhancing technologies
only for treatment uses but not for enhancement purposes is another
restriction of mental autonomy. Whether it is one we want to sanction
is still up for debate. Regardless, as the coronavirus pandemic has
made abundantly clear, complete autonomy is not practically possible
in a world in which one person&rsquo;s actions affect the well-being
of others.</p>

<p>
Belief in free will: Advances in neuroscience have been frequently
claimed to have bearing upon the question of whether we have free will
and on whether we can be truly morally responsible for our actions.
Although the philosophical problem of free will is generally
considered to be a metaphysical problem, demonstrable lack of freedom
would have significant ethical consequences. A number of
neuroscientists and psychologists have intimated or asserted that
neuroscience can show or has shown that free will is an illusion
(Brembs 2011; Libet 1983; Soon et al. 2008; Harris 2012; Sapolsky,
2023). Others have countered with arguments to the effect that such a
demonstration is in principle impossible (Roskies 2006), or have
offered competing interpretations of the data that do not undermine
free will (Schurger et al. 2021). Regardless of what science actually
shows about the nature of free will, the fact that people believe
neuroscience evidence supports or undermines free will arguably has
practical consequences. For example, evidence merely supporting the
premise that our minds are a function of our brains, as most of
neuroscience does, is perceived by some people to be a challenge to
free will. And in several studies, manipulating belief in free will
has been reported to affect the likelihood of cheating (e.g. Vohs and
Schooler 2008, although this study has failed to be replicated). The
debate within neuroscience about the nature and existence of free will
will remain relevant to neuroethics in part because of its impact on
our moral, legal and interpersonal practices of blaming and punishing
people for their harmful actions.</p>

<h4 id="AgenIden">2.3.2 Agency and Identity</h4>

<p>
One of the aspects of neuroethics that makes it distinctive and
importantly different from traditional bioethics is that we recognize
that, in some yet-to-be-articulated sense, the brain is the seat of
<em>who we are</em>. For example, we now have techniques that alter
memories by blunting them, strengthening them, or selectively editing
them. We have drugs that affect sexuality, and others that affect
mood. Here, neuroethics rubs up against some of the most challenging
and contentious questions in philosophy: What is the self? What sorts
of changes can we undergo and still remain ourselves? What is it that
makes us the same person over time? Of what value is this temporal
persistence? What costs would changing personhood incur?</p>

<p>
Because neuroscience intervention techniques can affect memory,
desires, personality, mood, impulsivity and other things we might
think of as constitutive of the person or the self, the changes they
can cause (and combat) have a unique potential to affect both the
meaning and quality of the most intimate aspects of our lives.
Although neuroethics is quite different from traditional bioethics in
this regard, it is not so different from genethics. For a long time,
it was argued that &ldquo;you are your genes&rdquo;, and so the
ability to interrogate our genomes, to change them, or to select among
them was seen as both a promising and potentially problematic one,
enabling us to understand and manipulate human nature to an extent far
beyond any we had previously enjoyed. But as we have discovered, we
are not (just) our genes. Our ability to sequence the human genome has
not laid bare the causes of cancer, the genetic basis for
intelligence, or of psychiatric illness, as many had anticipated. One
reason is that our genome is a distal cause of the people we come to
be: many complex and intervening factors matter along the way. Our
brains, on the other hand, are a far more proximal cause of who we are
and what we do. Our moment-to-moment behavior and our long-range plans
are directly controlled by our brains, in a way they are not directly
controlled by our genomes. If &ldquo;You are your genes&rdquo; seemed
a plausible maxim, &ldquo;You are your brain&rdquo; is far more
so.</p>

<p>
Despite its plausibility, it is notoriously difficult to articulate
the way in which we are our brains: What aspects of our brains makes
us the people that we are? What aspects of brain function shape our
memories, our personality, our dispositions? What aspects are
irrelevant or inessential to who we are? What makes possible a
coherent sense of self? When does a neurotechnology make us more
authentically ourselves, and when does it undermine authenticity? The
lack of answers we have to these deep neurophilosophical questions
does little to alleviate the pragmatic worries raised by neuroscience,
since our ability to intervene in brains outstrips our understanding
of what we are doing, and can affect all these aspects of our
being.</p>

<p>
In philosophy, work focusing on persons may address a variety of
distinct issues using different constructs. Philosophers might be
interested in the nature of personhood, in the nature of the self, in
the kinds of traits and psychological states or processes that give an
experienced life coherence or authenticity, or in the ingredients for
a flourishing life. Each calls for its own analysis. Outside of
philosophy, many of these issues are run together, and confusion often
results. Neuroethics, while in a unique position to leverage these
issues and apply them in a fruitful way, often fails to make the most
of the conceptual work philosophers have done in this area. For
example, papers in neuroethics often conflate a number of these
distinct concepts, referring them under the rubric of &ldquo;personal
identity&rdquo;. This conflation further muddies already difficult
waters, and diminishes the potential value of neuroethical work. Below
I try to give a brief roadmap of the separate strands that
neuroethicists have been concerned with.</p>

<p>
The philosopher&rsquo;s conception of personal identity refers to the
issue of what makes a person at one time numerically identical to a
person at another time. This metaphysical question has been addressed
by a variety of philosophical theories. For example, some theorists
argue that what it is to be the numerically identical over time is to
be the same human organism (Olson 1999), and that being the same
organism is determined by sameness of life. If having the same life is
the relevant criterion, one could argue that life-sustaining areas of
the brainstem are essential to personal identity (Olson 1999). For
those who believe instead that bodily integrity is what is essential,
the ability of neuroscience to alter the brain will arguably have
little effect on personal identity. Many other philosophers have
identified the same person as being grounded in psychological
continuity of some sort (e.g., Locke). If this criterion is the
correct one, then the stringency of that criterion may be crucial:
radical brain manipulation may cause an abrupt enough shift in
memories and other psychological states that a person after brain
intervention is no longer the same person he or she was prior. The
more stringent the criterion, the greater is the potential threat of
neurotherapies to personal identity (Jecker and Ko 2017; Pascalev et
al. 2016). On the other hand, if the standards for psychological
continuity or connectedness are high enough, changes in personal
identity may in fact be commonplace even without neurotherapies.
Recognizing this may prompt us to question the criterion and/or the
importance or value of personal identity. Parfit, for example, argues
that what makes us one and the same person over time, and what we
value (psychological continuity and connectedness) come apart (Parfit,
1984).</p>

<p>
For some, the question of personhood comes apart from the question of
identity. Even if personal (i.e. numerical) identity is unchallenged
by neurotechnologies and by brain dysfunction, important neuroethical
questions may still be raised. Philosophers less concerned with
metaphysical questions about numerical identity have focused more on
the self, and on notions of authenticity and self-identification,
emphasizing the importance of the psychological perspective of the
person in question in creating a coherent self (Mackenzie and Walker,
2015; Erler 2011; Pugh et al. 2017). In this vein, Schectman has
suggested that what is important is the ability to create a coherent
narrative, or &ldquo;narrative self&rdquo; (Schectman 2014). There is
evidence that the ability to create and sustain a coherent narrative
in which we are the protagonist and with which we identify, is a
measure of psychological health (Waters et al. 2014). On the other
hand, some philosophers deny that they have a narrative self and
locate selfhood in a synchronic property (Strawson 2004). To further
complicate matters, it has been suggested that there is a distinction
between the narrative person and the narrative self, these being
differentiable via degrees of appropriation. Concerns about the nature
and coherence of the narrative self, and about authenticity and
autonomy, tend to be the ones most relevant to neuroethics, since
these constructs clearly can be affected by even modest brain changes.
For example, how do we evaluate the costs and ethical issues attending
a dramatic change in personality, or a modification of key memories
(Erler 2011; Leuenberger 2022; Zawadzki and Adamczyk 2021; Zawadzki
2023)? What are the criteria governing whether one is authentic or
inauthentic, and what is the value of authenticity? If
neurointerventions promise to result in dramatic shifts in a
person&rsquo;s values and commitments, whose interests should take
priority if one person must be favored &ndash; the original or the
resulting person? The relevance of personhood, self, agency, identity
and identification needs further elaboration for neuroethics. In what
follows we discuss how one neurotechnology can bear upon some of these
questions.</p>

<h5>2.3.2.1 Example: Deep Brain Stimulation</h5>

<p>
Deep Brain Stimulation (DBS) involves the stimulation of chronically
implanted electrodes deep in the brain, and it is FDA approved for
treating Parkinson&rsquo;s Disease, a neurodegenerative disease
affecting the dopamine neurons in the striatum. Neuromodulation with
DBS often restores motor function in these patients, permitting many
to live much improved lives. It is also being explored as treatments
for treatment-resistant depression, OCD, addiction, and other
neurological and psychiatric issues (Aydin et al. 2024). Although DBS
is clearly a boon to many people suffering from neurological diseases,
there are a number of puzzling issues that arise from its adoption.
First, it is a highly invasive treatment, requiring brain surgery and
permanent implantation of a stimulator, thus posing a real possibility
of harm and raising questions of cost/benefit tradeoffs. This is
coupled with the fact that scientists have little mechanistic
understanding of how the treatment works when it does, and treatment
regimes and electrode placement tend to be symptomatic (Krauss et al.
2021). Occasionally DBS causes unusual side effects, such as mood
changes, hypomania or mania, addictive behaviors, or hypersexual
behavior. In one case a patient with wide-ranging musical tastes
developed a fixation for Johnny Cash&rsquo;s music, which persisted
until stimulation was ceased (Mantione et al. 2014). Other reported
cases involve changes in personality. The ethical questions in this
area revolve around the ethics of intervening in ways that alter mood
and/or personality, which is often discussed in terms of personal
identity or &ldquo;changing who the person is&rdquo;, and around
questions of autonomy and alienation (Klaming and Haselager 2013;
Kraemer 2013a,b).</p>

<p>
One poignant example from the literature tells of a patient who,
without intervention, was bedridden and had to be hospitalized due to
severe motor dysfunction caused by Parkinson&rsquo;s Disease
(Leentjens et al. 2003). DBS resulted in a marked improvement in his
motor symptoms but also caused him to be untreatably manic, which
required institutionalization. Thus, this unfortunate man had to
choose between being bedridden and catatonic, or manic and
institutionalized. He made the choice (in his unstimulated state) to
remain on stimulation (the literature does not mention whether his
stimulated self concurred, as he was not deemed mentally competent in
that state) (Kraemer 2013b). While it did not happen in this case, one
could imagine a situation in which the patient will choose, while
unstimulated, to undergo chronic stimulation, but, while under
stimulation, would choose otherwise (or <em>vice versa</em>). The
possibility for dilemmas or paradoxes will arise when, for example, we
try to determine the value of two potential outcomes that are
differently valued by the people who might exist. To which person (or
to the person in which state) should we give priority? Or, even more
perplexing: if the &ldquo;identity&rdquo; (narrative or numerical) of
the person is indeed shifted by the treatment, should we give one
person the authority to consent to a procedure or choose an outcome
that in practice affects a different person? DBS cases like this will
provide fodder for neuroethicists for years to come (Skorburg and
Sinnott-Armstrong 2020).</p>

<p>
Recent developments in DBS research leverage the ability of these
systems to both stimulate and record from the brain. Adaptive DBS or
aDBS, &ldquo;closes the loop&rdquo; by concurrently stimulating and
recording from neural tissue, and automatically adjusting stimulation
based on the state of the brain. Taking the user out of the loop
raises more pressing and somewhat different concerns about agency and
autonomy than does regular DBS, especially in cases in which machine
learning algorithms mediate the brain modulation (see, e.g. Klein et
al. 2016; Goering et al. 2017; Baker et al, 2023). Many other
neurotechnologies that have been developed for treating brain
dysfunction have primary or side effects that affect some aspect of
what we may think of as related to human agency (Zuk et al. 2018). The
ethical issues that arise with these neurotechnologies involve
determining 1) in which way they do impact our selves or our agency;
2) what value, positive or negative we should put on this impact (or
ability to so affect agency); and 3) how to weigh the positive gains
against the negatives. One issue that has been raised is whether we
possess a clear enough conception of the elements of agency in order
to effectively perform this sort of analysis (Roskies, 2015).
Moreover, given the likelihood that no objective criteria exist for
how to evaluate tradeoffs in these elements, and the fact that
different people may value different aspects of themselves
differently, the weighing process will likely have to be subjectively
relativized.</p>

<p>
Finally, DBS as well as neural prostheses and BCIs raise another
neuroethical issue: our conception of humanity and our relations to
machines. Some contend that these technologies effectively turn a
person into a cyborg, making him or her something other than human.
While some find this an ethically unproblematic natural extension of
our species&rsquo; characteristic drive to invent and improve our
selves with technology (Clark 2004), others fear that creating a
bio-cybernetic organism raises troubling questions about the nature or
value of humanity, about the bounds of self, or about Promethean
impulses. These questions too fall squarely in the domain of
neuroethics.</p>

<h3 id="ConsLifeDeat">2.4 Consciousness, life, and death</h3>

<h4 id="DisoCons">2.4.1 Disorders of Consciousness</h4>

<p>
The Hard Problem of consciousness (Chalmers 1995) has yielded little
to the probings of neuroscience, and it is not clear whether it ever
will. However, in the last decade impressive advances have been made
in other realms of consciousness research. Most impressive have been
the improvements in detecting altered levels of consciousness with
brain imaging. Diagnosing behaviorally unresponsive patients has long
been a problem for neurology, although as long as 20 years ago,
neurologists had recognized systematic differences between and
prognoses for a persistent vegetative state (PVS), a minimally
conscious state (MCS), and locked-in syndrome, a syndrome in which the
patient has normal levels of awareness but cannot move. Functional
brain imaging has fundamentally changed the problems faced by those
caring for these patients. Owen and colleagues have shown that it is
possible to identify some patients mischaracterized as being in PVS by
demonstrating that they are able to understand commands and follow
directions (Owen et al. 2006; Owen 2013). In these studies, both
normal subjects and brain injured patients were instructed to
visualize doing two different activities while in the fMRI scanner. In
normal subjects these two tasks reliably activated distinguishable
constellations of cortical areas. Owen showed that a patient diagnosed
as in PVS showed this normal pattern, unlike other PVS patients, who
showed no differential activation when given these instructions. This
data suggests that some PVS diagnosed subjects can in fact process and
understand the instructions, and that they have the capacity for
sustained attention and voluntary mental action. These results were
later replicated in other such patients, and a recent meta-analysis
suggests that approximately 25% of PVS patients have been misdiagnosed
(Bodien et al. 2024). In a further extension of this work, imagination
techniques were used to elicit from some patients with severe brain
injury answers to Yes/No questions (Monti et al. 2010). Unresponsive
patients who show evidence of awareness are now classified as
suffering from Cognitive-motor dissociation, or CMD. Given the
prevalence of people with disorders of consciousness and the scarcity
and cost of functional MRI, it will be important to to address these
problems with cheaper and more portable neurotechnologies, such as EEG
(Bai et al. 2021).</p>

<p>
Neuroimaging has the potential to revolutionize the way in which
patients with altered states of consciousness are diagnosed and cared
for, may have bearing on when life support is terminated, and raise
the possibility of allowing patients to have some control over
questions regarding their care and end of life decisions (Peterson et
al. 2020; Braddock 2017; Campbell et al. 2020). This last possibility,
while in some ways alleviating some worries about how to treat
severely brain-damaged individuals, raises other thorny ethical
problems. One of the most pressing is how to deal with questions of
competence and informed consent: These are people with severe brain
damage, and even when they do appear capable on occasion of
understanding and answering questions, there are still questions about
whether their abilities are stable, how sophisticated they are, and
whether they can competently make decisions about such weighty issues,
as well as whether it is really in their interest to remain on life
support (Kahane and Savulescu 2009; Fischer and Truog 2017).
Nonetheless, these methods open up new possibilities for diagnosis and
treatment, and for restoring a measure of autonomy and
self-determination to people with severe brain damage.</p>

<h4 id="BraiOrga">2.4.2 Brain Organoids</h4>

<p>
An emerging neuroethical issue concerns the moral status of brain
organoids (Sawai et al. 2019). Brain organoids are three-dimensional
clusters of pluripotent cells grown in vitro that develop properties
of classes of cells in the brain. They can be derived from human stem
cells, and thus inherit the ethical issues that attends stem cell
research. They offer a promising approach to studying certain brain
diseases and developing treatments. However, what sets cerebral
organoids apart is their neural identity, given that human brains give
rise to consciousness. Currently, brain organoids have shown a
capacity for self-organization and plasticity, yet it is unknown
whether they will ever develop the organizational complexity,
structure, or other (unknown) qualities sufficient to give rise to
consciousness. The frontiers of organoid research explores whether
organoids can be linked to sensory signals and to effectors, which
would be minimally necessary to create the conditions for
consciousness.</p>

<p>
Organoid research also raises the possibility of human-animal chimeras
and human-synthetic hybrids. Human derived organoids have been
successfully implanted in mouse brains, and have been linked to
synthetic sensors and effectors. The possibility of creating new forms
of life, conscious or not, raises novel questions for neuroethics (de
Jongh et al. 2022; Hyun et al. 2020; Kreitmar 2023).</p>

<h3 id="PracNeur">2.5 Practical neuroethics</h3>

<p>
Medical practice and neuroscientific research raise a number of
neuroethical issues, many of which are common to bioethics. For
example, issues of consent, of incidental findings, of competence, and
of privacy of information arise here (e.g., Illes et al. 2003, 2006).
In addition, practicing neurologists, psychologists and psychiatrists
may routinely encounter certain brain diseases, disabilities, or
psychological dysfunctions that raise neuroethical issues that they
must address in their practices. (For a more detailed discussion of
these more applied issues approached from a pragmatic point of view,
see for example Racine 2010; Martineau and Racine 2020).</p>

<h3 id="PublPercNeur">2.6 Public perception of neuroscience</h3>

<p>
The advances of neuroscience have become a common topic in the popular
media, with colorful brain images becoming a pervasive illustrative
trope in news stories about neuroscience. While no one doubts that
popularizing neuroscience is a positive good, neuroethicists have been
legitimately worried about the possibilities for misinformation. These
include worries about &ldquo;the seductive allure&rdquo; of
neuroscience, and of misleading and oversimplified media coverage of
complex scientific questions.</p>

<h4 id="SeduAllu">2.6.1 The seductive allure</h4>

<p>
There is a documented tendency for the layperson to think that
information that makes reference to the brain, or to neuroscience or
neurology, is more privileged, more objective, or more trustworthy
than information that makes reference to the mind or psychology. For
example, Weisberg and colleagues report that subjects with little or
no neuroscience training rated bad explanations as better when they
made reference to the brain or incorporated neuroscientific
terminology (Weisberg et al. 2008). This &ldquo;seductive allure of
neuroscience&rdquo; is akin to an unwarranted epistemic deference to
authority. This differential appraisal extends into real-world
settings, with testimony from a neuroscientist or neurologist judged
to be more credible than that of a psychologist. The tendency is to
view neuroscience as a hard science, in contrast to &ldquo;soft&rdquo;
methods of inquiry that focus on function or behavior. With
neuroimaging methods, this belies a deep misunderstanding of the
genesis and significance of the neuroscientific information. What
people fail to realize is that neuroimaging information is classified
and interpreted by its ties to function, so (barring unusual
circumstances) it cannot be more reliable or &ldquo;harder&rdquo; than
the psychology it relies upon.</p>

<p>
Brain images in particular have prompted worries that the colorful
images of brains with &ldquo;hotspots&rdquo; that accompany media
coverage could themselves be misleading. If people intuitively
appreciate brain images as if they were akin to a photograph of the
brain in action, that this could mislead them into thinking of these
images as objective representations of reality, prompting them to
overlook the many inferential steps and nondemonstrative decisions
that underlie creation of the image they see (Roskies 2007). The worry
is that the powerful pull of the brain image will lend a study more
epistemic weight than is justified, and discourage people from asking
the many complicated questions that one must ask in order to
understand what the image signifies, and what can be inferred from the
data. Further work, however, has suggested that once one takes into
account the privilege accorded to neuroscience over psychology, the
images themselves do not further mislead (Schweitzer et al.,
2011).</p>

<h4 id="MediHype">2.6.2 Media Hype</h4>

<p>
In this era of indubitably exciting progress in brain research, there
is a &ldquo;brain-mania&rdquo; that is partially warranted but holds
its own dangers. The culture of science is such that it is not
uncommon for scientists to describe their work in the most dramatic
terms possible in order to secure funding and/or fame. Although the
hyperbole can be discounted by knowledgeable readers, those less
sophisticated about the science may take it at face value. Studies
have shown that the media is rarely critical of the scientific
findings they report, and they tend not to present alternative
interpretations (Racine et al. 2006, 2015). The result is that the
popular media conveys sometimes wildly inaccurate pictures of
legitimate scientific discoveries, which can fuel both overly
optimistic enthusiasm as well as fear. One of the clear pragmatic
goals of neuroethics, whether it regards basic research or clinical
treatments, is to exhort and educate scientists and the media to
better convey both the promise and complexities of scientific
research. It is the job of both these groups to teach people enough
about science in general, and brain science in particular, that they
see it as worthy of respect, and also of the same critical assessment
that to which scientists themselves subject their own work.
Unfortunately, even some prominent neuroethicists are prone to
sensationalize neuroscientific advances and to ignore their
limitations.</p>

<p>
It is admittedly difficult to accurately translate complicated
scientific findings for the lay public, but it is essential.
Overstatement of the significance of results can instill unwarranted
hope in some cases, fear in others, and jadedness and suspicion going
forward. Providing fodder for scientific naysayers has policy
implications that go far beyond the reach of neuroscience. Mistrust of
science is its own epidemic that needs to be inoculated against by
careful, early, and continuing education of the public. This is
essential for the future status and funding of the basic sciences,
and, as we have seen, for the health of democracy and our planet more
generally. Given recent attacks on science and on truth, responsible
reporting and regaining the trust of the public has never been as
important as it is now.</p>

<h3 id="NeurJust">2.7 Neuroscience and justice</h3>

<p>
Social justice is a concern of ethics, and of neuroethics. Many of the
ethical questions are not new, but some have novel aspects. Bioethics
also has traditionally been concerned with issues of respect for
patient&rsquo;s autonomy and right to self-determination. As mentioned
above, these questions take on added weight when the organ at issue is
the patient&rsquo;s brain, and questions about competence arise.</p>

<p>
Ethical issues also attend doing neuroscientific research on
nonhumans. Like traditional bioethics, neuroethics must address
questions about the ethical use of animals for experimental purposes
in neuroscience. In addition, however, it ought to consider questions
regarding the use of animals as model systems for understanding the
human brain and human cognition (Johnson et al. 2020). Animal studies
have given us the bulk of our understanding of neural physiology and
anatomy and have provided significant insight into function of
conserved biological capacities. However, the further we push into
unknown territory about higher cognitive functions, the more we will
have to attend to the specifics of similarities and differences
between humans and other species and evaluating the model system may
involve considerable philosophical work. In some cases, the
dissimilarities may not warrant animal experiments.</p>

<p>
Other issues to which neuroethics also must be attentive to involve
social justice. As neuroscience promises to offer treatments and
enhancements, it must attend to issues of distributive justice, and
play a role in ensuring that the fruits of neuroscientific research do
not go only to those who enjoy the best our society has to offer.
Moreover, a growing understanding that poverty and socioeconomic
status more generally have long-lasting cognitive effects raises moral
questions about the social policy and the structure of our society,
and the growing gap between rich and poor (Farah 2017). It seems that
the social and neuroscientific realities may reveal the American Dream
to be largely hollow, and these findings may undercut some popular
political ideologies. There are also global issues to consider (Stein
and Singh 2020). Justice may demand more involvement of neuroethicists
in policy decisions.</p>

<p>
Neuroethics has also considered issues of diversity and
discrimination. Some neuroethicists have focused on the way in which
neuroscience can or should influence the way we view sex and gender
issues (Hoffman and Bluhm 2016). The neurodiversity movement advocates
for increased awareness and appreciation of the breadth of cognitive
differences, and careful neuroethical analysis should accompany
inferences from brain differences to normative judgments (Chapman and
Carel 2022; Goldberg 2023; May 2023, 2025).</p>

<p>
Finally, neuroethics stretches seamlessly into the law (see, e.g.
Vincent 2013; Morse and Roskies 2013; Jones et al. 2014). Neuroethical
issues arise in criminal law, in particular with the issue of criminal
responsibility (see, e.g. Birks &amp; Douglas, 2018). For example, the
recognition that a large percentage of prison inmates have some
history of head trauma or other abnormality raises the question of
where to draw the line between the bad and the mad. Neuroethics has
bearing on issues of addiction and juvenile responsibility, as well as
on some other areas of law, such as in tort law, employment law, and
health care law.</p>

<h2 id="NeurEthi">3. The Neuroscience of Ethics</h2>

<p>
Neuroscience, or more broadly the cognitive and neural sciences, have
made significant inroads into understanding the neural basis of
ethical thought and social behavior. In the last decades, these fields
have begun to flesh out the neural machinery underlying human
capacities for moral judgment, altruistic action, and the moral
emotions (Liao 2016). The field of social neuroscience, nonexistent
two decades ago, is thriving, and our understanding of the circuitry,
the neurochemistry, and the modulatory influences underlying some of
our most complex and nuanced interpersonal behaviors is growing
rapidly. Neuroethics recognizes that the heightened understanding of
the biological bases of social and moral behaviors can itself have
effects on how we conceptualize ourselves as social and moral agents,
and foresees the importance of the interplay between our scientific
conception of ourselves and our ethical views and theories (Roskies,
2002). The interplay and its effects provide reason to view the
neuroscience of ethics (or more broadly, of sociality) as part of the
domain of neuroethics.</p>

<p>
Perhaps the most well-known and controversial example of such an
interplay marks the beginning of this kind of exploration. In 2001,
Joshua Greene (Greene et al. 2001) scanned people while they made a
series of moral and nonmoral decisions in different scenarios,
including dilemmas modeled on the philosophical &ldquo;Trolley
Problem&rdquo; (Thomson 1985). He noted systematic differences in the
engagement of brain regions associated with moral processing in
&ldquo;personal&rdquo; as opposed to &ldquo;impersonal&rdquo; moral
dilemmas and hypothesized that emotional interference was behind the
differential reaction times in judgments of permissibility in the
footbridge case. In later work, he proposed a dual-process model of
moral judgment, where relatively automatic emotion-based reactions and
high-level cognitive control jointly determined responses to moral
dilemmas, and he related his findings to philosophical moral theories
(Greene et al. 2004, 2008). Most controversially, he suggested that
there are reasons to be suspicious of our deontological judgments, and
interpreted his work as lending credence to utilitarian theories
(Greene 2013). Greene&rsquo;s work is thus a clear example of how
neuroscience might affect our ethical theorizing. Claims regarding the
import of neuroscience studies for philosophical questions have
sparked a heated debate in philosophy and beyond, and prompted
critiques and replies from scholars both within and outside of
philosophy (see, e.g., Berker 2009; Kahane et al. 2011; Christensen,
2014). One effect of these exchanges is to highlight a problematic
tendency for scientists and some philosophers to think they can draw
normative conclusions from purely descriptive data; another is to
illuminate the ways in which descriptive data might itself masquerade
as normative (Roskies 2022).</p>

<p>
Greene&rsquo;s early studies demonstrated that neuroscience can be
used in the service of examining extremely high-level behaviors and
capacities, and have served as an inspiration for numerous other
experiments investigating the neural basis of social and moral
behavior and competences (May et al. 2022). Neuroethics has already
turned its attention to phenomena such as altruism, empathy,
well-being, and theory of mind, as well as to disorders such as autism
and psychopathy. The relevant works range from imaging studies using a
variety of imaging techniques, to manipulation of hormones and
neurochemicals, to purely behavioral studies, and the use of virtual
reality. In addition, interest in moral and social neuroscience has
collided synergistically with the growth of neuroeconomics, which has
flourished in large part independently. A recent bibliography has
collected almost 400 references to works in the neuroscience of ethics
since 2002 (Darragh et al. 2015). We can safely assume that many more
advances will be made in the years to come, and that neuroethicists
will be called upon to advance, evaluate, expound upon, or deflate
claims for the purported ethical implications of our new
knowledge.</p>

<h2 id="LookForwNewNeur">4. Looking forward: New neurotechnologies</h2>

<p>
The examples discussed above included pharmaceuticals that are already
approved for use, existing brain imaging techniques and invasive
neurotherapies. But practical neuroethical concerns, and some
theoretical concerns, are highly dependent upon the details of
technologies. Rapid advances in artificial intelligence are raising a
host of new issues, including for clinical diagnosis, prediction,
neural decoding, neural prostheses, and data security (e.g. Ienca and
Ignatiadis 2020; Kellmeyer 2021; Kritika 2025). Several technologies
are already on the horizon that are bound to raise some new
neuroethical questions, or old questions in new guises. One of the
most powerful new tools in the research neuroscientist&rsquo;s arsenal
is &ldquo;optogenetics&rdquo;, a method of transfecting brain cells
with genetically engineered proteins that make the cell responsive to
light of specific wavelengths (Diesseroth 2011). The cells can then be
activated or silenced by shining light upon them, allowing for
cell-specific external control. Optogenetics has been successfully
used in many model organisms, including rats, and work is underway to
use optogenetics in monkeys. One may presume it is only a matter of
time before it will be developed for use in humans. The method
promises to provide precise control of specific neural populations and
relatively noninvasive targeted treatments for diseases. It promises
to raise the kind of neuroethical issues raised by many mechanisms
that intervene on brain function: Questions of harm, of authenticity,
and the prospect of brain cells being controlled by someone other than
the agent himself (Gilbert et al. 2014; Adamczyk &amp; Zawadzki, 2020,
Zawadzki and Adamczyk 2021). A second technique, CRISPR, allows
powerful targeted gene editing. Although not strictly a
neuroscientific technique, it can be used on neural cells to effect
brain changes at the genetic level (Canli 2015). Genetic engineering
has already yielded babies with edited genomes, demonstrating the
feasibility of neural gene therapies and designer babies, consequences
of the genetic revolution thus far only imagined. Computational
psychiatry, which aims for a computational understanding of
psychiatric disorders, is in its infancy, but with advances in
artificial neural networks it is likely to advance rapidly, and may
provide new insight into and control over mental health problems
(Friedrich et al. 2021; Nour et al. 2022; Wiese and Friston 2022).
More speculative is the prospect of the development of &ldquo;digital
twin brains&rdquo;, accurate simulations of unique individual brains,
to help in understanding and treating brain function and dysfunction,
as well as predicting future states and behaviors of particular
individuals (Wang et al. 2024; Xiong et al. 2023). Here we caution
that the literature verges into science fiction, something which
neuroethicists should clearly flag. We are a long way from being able
to model the brain at a fine-grained enough level to think that we
have a brain simulation at all, except in the most attenuated sense,
let alone a duplicate of a particular person&rsquo;s brain. Those who
fail to make clear the yawning gap between a real brain and a
foreseeable computer model abandon scholarship for sensationalism.</p>

<p>
CRISPR, optogenetics, and other technologies were not even imagined a
few decades ago, and is likely that other future technologies will
emerge which we cannot currently conceive of. If many neuroethical
issues are closely tied to the capabilities of neurotechnologies, as I
have argued, then we will likely be unlikely to anticipate future
technologies in enough detail to predict the constellation of
neuroethical issues to which they may give rise. Neuroethics will have
to grow as neuroscience does, adapting to novel ethical and
technological challenges.</p>
</div>

<div id="bibliography">

<h2 id="Bib">Bibliography</h2>

<ul class="hanging">

<li>Abbott, M., and S. Peck, 2017, &ldquo;Emerging Ethical Issues
Related to the Use of Brain-Computer Interfaces for Patients with
Total Locked-in Syndrome,&rdquo; <em>Neuroethics</em>, 10(2):
235&ndash;242. doi:10.1007/s12152-016-9296-1</li>

<li>Adamczyk, A. and P. Zawadzki, 2020, &ldquo;The Memory-Modifying
Potential of Optogenetics and the Need for Neuroethics,&rdquo;
<em>NanoEthics</em>. doi:10.1007/s11569-020-00377-1</li>

<li>Aharoni, Eyal, Joshua Mallett, Gina M. Vincent, Carla L. Harenski,
Vince D. Calhoun, Walter Sinnott-Armstrong, Michael S. Gazzaniga, and
Kent A. Kiehl, 2014, &ldquo;Predictive Accuracy in the Neuroprediction
of Rearrest,&rdquo; <em>Social Neuroscience</em>, 9(4): 332&ndash;36.
doi:10.1080/17470919.2014.907201</li>

<li>Aharoni, E., G. Vincent, C. Harenski, V. Calhoun, W.
Sinnott-Armstrong, M. Gazzaniga, and K. Kiehl, 2013,
&ldquo;Neuroprediction of Future Rearrest,&rdquo; <em>Proceedings of
the National Academy of Sciences</em>, 110(15): 6223&ndash;28.
doi:10.1073/pnas.1219302110</li>

<li>Appel, Jacob, 2010 [2011], &ldquo;Beyond Fluoride:
Pharmaceuticals, Drinking Water and the Public Health,&rdquo; <em>The
Huffington Post</em>, 18 March 2010, updated 25 May 2011;
 <a href="https://www.huffpost.com/entry/beyond-fluoride-pharmaceu_b_398874?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAMj36UEG9RQBA_uv7HR7WIA2LsV6a4nt3uLtvGfsWXfb283Fh4lpZbY7RBhIkRYTHNbqfRItunX8t8vrRFYoWzRfDqrjb1pzpsHCx1nUeLuL6XGR0g1ENYdZ7tP0iLypkWbSsKZp5yFkMFZITIYrYfaKmN0XFx52d9Ru7gVpcGTI" target="other">available online</a>.</li>
 
<li>Aydin, O., P. Aydin, and A. Arslan, 2019, &ldquo;Development of
Neuroimaging-Based Biomarkers in Psychiatry,&rdquo; <em>Advances in
Experimental Medicine and Biology</em>, 1192: 159&ndash;95.
doi:10.1007/978-981-32-9721-0_9</li>

<li>Aydin, Serhat, Kwadwo Darko, Donald Detchou, and Umaru Barrie,
2024, &ldquo;Ethics of Deep Brain Stimulation for Neuropsychiatric
Disorders,&rdquo; <em>Neurosurgical Review</em> 47(1): 479.
doi:10.1007/s10143-024-02746-w</li>

<li>Bai, Y., Y. Lin, and U. Ziemann, 2021, &ldquo;Managing Disorders
of Consciousness: The Role of Electroencephalography,&rdquo;
<em>Journal of Neurology</em>, 268(11):
4033&ndash;4065. doi:10.1007/s00415-020-10095-z</li>

<li>Baker, Sunderland, Eliz Fenstermacher, Rachel A. Davis, Drew S.
Kern, John A. Thompson, Gidon Felsen, and Alexander J. Baumgartner,
2023, &ldquo;Ethical Considerations in Closed Loop Deep Brain
Stimulation,&rdquo; <em>Deep Brain Stimulation</em>, 3: 8&ndash;15.
doi:10.1016/j.jdbs.2023.11.001</li>

<li>Berker, S., 2009, &ldquo;The Normative Insignificance of
Neuroscience,&rdquo; <em>Philosophy &amp; Public Affairs</em>, 37(4):
293&ndash;329.</li>

<li>Birks, D. and T. Douglas (eds.), 2018, <em>Treatment for Crime:
Philosophical Essays on Neurointerventions in Criminal Justice</em>,
Oxford: Oxford University Press.</li>

<li>Bodien, G., Judith Allanson, Paolo Cardone, Arthur Bonhomme,
Jerina Carmona, Camille Chatelle, Srivas Chennu, Conte M, Dehaene S,
Finoia P, Heinonen G, Hersh JE, Kamau E, Lawrence PK, Lupson VC,
Meydan A, Rohaut B, Sanders WR, Sitt JD, Soddu A, Valente M, Velazquez
A, Voss HU, Vrosgou A, Claassen J, Edlow BL, Fins JJ, Gosseries O,
Laureys S, Menon D, Naccache L, Owen AM, Pickard J, Stamatakis EA,
Thibaut A, Victor JD, Giacino JT, Bagiella E, Schiff ND, 2024,
&ldquo;Cognitive Motor Dissociation in Disorders of
Consciousness&rdquo;, <em>New England Journal of Medicine</em>,
391(7): 598&ndash;608 (PMID: 39141852; PMCID: PMC7617195).
doi:10.1056/NEJMoa2400645</li>

<li>Boire, Richard G., 2001, &ldquo;On Cognitive Liberty,&rdquo;
<em>The Journal of Cognitive Liberties</em>, 2(1): 7&ndash;22</li>

<li>Braddock, Matthew, 2017, &ldquo;&lsquo;Should We Treat Vegetative
and Minimally Conscious Patients as Persons?&rsquo;&rdquo;
<em>Neuroethics</em>, 10(2): 267&ndash;80.
doi:10.1007/s12152-017-9309-8</li>

<li>Brembs, Bj&ouml;rn, 2011, &ldquo;Towards a Scientific Concept of
Free Will as a Biological Trait: Spontaneous Actions and
Decision-Making in Invertebrates,&rdquo; <em>Proceedings of the Royal
Society of London B: Biological Sciences</em>, 278(1707):
930&ndash;939.  doi:10.1098/rspb.2010.2325</li>

<li>Brown, Timothy, 2015, &ldquo;A Relational Take on Advisory Brain
Implant Systems,&rdquo; <em>AJOB Neuroscience</em>, 6(4): 46&ndash;47.
doi:10.1080/21507740.2015.1094559</li>

<li>Bublitz, J., 2020, &ldquo;The Nascent Right to Psychological
Integrity and Mental Self-Determination,&rdquo; in A. Von Arnauld, K.
Von der Decken, and M. Susi (eds.), <em>The Cambridge Handbook of New
Human Rights: Recognition, Novelty, Rhetoric</em>, pp. 387&ndash;403.
Cambridge: Cambridge University Press.
doi:10.1017/9781108676106.031</li>

<li>Buckner, Randy L., Jessica R. Andrews-Hanna, and Daniel L.
Schacter, 2008, &ldquo;The Brain&rsquo;s Default Network,&rdquo;
<em>Annals of the New York Academy of Sciences</em>, 1124(1):
1&ndash;38. doi:10.1196/annals.1440.011</li>

<li>Campbell, J., Z. Huang, J. Zhang, X. Wu, P. Qin, G. Northoff, G.
Mashour, and A. Hudetz, 2020, &ldquo;Pharmacologically Informed
Machine Learning Approach for Identifying Pathological States of
Unconsciousness via Resting-State FMRI,&rdquo; <em>NeuroImage</em>,
206: 116316. doi:10.1016/j.neuroimage.2019.116316</li>

<li>Canli, Turhan, 2015, &ldquo;Neurogenethics: An Emerging Discipline
at the Intersection of Ethics, Neuroscience, and Genomics,&rdquo;
<em>Applied &amp; Translational Genomics</em>, Neurogenomics: Coming
of Age, 5: 18&ndash;22. doi:10.1016/j.atg.2015.05.002</li>

<li>Chalmers, D. J., 1995, &ldquo;Facing up to the Problem of
Consciousness,&rdquo; <em>Journal of Consciousness Studies</em>, 2(3):
200&ndash;219</li>

<li>Chandler J.A., K.I. Van der Loos, S. Boehnke, J.S. Beaudry, D.Z.
Buchman, and J. Illes, 2022, &ldquo;Brain Computer Interfaces and
Communication Disabilities: Ethical, Legal, and Social Aspects of
Decoding Speech From the Brain,&rdquo; <em>Front Hum Neurosci</em>,
16: 841035 (PMID: 35529778; PMCID: PMC9069963).
doi:10.3389/fnhum.2022.841035</li>

<li>Chapman, R., &amp; Havi Carel, 2022, &ldquo;Neurodiversity,
epistemic injustice, and the good human life&rdquo; <em>Journal of
Social Philosophy</em>, 53: 614&ndash;631. doi:10.1111/josp.12456</li>

<li>Chekroud, Adam Mourad, Jim A.C. Everett, Holly Bridge, and Miles
Hewstone, 2014, &ldquo;A Review of Neuroimaging Studies of
Race-Related Prejudice: Does Amygdala Response Reflect Threat?&rdquo;
<em>Frontiers in Human Neuroscience</em>, 8: 179.
doi:10.3389/fnhum.2014.00179</li>

<li>Christensen, Julia F., Albert Flexas, Margareta Calabrese, Nadine
K. Gut, and Antoni Gomila, 2014, &ldquo;Moral Judgment Reloaded: A
Moral Dilemma Validation Study,&rdquo; <em>Emotion Science</em>, 5:
607. doi:10.3389/fpsyg.2014.00607.</li>

<li>Clark, Andy, 2004, <em>Natural-Born Cyborgs: Minds, Technologies,
and the Future of Human Intelligence</em>, first edition, New York:
Oxford University Press.</li>

<li>Darragh, Martina, Liana Buniak, and James Giordano, 2015, &ldquo;A
Four-Part Working Bibliography of Neuroethics: Part 2 &ndash;
Neuroscientific Studies of Morality and Ethics,&rdquo; <em>Philosophy,
Ethics, and Humanities in Medicine</em> (PEHM), 10.
doi:10.1186/s13010-015-0022-0</li>

<li>De Jongh, Dide, Emma K. Massey, the VANGUARD consortium, Ekaterine
Berishvili, Laura Mar Fonseca, Fanny Lebreton, Kevin Bellofatto, et
al., 2022, &ldquo;Organoids: A Systematic Review of Ethical
Issues,&rdquo; <em>Stem Cell Research &amp; Therapy</em> 13(1): 337.
doi:10.1186/s13287-022-02950-9</li>

<li>Deisseroth, K., 2010, &ldquo;Optogenetics,&rdquo; <em>Nature
Methods</em>, 8: 26&ndash;29. doi: 10.1038/nmeth.f.324</li>

<li>Delfin, Carl, Hedvig Krona, Peter Andin&eacute;, Erik Ryding,
M&auml;rta Wallinius, and Bj&ouml;rn Hofvander, 2019,
&ldquo;Prediction of Recidivism in a Long-Term Follow-up of Forensic
Psychiatric Patients: Incremental Effects of Neuroimaging Data,&rdquo;
<em>PLoS ONE</em>, 14(5). doi:10.1371/journal.pone.0217127</li>

<li>Douglas, Thomas, 2019, &ldquo;Enhancement and Desert,&rdquo;
<em>Politics, Philosophy &amp; Economics</em>, 18(1): 3&ndash;22.
doi:10.1177/1470594X18810439</li>

<li>&ndash;&ndash;&ndash;, 2008, &ldquo;Moral Enhancement,&rdquo;
<em>Journal of Applied Philosophy</em>, 25(3): 228&ndash;45.
doi:10.1111/j.1468-5930.2008.00412.x</li>

<li>Dresler, Martin, Anders Sandberg, Christoph Bublitz, Kathrin Ohla,
Carlos Trenado, Aleksandra Mroczko-W&#261;sowicz, Simone K&uuml;hn,
and Dimitris Repantis, 2019, &ldquo;Hacking the Brain: Dimensions of
Cognitive Enhancement,&rdquo; <em>ACS Chemical Neuroscience</em>
10(3): 1137&ndash;48. doi:10.1021/acschemneuro.8b00571</li>

<li>Dubljevi&#263;, Veljko, and Eric Racine, 2017, &ldquo;Moral
Enhancement Meets Normative and Empirical Reality: Assessing the
Practical Feasibility of Moral Enhancement Neurotechnologies,&rdquo;
<em>Bioethics</em>, 31(5): 338&ndash;48. doi:10.1111/bioe.12355</li>

<li>Erler, Alexandre, 2011,&ldquo;Does Memory Modification Threaten
Our Authenticity?&rdquo; <em>Neuroethics</em>, 4(3): 235&ndash;49.
doi:10.1007/s12152-010-9090-4</li>

<li>Farah, Martha J. (ed.), 2010, <em>Neuroethics: An Introduction
with Readings</em>, first Edition, Cambridge, MA: The MIT Press.</li>

<li>Farah, Martha J., 2017, &ldquo;The Neuroscience of Socioeconomic
Status: Correlates, Causes, and Consequences,&rdquo; <em>Neuron</em>,
96(1): 56&ndash;71. doi:10.1016/j.neuron.2017.08.034</li>

<li>Farah, Martha J., J. Benjamin Hutchinson, Elizabeth A. Phelps, and
Anthony D. Wagner, 2014, &ldquo;Functional MRI-Based Lie Detection:
Scientific and Societal Challenges,&rdquo; <em>Nature Reviews
Neuroscience</em>, 15(2): 123&ndash;31. doi:10.1038/nrn3665</li>

<li>Ferrell, Macy L., Ashley Beatty, and Veljko Dubljevic, 2025,
&ldquo;The Ethics of Neuromarketing: A Rapid Review,&rdquo;
<em>Neuroethics</em> 18(1): 19. doi:10.1007/s12152-025-09591-8</li>

<li>Finn, Emily S, Xilin Shen, Dustin Scheinost, Monica D Rosenberg,
Jessica Huang, Marvin M Chun, Xenophon Papademetris, and R Todd
Constable, 2015, &ldquo;Functional Connectome Fingerprinting:
Identifying Individuals Using Patterns of Brain Connectivity,&rdquo;
<em>Nature Neuroscience</em>, 18(11): 1664&ndash;71.
doi:10.1038/nn.4135</li>

<li>Fischer, David, and Robert D. Truog, 2017, &ldquo;The Problems
with Fixating on Consciousness in Disorders of Consciousness,&rdquo;
<em>American Journal of Bioethics: Neuroscience</em>, 8(3):
135&ndash;40.</li>

<li>Friedrich, O., A. Wolkenstein, C. Bublitz, R.J. Jox, &amp; E.
Racine (eds.), 2021, <em>Clinical Neurotechnology meets Artificial
Intelligence: Philosophical, Ethical, Legal and Social
Implications</em>, Cham: Springer/Nature.</li>

<li>Gilbert, Frederic, 2015, &ldquo;A Threat to Autonomy? The
Intrusion of Predictive Brain Implants,&rdquo; <em>AJOB
Neuroscience</em>, 6(4): 4&ndash;11.
doi:10.1080/21507740.2015.1076087</li>

<li>Gilbert, Frederic, Alexander R. Harris, and Robert M. I. Kapsa,
2014, &ldquo;Controlling Brain Cells With Light: Ethical
Considerations for Optogenetic Clinical Trials,&rdquo; <em>AJOB
Neuroscience</em>, 5(3): 3&ndash;11.
doi:10.1080/21507740.2014.911213</li>

<li>Goering, Sara, Eran Klein, Darin D. Dougherty, and Alik S. Widge,
2017, &ldquo;Staying in the Loop: Relational Agency and Identity in
Next-Generation DBS for Psychiatry,&rdquo; <em>AJOB Neuroscience</em>,
8(2): 59&ndash;70. doi:10.1080/21507740.2017.1320320</li>

<li>Goldberg, Hagar, 2023, &ldquo;Unraveling Neurodiversity: Insights
from Neuroscientific Perspectives&rdquo; <em>Encyclopedia</em> (MDPI),
3(3): 972&ndash;980. doi:10.3390/encyclopedia3030070</li>

<li>Gordon, Emma C., and Anil K. Seth, 2024, &ldquo;Ethical
Considerations for the Use of Brain&ndash;Computer Interfaces for
Cognitive Enhancement,&rdquo; <em>PLOS Biology</em>, 22(10): e3002899.
doi:10.1371/journal.pbio.3002899</li>

<li>Greely, Henry, Barbara Sahakian, John Harris, Ronald C. Kessler,
Michael Gazzaniga, Philip Campbell, and Martha J. Farah,
2008,&ldquo;Towards Responsible Use of Cognitive-Enhancing Drugs by
the Healthy,&rdquo; <em>Nature</em>, 456(7223): 702&ndash;5.
doi:10.1038/456702a</li>

<li>Greene, Joshua D., and Joseph M. Paxton, 2009, &ldquo;Patterns of
Neural Activity Associated with Honest and Dishonest Moral
Decisions,&rdquo; <em>Proceedings of the National Academy of
Sciences</em>, 106(30): 12506&ndash;11.
doi:10.1073/pnas.0900152106</li>

<li>Greene, Joshua D., Leigh E. Nystrom, Andrew D. Engell, John M.
Darley, and Jonathan D. Cohen, 2004, &ldquo;The Neural Bases of
Cognitive Conflict and Control in Moral Judgment,&rdquo;
<em>Neuron</em>, 44(2): 389&ndash;400.
doi:10.1016/j.neuron.2004.09.027</li>

<li>Greene, Joshua D., R. Brian Sommerville, Leigh E. Nystrom, John M.
Darley, and Jonathan D. Cohen, 2001, &ldquo;An fMRI Investigation of
Emotional Engagement in Moral Judgment,&rdquo; <em>Science</em>,
293(5537): 2105&ndash;8. doi:10.1126/science.1062872</li>

<li>Greene, Joshua D., Sylvia A. Morelli, Kelly Lowenberg, Leigh E.
Nystrom, and Jonathan D. Cohen, 2008, &ldquo;Cognitive Load
Selectively Interferes with Utilitarian Moral Judgment,&rdquo;
<em>Cognition</em>, 107(3): 1144&ndash;54.
doi:10.1016/j.cognition.2007.11.004</li>

<li>Greene, Joshua, 2013, <em>Moral Tribes: Emotion, Reason, and the
Gap Between Us and Them</em>, New York: Penguin Press.</li>

<li>Hoffman, Ginger A., and Robyn Bluhm, 2016,&ldquo;Neurosexism and
Neurofeminism,&rdquo; <em>Philosophy Compass</em>, 11: 716&ndash;29.
doi:10.1111/phc3.12357</li>

<li>Hsu, Chun-Wei, Chiara Begliomini, Tommaso Dall&rsquo;Acqua, and
Giorgio Ganis, 2019, &ldquo;The Effect of Mental Countermeasures on
Neuroimaging-Based Concealed Information Tests,&rdquo; <em>Human Brain
Mapping</em>, 40(10): 2899&ndash;2916. doi:10.1002/hbm.24567</li>

<li>Husain, Masud, and Mitul A. Mehta, 2011, &ldquo;Cognitive
Enhancement by Drugs in Health and Disease,&rdquo; <em>Trends in
Cognitive Sciences</em>, 15(1): 28&ndash;36.
doi:10.1016/j.tics.2010.11.002</li>

<li>Hyun, Insoo, Jennifer C. Scharf-Deering, and Jeantine E. Lunshof,
2020, &ldquo;Ethical issues related to brain organoid research,&rdquo;
<em>Brain Research</em>, 1732: 146653.</li>

<li>Ienca, Marcello, 2021, &ldquo;On Neurorights,&rdquo; <em>Frontiers
in Human Neuroscience</em>, 15: 701258.
doi:10.3389/fnhum.2021.701258</li>

<li>Ienca, Marcello, and Roberto Andorno, 2017, &ldquo;Towards New
Human Rights in the Age of Neuroscience and Neurotechnology,&rdquo;
<em>Life Sciences, Society and Policy</em>, 13(1): 5.
doi:10.1186/s40504-017-0050-1</li>

<li>Ienca, Marcello and Karolina Ignatiadis, 2020, &ldquo;Artificial
Intelligence in Clinical Neuroscience: Methodological and Ethical
Challenges,&rdquo; <em>AJOB Neuroscience</em>, 11(2): 77&ndash;87.
doi:10.1080/21507740.2020.1740352</li>

<li>Ilieva, Irena, Joseph Boland, and Martha J. Farah, 2013,
&ldquo;Objective and Subjective Cognitive Enhancing Effects of Mixed
Amphetamine Salts in Healthy People,&rdquo; <em>Neuropharmacology</em>
(Cognitive Enhancers: molecules, mechanisms and minds 22nd
Neuropharmacology Conference: Cognitive Enhancers) 64 (January):
496&ndash;505. doi:10.1016/j.neuropharm.2012.07.021</li>

<li>Illes, Judy, and Barbara J. Sahakian, 2011, <em>Oxford Handbook of
Neuroethics</em>, Oxford: Oxford University Press.</li>

<li>Illes, Judy, Matthew P. Kirschen, and John D. E. Gabrieli, 2003,
&ldquo;From Neuroimaging to Neuroethics,&rdquo; <em>Nature
Neuroscience</em>, 6(3): 205&ndash;205.
doi:10.1038/nn0303&ndash;205</li>

<li>Illes, Judy, Matthew P. Kirschen, Emmeline Edwards, L. R.
Stanford, Peter Bandettini, Mildred K. Cho, Paul J. Ford, et al.,
2006, &ldquo;Incidental Findings in Brain Imaging Research,&rdquo;
<em>Science</em>, 311(5762): 783&ndash;84.
doi:10.1126/science.1124665</li>

<li>Illes, Judy, 2006, <em>Neuroethics: Defining the Issues in Theory,
Practice, and Policy</em>, Oxford: Oxford University Press.</li>

<li>Jebari, Karim, 2013, &ldquo;Brain Machine Interface and Human
Enhancement &ndash; An Ethical Review,&rdquo; <em>Neuroethics</em>,
6(3): 617&ndash;25. doi:10.1007/s12152-012-9176-2</li>

<li>Jecker, Nancy S., and Andrew L. Ko, 2017, &ldquo;Is That the Same
Person? Case Studies in Neurosurgery,&rdquo; <em>AJOB
Neuroscience</em>, 8(3): 160&ndash;70.
doi:10.1080/21507740.2017.1366578</li>

<li>Johnson, L. Syd M., Andrew Fenton, and Adam Shriver (eds.), 2020,
<em>Neuroethics and Nonhuman Animals: Advances in Neuroethics</em>,
Springer International Publishing. doi:10.1007/978-3-030-31011-0</li>

<li>Jones, Owen D., Jeffrey D. Schall, and Francis X. Shen, 2014,
<em>Law &amp; Neuroscience</em>, 1st edition. New York: Wolters Kluwer
Law &amp; Business.</li>

<li>Jones, Owen D., Joshua Buckholtz, Jeffrey D. Schall, and Rene
Marois, 2009, <em>Brain Imaging for Legal Thinkers: A Guide for the
Perplexed</em>, SSRN Scholarly Paper ID 1563612. Rochester, NY: Social
Science Research Network.</li>

<li>Jotterand, Fabrice, and Marcello Ienca, (eds.) 2023, <em>The
Routledge handbook of the ethics of human enhancement</em>. Taylor
&amp; Francis.</li>

<li>Kahane, Guy and Julian Savulescu, 2009, &ldquo;Brain damage and
the moral significance of consciousness,&rdquo; <em>The Journal of
Medicine and Philosophy: A Forum for Bioethics and Philosophy of
Medicine</em>, 34(1):6&ndash;26.</li>

<li>Kahane, Guy, Katja Wiech, Nicholas Shackel, Miguel Farias, Julian
Savulescu, and Irene Tracey, 2011, &ldquo;The Neural Basis of
Intuitive and Counterintuitive Moral Judgment,&rdquo; <em>Social
Cognitive and Affective Neuroscience</em>, March, nsr005.
doi:10.1093/scan/nsr005</li>

<li>Kahane, Guy, 2011, &ldquo;Mastery Without Mystery: Why There Is No
Promethean Sin in Enhancement,&rdquo; <em>Journal of Applied
Philosophy</em>, 28(4): 355&ndash;68.
doi:10.1111/j.1468-5930.2011.00543.x</li>

<li>Kass, Leon, 2003, &ldquo;Beyond Therapy: Biotechnology and the
Pursuit of Human Improvement,&rdquo; <em>President&rsquo;s Council on
Bioethics</em>, Washington, D.C., 16.
 [<a href="https://bioethicsarchive.georgetown.edu/pcbe/background/kasspaper.html" target="other">Kass 2003 available online</a>]</li>
 
<li>Kellmeyer, Philipp, 2021, &ldquo;Big Brain Data: On the
Responsible Use of Brain Data from Clinical and Consumer-Directed
Neurotechnological Devices,&rdquo; <em>Neuroethics</em>, 14(1):
83&ndash;98. doi:10.1007/s12152-018-9371-x</li>

<li>Klaming, Larry and Pim Haselager, 2013, &ldquo;Did My Brain
Implant Make Me Do It? Questions Raised by DBS Regarding Psychological
Continuity, Responsibility for Action and Mental Competence,&rdquo;
<em>Neuroethics</em>, 6: 527&ndash;39.</li>

<li>Klein, Eran, Tim Brown, Matthew Sample, Anjali R. Truitt, and Sara
Goering, 2015, &ldquo;Engineering the Brain: Ethical Issues and the
Introduction of Neural Devices,&rdquo; <em>The Hastings Center
Report</em>, 45(6): 26&ndash;35. doi:10.1002/hast.515</li>

<li>Klein, Eran, Sara Goering, Josh Gagne, Conor V. Shea, Rachel
Franklin, Samuel Zorowitz, Darin D. Dougherty, and Alik S. Widge,
2016, &ldquo;Brain-Computer Interface-Based Control of Closed-Loop
Brain Stimulation: Attitudes and Ethical Considerations,&rdquo;
<em>Brain-Computer Interfaces</em>, 3(3): 140&ndash;48.
doi:10.1080/2326263X.2016.1207497</li>

<li>Knafo, Shira and C&eacute;sar Venero (eds.), 2015, <em>Cognitive
Enhancement</em>, San Diego: Academic Press,
doi:10.1016/B978-0-12-417042-1.00001-2</li>

<li>Kraemer, Felicitas, 2013a, &ldquo;Me, Myself and My Brain Implant:
Deep Brain Stimulation Raises Questions of Personal Authenticity and
Alienation,&rdquo; <em>Neuroethics</em>, 6: 483&ndash;97.</li>

<li>Kraemer, Felicitas, 2013b, &ldquo;Authenticity or Autonomy? When
Deep Brain Stimulation Causes a Dilemma,&rdquo; <em>Journal of Medical
Ethics</em>, 39(12): 757&ndash;60.
doi:10.1136/medethics-2011-100427</li>

<li>Krauss, Joachim K., Nir Lipsman, Tipu Aziz, Alexandre Boutet,
Peter Brown, Jin Woo Chang, Benjamin Davidson, et al. ,2021,
&ldquo;Technology of Deep Brain Stimulation: Current Status and Future
Directions,&rdquo; <em>Nature Reviews Neurology</em>, 17(2):
75&ndash;87. doi:10.1038/s41582-020-00426-z</li>

<li>Kreitmair, Karola, 2023, &ldquo;Consciousness and the Ethics of
Human Brain Organoid Research,&rdquo; <em>Cambridge Quarterly of
Healthcare Ethics</em> 32(4): 518&ndash;28.
doi:10.1017/S0963180123000063</li>

<li>Kritika, Er, 2025, &ldquo;Ethical Frontiers: Navigating the
Intersection of Neurotechnology and Cybersecurity,&rdquo; <em>Journal
of Experimental Neurology</em> 6(1): 21&ndash;25.
doi:10.33696/Neurol.6.106</li>

<li>Lavazza, Andrea, 2018, &ldquo;Freedom of Thought and Mental
Integrity: The Moral Requirements for Any Neural Prosthesis,&rdquo;
<em>Frontiers in Neuroscience</em>, 12.
doi:10.3389/fnins.2018.00082</li>

<li>L&aacute;zaro-Mu&ntilde;oz, Gabriel, Amy L. McGuire, and Wayne K.
Goodman, 2017, &ldquo;Should We Be Concerned About Preserving Agency
and Personal Identity in Patients With Adaptive Deep Brain Stimulation
Systems?&rdquo; <em>AJOB Neuroscience</em>, 8(2): 73&ndash;75.
doi:10.1080/21507740.2017.1320337</li>

<li>Lebedev, Mikhail A. and Miguel A. L. Nicolelis, 2017,
&ldquo;Brain-Machine Interfaces: From Basic Science to Neuroprostheses
and Neurorehabilitation&rdquo; <em>Physiological Reviews</em>, 97(2):
767&ndash;837.</li>

<li>Leentjens A.F., Visser-Vandewalle V., Temel Y., Verhey F.R., 2004,
&ldquo;Manipulation of mental competence: An ethical problem in case
of electrical stimulation of the subthalamic nucleus for severe
Parkinson&rsquo;s disease,&rdquo; <em>Nederlands Tijdschrift voor
Geneeskunde</em>, 148(28): 1394 &ndash; 98.</li>

<li>Leuenberger, Muriel, 2022, &ldquo;Memory Modification and
Authenticity: A Narrative Approach,&rdquo; <em>Neuroethics</em> 15(1):
10. doi:10.1007/s12152-022-09489-9</li>

<li>Liao, S. Matthew, 2016, <em>Moral Brains: The Neuroscience of
Morality</em>, first edition, New York, NY: Oxford University
Press.</li>

<li>Libet, Benjamin, Curtis A. Gleason, Elwood W. Wright, and Dennis
K. Pearl, 1983, &ldquo;Time of Conscious Intention to Act in Relation
to Onset of Cerebral Activity (readiness-Potential),&rdquo;
<em>Brain</em>, 106(3): 623&ndash;42. doi:10.1093/brain/106.3.623</li>

<li>Ligthart, Sjors, Marcello Ienca, Gerben Meynen, Fruzsina
Molnar-Gabor, Roberto Andorno, Christoph Bublitz, Paul Catley, et al.,
2023, &ldquo;Minding Rights: Mapping Ethical and Legal Foundations of
&lsquo;Neurorights.&rsquo;&rdquo; <em>Cambridge Quarterly of
Healthcare Ethics</em>, 32(4): 461&ndash;81.
doi:10.1017/S0963180123000245</li>

<li>Lin, Patrick, and Fritz Allhoff, 2008, &ldquo;Against Unrestricted
Human Enhancement,&rdquo; <em>Journal of Evolution &amp;
Technology</em>, 18(1): 35&ndash;41.</li>

<li>Littlejohn, Kaylo T., Cheol Jun Cho, Jessie R. Liu, Alexander B.
Silva, Bohan Yu, Vanessa R. Anderson, Cady M. Kurtz-Miott, et al.
2025, &ldquo;A Streaming Brain-to-Voice Neuroprosthesis to Restore
Naturalistic Communication,&rdquo; <em>Nature Neuroscience</em>,
28(4): 902&ndash;12. doi:10.1038/s41593-025-01905-6</li>

<li>Liu, Xiaonan, Kewei Chen, Teresa Wu, David Weidman, Fleming Lure,
and Jing Li, 2018, &ldquo;Use of Multimodality Imaging and Artificial
Intelligence for Diagnosis and Prognosis of Early Stages of
Alzheimer&rsquo;s Disease,&rdquo; <em>Translational Research: The
Journal of Laboratory and Clinical Medicine</em>, 194: 56&ndash;67.
doi:10.1016/j.trsl.2018.01.001</li>

<li>Mackenzie, Catriona, and Mary Walker, 2015,
&ldquo;Neurotechnologies, Personal Identity, and the Ethics of
Authenticity,&rdquo; in <em>Handbook of Neuroethics</em>, edited by
Jens Clausen and Neil Levy, Dordrecht: Springer Netherlands, pp.
373&ndash;92. doi:10.1007/978-94-007-4707-4_10</li>

<li>Mantione, Mariska, Martijn Figee, and Damiaan Denys, 2014,
&ldquo;A case of musical preference for Johnny Cash following deep
brain stimulation of the nucleus accumbens,&rdquo; <em>Frontiers in
Behavioral Neuroscience</em>, 8: 152.</li>

<li>Marcus, Steven J. (ed.), 2002, <em>Neuroethics: Mapping the
Field</em>, first edition, New York: Dana Press.</li>

<li>Mattay, Venkata S., Joseph H. Callicott, Alessandro Bertolino, Ian
Heaton, Joseph A. Frank, Richard Coppola, Karen F. Berman, Terry E.
Goldberg, and Daniel R. Weinberger, 2000, &ldquo;Effects of
Dextroamphetamine on Cognitive Performance and Cortical
Activation,&rdquo; <em>NeuroImage</em>, 12(3): 268&ndash;75.
doi:10.1006/nimg.2000.0610</li>

<li>May, Joshua, 2023, <em>Neuroethics: Agency in the Age of Brain
Science</em>, Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2025, &ldquo;Neurodiversity with
Nuance&rdquo;. <em>Neuroethics</em>, 18: 30.
doi:10.1007/s12152-025-09603-7</li>

<li>May, Joshua, Clifford L. Workman, Julia Haas, and Hyemin Han,
2022,&ldquo;The Neuroscience of Moral Judgment: Empirical and
Philosophical Developments,&rdquo; in <em>Neuroscience and
Philosophy</em>, Felipe De Brigard and Walter Sinnott-Armstrong
(eds.), Cambridge, MA: The MIT Press.
doi:10.7551/mitpress/12611.003.0005</li>

<li>May, Joshua, Clifford Ian Workman, Hyemin Han, and Julia Haas,
forthcoming, &ldquo;The Neuroscience of Moral Judgment: Empirical and
Philosophical Developments,&rdquo; in <em>Neuroscience and
Philosophy</em>, Felipe De Brigard and Walter Sinnott-Armstrong
(eds.), Cambridge, MA: The MIT Press. preprint
doi:10.31234/osf.io/89jcx</li>

<li>Molenberghs, Pascal, and Winnifred R. Louis, 2018, &ldquo;Insights
From FMRI Studies Into Ingroup Bias,&rdquo; <em>Frontiers in
Psychology</em>, 9. doi:10.3389/fpsyg.2018.01868</li>

<li>Monti, Martin M., Audrey Vanhaudenhuyse, Martin R. Coleman,
Melanie Boly, John D. Pickard, Luaba Tshibanda, Adrian M. Owen, and
Steven Laureys, 2010, &ldquo;Willful Modulation of Brain Activity in
Disorders of Consciousness,&rdquo; <em>New England Journal of
Medicine</em>, 362(7): 579&ndash;89. doi:10.1056/NEJMoa0905370</li>

<li>Morse, Stephen J., and Adina L. Roskies (eds.), 2013, <em>A Primer
on Criminal Law and Neuroscience</em>, Oxford, New York: Oxford
University Press.</li>

<li>Nour, Matthew M., Yunzhe Liu, and Raymond J. Dolan, 2022,
&ldquo;Functional Neuroimaging in Psychiatry and the Case for Failing
Better,&rdquo; <em>Neuron</em> 110(16): 2524&ndash;2544.
doi:10.1016/j.neuron.2022.07.005</li>

<li>Olson, Eric T., 1999, <em>The Human Animal: Personal Identity
without Psychology</em>, New York: Oxford University Press.</li>

<li>Owen. Adrian M., 2013, &ldquo;Detecting Consciousness: A Unique
Role for Neuroimaging,&rdquo; <em>Annual Review of Psychology</em>,
64(1): 109&ndash;33. doi:10.1146/annurev-psych-113011-143729</li>

<li>Owen, Adrian M., Martin R. Coleman, Melanie Boly, Matthew H.
Davis, Steven Laureys, and John D. Pickard, 2006, &ldquo;Detecting
Awareness in the Vegetative State,&rdquo; <em>Science</em>, 313(5792):
1402&ndash;1402. doi:10.1126/science.1130197</li>

<li>Parens, Erik, 2005, &ldquo;Authenticity and Ambivalence: Toward
Understanding the Enhancement Debate,&rdquo; <em>The Hastings Center
Report</em>, 35(3): 34&ndash;41. doi:10.2307/3528804</li>

<li>Parfit, Derek, 1984, <em>Reasons and Persons</em>, Oxford: Oxford
University Press.</li>

<li>Pascalev, Assya, Mario Pascalev, and James Giordano, 2016,
&ldquo;Head Transplants, Personal Identity and Neuroethics,&rdquo;
<em>Neuroethics</em>, 9(1) : 15&ndash;22.
doi:10.1007/s12152-015-9245-4</li>

<li>Peterson, Andrew, Adrian M. Owen, and Jason Karlawish, 2020,
&ldquo;Alive Inside,&rdquo; <em>Bioethics</em>, 34(3): 295&ndash;305.
doi:10.1111/bioe.12678</li>

<li>Poldrack, Russell A., John Monahan, Peter B. Imrey, Valerie Reyna,
Marcus Raichle, David Faigman, and Joshua W. Buckholtz, 2018,
&ldquo;Predicting Violent Behavior: What Can Neuroscience Add?&rdquo;
<em>Trends in Cognitive Sciences</em>, 22(2): 111&ndash;23.
doi:10.1016/j.tics.2017.11.003</li>

<li>Presidential Commission for the Study of Bioethical Issues, 2015,
<em>Gray Matters</em> (Volume 2).
 [<a href="https://bioethicsarchive.georgetown.edu/pcsbi/node/4716.html" target="other">Presidential Commission 2015 available online</a>]</li>
 
<li>Pugh, Jonathan, Hannah Maslen, and Julian Savulescu, 2017,
&ldquo;Deep Brain Stimulation, Authenticity and Value,&rdquo;
<em>Cambridge Quarterly of Healthcare Ethics</em>, 26(4):
640&ndash;57. doi:10.1017/S0963180117000147</li>

<li>Racine, Eric, Ofek Bar-Ilan, and Judy Illes, 2006, &ldquo;Brain
Imaging: A decade of coverage in the print media,&rdquo; <em>Science
Communication</em>, 28(1): 122&ndash;42.
doi:10.1177/1075547006291990</li>

<li>Racine, Eric, 2015, &ldquo;Neuroscience, Neuroethics, and the
Media,&rdquo; in <em>Handbook of Neuroethics</em>, Jens Clausen and
Neil Levy (eds.), Dordrecht: Springer Netherlands, pp. 1465&ndash;71,
doi:10.1007/978-94-007-4707-4_82</li>

<li>Racine, Eric, 2010, <em>Pragmatic Neuroethics: Improving Treatment
and Understanding of the Mind-Brain</em>, Cambridge, MA: The MIT
Press.</li>

<li>Roskies, Adina, 2002, &ldquo;Neuroethics for the New
Millenium,&rdquo; <em>Neuron</em>, 35(1): 21&ndash;23.
doi:10.1016/S0896-6273(02)00763-8</li>

<li>&ndash;&ndash;&ndash;, 2007, &ldquo;Are Neuroimages like
Photographs of the Brain?&rdquo; <em>Philosophy of Science</em>, 74:
860&ndash;72.</li>

<li>&ndash;&ndash;&ndash;, 2006, &ldquo;Neuroscientific Challenges to
Free Will and Responsibility,&rdquo; <em>Trends in Cognitive
Sciences</em>, 10(9): 419&ndash;23.
doi:10.1016/j.tics.2006.07.011</li>

<li>&ndash;&ndash;&ndash;, 2015, &ldquo;Agency and
intervention,&rdquo; <em>Philosophical Transactions of the Royal
Society B</em>, 370(1677): 20140215. doi:10.1098/rstb.2014.0215</li>

<li>&ndash;&ndash;&ndash;, 2015. &ldquo;Mind Reading, Lie Detection,
and Privacy,&rdquo; in <em>Handbook of Neuroethics</em>, Jens Clausen
and Neil Levy (eds.), Dordrecht: Springer Netherlands, pp.
679&ndash;95</li>

<li>&ndash;&ndash;&ndash;, 2020, &ldquo;Mindreading and
Privacy,&rdquo; <em>The New Cognitive Neurosciences</em>, 6th Edition,
D. Poeppel, G.R. Mangun, and M.S. Gazzaniga (eds.), Cambridge, MA: MIT
Press, pp. 1049&ndash;57.</li>

<li>&ndash;&ndash;&ndash;, 2022. &ldquo;The limits of neuroscience for
ethics,&rdquo; in <em>The Oxford Handbook of Moral Psychology</em>,
Vargas and Doris (eds.) Oxford: Oxford University Press,
495&ndash;508.</li>

<li>Ruiz, Sergio, Luca Valera, Paulina Ramos, and Ranganatha Sitaram,
2024, &ldquo;Neurorights in the Constitution: From Neurotechnology to
Ethics and Politics,&rdquo; <em>Philosophical Transactions of the
Royal Society B: Biological Sciences</em>, 379(1915): 20230098.
doi:10.1098/rstb.2023.0098</li>

<li>Sahakian, Barbara, and Sharon Morein-Zamir, 2007,
&ldquo;Professor&rsquo;s Little Helper,&rdquo; <em>Nature</em>,
450(7173): 1157&ndash;59. doi:10.1038/4501157a</li>

<li>Sandel, Michael, 2002,&ldquo;What&rsquo;s Wrong with
Enhancement,&rdquo; <em>President&rsquo;s Council on Bioethics</em>,
Washington, D.C., 12.
 [<a href="https://bioethicsarchive.georgetown.edu/pcbe/background/sandelpaper.html" target="other">Sandel 2002 available online</a>]</li>
 
<li>Sapolsky, Robert, 2023, <em>Determined: a science of life without
free will</em>, New York: Penguin Press.</li>

<li>Savulescu, Julian, and Ingmar Persson, 2012, &ldquo;Moral
Enhancement, Freedom and the God Machine,&rdquo; <em>The Monist</em> ,
95(3): 399&ndash;421.</li>

<li>Sawai, Tsutomu, Hideya Sakaguchi, Elizabeth Thomas, Jun Takahashi,
and Misao Fujita, 2019, &ldquo;The Ethics of Cerebral Organoid
Research: Being Conscious of Consciousness,&rdquo; <em>Stem Cell
Reports</em>, 13(3): 440&ndash;447.
doi:10.1016/j.stemcr.2019.08.003</li>

<li>Schechtman, Marya, 2014, <em>Staying Alive: Personal Identity,
Practical Concerns, and the Unity of a Life</em>, Oxford: Oxford
University Press.</li>

<li>Schermer, Maartje, 2008, &ldquo;Enhancements, Easy Shortcuts, and
the Richness of Human Activities,&rdquo; <em>Bioethics</em>, 22(7):
355&ndash;63. doi:10.1111/j.1467-8519.2008.00657.x</li>

<li>Schweitzer, N. J., Michael J. Saks, Emily R. Murphy, Adina L.
Roskies, Walter Sinnott-Armstrong, and Lyn M. Gaudet, 2011,
&ldquo;Neuroimages as Evidence in a Mens Rea Defense: No
Impact,&rdquo; <em>Psychology, Public Policy, and Law</em>, 17(3):
357&ndash;93. doi:http://dx.doi.org/10.1037/a0023581</li>

<li>Schurger, Aaron, Pengbo &ldquo;Ben&rdquo; Hu, Joanna Pak, and
Adina L. Roskies, 2021, &ldquo;What Is the Readiness Potential?&rdquo;
<em>Trends in Cognitive Sciences</em> 25(7): 558&ndash;70.
doi:10.1016/j.tics.2021.04.001</li>

<li>Selgelid, Michael J., 2007. &ldquo;An Argument Against Arguments
for Enhancement,&rdquo; <em>Studies in Ethics, Law, and
Technology</em>, 1(1).</li>

<li>Sententia, Wrye, 2013, &ldquo;Freedom by Design,&rdquo; in <em>The
Transhumanist Reader</em>, Max More and Natasha Vita-More (eds.),
Chichester: John Wiley &amp; Sons, pp. 355&ndash;60.
doi:10.1002/9781118555927.ch34</li>

<li>Shen, Francis, 2013, &ldquo;Neuroscience, Mental Privacy, and the
Law,,&rdquo; <em>Harvard Journal of Law &amp; Public Policy</em>,
36.</li>

<li>Silva, Alexander B., Kaylo T. Littlejohn, Jessie R. Liu, David A.
Moses, and Edward F. Chang, 2024, &ldquo;The Speech
Neuroprosthesis,&rdquo; <em>Nature Reviews Neuroscience</em>, 25(7):
473&ndash;92. doi:10.1038/s41583-024-00819-9</li>

<li>Skorburg, Joshua August, and Walter Sinnott Armstrong, 2020
&ldquo;Some Ethics of Deep Brain Stimulation,&rdquo; in <em>Global
Mental Health and Neuroethics</em>, Dan Stein and Ilina Singh (eds.),
London: Academic Press, pp. 117&ndash;32.</li>

<li>Soon, Chun Siong, Marcel Brass, Hans-Jochen Heinze, and John-Dylan
Haynes, 2008, &ldquo;Unconscious Determinants of Free Decisions in the
Human Brain,&rdquo; <em>Nature Neuroscience</em>, 11(5): 543&ndash;45.
doi:10.1038/nn.2112</li>

<li>Spence, Charles, 2020, &ldquo;On the Ethics of Neuromarketing and
Sensory Marketing,&rdquo; <em>In Organizational Neuroethics:
Reflections on the Contributions of Neuroscience to Management
Theories and Business Practices</em>, Jo&eacute; T. Martineau and Eric
Racine (eds.), Cham: Springer International Publishing, pp.
9&ndash;29. doi:10.1007/978-3-030-27177-0_3</li>

<li>Spielberg, Steven (director), 2002, Film: <em>Minority
Report</em>.</li>

<li>Stanton, Steven J., Walter Sinnott-Armstrong, and Scott A.
Huettel, 2017, &ldquo;Neuromarketing: Ethical Implications of Its Use
and Potential Misuse,&rdquo; <em>Journal of Business Ethics</em>,
144(4): 799&ndash;81. doi:10.1007/s10551-016-3059-0</li>

<li>Stein, Dan, and Ilina Singh (eds.), 2020, <em>Global Mental Health
and Neuroethics</em>, London: Academic Press.</li>

<li>Strawson, Galen, 2004, &ldquo;Against Narrativity,&rdquo;
<em>Ratio</em>, 17(4): 428&ndash;52.
doi:10.1111/j.1467-9329.2004.00264.x</li>

<li>Sui, Jing, Rongtao Jiang, Juan Bustillo, Vince Calhoun, 2020,
&ldquo;Neuroimaging-based Individualized Prediction of Cognition and
Behavior for Mental Disorders and Health: Methods and Promises,&rdquo;
<em>Biological Psychiatry</em>, 88(11): 818&ndash;828.</li>

<li>Tang J., A. LeBel, S. Jain, and A.G. Huth, 2023, &ldquo;Semantic
reconstruction of continuous language from non-invasive brain
recordings,&rdquo; <em>Nat Neurosci</em>, 26(5): 858&ndash;866 (PMID:
37127759; PMCID:PMC11304553). doi:10.1038/s41593-023-01304-9</li>

<li>Tang, Jerry, and Alexander G. Huth, 2025, &ldquo;Semantic Language
Decoding across Participants and Stimulus Modalities,&rdquo;
<em>Current Biology</em>, 35(5): 1023&ndash;1032.e6.
doi:10.1016/j.cub.2025.01.024.</li>

<li>Thomson, Judith Jarvis, 1985, &ldquo;The Trolley Problem,&rdquo;
<em>The Yale Law Journal</em>, 94(6): 1395&ndash;1415.
doi:10.2307/796133</li>

<li><em>United States v. Semrau</em>, No. 11&ndash;5396 (6th Cir.
2012).</li>

<li>Urban, Kimberly R., and Wen-Jun Gao, 2014, &ldquo;Performance
Enhancement at the Cost of Potential Brain Plasticity: Neural
Ramifications of Nootropic Drugs in the Healthy Developing
Brain,&rdquo; <em>Frontiers in Systems Neuroscience</em>, 8 (May): 38.
doi:10.3389/fnsys.2014.00038</li>

<li>Valizadeh, Seyed Abolfazl, Franziskus Liem, Susan M&eacute;rillat,
J&uuml;rgen H&auml;nggi, and Lutz J&auml;ncke, 2018,
&ldquo;Identification of Individual Subjects on the Basis of Their
Brain Anatomical Features,&rdquo; <em>Scientific Reports</em> , 8(1):
5611. doi:10.1038/s41598-018-23696-6</li>

<li>Vincent, Nicole A. (ed.), 2013, <em>Neuroscience and Legal
Responsibility</em>, first edition, New York: Oxford University
Press.</li>

<li>Vohs, Kathleen D., and Jonathan W. Schooler, 2008, &ldquo;The
Value of Believing in Free Will Encouraging a Belief in Determinism
Increases Cheating,&rdquo; <em>Psychological Science</em>, 19(1):
49&ndash;54. doi:10.1111/j.1467-9280.2008.02045.x</li>

<li>Walker, Mary Jean, and Catriona Mackenzie, 2020,
&ldquo;Neurotechnologies, Relational Autonomy, and
Authenticity,&rdquo; <em>IJFAB: International Journal of Feminist
Approaches to Bioethics</em>. doi:10.3138/ijfab.13.1.06</li>

<li>Wang, Huifang E, Paul Triebkorn, Martin Breyton, Borana Dollomaja,
Jean-Didier Lemarechal, Spase Petkoski, Pierpaolo Sorrentino, Damien
Depannemaecker, Meysam Hashemi, and Viktor K Jirsa, 2024,
&ldquo;Virtual Brain Twins: From Basic Neuroscience to Clinical
Use,&rdquo; <em>National Science Review</em>, 11(5): nwae079.
doi:10.1093/nsr/nwae079</li>

<li>Warren, Samuel D., and Louis D. Brandeis, 1890, &ldquo;Right to
Privacy,&rdquo; <em>Harvard Law Review</em>, 4: 193.</li>

<li>Waters, Theodore E. A., and Robyn Fivush, 2014, &ldquo;Relations
Between Narrative Coherence, Identity, and Psychological Well-Being in
Emerging Adulthood,&rdquo; <em>Journal of Personality</em>, 83(4):
441&ndash;451. doi:10.1111/jopy.12120</li>

<li>Weisberg, Deena Skolnick, Frank C. Keil, Joshua Goodstein,
Elizabeth Rawson, and Jeremy R. Gray, 2008, &ldquo;The Seductive
Allure of Neuroscience Explanations,&rdquo; <em>Journal of Cognitive
Neuroscience</em>, 20(3): 470&ndash;77.
doi:10.1162/jocn.2008.20040</li>

<li>Wiese W, and Friston Karl, 2022, &ldquo;AI ethics in computational
psychiatry: From the neuroscience of consciousness to the ethics of
consciousness&rdquo;. <em>Behav Brain Res</em>, 420: 113704 (PMID:
34871706; PMCID: PMC9125160). doi:10.1016/j.bbr.2021.113704</li>

<li>Xiong, Hui, Congying Chu, Lingzhong Fan, Ming Song, Jiaqi Zhang,
Yawei Ma, Ruonan Zheng, Junyang Zhang, Zhengyi Yang, and Tianzi Jiang,
2023, &ldquo;The Digital Twin Brain: A Bridge between Biological and
Artificial Intelligence,&rdquo; <em>Intelligent Computing</em>, 2:
0055. doi:10.34133/icomputing.0055</li>

<li>Zawadzki, Przemys&#322;aw, 2023, &ldquo;The Ethics of Memory
Modification: Personal Narratives, Relational Selves and
Autonomy&rdquo;. <em>Neuroethics</em>, 16(6).
doi:10.1007/s12152-022-09512-z</li>

<li>Zawadzki, Przemys&#322;aw, and Agnieszka K Adamczyk, 2021,
&ldquo;Personality and Authenticity in Light of the Memory-Modifying
Potential of Optogenetics,&rdquo; <em>AJOB Neuroscience</em>, 12(1):
3&ndash;21. doi:10.1080/21507740.2020.1866097</li>

<li>Zuk, Peter, Laura Torgerson, Demetrio Sierra-Mercado, and Gabriel
L&aacute;zaro-Mu&ntilde;oz, 2018, &ldquo;Neuroethics of
Neuromodulation: An Update,&rdquo; <em>Current Opinion in Biomedical
Engineering</em>, 8: 45&ndash;50. doi:10.1016/j.cobme.2018.10.003</li>
</ul>
</div> 

<div id="academic-tools">
<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=neuroethics" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/neuroethics/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=neuroethics&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="https://philpapers.org/sep/neuroethics/" target="other">Enhanced bibliography for this entry</a>
at <a href="https://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>
</div>

<div id="other-internet-resources">

<h2 id="Oth">Other Internet Resources</h2>

<ul>
 <li><a href="https://www.thehastingscenter.org/category/enhancement/" target="other">The Hastings Center page on Enhancement</a></li>
 <li><a href="http://www.cognitiveliberty.org/" target="other">Center for Cognitive Liberty</a></li>
 <li><a href="http://neuroethics.upenn.edu/" target="other">Center for Neuroscience and Society, University of Pennsylvania</a></li>
 <li><a href="http://www.neuroethicssociety.org/" target="other">International Neuroethics Society</a></li>
 <li><a href="http://www.theneuroethicsblog.com/" target="other">The Neuroethics Blog</a>,
 hosted by the Center for Ethics, Neuroethics Program at Emory
University</li>
 <li><a href="http://philosophicaldisquisitions.blogspot.com/2013/07/the-ethics-of-human-enhancement-index.html" target="other">The Ethics of Human Enhancement (Index to all Posts)</a>,
 Philosophical Disquisitions blog</li>
 <li><a href="https://bioethicsarchive.georgetown.edu/pcsbi/node/851.html" target="other">Presidential Commission for the Study of Bioethics</a>
 
<ul>
 <li><a href="https://bioethicsarchive.georgetown.edu/pcsbi/node/3543.html" target="other">Gray Matters: Integrative Approaches for Neuroscience, Ethics, and Society</a></li>
 <li><a href="https://bioethicsarchive.georgetown.edu/pcsbi/node/851.html" target="other">Gray Matters: Topics at the Intersection of Neuroscience, Ethics, and Society</a></li>
 </ul></li> <!--LINK CHECKER COMMENTED OUT (Sun Sep 17 11:47:00 PDT 2023)  <li><a href="https://teamweb.uni-mainz.de/fb05/Neuroethics/" target="other">Neuroethics bibliography from University of Mainz</a>,
 maintained until 2016.</li> LINK CHECKER-->
</ul>
</div>

<div id="related-entries">

<h2 id="Rel">Related Entries</h2>

<p>

 <a href="../autonomy-moral/">autonomy: in moral and political philosophy</a> |
 <a href="../personal-autonomy/">autonomy: personal</a> |
 <a href="../implicit-bias/">bias, implicit</a> |
 <a href="../decision-capacity/">decision-making capacity</a> |
 <a href="../clinical-research/">ethics, biomedical: clinical research</a> |
 <a href="../justice-inequality-health/">ethics, biomedical: justice, inequality, and health</a> |
 <a href="../privacy-medicine/">ethics, biomedical: privacy and medicine</a> |
 <a href="../freewill/">free will</a> |
 <a href="../health-disease/">health</a> |
 <a href="../enhancement/">human enhancement</a> |
 <a href="../informed-consent/">informed consent</a> |
 <a href="../moral-responsibility/">moral responsibility</a> |
 <a href="../identity-personal/">personal identity</a> |
 <a href="../identity-ethics/">personal identity: and ethics</a>

 </p>
</div>

<div id="acknowledgments">

<h3>Acknowledgments</h3>

<p>
The author would like to acknowledge the research assistance of Yaning
Chen for this project.</p>
</div> 


</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2025</a> by

<br />
<a href="https://www.philosophy.ucsb.edu/people/adina-l-roskies" target="other">Adina Roskies</a>
&lt;<a href="m&#97;ilto:aroskies&#37;40ucsb&#37;2eedu"><em>aroskies<abbr title=" at ">&#64;</abbr>ucsb<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
            <li role="menuitem"><a href="../../new.html">What's New</a></li>
            <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li role="menuitem"><a href="../../published.html">Chronological</a></li>
            <li role="menuitem"><a href="../../archives/">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
            <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
            <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
            <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
            <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
            <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
            <li role="menuitem"><a href="../../accessibility.html">Accessibility</a></li>
            <li role="menuitem"><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
            <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
            <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2025</a> by <a href="https://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>
</html>
