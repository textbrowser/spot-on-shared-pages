<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html lang="en"> <!-- <![endif]-->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Ontology and Information Systems (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Ontology and Information Systems" />
<meta property="citation_author" content="Pease, Adam" />
<meta property="citation_publication_date" content="2026/01/03" />
<meta name="DC.title" content="Ontology and Information Systems" />
<meta name="DC.creator" content="Pease, Adam" />
<meta name="DCTERMS.issued" content="2026-01-03" />
<meta name="DCTERMS.modified" content="2026-01-03" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP home page" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
                    <li role="menuitem"><a href="../../new.html">What's New</a></li>
                    <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li role="menuitem"><a href="../../published.html">Chronological</a></li>
                    <li role="menuitem"><a href="../../archives/">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
                    <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
                    <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
                    <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
                    <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
                    <li role="menuitem"><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
                    <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
                    <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="../../search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit" aria-label="search"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/ontology-is/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=ontology-is">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Ontology and Information Systems</h1><div id="pubinfo"><em>First published Sat Jan 3, 2026</em></div>

<div id="preamble">

<p>
When two agents communicate they must have some significant body of
shared understanding about the meaning of the symbols they use. Humans
have attempted to codify some of those shared meanings in
dictionaries. In the computer and information sciences we face the
challenge of how to enable machines to share at least some of the
catalog of the symbols humans use and what they mean. In dealing with
machines one must rely on mathematics to state meaning rather than
relying on the experience and intuitions of the communicating agents.
Ontology (in information systems) is the field that attempts to create
shared meanings of symbols. Different practitioners in the field may
decide to create different lists of symbols with different
definitions.</p>

<p>
A motivation for the development of ontology as a discipline has been
a common issue in software development, where the use of symbols in
computer code by different programmers can change over time, causing
unintended performance in a system. This issue motivated efforts to
catalog, standardize and reuse concepts, recorded as a set of labels
and definitions. Establishing an ontology helps to avoid concept drift
(Magne 2017; Lu et al. 2019; Pancha 2016) and supports the
interoperability of computer software systems.</p>
</div> 

<div id="toc"><!--Entry Contents-->
<ul>
	<li><a href="#Int">1. Introduction</a></li>
	<li><a href="#His">2. History</a></li>
	<li><a href="#DomOntUppOnt">3. Domain Ontology and Upper Ontology</a></li>
	<li><a href="#OntCom">4. Ontological Commitment</a></li>
	<li><a href="#OntTheEle">5. Ontology by Theory Elements</a></li>
	<li><a href="#OntLogLan">6. Ontology by Logical Language</a></li>
	<li><a href="#AssOnt">7. Assessment of An Ontology</a></li>
	<li><a href="#OntLarLanMod">8. Ontology and Large Language Models</a></li>
	<li><a href="#AppOnt">9. Applications of Ontologies</a></li>
	<li><a href="#FutDir">10. Future Directions</a></li>
	<li><a href="#Bib">Bibliography</a></li>
	<li><a href="#Aca">Academic Tools</a></li>
	<li><a href="#Oth">Other Internet Resources</a></li>
	<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->

<hr /></div>

<div id="main-text">

<h2 id="Int">1. Introduction</h2>

<p>
In information and computer science the study of ontology is about how
to define or describe the things that <em>are</em> (including imagined
or possible things) for the purpose of some process of computation on
a computer. In philosophy, the field of ontology is often described as
&ldquo;the study of what there is&rdquo; (see the entries on
 <a href="../social-ontology/">social ontology</a>,
 <a href="../logic-ontology/">logic ontology</a>
 and
 <a href="../natural-language-ontology/">natural language ontology</a>).
 A philosophical ontology will thus purport to identify the
fundamental constituents of reality, the categories they fall into,
and the relations they stand in to one another. Ontology in computer
and information science shares with philosophy that it includes a
study of categories (see the entry on
 <a href="../categories/">categories</a>)
 but with a practical focus on recording an inventory of categories in
a formal syntax and often with some formal semantics. Some individual
information science ontologies are also concerned with a formal
specification of the definitions of those categories. Ontology as a
field in computer and information science is also reasonably
characterized as the study of what there is, but not necessarily of
what ultimately exists, rather of what is assumed to exist in some
relevant domain for some computational purpose. A computer scientist
is less concerned about the metaphysical status of categories &ndash; such
as whether they actually exist or are just human constructs &ndash; than
with their practical use in computation. In computer and information
science, an ontology may also catalogue individuals and relationships,
in addition to categories.</p>

<p>
One popular description of an ontology in computer science is &ldquo;a
specification of a conceptualization&rdquo; (Gruber 1993). But this
requires an explanation of of what a specification is and what a
conceptualization is.  A conceptualization is a way to understand the
structure of a particular concept by considering both its relationship
to other concepts and the principles that may govern it. So a
conceptualization includes a way to understand how a concept
differentiates the objects falling under it (whether abstract or
concrete), from other things. Historically, a way of understanding a
concept would be expressible in a human language as an entry in a
dictionary or encyclopedia. Concepts are often labeled using single
words or phrases and since they are the meanings of those words and
phrases, they are not part of the syntax.  Different human languages
use different symbols but can express the same concepts, although
whether one can have truly exact translations is a subject of some
debate (Levine &amp; Lateef-Jan 2017). Words are one method
of <em>reference</em> (see the entry on
 <a href="../reference/">reference</a>).  We hope that when we use a
proper noun like &ldquo;Mount Kilimanjaro&rdquo; that the listener
will have enough common information associated with the words that the
desired information is communicated. But with more abstract concepts
such as &ldquo;object&rdquo; or &ldquo;beauty&rdquo; this is more
problematic.  Once a concept is expressed in some way for
communication then we can examine what it means to be a
specification. If we do not rely on human intuition about the intended
meaning of a word or words, or even on the process of human
clarification dialogues, then we must have some other way of recording
ideas or thoughts.</p>

<p>
Since its adoption in the computer science community, the word
&lsquo;ontology&rsquo; has become broader in usage. Collections of
words with natural language definitions have been labeled as an
ontology, even though we could call them glossaries and not have to
resort to adopting this new word for something that already has an
older label. Other approaches to specifying an ontology include use of
taxonomy languages (Dallwitz 1980) or Unified Modeling Language (UML:
Rumbaugh, Jacobson, &amp; Booch 2004). Others have treated a graph of
concept names and binary relationships to be sufficient for a
specification, such as what is found in semantic networks (Woods 1975)
or knowledge graphs (which might be stated in Resource Description
Framework (RDF: see the link to RDF in Other Internet Resources
below), or a graph database (Kaliyar 2015)). Description logics
(Baader, Calvanese, McGuinness, Nardi, &amp; Patel-Schneider 2007) are
a popular choice for specification of an ontology. At its most formal,
a specification can be a set of formulas in an expressive mathematical
logic such as first-order logic (Enderton 1972), modal logic or
higher-order logic (see the entries on
 <a href="../logic-modal/">modal logic</a>
 and
 <a href="../logic-higher-order/">higher-order logic</a>).</p>
 
<p>
Two of the most important motivations for constructing an ontology are
that (i) it can help to prevent concept drift and (ii) it supports the
interoperability of systems. Regarding the first of these, a common
issue in software development is that the use of strings of symbols in
computer code by different programmers can change over time, causing
unintended performance in a system. An ontology standardizes and
reuses concepts, thereby preventing a concept expressed by a string
within a given body of code at one time from drifting into use as
another, different concept at a later time. Regarding
interoperability, note first that the kind of ontology one creates
will, at least in part, be driven by its intended uses. Broadly, there
are three categories of use, ultimately leading to a computational
implementation, which may all be present in some application: (1)
communication among people, (2) communication among machines or
between people and machines, and (3) computation.</p>

<p>
In (1) the ontology is used to align the terminology and understanding
of that terminology among developers of a computational system. There
may be no exact transfer of the set of labels or definitions into any
formal computational system. An ontology that exists to facilitate
understanding among humans may rely on intuitions about concepts based
on their names, as well as natural language definitions. Grounding the
meaning of specialized terms in a glossary can help to eliminate some
interpretations, for example, misunderstandings based on word
polysemy.</p>

<p>
In (2) the set of labels used in a computational system forms a
standard that people and software systems adhere to. The people who
develop the computational system agree on the set of symbols to be
used and agree on some set of definitions which are at least partly
given in natural language and require human intelligence to
interpret.</p>

<p>
In (3) there is a fully computational representation of a set of
concepts, in which the intended meaning of a set of symbols is fully
specified in a computational form, such as a computationally
implemented mathematical logic. People may still have intuitions about
concepts which are not fully captured in the logical language, but
that would be considered a bug or omission to be rectified.</p>

<p>
This classification of an ontology with respect to these three
categories is a framework for understanding the usage of an ontology
rather than a mutually exclusive and rigid set. One might for example
have an ontology strictly implemented in a computational mathematical
logic as a way for people to adjudicate disagreements about
terminology, rather than to govern the behavior of a software
system.</p>

<h2 id="His">2. History</h2>

<p>
The conception of ontology adopted in information science has its
roots in the history of philosophy and may be traced all the way back
to the &ldquo;Tree of Porphyry&rdquo; (with reference to the
3rd-century Greek neoplatonist philosopher Porphyry of Tyre: Franklin
1986). The abstraction of a tree was used to show the relationships
between concepts.</p>

<p>
This abstraction would become a dominant way to depict ontological
distinctions from the biological taxonomy of Linnaeus (1758) to the
present day. Much writing about categories throughout the Middle Ages
consists of commentary (see the entry on
 <a href="../medieval-categories/">medieval categories</a>)
 on Aristotle&rsquo;s work. After the Middle Ages, efforts to catalog
categories were more independent of Aristotle, and the advent of the
scientific method led to interest in defining categories in the
natural sciences, including in Linnaeus&rsquo; writings.</p>

<p>
A less-well known effort of particular note, which predates Linnaeus,
is John Wilkins&rsquo; monumental &ldquo;An Essay Towards a Real
Character and a Philosophical Language&rdquo; of 1685 (Subbiondo
1992). It contains hundreds of pages of a single tree structure of
concepts, each with a natural language definition. While much of the
content, such as the categories for organisms, is only of historical
interest, some innovations, such as a concept of &lsquo;glove&rsquo;
being viewed as a function that denotes clothing for a body part,
point to modern uses of logical functions in ontological definitions.
His work also is notable in that he presents the concepts not only in
a taxonomy but also with a written and spoken language that uses the
categories in a grammar in order to form a more perfect language (Eco
1995), free from ambiguity.</p>

<p>
Before Frege and Peirce (see the entries on
 <a href="../frege/">Frege</a>
 and
 <a href="../peirce-logic/">Peirce&rsquo;s deductive logic</a>)
 laid the foundations for modern mathematical logic, the concepts in
an ontology were defined informally in natural language. Hence, until
the development of modern computers, only humans were capable of
working with an ontology.</p>

<p>
Before the word &lsquo;ontology&rsquo; was adopted in computer science
there was a long history in Artificial Intelligence (AI) of using
formal logic and logic-inspired systems such as Prolog (Clocksin &amp;
Mellish 2003) to define concepts. Collections of logical theories
(Farquhar, Fikes, &amp; Rice 1997) showed how many logical definitions
of general concepts could be documented, but at that point the
concepts were not integrated so that they could be combined and used
together in a single consistent theory.</p>

<p>
Another knowledge representation method used in some information
science ontologies is that of Semantic Networks (Woods 1975; Lehmann
1992; see also the section &ldquo;Representationalist
Approaches&rdquo; in the entry on
 <a href="../computational-linguistics/">computational linguistics</a>).
 They are also called Knowledge Graphs and often implemented in graph
databases (Robinson, Webber, &amp; Eifrem 2015). They consist of a set
of labeled nodes and arcs, arranged as a graph, that state
relationships between entities. This approach was popular in AI in the
1970s and has again become popular in the 2020s.</p>

<p>
Expert systems, prevalent in the 1970s and 1980s, were arguably the
earliest systems that used a computational ontology, although they
were not known by that label at that time. But if we consider a
computational product that consists of a collection of symbols and
some symbolic language that defines the concepts, such systems did
include ontologies. Mycin (Buchanan &amp; Shortliffe 1985), Prospector
(Duda, Gaschnig, &amp; Hart 1979) and many other expert systems were
developed through the 1970s and 1980s.</p>

<p>
Semantic networks and first-order logic were two of the earliest
knowledge representation paradigms in Artificial Intelligence and also
exemplars of the &ldquo;neat&rdquo; vs. &ldquo;scruffy&rdquo; debate
(Crevier 1993; Poirier 2024; Gon&ccedil;alves &amp; Cozman 2021) about
whether knowledge representation required a formal mathematics. Some
practitioners (&ldquo;neats&rdquo;) would advocate that a solid
theoretical basis for reasoning is needed. Others
(&ldquo;scruffies&rdquo;) argue that having a system that &ldquo;just
works&rdquo; is enough, and that a system that accomplishes a task
need not have a theoretical underpinning. This echoes a broader debate
about the validity of <em>empiricism</em> (see the entry on
 <a href="../logical-empiricism/">logical empiricism</a>).
 In the mid-1990s the value of a collection of named concepts as a
resource, somewhat independent of its use, began to be recognized in
computer science.</p>

<p>
Another response to the difficulties in knowledge engineering for
expert systems, which predated the use of &ldquo;ontology&rdquo; as a
term in computer science, is the Cyc project (Lenat &amp; Guha 1989).
Cyc is a commercial endeavor conceived of as a repository of
common-sense knowledge to support Artificial Intelligence
applications. It is the largest effort to date to collect concepts and
definitions in an expressive logic in a computational system. There
was a recognition that an important area of study for ontology was the
&ldquo;upper ontology&rdquo; (see
 <a href="#DomOntUppOnt">section 3</a>)
 &ndash; a set of concepts that are likely to be needed and held in
common among many domains. Some of the first upper ontologies
conceived with that description were the Suggested Upper Merged
Ontology (SUMO: Niles &amp; Pease 2001; Pease 2011), the Descriptive
Ontology for Linguistic and Cognitive Engineering (DOLCE: Gangemi,
Guarino, Masolo, Oltramari, &amp; Schneider 2002) and Basic Formal
Ontology (BFO: Arp, Smith, &amp; Spear 2015; Smith, Grenon, &amp;
Goldberg 2004). Many others followed (see the link to Upper Ontology
in the Other Internet Resources section below). Ontology languages
evolved in parallel with creation of new ontologies. Expert systems
were implemented in Prolog (Clocksin &amp; Mellish 2003) or expert
system &ldquo;shells&rdquo; such as Clips (Riley, Culbert, Savely,
&amp; Lopez 1987) and OPS5 (Brownston, Farrell, Kant, &amp; Martin
1985). Some ontologies are defined in languages that can be used in
computation to answer questions or check their consistency.
Theorem-proving languages for particular mathematical logics were
developed with increasing expressiveness from first-order logic
(Sutcliffe &amp; Suttner 1998) to typed first-order logic (Sutcliffe,
Schulz, Claessen, &amp; Baumgartner 2012), modal (Raths &amp; Otten
2012) and higher-order logic (Benzm&uuml;ller, Rabe, &amp; Sutcliffe
2008), and implemented in automated theorem-proving systems (Sutcliffe
2010). Languages including Knowledge Interchange Format (KIF:
Genesereth &amp; Fikes 1992) and Description Logics such as the
Ontology Web Language (OWL) family of languages (Bechhofer et al.
2004) were developed explicitly to support ontologies.</p>

<h2 id="DomOntUppOnt">3. Domain Ontology and Upper Ontology</h2>

<p>
An <em>upper ontology</em> is a collection of concepts that are not
specific to any application domain. The determination of whether a
concept belongs in an upper ontology or not is not an objective
decision, except relative to other terms in the same ontology. Some
upper ontologies aim to be minimal, containing only a small number of
the most general concepts, and others include larger collections from
the most general to the more specific. Many domain ontologies are
created as extensions of upper ontologies. An upper ontology starts
with a category of all things and then elaborates, adding categories
(and sometimes, definitions) for physical and abstract things,
relations and functions etc. But the boundary of where upper ontology
becomes domain ontology is arbitrary. A domain ontology would not have
a decomposition of categories starting from the class of all things,
but many domain ontologies that do not extend an upper ontology still
will require a few very general categories, such as the notion of a
physical object or a process.</p>

<p>
What counts as a domain is an issue of perspective, and is relative to
the practitioner&rsquo;s objectives. A particular application for
preventing negative drug interactions (Zhao, Yin, Zhang, Zhang, &amp;
Chen 2023) might have few concepts relating to drug chemistry, while
an application to support drug synthesis might have no concept of a
drug interaction. However, a more general ontology about drugs might
have both those concepts and more, but possibly a less extensive
catalog of drugs.</p>

<p>
There are vastly more domain ontologies in existence than upper
ontologies (see the links to ontologies in the Other Internet
Resources section below).</p>

<h2 id="OntCom">4. Ontological Commitment</h2>

<p>
What should an ontology commit to and what should it leave
unspecified? If ontological commitment (see the entry on
 <a href="../ontological-commitment/">ontological commitment</a>)
 is something to be minimized, then one might only commit to
categories of Entity and Relation, with no other terms in the
ontology. With such a minimal ontology of only two concepts there are
virtually no commitments, but then also little utility is derived from
such a theory in describing the world and assisting in creating a set
of concepts and definitions that can be held in common by different
entities. There is a clear tension between not wanting to make
commitments that would limit the application of an ontology to only
some narrow contexts, and with wanting to have as large a set of
commitments as possible in order to facilitate common
understandings.</p>

<p>
But does creating and defining a concept in an ontology necessarily
create a commitment? It depends on how such a definition is made.
Let&rsquo;s examine two cases consisting of a strong commitment and a
weak commitment. If one states \(\exists x \: \text{unicorn}(x)\) this
has created what is likely a strong and unwise commitment. However if
one states \(\forall x \: (\text{unicorn}(x) \implies \exists y \:
(\text{horn}(y) \land \text{part}(y,x)))\) a different, weak sort of
commitment has been made that is likely not problematic. The latter
formula only commits to the fact that <em>if</em> there were a unicorn
in existence, it would have a horn. A commitment about how to define
the characteristics of an imaginary entity, which isn&rsquo;t
necessarily presumed to exist, is quite a weak commitment. The
practical issue of ontological commitment in the context of a
computational ontology (as well as in philosophy more generally)
hinges on whether a theory is not false &ndash; that is, not incompatible
with modeling the world in useful software applications. One need not
have an ontology that is capable of modeling all knowledge in the
world for it to be practically useful. The question at hand then
becomes the degree to which useful models of the world are excluded by
a particular ontology, and the degree to which the ontology supports
definition of various models. One could be concerned only with
commitments that may rule out other reasonable commitments. An
ontology that makes obviously poor modeling choices, such as requiring
the Earth to be flat, makes an error of <em>commission</em> that
excludes many of its possible uses. An ontology that has very few
concepts or categories, or few definitions, has limited utility for
modeling. It is an error of <em>omission</em> to avoid making
commitments to concepts that are needed in modeling the world, such as
omitting spatial or temporal relationships, or a way to model time or
action. One can avoid being wrong by saying nothing at all. The
challenge is to say as many things about the world as possible while
not saying things that are false.</p>

<p>
An illustration of choices in commitment (see the entry on
 <a href="../identity-time/">identity over time</a>)
 is that of Endurantism vs. Perdurantism: do objects have temporal
parts and how are those parts related (Haslanger &amp; Kurtz 2006)?
But must one choose between alternatives for how we define a single
notion of parthood or identity (see the entry
 <a href="../identity-relative/">relative identity</a>)?
 One can have properties of an object that change while identity is
maintained. A formal ontology creates not only a computationally
useful product but also a laboratory for exploring how we see the
world. One might suppose a conflict in views or theories, but absent a
formal proof in the logic employed by a particular ontology, worries
about a particular conflict in modeling choices are at best just
unverified hypotheses. On the other hand if there is a proof of a
logical contradiction, then there is a mathematical basis for
asserting that a conflict in modeling choices actually exists, and
working towards a harmonization of those choices. One might informally
assume, for example, that identity must assume identicality (see the
entry on
 <a href="../identity-indiscernible/">identity of indiscernibles</a>)
 (\(\forall F(Fx \leftrightarrow Fy \implies x=y)\) for all properties
\(F\)), but unless that ontological commitment is made axiomatically,
in code that an automated theorem-prover or other inference system can
execute, it is only a potential bad choice that has been avoided in
practice.</p>

<p>
An ontology that commits to every entity having a place in space and
time has excluded timeless entities such as numbers. An ontology that
commits to a notion of physical things (which have a place in space
and time) and abstract things (which do not have a position in space
or time) has merely created modeling facilities that may be employed,
rather than a commitment that excludes an important aspect or view of
the world.</p>

<p>
A goal to minimize ontological commitments is related to a similar
desire for an ontology that contains only a minimal set of primitives.
How many concepts does one need? Is there a limit to the number of
concepts that exist? If one takes human language as a guide, it would
seem not: new words that express new concepts are created continually.
The words &ldquo;smartphone&rdquo; and &ldquo;selfie&rdquo; were
coined to express concepts that did not previously exist. While one
could use existing words to express a similar thought, such as in
&ldquo;I took my &ndash; small computer that has a touchscreen and also
functions as a phone &ndash; out of my pocket&rdquo;, this would be a very
inefficient form of discourse, which would still leave out the many
connotations of the modern word of &ldquo;smartphone&rdquo;. One could
conceivably define every concept during the course of communication,
and avoid committing <em>a priori</em> to many words with associated
definitions. Similarly, one might be able to build up a set of terms
in an ontology from a small set of primitives, but it would be more
efficient to archive each new term and definition as it appears to be
needed.</p>

<p>
One argument for a small set of ontological primitives is that it is
easier to learn a smaller set than a larger one. One might look to
modern software development for lessons learned in this case. While
reusable software libraries were non-existent at the dawn of
computing, now large libraries form an essential part of the modern
software development process. It is inefficient to reinvent common
abstractions. There are enough common abstractions that modern
programming languages have tens of thousands of functions available
for reuse. No programmer need learn all of them, and the ones that are
unused in any given project cause no harm since unused library
functions are not included by a compiler into a runnable program.
Reusable components speed up development and increase compatibility
among systems. An additional analogy is that an English dictionary
that fits on a single page has vastly less utility for standardizing
the meaning of words than a comprehensive collection such as
Webster&rsquo;s (Merriam-Webster 2003) or the OED (Oxford English
Dictionary 2020).</p>

<h2 id="OntTheEle">5. Ontology by Theory Elements</h2>

<p>
Ontologies that concern themselves with top-level or general
categories (which are often called &ldquo;upper ontologies&rdquo;), as
opposed to concepts specific to a domain (see
 <a href="#DomOntUppOnt">section 3</a>),
 have broadly similar inventories. One needs to have physical entities
and abstract ones, substances and objects, processes, attributes,
numbers of different sorts, and define these notions to organize the
conceptual space and provide as much opportunity for abstraction as
possible. The Tree of Porphyry (see section 2) also sets an example of
providing <em>differentia</em> &ndash; an explanation of how each concept
differs from the others. An undifferentiated concept is just a synonym
of some others in an ontology. The first challenge for any ontologist
is to learn how to create these descriptions, and reject any proposed
concept for which no set of precise differentia can be given.</p>

<p>
All the prominent upper ontologies have at least some version of the
following concepts:</p>

<ul>

<li>

<p>
Thing/Entity &ndash; The class of all things.</p></li>

<li>

<p>
Physical &ndash; The class of all things that have a position in space and
time.</p></li>

<li>

<p>
Process/Action/Event &ndash; The class of things that
<em>happen</em>.</p></li>

<li>

<p>
Object/PhysicalThing &ndash; The class of things that <em>are</em>. Tangible
entities.</p></li>

<li>

<p>
Stuff/Mass &ndash; The class of things that may be subdivided and retain
their identity (see the entry on
 <a href="../metaphysics-massexpress/">mass expressions</a>).</p></li>
 
<li>

<p>
PhysicalObject/CorpuscularObject &ndash; The class of things that may not be
subdivided and retain their identity.</p></li>

<li>

<p>
Abstract/NonTangibleThing &ndash; The class of things that do not have a
position in space and time.</p></li>

<li>

<p>
Relation &ndash; The class of relationships among entities.</p></li>

<li>

<p>
Property/Attribute.</p></li>

<li>

<p>
Function &ndash; The class of functional relationships: for every one
element or unique combination of elements of the relation there is a
unique other element.</p></li>
</ul>

<p>
Less common are catalogues of relationships. A few types of
relationships such as the class of transitive relations are built into
the Ontology Web Language (OWL) used in the semantic web community,
rather than being defined in the ontology language, since the OWL
language is not sufficient to express that property. Other common
classes of relations are symmetric, reflexive, anti-symmetric etc.</p>

<p>
Relationships found in common in some ontologies are:</p>

<ul>

<li>

<p>
physical part/&lsquo;has a&rsquo; &mdash; one physical entity has
another as a physical part, such as a door having a doorknob or a car
having a wheel (see the entry on
 <a href="../mereology/">mereology</a>).</p></li>
 
<li>

<p>
temporal part &mdash; an event or process has another event or process
that is a part of the parent process (see the entry on
 <a href="../temporal-parts/">temporal parts</a>).</p></li>
 
<li>

<p>
physical location &mdash; something is located at a region or other
object (see the entry on
 <a href="../location-mereology/">location and mereology</a>)</p></li>
 
<li>

<p>
subclass/&lsquo;is a&rsquo; &mdash; one class of things is more
specific than another class of things</p></li>

<li>

<p>
instance &mdash; an individual entity is a member of a class</p></li>

<li>

<p>
case roles (Fillmore 1968; Gisborne &amp; Donaldson 2019) such as
agent, patient, instrument etc.</p></li>

<li>

<p>
temporal relationships among events (as in Allen 1984): including
before, meets, during, starts etc.</p></li>
</ul>

<h2 id="OntLogLan">6. Ontology by Logical Language</h2>

<p>
While most things called ontologies are stated in some formal
language, some ontologies do not employ a language with a formal
(mathematical) semantics. A ontology that is essentially a glossary
may collect words and natural language definitions. Humans must read
such a product, resolve ambiguities in the language and reason about
how they may apply to a specific problem. While a spelling or grammar
checker can help with construction of such a document, machine or
mathematical processes cannot be used to determine whether definitions
are in conflict with one another. These shortcomings of natural
language ontologies motivated the use of formal languages in the
construction of ontologies.</p>

<p>
The simplest formal languages used in ontologies are taxonomies and
graphical languages. In a taxonomy, the only error that can be
identified with automation is the presence of a cycle, where \(A\) is
a parent (possibly transitively) of \(B\) and vice versa. The formal
semantics for a taxonomy is that child nodes denote more specific
concepts than their parent \(\forall x : \text{child-class}(x)
\implies \text{parent-class}(x)\).</p>

<p>
The simplest graph language is one comprised of named nodes and arcs.
Graphs do not have any inherent formal semantics other than that some
relations hold. It may be as simple as that a graph G consists of
vertices and edges \(G = (V,E)\), although typically there will be
some reusable set of edge labels (relations) \(R\) and there should be
no &ldquo;orphan&rdquo; nodes with no relationships &ndash; \(G = (V,E,R)\)
and:</p>

 \[\forall x \in V : \exists r,y: x r y \land r \in R \land y \in
V.\]

<p>
 Some meta-language may then be used to express a formal semantics
for particular node and arc symbols, such as that a
&ldquo;PhysicalPart&rdquo; arc is transitive. But many knowledge
graphs and semantic networks do not have a formal specification, just
an implementation in a software system. Note that an implementation in
a software program is not a formal semantics. A semantics is a
mathematical construct that exists outside any implementation. A
program may enforce restrictions that are entailed by a mathematics,
and several different programs might use different procedures to
implement a single given body of semantics.</p>

<p>
Description logic is a subset of first-order logic. It was created in
order to provide a logical language with decidable inference, as in
propositional logic, but with greater expressivity. First-order logic
is only semi-decidable &ndash; while contradictions can be found in finite
time, there is no guarantee that a theorem-prover will determine that
no contradiction exists in finite time. The notion of finding
contradictions is of critical importance since the most
computationally efficient automated theorem-proving systems work by
employing proof by refutation.</p>

<p>
However, some variants of OWL go beyond description logic while also
losing strict decidability but also not supporting all of standard
first-order logic (Baader et al. 2007). Considerable progress has also
been made in first-order automated theorem-proving to avoid the worst
case of undecidability (Geoff Sutcliffe &amp; Desharnais 2024).
Practitioners therefore differ in opinions about the choice of a
particular logic to solve classes of problems.</p>

<p>
Description logics such as the OWL family (Baader, Horrocks, &amp;
Sattler 2005) employ as part of the logic keywords that have
definitions in a meta-language, since description logic is
insufficient to describe their semantics. The OWL language must employ
first-order logic in its language definition to state the semantics of
some keywords that are part of the OWL language. In addition, OWL has
the associated SWRL language (Horrocks, Patel-Schneider, Bechhofer,
&amp; Tsarkov 2005), in order to augment the description logic with a
language capable of expressing rules. One implementation that
preserves the semantics of SWRL uses a first-order-logic
theorem-prover (Tsarkov, Riazanov, Bechhofer, &amp; Horrocks 2004).
Other implementations use the Drools rule engine (see the section
Other Internet Resources) which is a production system rather than a
logic (Shapiro 2001) and therefore loses some of the semantics of
SWRL.</p>

<p>
Relatively few ontologies are defined in more expressive languages
such as first-order logic or beyond (notable exceptions are SUMO
(Niles &amp; Pease 2001; Pease 2011) and Cyc (Lenat 1995)). The more
expressive the logic used, the more things that can be said about
concepts, and therefore the more machine reasoning can be applied to
answer questions with the ontology, or verify its consistency. For
example, in a propositional logic one might have the propositional
terms \(S =\) &ldquo;Socrates is a man&rdquo; and \(M =\)
&ldquo;Socrates is mortal&rdquo; and state \(S \implies M\). One would
have to state that implication for all humans (and better yet, all
organisms). In predicate calculus, one can state a more general rule
just once:</p>

\[\forall x \: \text{Organism}(x) \implies
\text{Mortal}(x)\]

<p>along with</p>

 \[\forall x \: \text{Man}(x) \implies
\text{Organism}(x).\] 

<p>
Going beyond first-order logic one might want to
state the axiom of transitivity just once and have it hold for all
instances of the type &ldquo;TransitiveRelation&rdquo;, rather than
repeating that axiom for every such relation. The more expressive the
logical language, the more efficient it is at encoding knowledge and
creating generalizations, so any metrics about the size of an ontology
must also take into account the logical expressiveness of the formulas
counted.</p>

<p>
Another issue in ontology languages and the reasoners that can process
them is whether numbers and arithmetic are supported in the logical
language. Measures and metric times are part of the world and yet very
few ontologies employ a logic that can be paired with a reasoning
system capable of reasoning with numbers. SNARK (Waldinger et al.
2004) is one such reasoner, which has its own language. TPTP Typed
First-Order Form with Arithmetic (TFA: Sutcliffe, Schulz, Claessen,
&amp; Baumgartner 2012) is another language, implemented by a few
theorem-provers including iProver (Korovin 2008) and Vampire
(Kov&aacute;cs &amp; Voronkov 2013).</p>

<p>
Ontologies that are implemented in less expressive logical languages
will leave more of their definitions to the intuitions and
interpretations of humans. Such ontologies may be used for
standardization of terminology among humans. Humans are then
responsible for realization of those concepts in software. People must
ensure that programs use those concepts correctly and embody their
intended meaning. If the author of the ontology is also the author of
the software, the realization is likely to be as intended. But there
is a risk that others attempting to use the ontology to govern the
behavior of their software may have a different understanding. This
issue may become more prominent if the size of the system grows or if
its use continues over a long period. Maintaining the same intuitions
about the meaning of concepts will be more challenging without
automation to ensure that interpretations remain consistent.</p>

<p>
It is easy to conflate our own knowledge or interpretation with
someone else&rsquo;s. A good example of this is Newton1990, which
shows how difficult it is for people to recognize a tune just by its
rhythm, and how correspondingly challenging it is for a person
providing a rhythm to realize that they haven&rsquo;t provided enough
information. An ontologist may believe that a label or natural
language description is enough to constrain the interpretation of a
symbol, but without detailed formal specification, it is all too easy
for a different person to have a different interpretation. The more
detailed and formal the specification, the more likely that different
and conflicting interpretations can be avoided.</p>

<p>
For those systems that do have an implementation of the ontology based
on a taxonomy or graph language, developers may implement constraints
on concepts in procedural code, such as the popular Java or Python
programming languages, or may choose some auxilliary language that is
more declarative, like Prolog, SWRL or Clips.</p>

<p>
One advantage to using a less expressive logical language is greater
computational efficiency. Description logics are decidable, and so
queries are guaranteed to terminate. First-order logic is only
semi-decidable and therefore queries may not terminate when there is
not a proof showing how to satisfy the query. Higher-order logics have
even fewer guarantees of performance. However, considerable progress
(Sutcliffe &amp; Desharnais 2023) has been made in avoiding
theoretical worst-case scenarios for inference, and improving
performance even on large theories (Pease, Sutcliffe, Siegel, &amp;
Trac 2010). Additionally, one can easily remove expressive formulas
from an ontology for a given application in order to meet specific
performance constraints, while retaining expressive formulas as a set
of definition of the terms to align human understanding.</p>

<h2 id="AssOnt">7. Assessment of an Ontology</h2>

<p>
Objective assessments of ontologies performed by disinterested third
parties are rare, but Mascardi, Cordi, &amp; Rosso 2007 is one,
although it was done for upper ontologies rather than ontologies in
general. Some objective measures include:</p>

<ul>

<li>

<p>
whether a mathematical logic is used, and if so, which one. The choice
of logical language will dictate what aspects of the definition of
each concept are formally expressible, and what content has to be
provided instead as an informal natural language comment.</p></li>

<li>

<p>
whether the logic has been implemented as a computational system, such
as with an automated theorem-prover or inference engine. There are
many logics with a formal semantics that have not been implemented for
computation. If an ontology is defined in an unimplemented logic (and
of non-trivial size) it will not be possible to validate that the
ontology is free of contradictions, or to pose queries to it without
using a human to calculate the result.</p></li>

<li>

<p>
which automated reasoner (if any) was used to validate the formulas
and what are the limitations of the validation. A description-logic
reasoner (such as FaCT++ (Tsarkov &amp; Horrocks 2006) or Pellet
(Sirin, Parsia, Grau, Kalyanpur, &amp; Katz 2007)) can guarantee that
there are no type conflicts in an OWL ontology. A first-order reasoner
can test an ontology in first-order logic in which more things can be
stated than a description logic, but cannot guarantee to find all
conflicts, due to first-order logic being semi-decidable. A
first-order model-finder guarantees consistency if it finds a model,
but the limitations of model-finders mean that it is only practical to
attempt to analyze relatively small collections of formulas. A
higher-order logic theorem-prover can attempt to validate yet more
kinds of statements that are not expressible in less expressive
logics, but performance of such systems is such that they are even
less likely to find all contradictions that may exist.</p></li>

<li>

<p>
the number of concepts, which may be broken down further into
instances, classes and relationships</p></li>

<li>

<p>
the number of formulas, and of which type, whether</p>

<ul>

<li>

<p>
ground or not (the formula does not contain any variables)</p></li>

<li>

<p>
number of implications or disjunctions</p></li>

<li>

<p>
number of formulas containing a relation of a given arity (graphs and
description logics are limited to binary relations)</p></li>

<li>

<p>
number of formulas requiring a given level of logical expressiveness,
such as:</p>

<ul>

<li>

<p>
propositional (no variables)</p></li>

<li>

<p>
description logic (classification/type reasoning)</p></li>

<li>

<p>
first-order logic (quantification over terms only)</p></li>

<li>

<p>
modal logic (and which particular modal-logic operators and supporting
axioms)</p></li>

<li>

<p>
higher-order logic (quantification over formulas)</p></li>
</ul></li>

<li>

<p>
number of formulas including numbers and/or arithmetic
expressions</p></li>
</ul></li>
</ul>

<p>
Some ontologies may have lexical mappings for their terms such as to
WordNet (Fellbaum 1998), in one or more human languages, so there
could be a measurement of how many lexical mappings exist, and in how
many languages.</p>

<p>
For each of these measures, all others being equal, we may say that
more is better.</p>

<p>
Assessments may be also made as to non-technical characteristics, such
as measurements of popularity, tool support, standards conformance, or
licensing. Claims have often been made of the need to conform to some
interpretation of an overarching philosophical principle, such as
Realism (see the entry
 <a href="../realism/">realism</a>),
 Post-modernism and Relativism (see the entry on
 <a href="../relativism/">relativism</a>),
 or Positivism (see the entries on
 <a href="../logical-empiricism/">logical empiricism</a>
 and
 <a href="../comte/">Auguste Comte</a>).</p>
 
<h2 id="OntLarLanMod">8. Ontology and Large Language Models</h2>

<p>
Large Language Models (Jurafsky &amp; Martin 2000) are a model of
language but not of the world (Bender, Gebru, McMillan-Major, &amp;
Shmitchell 2021). When LLMs generate text that is clearly at odds with
what humans know about the world it has been called (rather
anthropomorphically) &ldquo;hallucination&rdquo;. One method that has
been proposed to address this issue is to combine LLMs and logical
reasoning in a <em>neuro-symbolic</em> approach (Hitzler &amp; Sarker
2021). LLMs may be trained on symbolically-expressed knowledge
(Chattopadhyay, Dandekar, &amp; Roy 2025), and symbolic knowledge may
be used in prompts (Lewis et al. 2020). LLMs may also be used to align
terminological ontologies (Hertling &amp; Paulheim 2023).</p>

<p>
Most work in this area has been with ontologies expressed as knowledge
graphs. This potentially encourages LLMs to conform to facts such as
taxonomic relationships, measures such as the cost or number of
something, or expressions of simple relationships such as physical
parthood. Using ontologies defined in expressive logics would allow
LLMs to conform to the more complex relationships inherent in the
world, but it remains to be seen how this can be implemented.</p>

<h2 id="AppOnt">9. Applications of Ontologies</h2>

<p>
An ontology can be used solely as a tool for ensuring common
understanding of concepts, or it can be used for reasoning (or both).
Some surveys of ontology use include Qaswar et al. 2022; Poli, Healy,
&amp; Kameas 2010; Uschold &amp; Jasper 1999. Many ontologies have
been developed as an independent product that forms a standard for
vocabulary, rather than as part of a running computational system.
Many ontologies are used in application only by their authors, to
illustrate their value, rather than being motivated by solving a
particular application need.</p>

<p>
Some uses of ontologies in applications are for search (Suomela &amp;
Kek&auml;l&auml;inen 2005), natural language processing (Bateman,
Hois, Ross, &amp; Tenbrink 2010; Behr, V&ouml;lkenrath, &amp; Kockmann
2023), Internet of Things applications (Qaswar et al. 2022) and
engineering (Zheng et al. 2021). Biology is one application area that
has seen considerable work on ontology development (Stevens &amp; Lord
2009; Kramer &amp; Bei&szlig;barth 2017). Implementations of such
ontologies are often in the form of databases, and the positioning of
such products as ontologies stems from the perspective of its authors
rather than features of the product itself.</p>

<h2 id="FutDir">10. Future Directions</h2>

<p>
There is wide scope for further work in ontology, especially in
developing ever larger and more formal theories for aspects of the
world. Research at the most general levels of ontology in Computer
Science is already starting to benefit from collaboration with what
has been termed <em>computational metaphysics</em> (Kirchner,
Benzm&uuml;ller, &amp; Zalta 2019; Fitelson &amp; Zalta
2007). Research on formally specifying aspects of the physical world,
such as Casati &amp; Varzi 1999 and Casati &amp; Varzi 1994,
illustrates comprehensive formal axiomatizations that could be
implemented computationally.</p>

<p>
One example of fundamental work on formalizing ontology of an aspect
of the physical world, for which there does not yet appear to be a
computational theory, is a theory of substances or substance-like
actions that define what properties are true of parts of stuff that
are true of the whole, at a given level of decomposition. For example,
when does a temporal slice of walking cease to be walking and start
being just a stepping or a motion? When does a part of a cake stop
being a cake and start to be a sugar molecule? What relationships or
concepts would allow for stating these limits of granularity and
determine how properties of the whole are held by its parts? To what
degree are the granularities of a class true of its subclasses?</p>

<p>
The notion of competency questions points to a direction for
evaluating the computational capabilities of ontologies
(Wi&#347;niewski, Potoniec, &#321;awrynowicz, &amp; Keet 2019;
Bezerra, Freitas, &amp; Santana da Silva 2013). This area of study
attempts to collect questions that may be asked of ontologies to
evaluate their degree of knowledge. The challenge is to develop a
corpus containing a wide range of questions, and determine how such a
corpus can be tested without having an ontology simply be written for
the test. One large project that took this approach, at least to an
extent, was Cohen et al. 1998.</p>

<p>
While description logics are the most widely used family of languages
for ontologies, future work may increasingly use more expressive
logics, and the OWL family of logics has grown to include
incrementally more expressive languages. The automated theorem-proving
community has been standardizing more expressive logics and
implementing them in automated theorem-provers (Sutcliffe 2024). It is
possible that increasing numbers of projects in ontology may take
advantage of that work.</p>
</div>

<div id="bibliography">

<h2 id="Bib">Bibliography</h2>

<ul class="hanging">

<li>Allen, James, 1984, &ldquo;Towards a General Theory of Action and
Time,&rdquo; <em>Artificial Intelligence</em>, 23: 123&ndash;154.</li>

<li>Arp, Robert, Barry Smith, and Andrew D. Spear, 2015, <em>Building
Ontologies with Basic Formal Ontology</em>, Cambridge, MA: MIT
Press.</li>

<li>Baader, Franz, Diego Calvanese, Deborah L. McGuinness, Daniele
Nardi, and Peter F. Patel-Schneider (eds.), 2007, <em>The Description
Logic Handbook</em>, 2nd edition, Cambridge: Cambridge University
Press.</li>

<li>Baader, Franz, Ian Horrocks, and Ulrike Sattler, 2005,
&ldquo;Description Logics as Ontology Languages for the Semantic
Web,&rdquo; in Dieter Hutter &amp; Werner Stephan (eds.),
<em>Mechanizing Mathematical Reasoning: Essays in Honor of J&ouml;rg
H. Siekmann on the Occasion of his 60th Birthday</em>, pp.
228&ndash;248, Berlin, Heidelberg: Springer.
doi:10.1007/978-3-540-32254-2_14</li>

<li>Bateman, John A., Joana Hois, Robert Ross, and Thora Tenbrink,
2010, &ldquo;A Linguistic Ontology of Space for Natural Language
Processing,&rdquo; <em>Artificial Intelligence</em>, 174(14):
1027&ndash;1071.  doi:10.1016/j.artint.2010.05.008</li>

<li>Bechhofer, Sean, Frank van Harmelen, Jim Hendler, Ian Horrocks,
Deborah McGuinness, Peter Patel-Schneijder, and Lynn Andrea Stein,
2004, <em>OWL Web Ontology Language Reference</em> (W3C
Recommendation), Mike Dean &amp; Guus Schreijber (eds.), World Wide Web
Consortium (W3C).</li>

<li>Behr, Alexander S., Marc V&ouml;lkenrath, and Norbert Kockmann,
2023, &ldquo;Ontology Extension with NLP-Based Concept Extraction for
Domain Experts in Catalytic Sciences,&rdquo; <em>Knowledge and Information
Systems</em>, 65(12): 5503&ndash;5522.
doi:10.1007/s10115-023-01919-1</li>

<li>Bender, Emily M., Timnit Gebru, Angelina McMillan-Major, and
Shmargaret Shmitchell, 2021, &ldquo;On the Dangers of Stochastic
Parrots: Can Language Models Be Too Big?&rdquo; in <em>Proceedings of
the 2021 ACM Conference on Fairness, Accountability, and
Transparency</em>, pp. 610&ndash;623, New York: Association for
Computing Machinery. doi:10.1145/3442188.3445922</li>

<li>Benzm&uuml;ller, Christoph, Florian Rabe, and Geoff Sutcliffe,
2008, &ldquo;THF0 &ndash; the Core of the TPTP Language for
Higher-Order Logic,&rdquo; in Alessandro Armando, Peter Baumgartner,
&amp; Gilles Dowek (eds.), <em>Automated Reasoning</em>, pp.
491&ndash;506, Berlin, Heidelberg: Springer.</li>

<li>Bezerra, Camila, Fred Freitas, and Filipe Santana da Silva, 2013,
&ldquo;Evaluating Ontologies with Competency Questions,&rdquo; in
<em>2013 IEEE/WIC/ACM International Joint Conferences on Web
Intelligence (WI) and Intelligent Agent Technologies (IAT)</em>, pp.
284&ndash;285. doi:10.1109/WI-IAT.2013.199</li>

<li>Brownston, Lee, Robert Farrell, Elaine Kant, and Nancy Martin,
1985, <em>Programming Expert Systems in OPS5: An Introduction to
Rule-Based Programming</em>, Reading, MA: Addison-Wesley.</li>

<li>Buchanan, Bruce G., and Edward H. Shortliffe (eds.), 1985,
<em>Rule-Based Expert Systems: The MYCIN Experiments of the Stanford
Heuristic Programming Project</em>, Reading, MA: Addison-Wesley.</li>

<li>Casati, Roberto, and Achille C. Varzi, 1994, <em>Holes and Other
Superficialities</em>, Cambridge, MA: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 1999, <em>Parts and Places: The Structures
of Spatial Representation</em>, Cambridge, MA: MIT Press.</li>

<li>Chattopadhyay, Aniruddha, Raj Dandekar, and Kaushik Roy, 2025,
&ldquo;Learning and Reasoning with Model-Grounded Symbolic Artificial
Intelligence Systems,&rdquo; in Leilani H. Gilpin, Eleonora
Giunchiglia, Pascal Hitzler, &amp; Emile van Krieken (eds.),
<em>Proceedings of the 19th International Conference on Neurosymbolic
Learning and Reasoning</em>, Vol. 284, pp. 957&ndash;976, PMLR.
 [<a href="https://proceedings.mlr.press/v284/chattopadhyay25a.html" target="other">Chattopadhyay et al. 2025 available online</a>]</li>
 
<li>Clocksin, William F., and Christopher S. Mellish, 2003,
<em>Programming in Prolog</em>, 5th edition, Berlin, Heidelberg:
Springer. doi:10.1007/978-3-642-55481-0</li>

<li>Cohen, Paul, Robert Schrag, Eric Jones, Adam Pease, Albert Lin,
Barbara Starr, David Gunning, Murray Burke, 1998, &ldquo;The DARPA
High Performance Knowledge Bases Project,&rdquo; <em>AI Magazine</em>,
19(4).</li>

<li>Crevier, Daniel, 1993, <em>AI: The Tumultuous History of the
Search for Artificial Intelligence</em>, New York: Basic Books,
Inc.</li>

<li>Dallwitz, M. J., 1980, &ldquo;A General System for Coding
Taxonomic Descriptions,&rdquo; <em>Taxon</em>, 29(1):
41&ndash;46.</li>

<li>Duda, R. O., J. Gaschnig, and P. E. Hart, 1979, &ldquo;Model
Design in the PROSPECTOR Consultant Program for Mineral
Exploration,&rdquo; in D. Michie (ed.), <em>Expert Systems in the
Microelectronic Age</em>, pp. 153&ndash;167, Edinburgh: Edinburgh
University Press.</li>

<li>Eco, Umberto, 1995, <em>The Search for the Perfect Language
[Ricerca della lingua perfetta nella cultura europea]</em>, Oxford:
Blackwell.</li>

<li>Enderton, Herbert Bruce, 1972, <em>A Mathematical Introduction to
Logic</em>, New York: Academic Press.</li>

<li>Farquhar, Adam, Richard Fikes, and James Rice, 1997, &ldquo;The
Ontolingua Server: A Tool for Collaborative Ontology
Construction,&rdquo; <em>International Journal of Human-Computer
Studies</em>, 46(6): 707&ndash;727.
doi:10.1006/ijhc.1996.0121</li>

<li>Fellbaum, Christiane (ed.), 1998, <em>WordNet: An Electronic
Lexical Database</em>, Cambridge, MA: MIT Press.</li>

<li>Fillmore, Charles J., 1968, &ldquo;The Case for Case,&rdquo; in
Emmon Bach &amp; Robert T. Harms (eds.), <em>Universals in Linguistic
Theory</em>, pp. 0&ndash;88, New York: Holt, Rinehart, &amp;
Winston.</li>

<li>Fitelson, Branden, and Edward N. Zalta, 2007, &ldquo;Steps Toward
a Computational Metaphysics,&rdquo; <em>Journal of Philosophical
Logic</em>, 36(2): 227&ndash;247. doi:10.1007/s10992-006-9038-7</li>

<li>Franklin, James, 1986, &ldquo;Aristotle on Species
Variation,&rdquo; <em>Philosophy</em>, 61(236): 245&ndash;252.</li>

<li>Gangemi, Aldo, Nicola Guarino, Claudio Masolo, Alessandro
Oltramari, and Luc Schneider, 2002, &ldquo;Sweetening Ontologies with
DOLCE,&rdquo; in Asunci&oacute;n G&oacute;mez-P&eacute;rez &amp; V.
Richard Benjamins (eds.), <em>Knowledge Engineering and Knowledge
Management: Ontologies and the Semantic Web: 13th International
Conference, EKAW 2002 Sig&uuml;enza, Spain, October 1&ndash;4, 2002
Proceedings</em>, pp. 166&ndash;181, Berlin, Heidelberg: Springer.
doi:10.1007/3-540-45810-7_18</li>

<li>Genesereth, M. R., and R. E. Fikes, 1992, <em>Knowledge
Interchange Format, Version 3.0 Reference Manual</em> (No.
Logic-92-1), Stanford, CA: Stanford University. 
 [<a href="http://logic.stanford.edu/publications/genesereth/kif.pdf" target="other">Genensereth &amp; Fikes 1992 available online</a>]</li>
 
<li>Gisborne, Nikolas, and James Donaldson, 2019, &ldquo;Thematic
Roles and Events,&rdquo; in Robert Truswell (ed.), <em>The Oxford
Handbook of Event Structure</em>, pp. 236&ndash;264, Oxford: Oxford
University Press.</li>

<li>Gon&ccedil;alves, Bernardo, and Fabio Gagliardi Cozman, 2021,
&ldquo;The Future of AI: Neat or Scruffy?&rdquo; in <em>Intelligent
Systems: 10th Brazilian Conference, BRACIS 2021, Virtual Event,
November 29 &ndash; December 3, 2021, Proceedings, Part II</em>, pp.
177&ndash;192, Berlin, Heidelberg: Springer.
doi:10.1007/978-3-030-91699-2_13</li>

<li>Gruber, Thomas R., 1993, &ldquo;A Translation Approach to Portable
Ontology Specifications,&rdquo; <em>Knowledge Acquisition</em>, 5(2):
199&ndash;220. doi:10.1006/knac.1993.1008</li>

<li>Haslanger, Sally Anne, and Roxanne Marie Kurtz (eds.), 2006,
<em>Persistence: Contemporary Readings</em>, Cambridge, MA: MIT
Press.</li>

<li>Hertling, Sven, and Heiko Paulheim, 2023, &ldquo;OLaLa: Ontology
Matching with Large Language Models,&rdquo; in <em>Proceedings of the
12th Knowledge Capture Conference 2023</em>, pp. 131&ndash;139, New
York, NY: Association for Computing Machinery.
doi:10.1145/3587259.3627571</li>

<li>Hitzler, Pascal, and Md. Kamruzzaman Sarker, 2021,
&ldquo;Neuro-Symbolic Artificial Intelligence: The State of the
Art,&rdquo; in <em>Neuro-Symbolic Artificial Intelligence</em>,
Thousand Oaks, CA: Sage. 
 [<a href="https://www.gbv.de/dms/tib-ub-hannover/1786636506.pdf" target="other">Hitzler &amp; Sarker 2021 available online</a>]</li>
 
<li>Horrocks, Ian, Peter F. Patel-Schneider, Sean Bechhofer, and
Dmitry Tsarkov, 2005, &ldquo;OWL Rules: A Proposal and Prototype
Implementation,&rdquo; <em>Journal of Web Semantics</em>, 3(1):
23&ndash;40. doi:10.1016/j.websem.2005.05.003</li>

<li>Jurafsky, Daniel, and James H. Martin, 2000, <em>Speech and
Language Processing: An Introduction to Natural Language Processing,
Computational Linguistics, and Speech Recognition</em>, 1st edition,
Upper Saddle River, PA: Prentice Hall.</li>

<li>Kaliyar, Rohit Kumar, 2015, &ldquo;Graph Databases: A
Survey,&rdquo; in Abhishek Swaroop &amp; Vishnu Sharma (eds.),
<em>International Conference on Computing, Communication and
Automation (ICCCA-2015)</em>, pp. 785&ndash;790, Curran Assoc.
doi:10.1109/CCAA.2015.7148480</li>

<li>Kirchner, Daniel, Christoph Benzm&uuml;ller, and Edward N. Zalta,
2019, &ldquo;Computer Science and Metaphysics: A
Cross-Fertilization,&rdquo; <em>Open Philosophy</em>, 2(1):
230&ndash;251. doi:doi:10.1515/opphil-2019-0015</li>

<li>Korovin, Konstantin, 2008, &ldquo;iProver &ndash; an
Instantiation-Based Theorem Prover for First-Order Logic (System
Description),&rdquo; in Alessandro Armando, Peter Baumgartner, &amp;
Gilles Dowek (eds.), <em>Automated Reasoning</em>, pp. 292&ndash;298,
Berlin, Heidelberg: Springer.</li>

<li>Kov&aacute;cs, Laura, and Andrei Voronkov, 2013,
&ldquo;First-Order Theorem Proving and Vampire,&rdquo; in
<em>Proceedings of the 25th International Conference on Computer Aided
Verification</em>, Vol. 8044, pp. 1&ndash;35, New York, NY: Springer.
doi:10.1007/978-3-642-39799-8_1</li>

<li>Kramer, Frank, and Tim Bei&szlig;barth, 2017, &ldquo;Working with
Ontologies,&rdquo; in <em>Methods in Molecular Biology</em>, 1525:
123&ndash;135, Berlin, Heidelberg: Springer.
doi:10.1007/978-1-4939-6622-6_6</li>

<li>Lehmann, F., 1992, <em>Semantic Networks in Artificial
Intelligence</em>, Amsterdam: Elsevier Science Inc.</li>

<li>Lenat, D., 1995, &ldquo;Cyc: A Large-Scale Investment in Knowledge
Infrastructure,&rdquo; <em>Comm. ACM</em>, 38(11).</li>

<li>Lenat, Douglas B., and R. V. Guha, 1989, <em>Building Large
Knowledge-Based Systems; Representation and Inference in the Cyc
Project</em>, 1st edition, USA: Reading, MA: Addison-Wesley.</li>

<li>Levine, S. J., and K. Lateef-Jan, 2017, <em>Untranslatability Goes
Global</em>, Abingdon: Routledge.</li>
 
<li>Lewis, Patrick, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
Vladimir Karpukhin, Naman Goyal, Heinrich K&uuml;ttler, Mike Lewis,
Wen-tau Yih, Tim Rockt&auml;schel, Sebastian Riedel, and Douwe Kiela,
2020, &ldquo;Retrieval-Augmented Generation for Knowledge-Intensive
NLP Tasks,&rdquo; in H. Larochelle, M. Ranzato, R. Hadsell, M. F.
Balcan, &amp; H. Lin (eds.), <em>Advances in Neural Information
Processing Systems</em>, Vol. 33, pp. 9459&ndash;9474, Red Hook, NY:
Curran Associates, Inc. 
 [<a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf" target="other">Lewis et al. 2020 available online</a>]</li>
 
<li>Linnaeus, Carl von, 1758, <em>Systema naturae per regna tria
naturae: secundum classes, ordines, genera, species, cum
characteribus, differentiis, synonymis, locis</em>, Vol. V.1,
Stockholm: Salvius. 
 [<a href="https://archive.org/details/mobot31753000798865/page/n1/mode/2up" target="other">Linnaeus 1758 available online</a>]</li>
 
<li>Lu, Jie, Anjin Liu, Fan Dong, Feng Gu, Jo&atilde;o Gama, and
Guangquan Zhang, 2019, &ldquo;Learning Under Concept Drift: A
Review,&rdquo; <em>IEEE Transactions on Knowledge and Data
Engineering</em>, 31(12): 2346&ndash;2363.
doi:10.1109/TKDE.2018.2876857</li>

<li>Magne, Matthew, 2017, &ldquo;Data Drift Happens: 7 Pesky Problems
with People Data,&rdquo; <em>InformationWeek</em>, July 19.
 [<a href="https://www.informationweek.com/data-management/data-drift-happens-7-pesky-problems-with-people-data" target="other">Magne 2017 available online</a>]</li>
 
<li>Mascardi, V., V. Cordi, and P. Rosso, 2007, &ldquo;A Comparison of
Upper Ontologies,&rdquo; in Matteo Baldoni, Antonio Boccalatte, Flavio
De Paoli, Maurizio Martelli, &amp; Viviana Mascardi (eds.),
<em>Proceedings of WOA 2007</em>, pp. 55&ndash;64, Torino:
Seneca.</li>

<li>Merriam-Webster, 2003, <em>Merriam-Webster&rsquo;s Collegiate
Dictionary</em>, 11th edition, Springfield, MA: Merriam-Webster.</li>

<li>Newton, L., 1990, <em>Overconfidence in the Communication of
Intent: Heard and Unheard Melodies</em>, Ph.D. Thesis, Stanford, CA:
Stanford University.</li>

<li>Niles, Ian, and Adam Pease, 2001, &ldquo;Toward a Standard Upper
Ontology,&rdquo; in Chris Welty &amp; Barry Smith (eds.),
<em>Proceedings of the 2nd International Conference on Formal Ontology
in Information Systems (FOIS-2001)</em>, pp. 2&ndash;9, New York:
Association for Computing Machinery.</li>

<li>Oxford English Dictionary, 2020, <em>OED Online</em>, Oxford:
Oxford University Press. 
 [<a href="https://www.oed.com/" target="other">OED available online</a>]</li>
 
<li>Pancha, Girish, 2016, &ldquo;Big Data&rsquo;s Hidden Scourge: Data
Drift,&rdquo; <em>CMSWire</em>, April 8. 
 [<a href="https://www.cmswire.com/big-data/big-datas-hidden-scourge-data-drift/" target="other">Pancha 2016 available online</a>]</li>
 
<li>Pease, Adam, 2011, <em>Ontology: A Practical Guide</em>, Angwin,
CA: Articulate Software Press.</li>

<li>Pease, Adam, Geoff Sutcliffe, Nick Siegel, and Steven Trac, 2010,
&ldquo;Large Theory Reasoning with SUMO at CASC,&rdquo; <em>AI
Communications, Special Issue on Practical Aspects of Automated
Reasoning</em>, 23(2&ndash;3): 137&ndash;144.</li>

<li>Poirier, Lindsay, 2024, &ldquo;Neat vs. Scruffy: How Early AI
Researchers Classified Epistemic Cultures of Knowledge
Representation,&rdquo; <em>IEEE Annals of the History of
Computing</em>, PP(99): 1&ndash;29. doi:10.1109/MAHC.2024.3498692</li>

<li>Poli, Roberto, Michael Healy, and Achilles Kameas, 2010,
<em>Theory and Applications of Ontology: Computer Applications</em>,
Berlin, Heidelberg: Springer.</li>

<li>Qaswar, Fahad, M. Rahmah, Muhammad Ahsan Raza, A. Noraziah, Basem
Alkazemi, Z. Fauziah, Mohd. Khairul Azmi Hassan, and Ahmed Sharaf,
2022, &ldquo;Applications of Ontology in the Internet of Things: A
Systematic Analysis,&rdquo; <em>Electronics</em>, 12(1), 111.
doi:10.3390/electronics12010111</li>

<li>Raths, Thomas, and Jens Otten, 2012, &ldquo;The QMLTP Problem
Library for First-Order Modal Logics,&rdquo; in Bernhard Gramlich,
Dale Miller, &amp; Uli Sattler (eds.), <em>Automated Reasoning</em>,
pp. 454&ndash;461, Berlin, Heidelberg: Springer.</li>

<li>Riley, Gary, Chris Culbert, Robert T. Savely, and Frank Lopez,
1987, &ldquo;CLIPS: An Expert System Tool for Delivery and
Training,&rdquo; in J. S. Denton, M. S. Freeman, &amp; M. Vereen
(ed.), <em>Third Conference on Artificial Intelligence for Space
Applications &ndash; Part I</em>, pp. 53&ndash;57, NASA. 
 [<a href="https://ntrs.nasa.gov/api/citations/19880006986/downloads/19880006986.pdf" target="other">Riley et al. 1987 available online</a>]</li>
 
<li>Robinson, Ian, Jim Webber, and Emil Eifrem, 2015, <em>Graph
Databases</em>, 2nd edition, Beijing: O&rsquo;Reilly.</li>
  
<li>Rumbaugh, James, Ivar Jacobson, and Grady Booch, 2004, <em>Unified
Modeling Language Reference Manual</em>, 2nd edition, Pearson Higher
Education.</li>

<li>Shapiro, Stuart C., 2001, &ldquo;Review of &rdquo;Knowledge
Representation: Logical, Philosophical, and Computational Foundations&ldquo;
by John F. Sowa,&rdquo; <em>Computational Linguistics &ndash;
COLI</em>.</li>

<li>Sirin, Evren, Bijan Parsia, Bernardo Cuenca Grau, Aditya
Kalyanpur, and Yarden Katz, 2007, &ldquo;Pellet: A Practical OWL-DL
Reasoner,&rdquo; <em>Web Semant.</em>, 5(2): 51&ndash;53.
doi:10.1016/j.websem.2007.03.004</li>

<li>Smith, Barry, Pierre Grenon, and Louis Goldberg, 2004,
&ldquo;Biodynamic Ontology: Applying Bfo in the Biomedical
Domain,&rdquo; <em>Studies in Health and Technology Informatics</em>,
102: 20&ndash;38.</li>

<li>Stevens, Robert, and Phillip Lord, 2009, &ldquo;Application of
Ontologies in Bioinformatics,&rdquo; in Steffen Staab &amp; Rudi
Studer (eds.), <em>Handbook on Ontologies</em>, pp. 735&ndash;756,
Berlin, Heidelberg: Springer.</li>

<li>Subbiondo, Joseph L. (ed.), 1992, <em>John Wilkins and
17th-Century British Linguistics</em>, Amsterdam: John Benjamins.</li>
 
<li>Suomela, Sari, and Jaana Kek&auml;l&auml;inen, 2005,
&ldquo;Ontology as a Search-Tool: A Study of Real Users&rsquo; Query
Formulation With and Without Conceptual Support,&rdquo; in David E.
Losada &amp; Juan M. Fern&aacute;ndez-Luna (eds.), <em>Advances in
Information Retrieval</em>, pp. 315&ndash;329, Berlin, Heidelberg:
Springer.</li>

<li>Sutcliffe, Geoff, 2010, &ldquo;The TPTP World &ndash;
Infrastructure for Automated Reasoning,&rdquo; in Edmund M. Clarke
&amp; Andrei Voronkov (eds.), <em>Logic for Programming, Artificial
Intelligence, and Reasoning</em>, pp. 1&ndash;12, Berlin, Heidelberg:
Springer.</li>

<li>&ndash;&ndash;&ndash;, 2024, &ldquo;Stepping Stones in the TPTP
World,&rdquo; in C. Benzm&uuml;ller, M. Heule, &amp; R. Schmidt
(eds.), <em>Proceedings of the 12th International Joint Conference on
Automated Reasoning</em>, pp. 30&ndash;50, Berlin, Heidelberg:
Springer.</li>

<li>Sutcliffe, Geoff, and Martin Desharnais, 2023, &ldquo;The 11th
IJCAR Automated Theorem Proving System Competition &ndash; CASC-J11,&rdquo;
<em>AI Communications</em>, 36(2): 73&ndash;91.</li>

<li>&ndash;&ndash;&ndash;, 2024, &ldquo;The CADE-29 Automated Theorem
Proving System Competition &ndash; CASC-29,&rdquo; <em>AI
Communications</em>, 37(4): 485&ndash;503. doi:10.3233/AIC-230325</li>

<li>Sutcliffe, Geoff, Stephan Schulz, Koen Claessen, and Peter
Baumgartner, 2012, &ldquo;The TPTP Typed First-Order Form with
Arithmetic,&rdquo; in Nikolaj Bj&oslash;rner &amp; Andrei Voronkov
(eds.), <em>Logic for Programming, Artificial Intelligence, and
Reasoning</em> (LPAR 2012), pp. 406&ndash;419, Berlin, Heidelberg:
Springer.</li>

<li>Sutcliffe, Geoff, and Christian Suttner, 1998, &ldquo;The TPTP
Problem Library,&rdquo; <em>J. Autom. Reason.</em>, 21: 177&ndash;203,
Berlin, Heidelberg: Springer. doi:10.1023/A:1005806324129</li>

<li>Tsarkov, Dmitry, and Ian Horrocks, 2006, &ldquo;FaCT++ Description
Logic Reasoner: System Description,&rdquo; in <em>Proceedings of the
Third International Joint Conference on Automated Reasoning</em>, pp.
292&ndash;297, Berlin, Heidelberg: Springer.
doi:10.1007/11814771_26</li>

<li>Tsarkov, Dmitry, Alexandre Riazano, Sean Bechhofer, and Ian
Horrocks, 2004, &ldquo;Using Vampire to Reason with OWL,&rdquo; in
Sheila A. McIlraith, Dimitris Plexousakis, &amp; Frank van Harmelen
(eds.), <em>The Semantic Web &ndash; ISWC 2004</em>, pp.
471&ndash;485, Berlin, Heidelberg: Springer.</li>

<li>Uschold, Mike, and Jasper, Robert, 1999, &ldquo;A Framework for
Understanding and Classifying Ontology Applications,&rdquo; in Richard
Benjamins (ed.) <em>Proceedings of the IJCAI-99 Workshop on Ontologies
and Problem-Solving Methods (KRR5)</em>, Vol. 2, Amsterdam: CEUR.</li>

<li>Waldinger, Richard, Douglas E. Appelt, John Fry, David Israel,
Peter Jarvis, David Martin, Susanne Riehemann, Mark E. Stickel, Mabry
Tyson, Jerry Hobbs, and Jennifer Dungan, 2004, &ldquo;Deductive
Question Answering from Multiple Resources,&rdquo; in Mark Maybury
(ed.), <em>New Directions in Question Answering</em>, pp.
253&ndash;262, Berlin, Heidelberg: Springer.</li>

<li>Wi&#347;niewski, Dawid, Jedrzej Potoniec, Agnieszka
&#321;awrynowicz, and C. Maria Keet, 2019, &ldquo;Analysis of Ontology
Competency Questions and Their Formalizations in SPARQL-OWL,&rdquo;
<em>Journal of Web Semantics</em>, 59 (100534).
doi:10.1016/j.websem.2019.100534</li>

<li>Woods, W. A., 1975, &ldquo;What&rsquo;s in a Link: Foundations for
Semantic Networks,&rdquo; in D. G. Bobrow &amp; A. M. Collins (eds.),
<em>Representation and Understanding: Studies in Cognitive
Science</em>, pp. 35&ndash;82, New York: Academic Press.</li>

<li>Zhao, Yan, Jun Yin, Li Zhang, Yong Zhang, and Xing Chen, 2023,
&ldquo;Drug&ndash;Drug Interaction Prediction: Databases, Web Servers
and Computational Models,&rdquo; <em>Briefings in Bioinformatics</em>,
25(1): bbad445. doi:10.1093/bib/bbad445</li>

<li>Zheng, Xiaochen, Jinzhi Lu, Rebeca Arista, Xiaodu Hu, Joachim
Lentes, Fernando Ubis, Jyri Sorvari, and Dimitris Kiritsis, 2021,
&ldquo;Development of an Application Ontology for Knowledge Management
to Support Aircraft Assembly System Design,&rdquo; in Emilio M.
Sanfilippo, Oliver Kutz, Nicolas Troquard, et al. (eds.),
<em>JOWO</em>, Volume 2969, CEUR-WS.org.
 [<a href="https://ceur-ws.org/Vol-2969/paper21-FOMI.pdf" target="other">Zheng et al. 2021 available online</a>]</li>
 
</ul>
</div> 

<div id="academic-tools">
<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=ontology-is" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/ontology-is/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=ontology-is&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="https://philpapers.org/sep/ontology-is/" target="other">Enhanced bibliography for this entry</a>
at <a href="https://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>
</div>

<div id="other-internet-resources">

<h2 id="Oth">Other Internet Resources</h2>

<ul>

 <li><a href="https://en.wikipedia.org/wiki/Upper_ontology" target="other">Upper Ontology</a>,
 entry in Wikipedia</li>

<!--
 <li><a href="https://guides.library.ucla.edu/semantic-web/semantic_web_ontologies" target="other">Semantic web ontologies</a>,
 UCLA Library guides</li>
-->

 <li><a href="https://github.com/semantalytics/awesome-semantic-web?tab=readme-ov-file#ontologies" target="other">Ontologies</a>,
 at GitHub.</li>

 <li><a href="https://www.w3.org/RDF/" target="other">Resource Description Framework</a>,
 at www.w3.org</li>

 <li><a href="https://www.drools.org" target="other">Drools rule engine</a></li>

 </ul>

</div>

<div id="related-entries">

<h2 id="Rel">Related Entries</h2>

<p>
[To be completed.]</p>
</div>

<div id="acknowledgments">

<h3>Acknowledgments</h3>

<p>
Thanks to Stephan Schulz and the anonymous reviewers for thorough
reviews that helped improve the entry.</p>
</div>
<script type="text/javascript" src="local.js"></script>
<script type="text/javascript" src="../../MathJax/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2026</a> by

<br />
<a href="https://www.adampease.org" target="other">Adam Pease</a>
&lt;<a href="m&#97;ilto:apease&#37;40articulatesoftware&#37;2ecom"><em>apease<abbr title=" at ">&#64;</abbr>articulatesoftware<abbr title=" dot ">&#46;</abbr>com</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
            <li role="menuitem"><a href="../../new.html">What's New</a></li>
            <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li role="menuitem"><a href="../../published.html">Chronological</a></li>
            <li role="menuitem"><a href="../../archives/">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
            <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
            <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
            <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
            <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
            <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
            <li role="menuitem"><a href="../../accessibility.html">Accessibility</a></li>
            <li role="menuitem"><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
            <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
            <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2026</a> by <a href="https://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>
</html>
