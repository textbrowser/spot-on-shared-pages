<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html lang="en"> <!-- <![endif]-->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Epistemic Foundations of Game Theory (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Epistemic Foundations of Game Theory" />
<meta property="citation_author" content="Pacuit, Eric" />
<meta property="citation_author" content="Roy, Olivier" />
<meta property="citation_publication_date" content="2015/03/13" />
<meta name="DC.title" content="Epistemic Foundations of Game Theory" />
<meta name="DC.creator" content="Pacuit, Eric" />
<meta name="DC.creator" content="Roy, Olivier" />
<meta name="DCTERMS.issued" content="2015-03-13" />
<meta name="DCTERMS.modified" content="2025-06-27" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP home page" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
                    <li role="menuitem"><a href="../../new.html">What's New</a></li>
                    <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li role="menuitem"><a href="../../published.html">Chronological</a></li>
                    <li role="menuitem"><a href="../../archives/">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
                    <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
                    <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
                    <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
                    <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
                    <li role="menuitem"><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
                    <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
                    <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="../../search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit" aria-label="search"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/epistemic-game/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=epistemic-game">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Epistemic Foundations of Game Theory</h1><div id="pubinfo"><em>First published Fri Mar 13, 2015; substantive revision Fri Jun 27, 2025</em></div>

<div id="preamble">

<p>
Non-cooperative game theory studies how individual players, or agents,
make decisions in situations involving strategic interaction. In these
situations, each player&rsquo;s outcome depends not only on their own
choices but also on the choices of the other players (see Ross 1997
[2024] for an overview). Epistemic game theory investigates how
assumptions about the players&rsquo; beliefs and rationality influence
their choices in strategic situations. This entry begins by discussing
the role of uncertainty in strategic situations. It then introduces
models of multi-agent knowledge and belief developed in the epistemic
game theory and epistemic logic literature. Next, it examines how
these models can be used to characterize classical game-theoretic
solution concepts, focusing on the relationship between players&rsquo;
rationality and their mutual beliefs about each other&rsquo;s
rationality. The entry concludes with a brief overview of other key
topics in the epistemic game theory literature and suggestions for
further reading. </p>
</div> 

<div id="toc"><!--Entry Contents-->
<ul>
	<li><a href="#N1EpisViewGame">1. The Epistemic View of Games</a>

	<ul>
		<li><a href="#ClasGameTheo">1.1 Classical Game Theory</a></li>
		<li><a href="#EpisGameTheo">1.2 Epistemic Game Theory</a></li>
		<li><a href="#StagDeciMaki">1.3 Stages of Decision Making</a></li>
		<li><a href="#IncoInfo">1.4 Incomplete Information</a></li>
		<li><a href="#ImpeInfoPerfReca">1.5 Imperfect Information and Perfect Recall</a></li>
	</ul>
	</li>
	<li><a href="#GameMode">2. Game Models</a>
	<ul>
		<li><a href="#EpisProbMode">2.1 Epistemic-Probability Models</a>
		<ul>
			<li><a href="#EpisMode">2.1.1 Epistemic Models </a></li>
			<li><a href="#AddiBeli">2.1.2 Adding Beliefs </a></li>
			<li><a href="#RatiChoiEpisProbMode">2.1.3 Rational Choice in Epistemic-Probability Models</a></li>
		</ul>
		</li>
		<li><a href="#TypeSpac">2.2 Type Spaces</a>
		<ul>
			<li><a href="#BeliHier">2.2.1 Belief Hierarchies</a></li>
			<li><a href="#QualTypeSpac">2.2.2 Qualitative Type Spaces</a></li>
			<li><a href="#ProbTypeSpac">2.2.3 Probabilistic Type Spaces</a></li>
			<li><a href="#RatiChoiTypeSpac">2.2.4 Rational Choice in Type Spaces</a></li>
		</ul>
		</li>
		<li><a href="#CommKnowBeli">2.3 Common Knowledge and Belief</a></li>
		<li><a href="#ParaSelfRefeGameMode">2.4 A Paradox of Self-Reference in Game Models</a></li>
	</ul>
	</li>
	<li><a href="#EpisCharSoluConc">3. Epistemic Characterizations of Solution Concepts</a>
	<ul>
		<li><a href="#FundTheoEpisGameTheo">3.1 The Fundamental Theorem of Epistemic Game Theory</a>
		<ul>
			<li><a href="#StriDomi">3.1.1 Strict Dominance </a></li>
			<li><a href="#CommBeliRatiIterElimStriDomiStra">3.1.2 Common Belief in Rationality and Iterated Elimination of Strictly Dominated Strategies </a></li>
			<li><a href="#BeliAbouCorrChoi">3.1.3 Beliefs about Correlated Choices</a></li>
		</ul>
		</li>
		<li><a href="#SubgPerfEqui">3.2 Subgame Perfect Equilibrium</a>
		<ul>
			<li><a href="#GameExteForm">3.2.1 Games in Extensive Form </a></li>
			<li><a href="#ModeGameExteForm">3.2.2 Models of Games in Extensive Form </a></li>
			<li><a href="#CommKnowRatiSubgPerfEqui">3.2.3 Common Knowledge of Rationality and Subgame Perfect Equilibrium</a></li>
		</ul>
		</li>
		<li><a href="#NashEqui">3.3 Nash Equilibrium</a>
		<ul>
			<li><a href="#EpisCharEquiPlay">3.3.1 Epistemic Characterizations of Equilibrium Play</a></li>
			<li><a href="#EpisInteMixeStraEqui">3.3.2 Epistemic Interpretation of Mixed Strategy Equilibrium</a></li>
		</ul>
		</li>
		<li><a href="#IterWeakDomiCautBeli">3.4 Iterated Weak Dominance and Cautious Beliefs</a></li>
		<li><a href="#ForwInduExteFormRati">3.5 Forward Induction and Extensive Form Rationalizability</a></li>
	</ul>
	</li>
	<li><a href="#AddiTopi">4. Additional Topics</a>
	<ul>
		<li><a href="#IncoUnaw">4.1 Incorporating Unawareness</a></li>
		<li><a href="#AlteChoiRule">4.2 Alternative Choice Rules</a></li>
		<li><a href="#DynaGameMode">4.3 Dynamic Game Models</a></li>
		<li><a href="#FiniHierBeli">4.4 Finite Hierarchies of Belief</a></li>
	</ul>
	</li>
	<li><a href="#ConcRema">5. Concluding Remarks</a></li>
	<li><a href="#Bib">Bibliography</a></li>
	<li><a href="#Aca">Academic Tools</a></li>
	<li><a href="#Oth">Other Internet Resources</a></li>
	<li><a href="#Rel">Related Entries</a></li>
</ul>

<!--Entry Contents-->

<hr /></div>

<div id="main-text">

<h2 id="N1EpisViewGame">1. The Epistemic View of Games</h2>

<p>
This section provides an overview of the key ideas and concepts that
are used throughout epistemic game theory.</p>

<h3 id="ClasGameTheo">1.1 Classical Game Theory</h3>

<p>
A <em>game</em> refers to an interactive situation involving a group
of &ldquo;self-interested&rdquo; players, or agents. The defining
feature of a game is that the players are engaged in an
&ldquo;interdependent decision problem&rdquo; where the outcome of the
game depends on all of the player&rsquo;s choices (Schelling 1960).
The mathematical description of a game includes at least the following
components:</p>

<ol>

<li>

<p>
the <em>players</em>: in this entry, we only consider games with
finitely many players and use \(N \) to denote the set of players in a
game;</p> </li>

<li>

<p>
for each player \(i\in N\), a finite set of <em>feasible</em> options
(typically called <em>actions</em> or <em>strategies</em>); and</p>
</li>

<li>

<p>
for each player \(i\in N\), a <em>utility function</em> that
represents \(i\)&rsquo;s preference over the possible outcomes of the
game. A standard assumption in game theory is that the outcomes of a
game are the sequences of actions, one for each player. A sequence of
actions is called a <strong>strategy profile</strong>. Identifying the
outcomes of a game with strategy profiles reflects the key idea that
the outcome of a game depends on the choices of <em>all
players</em>.</p> </li>
</ol>

<p>
Different mathematical representations of a game describe other
features of the interactive situation, such as the order in which the
players move.</p>

<p class="indent">
<strong>Definition 1.1 (Game in Strategic Form)</strong> A game in
<strong>strategic form</strong> is a tuple \(\langle N , (S_i)_{i\in
N}, (u_i)_{i\in N }\rangle\) where \(N \) is a nonempty finite set of
players, for each \(i\in N\), \(S_i\) is a nonempty set of actions for
player \(i\), and for each \(i\in N\), \(u_i:\times_{i\in N }
S_i\rightarrow\mathbb{R}\) is player \(i\)&rsquo;s utility function,
where \(\times_{i\in N} S_i\) is the set of strategy profiles.</p>

<p>
A game in strategic form represents a situation in which all the
players make a single decision simultaneously without stochastic
moves.</p>

<p>

 <a href="#coord-game-first">Figure 1</a>
 is an example of a game in strategic form. There are two players, Ann
and Bob, and each has two available actions: \(N = \{\Ann, \Bob\}\),
\(S_{\Ann} = \{u, d\}\) and \(S_{\Bob} = \{l, r\}\). The
players&rsquo; utilities \(u_{\Ann}\) and \(u_{\Bob}\) are displayed
in the cells of the matrix (the first number in the tuple is
Ann&rsquo;s utility and the second number is Bob&rsquo;s utility). If
Bob chooses \(l\), for instance, Ann prefers the outcome she would get
by choosing \(u\) to the one she would get by choosing \(d\) since
\(u_{\Ann}(u,l) &gt; u_{\Ann}(d,l)\), but this preference is reversed
if Bob chooses \(r\). In the game in
 <a href="#coord-game-first">Figure 1</a>,
 there are 4 outcomes of the game corresponding to the 4 different
strategy profiles \(\{(u,l), (u, r), (d, l), (d,r)\}\) (represented by
each of the 4 cells in the matrix displayed in
 <a href="#coord-game-first">Figure 1</a>).</p>
 
<div class="figure" id="coord-game-first">

<table class="cell-center cellpad-small-dense centered inner-boxTH nocaption vert-mid">
<thead style="line-height:1.1em">
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th colspan="2">Bob</th> </tr>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody class="cellpad-small">
<tr>
<th rowspan="2">Ann</th>
<th><em>u</em></th>
  <td>1,1</td>
  <td>0,0</td> </tr>
<tr>
<th><em>d</em></th>
  <td>0,0</td>
  <td>1,1</td> </tr> </tbody>
</table>

<p class="center">
<span class="figlabel">Figure 1:</span> A coordination game</p>
</div>

<p>
The game displayed in
 <a href="#coord-game-first">Figure 1</a>
 is called a <em>pure coordination game</em>: the players have a
common interest in coordinating their choices on \((u, l)\) or \((d,
r)\) and they are both indifferent about which way they coordinate
their choices.</p>

<h4 id="SoluConcMixeStra">1.1.1 Solution Concepts and Mixed Strategies</h4>

<p>
A major focus of classical game theory research is studying and
developing <em>solution concepts</em>. A solution concept associates a
set of outcomes (i.e., a set of strategy profiles) with each game
(from some fixed class of games). The most well-known solution concept
is the Nash equilibrium, although we will encounter others in this
entry. From a prescriptive point of view, a solution concept is a
recommendation about what the players should do in a game, or about
what outcomes can be expected assuming that the players choose
rationally. From a predictive point of view, solution concepts
describe what the players will actually do in a game.</p>

<p>
Many solution concepts in game theory involve <em>mixed
strategies</em>, where a player deliberately randomizes between their
available actions rather than choosing one with certainty. The
matching pennies game illustrates why mixed strategies are important:
two players simultaneously show heads or tails, where one player wins
if the coins match and the other wins if they differ. In this game, if
your opponent can predict your choice, they will win by choosing
accordingly. To prevent your opponent from gaining this advantage, you
should make your choice truly unpredictable&mdash;even to
yourself&mdash;by randomizing. A mixed strategy specifies the
probability of choosing each action (e.g., 60% heads, 40% tails),
selected from the infinitely many possible probability distributions
over your available actions. </p>

<p>
Formally, a mixed strategy for a player \(i\) is a probability over
\(i\)&rsquo;s available strategies. Let \(\Delta(X)\) denote the set
of probability measures over the
 finite<sup>[<a href="notes.html#note-1" id="ref-1">1</a>]</sup>
 set \(X\). Each \(m\in \Delta(S_i)\) is called a <strong>mixed
strategy</strong> for player \(i\). If \(m\in\Delta(S_i)\) assigns
probability 1 to a strategy \(s\in S_i\), then \(m\) is called a
<strong>pure strategy</strong> (in this case, we write \(s\) for
\(m\)). <!-- Suppose that \(G=\langle N, (S_i)_{i\in N}, (u_i)_{i\in N}\rangle\) is a game in strategic form and \(m\in\Delta(S_i)\) is a mixed strategy for player <i class="m">i</i>.
If \(s_{-i}\in S_{-i}\)
is a sequence of strategies for the players other than <i class="m">i</i>,
then let \(U_i(m, s_{-i})=\sum_{s\in S_i} m(s) *
u_i(s,s_{-i})\), where \(u_i(s, s_{-i})\) is the utility of player <i class="m">i</i>
for the strategy profile where <i class="m">i</i>
chooses <i class="m">s</i> and the other players choose as in
\(s_{-i}\).--></p>

<p>
Mixed strategies play an important role in game theory, especially
when it comes to the existence of Nash equilibria. However, the
interpretation of mixed strategies is controversial (see, for
instance, Rubinstein 1991: 913). The main issue is whether players
should be seen as genuinely randomizing&mdash;i.e., as delegating
their choices to some randomization device&mdash;or whether mixed
strategies capture something else, such as the opponents&rsquo;
<em>uncertainty</em> about a player&rsquo;s choice (cf. Zollman 2022
and Icard 2021). We return to the interpretation of mixed strategies
in
 <a href="#EpisInteMixeStraEqui">Section 3.3.2</a>.</p>
 
<h3 id="EpisGameTheo">1.2 Epistemic Game Theory</h3>

<p>
Epistemic game theory emerged as a well-defined research program in
the 1980s as a response to the equilibrium refinement program. The
equilibrium refinement program (see van Damme 1983 for an overview)
started with the observation that the Nash equilibrium (see
 <a href="#NashEqui">Section 3.3</a>
 for a definition of Nash equilibrium) does not always provide a
unique or compelling solution of a game. The equilibrium refinement
program aims to identify more desirable solutions to a game by
imposing additional criteria on the set of Nash equilibria. These
refined equilibrium concepts were often based on intuitive judgments
about what constituted rational plays in games. The development of
epistemic game theory was motivated by a desire to formalize these
intuitive judgments. Armbruster &amp; B&ouml;ge (1979) is arguably the
earliest contribution to this approach, but other notable works
include Spohn (1982), Bernheim (1984), Pearce (1984), and Tan &amp;
Werlang (1988), all of which present clear statements contrasting the
epistemic program with the equilibrium refinement program. Consult
Perea (2014b) for a more comprehensive discussion on the history of
epistemic game theory.</p>

<p>
One of the objectives of epistemic game theory is to characterize the
behavior of rational players who mutually recognize each other&rsquo;s
rationality, where rationality is typically understood as in standard
decision theory (see Briggs 2014 [2019]). This approach to the study
of games is nicely encapsulated by the following:</p>

<blockquote>

<p>
There is no special concept of rationality for decision making in a
situation where the outcomes depend on the actions of more than one
agent. The acts of other agents are, like chance events, natural
disasters and acts of God, just facts about an uncertain world that
agents have beliefs and degrees of belief about. The utilities of
other agents are relevant to an agent only as information that,
together with beliefs about the rationality of those agents, helps to
predict their actions. (Stalnaker 1996: 136)</p>
</blockquote>

<p>
A central component of an epistemic analysis of a game is a
description of what the players know and believe about each other. In
epistemic game theory, there are two main sources of uncertainty for
the players:</p>

<ul>

<li>

<p>
Strategic uncertainty: What will the other players do?</p> </li>

<li>

<p>
Higher-order information: What are the other players thinking?</p>
</li>
</ul>

<p>
Of course, game theorists have studied uncertainty in games long
before the emergence of epistemic game theory. This work has largely
focused on two other sources of uncertainty in game:</p>

<ul>

<li>

<p>
Information about the structure of the game (called
<em>complete/incomplete information</em>): Who else is involved in the
game? What actions are available? What are the payoffs for each
player? This type of uncertainty in games is briefly discussed in
 <a href="#IncoInfo">Section 1.4</a>
 </p> </li>

<li>

<p>
Information about the play of the game (called <em>perfect/imperfect
information</em>): Which moves have been played? This type of
uncertainty in games is briefly discussed in
 <a href="#ImpeInfoPerfReca">Section 1.5</a>.</p>
 </li>
</ul>

<p>
These four sources of uncertainty in games are conceptually important,
but not necessarily exhaustive nor mutually exclusive. John Harsanyi,
for instance, argued that all uncertainty about the structure of the
game&mdash;i.e., all possible incompleteness in information&mdash;can
be reduced to uncertainty about the payoffs (Harsanyi 1967&ndash;68,
cf. also Hu &amp; Stuart 2002 and Lorini &amp; Schwarzentruber 2010).
In a similar vein, Kadane &amp; Larkey argue that for a player</p>

<blockquote>

<p>
in a single-play game, all aspects of his opinion except his [opinion]
about his opponent&rsquo;s behavior are irrelevant, and can be ignored
in the analysis by integrating them out of the joint opinion. (1982:
116)</p>
</blockquote>

<h3 id="StagDeciMaki">1.3 Stages of Decision Making</h3>

<p>
It is standard in the game theory literature to distinguish three
stages of the decision making process: <em>ex ante</em>, <em>ex
interim</em>, and <em>ex post</em>. At one extreme is the <em>ex
ante</em> stage where no decision has yet been made. The other extreme
is the <em>ex post</em> stage where the choices of all players are
openly disclosed. In between these two extremes is the <em>ex
interim</em> stage where the players have made their decisions, but
they are still uninformed about the choices of the other players.</p>

<p>
These distinctions are not intended to be sharp. Rather, they describe
various stages of information disclosure for the players during the
decision-making process. At the <em>ex ante</em> stage, little is
known except the structure of the game, who is taking part, and
possibly (but not necessarily) something about the other
players&rsquo; beliefs. At the <em>ex post</em> stage the game is
basically over: all players have made their decision and these are now
irrevocably out in the open. This does not mean that all uncertainty
is removed as an agent may remain uncertain about what exactly the
others were expecting of her. In between these two extremes lies a
whole gradation of states of information disclosure that we loosely
refer to as &ldquo;the&rdquo; <em>ex interim</em> stage. Common to
these states of information disclosure is the fact that the agents
have made <em>a</em> decision, although not necessarily an irrevocable
one.</p>

<p>
In this entry, we focus on the <em>ex interim</em> stage of decision
making. This is in line with much of the literature on the epistemic
foundations of game theory as it allows for a straightforward
assessment of the players&rsquo; rationality given their expectations
about what their opponents will do. Focusing on the <em>ex
interim</em> stage does raise some interesting questions about how a
player should react to learning that she did not choose
&ldquo;rationally&rdquo; (cf. Stalnaker 1999, Section 4, and Skyrms
1990). Note that this question is different from the one of how
players should revise their beliefs upon learning that <em>others</em>
did not choose rationally. This second question is very relevant in
games in which players choose sequentially, and will be addressed in
 <a href="#SubgPerfEqui">Section 3.2</a>.</p>
 
<h3 id="IncoInfo">1.4 Incomplete Information</h3>

<p>
A natural question to ask about <em>any</em> mathematical model of a
game situation is <em>how does the analysis change if the players are
uncertain about some parameters of the model?</em> This motivated
Harsanyi&rsquo;s seminal 1967&ndash;68 paper that introduced a model
of beliefs for players with incomplete information about some aspect
of a game. Building on these ideas, there is an extensive literature
that studies <em>Bayesian games</em>, that is, games in which the
players are uncertain about some aspect of the game. Consult
Leyton-Brown &amp; Shoham (2008: ch. 7) for a concise summary and
pointers to the relevant literature. We discuss Harsanyi&rsquo;s
approach to modeling higher-order beliefs in
 <a href="#TypeSpac">Section 2.2</a>.
 Following Brandenburger 2010 (Sections 4 and 5), we note two crucial
differences between the study of Bayesian games and epistemic game
theory.</p>

<ol>

<li>

<p>
In a Bayesian game, the only source of uncertainty for a player is the
payoffs of the game, what the other players believe are the correct
payoffs, what other players believe that the other players believe
about the payoffs, and so on. The underlying idea is that the
players&rsquo; (higher-order) beliefs about the payoffs in a game
completely determine the (higher-order) beliefs about the other
aspects of the game. In particular, if a player comes to <em>know</em>
the payoffs of the other players, then that player is certain (and
correct) about the possible (rational) choices of the other
 players.<sup>[<a href="notes.html#note-2" id="ref-2">2</a>]</sup>
 As discussed in Section 1.2, in epistemic game theory, the models of
beliefs focus on other sources of uncertainty for the players, such as
strategic uncertainty.</p> </li>

<li>

<p>
In a Bayesian game, it is assumed that all players choose optimally
given their information. That is, all players choose a strategy that
maximizes their expected utility given their beliefs about the game,
beliefs about what other players believe about the game, and so on.
This means, in particular, that players do not entertain the
possibility that their opponents may choose
&ldquo;irrationally&rdquo;. In contrast, epistemic game theory models
allow for the possibility that players may believe that the other
players choose irrationally.</p> </li>
</ol>

<p>
Note that these assumptions are not inherent in the formalism that
Harsanyi used to represent the players&rsquo; beliefs in a game of
incomplete information. Rather, they are conventions followed by
Harsanyi and subsequent researchers studying Bayesian games.</p>

<h3 id="ImpeInfoPerfReca">1.5 Imperfect Information and Perfect Recall</h3>

<p>
The defining feature of a game in strategic form is that the players
choose their actions <em>simultaneously</em>. This is not an
assumption about the precise timing of the players&rsquo; choices in
the game, but rather an assumption about what the players know and
believe about the choices of the other players in the game. More
generally, a game in strategic form is an example of a game with
<em>imperfect information</em> in which the players may not be
perfectly informed about the moves of their opponents or the outcome
of chance moves by nature. The choices of two players that do not move
at the same time, but are not informed about the choice of the other
player can be pictured as follows (where, for instance, the first
player chooses at \(d_0\) and the second player chooses at \(d_1\) and
\(d_2\), and the labels for the available actions are suppressed):</p>

<div class="figure" id="fig2">
<img alt="a diagram: link to extended description below" src="fig2.png" style="padding-bottom:10px; width:15em" />

<p class="center">
<span class="figlabel">Figure 2</span> [An
 <a href="figdesc.html#fig2">extended description of figure 2</a>
 is in the supplement.]</p>
</div>

<p>
The interpretation is that the decision made at the first node
(\(d_0\)) is forgotten or not observed, and so the second decision is
made under uncertainty about whether the decision maker is at node
\(d_1\) or \(d_2\). See Osborne (2004: ch. 9 &amp; 10) for the general
theory of games with imperfect information. Allowing imperfect
information in a game raises an interesting question about whether
players may be imperfectly informed about their own past
decisions.</p>

<p>
Harold Kuhn (1953) introduced the distinction between <em>perfect</em>
and <em>imperfect</em> recall in games with imperfect information. The
key idea is that players have perfect recall when they remember all of
their own past moves. A standard assumption in game theory is that all
players have perfect recall&mdash;i.e., they may be uncertain about
previous choices of their opponents or nature, but they do remember
all of their own moves. The perfect recall assumption has not only
played an important role in game theory (Bonanno 2004; Kaneko &amp;
Kline 1995; Piccione &amp; Rubinstein 1997a), but also in the study of
logics of knowledge and time (Halpern, van der Meyden, &amp; Vardi
2004), and in computational models of poker (Waugh et al. 2009).</p>

<p>
As we noted in
 <a href="#StagDeciMaki">Section 1.3</a>,
 there are different stages to the decision making process.
Differences between these stages of decision-making are more
pronounced in <em>sequential</em> decision problems in which decision
makers choose at different moments in time. There are two ways to
think about the decision making process in sequential decision
problems. The first is to focus on the initial &ldquo;planning
stage&rdquo;. Initially (before any moves are made), the decision
makers settle on a <em>plan</em> specifying the (possibly random) move
they will make at each of their choice nodes. Then, the players start
making their respective moves following the plan which they have
committed to without reconsidering their options at each choice node.
Alternatively, the decision makers can make &ldquo;local
judgements&rdquo; at each of their choice nodes, always choosing the
best option given the information that is currently available to them.
Kuhn&rsquo;s Theorem (1953) shows that if players have perfect recall,
then a plan is optimal if, and only if, it is locally
optimal&mdash;that is, an optimal plan leads to the same sequence of
choices that result from each decision maker choosing optimally at
their decision node (see Maschler, Solan, &amp; Zamir 2013:
219&ndash;250, for a proof of this classic result).</p>

<p>
The assumption of perfect recall is crucial for Kuhn&rsquo;s result.
This is demonstrated by the so-called <em>absent-minded driver&rsquo;s
problem</em> of Piccione &amp; Rubinstein (1997a):</p>

<blockquote>

<p>
An individual is sitting late at night in a bar planning his midnight
trip home. In order to get home he has to take the highway and get off
at the second exit. Turning at the first exit leads into a disastrous
area (payoff 0). Turning at the second exit yields the highest reward
(payoff 4). If he continues beyond the second exit, he cannot go back
and at the end of the highway he will find a motel where he can spend
the night (payoff 1). The driver is absentminded and is aware of this
fact. At an intersection, he cannot tell whether it is the first or
the second intersection and he cannot remember how many he has passed
(one can make the situation more realistic by referring to the 17th
intersection). While sitting at the bar, all he can do is to decide
whether or not to exit at an intersection. (Piccione &amp; Rubinstein
1997a: 7)</p>
</blockquote>

<p>
The decision tree for the absent-minded driver is depicted below:</p>

<div class="figure" id="fig3">
<img alt="a diagram: link to extended description below" src="fig3.png" style="padding-bottom:0px; width:13em" />

<p class="center">
<span class="figlabel">Figure 3</span> [An
 <a href="figdesc.html#fig3">extended description of figure 3</a>
 is in the supplement.]</p>
</div>

<p>
This problem shows that there may be a conflict between what the
decision maker commits to do while planning at the bar and what he
thinks is best at the first intersection:</p>

<p class="indent">
<strong>Planning stage:</strong> While planning his trip home at the
bar, the decision maker is faced with a choice between
&ldquo;Continue; Continue&rdquo; and &ldquo;Exit&rdquo;. Since he
cannot distinguish between the two intersections, he cannot plan to
&ldquo;Exit&rdquo; at the second intersection (he must plan the same
behavior at both \(X\) and \(Y\)). Since &ldquo;Exit&rdquo; will lead
to the worst outcome (with a payoff of 0), the optimal strategy is
&ldquo;Continue; Continue&rdquo; with a guaranteed payoff of 1.</p>

<p class="indent">
<strong>Action stage:</strong> When arriving at an intersection, the
decision maker is faced with a local choice of either
&ldquo;Exit&rdquo; or &ldquo;Continue&rdquo; (possibly followed by
another decision). Now the decision maker knows that since he
committed to the plan of choosing &ldquo;Continue&rdquo; at each
intersection, it is possible that he is at the second intersection.
Indeed, the decision maker concludes that he is at the first
intersection with probability 1/2. But then, his expected payoff for
&ldquo;Exit&rdquo; is \(1/2 * 4 + 1/2 * 0 = 2\), which is greater than
the payoff guaranteed by following the strategy he previously
committed to. Thus, he chooses to &ldquo;Exit&rdquo;.</p>

<p>
This problem has been discussed by a number of different
 researchers.<sup>[<a href="notes.html#note-3" id="ref-3">3</a>]</sup>
 It is beyond the scope of this article to discuss the details of the
different analyses. An entire issue of <em>Games and Economic
Behavior</em> (Volume 20, 1997) was devoted to the analysis of this
problem. For a representative sampling of the approaches to this
problem, see Aumann, Hart, &amp; Perry (1997); Board (2003); Halpern
(1997); Piccione &amp; Rubinstein (1997b); Kline (2002); Levati, Uhl
&amp; Zultan (2014); Schwarz (2015); and Milano and Perea (2023).</p>

<h2 id="GameMode">2. Game Models</h2>

<p>
Researchers interested in the foundations of decision and game theory,
epistemic and doxastic logic, and formal epistemology have developed
many different formal models that can describe a variety of
informational attitudes important for assessing the choices of players
in a game. It is beyond the scope of this article to survey the
details of these different models (cf. Genin &amp; Huber 2020 [2022]
and Weisberg 2015 [2021]). In this section, we introduce the two main
types of models found in the Epistemic Game Theory literature:
<em>Epistemic-Probability Models</em>, also called <em>Aumann-</em> or
<em>Kripke-structures</em>, (Aumann 1999a; Fagin, Halpern, Moses,
&amp; Vardi 1995) and <em>Type Spaces</em> (Harsanyi 1967&ndash;68;
Siniscalchi
 2008).<sup>[<a href="notes.html#note-4" id="ref-4">4</a>]</sup></p>
 
<p>
A <em>model</em> of a game represents both the strategies chosen by
each player and the players&rsquo; opinions about the choices and
opinions of the other players. The players&rsquo; opinions are
described in terms of the players&rsquo; <em>hard</em> and
<em>soft</em> informational attitudes (cf. van Benthem 2011). Hard
informational attitudes capture what a player is certain of in a game.
They are veridical, fully introspective and not revisable. At the
<em>ex interim</em> stage, for instance, the players have hard
information about their own choice. They &ldquo;know&rdquo; which
strategy they chose, they know that they know this, and no new
incoming information could make them change their opinion about which
strategy they chose. As this phrasing suggests,
&ldquo;knowledge&rdquo; is often used, in absence of better
terminology, to describe this very strong type of informational
 attitude.<sup>[<a href="notes.html#note-5" id="ref-5">5</a>]</sup>
 Soft informational attitudes are not necessarily veridical, not
necessarily fully introspective and/or revisable in the presence of
new information. As such, they come much closer to
 <em>beliefs</em>.<sup>[<a href="notes.html#note-6" id="ref-6">6</a>]</sup>
 The game models discussed in this entry can be broadly described as
&ldquo;possible worlds models&rdquo; which are typically associated
with a <em>propositional</em> view of the players&rsquo; informational
attitudes. Players have beliefs/knowledge about <em>propositions</em>,
called <em>events</em> in the game-theory literature, represented as
sets of possible worlds. These basic modeling choices are not
uncontroversial, but such issues are not our concern in this
entry.</p>

<h3 id="EpisProbMode">2.1 Epistemic-Probability Models</h3>

<p>
We start with models that are familiar from the philosophical logic
(van Benthem 2010) and computer science (Fagin, Halpern, et al. 1995)
literatures. These models were introduced to game theory by Robert
Aumann in his seminal paper <em>Agreeing to Disagree</em> (1976).</p>

<p>
The starting point is a non-empty (finite) set \(S\) of strategy
profiles from some underlying
 game<sup>[<a href="notes.html#note-7" id="ref-7">7</a>]</sup>
 and a set \(W\) of <em>possible worlds</em>, or <em>(epistemic)
states</em>. Each possible world is associated with a <em>unique</em>
element of \(S\) (i.e., there is a function from \(W\) to \(S\), but
this function need not be one&ndash;one or even onto). It is crucial
for the analysis of rationality in games that <em>different</em>
possible worlds may be associated with the same strategy profile in
order to represent different states of information for a player.</p>

<h4 id="EpisMode">2.1.1 Epistemic Models</h4>

<p>
Before giving the definition of an epistemic model for a game, we need
some notation. Let \(W\) be a non-empty set, elements of which are
called <em>states</em>, or <em>possible worlds</em>. A subset
\(E\subseteq W\) is called an <em>event</em> or <em>proposition</em>.
Given events \(E\subseteq W\) and \(F\subseteq W\), we use standard
set-theoretic notation for intersection (\(E\cap F\), read
&ldquo;\(E\) and \(F\)&rdquo;), union <span class="nw">(\(E\cup
F\),</span> read &ldquo;\(E\) or \(F\)&rdquo;) and (relative)
complement (\(-{E}\), read &ldquo;not \(E\)&rdquo;).</p>

<p>
We say that an event \(E\subseteq W\) <em>occurs at state \(w\)</em>
when \(w\in E\). Given a set \(X\), we write \(\wp(X)\) for the
<em>powerset of \(X\)</em>&mdash;i.e., the set of all subsets of
\(W\). A set \(\Pi\subseteq \wp(W)\) is called a
<strong>partition</strong> on \(W\) when 1. the sets in \(\Pi\) are
pairwise disjoint: for all \(E, F\in\Pi\), \(E\cap F=\varnothing\);
and 2. the union of the sets in \(\Pi\) is \(W\): \(\bigcup\Pi = W\).
If \(\Pi\) is a partition on \(W\) and \(w\in W\), then \(\Pi(w)\) is
the unique element of \(\Pi\) that contains \(w\).</p>

<div class="indent" id="def21">

<p>
<strong>Definition 2.1 (Epistemic Model)</strong> Suppose that</p>

\[G=\langle N, (S_i)_{i\in N}, (u_i)_{i\in N}\rangle\]

<p>
is a game in strategic form. An <strong>epistemic model for
\(G\)</strong> is a triple \(\langle W, (\Pi_i)_{i\in N
},\sigma\rangle\), where \(W\) is a nonempty set, for each \(i\in N
\), \(\Pi_i\) is a partition on \(W\), and \(\sigma:W\rightarrow
\times_{i\in N} S_i\).</p>
</div>

<p>
The function \(\sigma\) assigns to each state a unique outcome of the
game. If \(\sigma(w) = \sigma(w')\) then the two worlds \(w\) and
\(w'\) agree on the players&rsquo; choices in the game, but,
crucially, the players may have different information at \(w\) and
\(w'\) (i.e., \(w\) and \(w'\) may belong to different elements of
\(\Pi_i\)). So, the possible worlds \(W\) are <em>richer</em> than the
elements of \(S\) (more on this below).</p>

<p>
Given a state \(w\in W\), the element of the partition \(\Pi_i\)
containing \(w\), denoted \(\Pi_i(w)\), is called player \(i\)&rsquo;s
<em>information set at \(w\)</em>. Following standard terminology, if
\(\Pi_i(w)\subseteq E\), we say the player \(i\) <em>knows</em> that
the event \(E\) holds at state \(w\). Formally, for each player \(i\)
we define a knowledge function that assigns to every event \(E\) the
event that the player \(i\) knows that \(E\):</p>

<div class="indent" id="know-function">

<p>
<strong>Definition 2.2 (Knowledge Function)</strong> Let \(\cM=\langle
W,(\Pi_i)_{i\in N },\sigma\rangle\) be an epistemic model for a game.
The <strong>knowledge function</strong> for \(i\in N\) based on
\(\cM\) is the function \(K_i:\wp(W)\rightarrow\wp(W)\) defined as
follow: for all \(E\subseteq W\),</p> 
\[K_i(E)=\{w \mid \Pi_i(w)\subseteq E\}\]

</div>

<div class="indent" id="equivrelations">

<p>
<strong>Remark 2.3</strong> It is often convenient to use
<em>equivalence relations</em> rather than partitions in an epistemic
model. In this case, an epistemic model is a triple \(\langle
W,(\sim_i)_{i\in N },\sigma \rangle\) where \(W\) and \(\sigma\) are
as above and for each \(i\in N \), \(\sim_i\subseteq W\times W\) is a
reflexive, transitive and symmetric relation on \(W\). For each \(w\in
W\) let \([w]_i=\{v\in W \mid w\sim_i v\}\) be the equivalence class
of \(w\). Since there is a correspondence between equivalence
relations and
 partitions,<sup>[<a href="notes.html#note-8" id="ref-8">8</a>]</sup>
 we will abuse notation and use \(\sim_i\) and \(\Pi_i\)
interchangeably. In particular, an alternative definition of \(K_i\)
is \(K_i(E)=\{w\mid [w]_i\subseteq E\}\). That is, \(w\in K_i(E)\)
when \(E\) contains all states equivalent to \(w\) according to
\(\sim_i\).</p>
</div>

<p>
Partitions (or equivalence relations) are intended to represent the
players&rsquo; <em>hard information</em>. It is well-known that the
knowledge function based on an epistemic model satisfies the following
properties (see Rendsvig &amp; Symons 2019 [2021] for a discussion).
For all players \(i\) and events \(E\) and \(F\):</p>

<ul>

<li>(<em>Monotonicity</em>) If \(E\subseteq F\), then
\(K_i(E)\subseteq K_i(F)\)</li>

<li>(<em>Conjunction</em>) \(K_i(E)\cap K_i(F) = K_i(E\cap F)\)</li>

<li>(<em>Truth</em>) \(K_i(E)\subseteq E\)</li>

<li>(<em>Positive Introspection</em>) \(K_i(E) \subseteq
K_i(K_i(E))\)</li>

<li>(<em>Negative Introspection</em>) \(-K_i(E) \subseteq
K_i(-K_i(E))\)</li>
</ul>

<div class="indent" id="doxasticmodels">

<p>
<strong>Remark 2.4</strong> The players&rsquo; beliefs can be
represented by changing the properties of the relations associated
with the players in an epistemic model of a game. For instance, a
<strong>doxastic model</strong> of a game \(G\) is a tuple \(\langle
W,(R_i)_{i\in N },\sigma\rangle\) where \(W\) and \(\sigma\) are
defined as in
 <a href="#def21">Definition 2.1</a>,
 and for each \(i\in N\), \(R_i\subseteq W\times W\) is serial (for
all \(w\in W\) there is a \(v\in W\) such that \(w\mathrel{R_i} v\)),
transitive (for all \(w,v,x\in W\), if \(w\mathrel{R_i} v\) and
\(v\mathrel{R_i}x\), then \(w\mathrel{R_i} x\)) and Euclidean (for all
\(w,v,x\in W\), if \(w\mathrel{R_i} v\) and \(w\mathrel{R_i}x\), then
\(v\mathrel{R_i} x\)). For states \(w,v\in W\) and a player \(i\),
\(w\mathrel{R_i} v\) means that \(v\) is a doxastic possibility for
player \(i\) at state \(w\). Then, a player \(i\)
<strong>believes</strong> an event \(E\subseteq W\) at state \(w\)
when \(\{v\mid w\mathrel{R}_i v\}\subseteq E\). This notion of belief
shares all of the properties of \(K_i\) listed above except
<em>Truth</em> (this is replaced with a weaker assumption of
&ldquo;consistency&rdquo; stating that players do not believe
contradictions).</p>
</div>

<p>
To illustrate an epistemic model of a game, consider the following
coordination game between Ann (<em>a</em>) and Bob (<em>b</em>).</p>

<div class="figure" id="coord-game2">

<table class="avoid-break cell-center cellpad-small-dense centered inner-boxTH nocaption vert-mid">
<thead style="line-height:1.1em">
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th colspan="2"><em>b</em></th> </tr>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody class="cellpad-small">
<tr>
<th rowspan="2"><em>a</em></th>
<th><em>u</em></th>
  <td>3,3</td>
  <td>0,0</td> </tr>
<tr>
<th><em>d</em></th>
  <td>0,0</td>
  <td>1,1</td> </tr> </tbody>
</table>

<p class="center">
<span class="figlabel">Figure 4:</span> A strategic coordination game
between two players <em>a</em> and <em>b</em>.</p>
</div>

<p>
The set of strategy profiles is \(S=\{(u,l),(d,l),(u,r),(d,l)\}\) and
the set of players is \(N =\{a, b\}\). To complete the description of
the game model we must specify the set \(W\) of possible worlds and a
partition on \(W\).</p>

<p>
For simplicity, we start by assuming \(W=S\), so there is exactly one
possible world corresponding to each strategy profile. There are many
different partitions on \(W\) for the players that we can use to
complete the description of this simple epistemic model. However, not
all of the partitions are appropriate for analyzing the <em>ex
interim</em> stage of the decision-making process. For example,
suppose \(\Pi_{a}=\Pi_{b}=\{W\}\) and consider the event
\(U=\{(u,l),(u,r)\}\) representing the event that Ann chooses \(u\).
Notice that \(K_a(U)=\emptyset\) since for all \(w\in W\),
\(\Pi_a(w)\not\subseteq U\), so there is no state where Ann
<em>knows</em> that she chooses \(u\). This means that this model is
appropriate for representing the <em>ex ante</em> rather than the
<em>ex interim</em> stage of decision-making in the game. This is
easily fixed with an additional assumption:</p>

<p class="indent">
An epistemic model of a game \(\langle W, (\Pi_i)_{i\in N },\sigma
\rangle\) is an <strong><em>ex interim</em> epistemic model</strong>
if for all \(i\in N \) and \(w,v\in W\), if \(v\in\Pi_i(w)\) then
\(\sigma_i(w)=\sigma_i(v)\)</p>

<p>
where \(\sigma_i(w)\) is player \(i\)&rsquo;s component of the
strategy profile \(s\in S\) assigned to \(w\) by \(\sigma\). An
example of an <em>ex interim</em> epistemic model with states \(W\)
is:</p>

<ul>

<li>

<p>
\(\Pi_a=\{\{(u,l),(u,r)\},\{(d,l),(d,r)\}\}\) and</p> </li>

<li>

<p>
\(\Pi_b=\{\{(u,l),(d,l)\},\{(u,r),(d,r)\}\}\).</p> </li>
</ul>

<p>
Note that this simply reinterprets the game matrix in
 <a href="#coord-game2">Figure 4</a>
 as an epistemic model where the rows are <em>a</em>&rsquo;s
information sets and the columns are <em>b</em>&rsquo;s information
sets.</p>

<p>
Unless otherwise stated, we assume that our epistemic models are
<em>ex interim</em>. The class of <em>ex interim</em> epistemic models
is very rich with models describing the (hard) information the players
have about their own choices, the (possible) choices of the other
players <em>and</em> the players&rsquo; higher-order (hard)
information (e.g., &ldquo;<em>a</em> knows that <em>b</em> knows
that&hellip;&rdquo;).</p>

<p>
It is standard to use the following diagrammatic representation of an
epistemic model to ease exposition. Suppose that \(W=\{w_1, w_2, w_3,
w_4\}\) and \(\sigma\) is the function where \(\sigma(w_1)=(u, l),
\sigma(w_2)=(d, l), \sigma(w_3)=(u, r),\) and \(\sigma(w_4)=(d, r)\).
Furthermore, the partitions for the players are \(\Pi_a=\{\{w_1,
w_3\}, \{w_2, w_4\}\}\) and \(\Pi_b=\{\{w_1, w_2\}, \{w_3, w_4\}\}\).
This epistemic model is depicted in
 <a href="#fig5">Figure 5</a>
 where the nodes represent the states with the strategy profile
associated with that state displayed inside the node and there is a
(undirected) edge between states \(w_i\) and \(w_j\) when \(w_i\) and
\(w_j\) are in the same partition cell. We use a solid line labeled
with <em>a</em> for <em>a</em>&rsquo;s partition and a dashed line
labeled with <em>b</em> for <em>b</em>&rsquo;s partition. Note that
reflexive edges and edges that can be inferred by transitivity are
typically not represented (so, for instance, there is no edge between
\(w_1\) and itself). The event \(U=\{w_1,w_3\}\) representing the
proposition that &ldquo;<em>a</em> chooses strategy \(u\)&rdquo; is
the shaded gray region.</p>

<div class="figure" id="fig5">
<img alt="a diagram: link to extended description below" src="fig5.png" style="padding-bottom:10px; width:20em" />

<p class="center">
<span class="figlabel">Figure 5</span> [An
 <a href="figdesc.html#fig5">extended description of figure 5</a>
 is in the supplement.]</p>
</div>

<p>
Notice that the following events are true at all states:</p>

<ol>

<li>

<p>
\(-K_b(U) = W\): at each state, &ldquo;<em>b</em> does not know that
<em>a</em> chose action <span class="nobr">\(u\)&rdquo;.</span></p>
</li>

<li>

<p>
\(K_b(K_a(U)\cup K_a(-U)) = W\): at each state, &ldquo;<em>b</em>
knows that <em>a</em> knows whether she has chosen action
\(u\)&rdquo;.</p> </li>

<li>

<p>
\(K_a(-K_b(U))=W\): at each state, &ldquo;<em>a</em> knows that
<em>b</em> does not know that she has chosen action \(u\)&rdquo;.</p>
</li>
</ol>

<p>
In particular, these events are true at state \(w_1\) where <em>a</em>
has chosen \(u\) (i.e., \(w_1\in U\)). The first event makes sense
given the assumptions about the available information at the <em>ex
interim</em> stage: each player knows their own choice but, in
general, not the other players&rsquo; choices. The second event is a
natural assumption about <em>b</em>&rsquo;s information about
<em>a</em>&rsquo;s choice in the game: <em>b</em> has the information
that <em>a</em> has, in fact, settled on <em>some</em> choice. But
what reason does <em>a</em> have to conclude that <em>b</em> does not
know she has chosen \(u\) (the third event)? This is a substantive
assumption about what <em>a</em> knows about what <em>b</em> expects
her to do. Indeed, in certain contexts, <em>a</em> may have very good
reasons to think it is possible that <em>b</em> actually
<em>knows</em> that she chose \(u\). There is an <em>ex interim</em>
epistemic model where this event (\(-K_a(-K_b(U))\)) is true at
\(w_1\), but this requires adding an additional element to \(W\):</p>

<div class="figure" id="fig6">
<img alt="a diagram: link to extended description below" src="fig6.png" style="padding-bottom:10px; width:25em" />

<p class="center">
<span class="figlabel">Figure 6</span> [An
 <a href="figdesc.html#fig6">extended description of figure 6</a>
 is in the supplement.]</p>
</div>

<p>
Notice that since \(\Pi_b(w')=\{w'\}\subseteq U\) we have \(w'\in
K_b(U)\). That is, <em>b</em> knows that <em>a</em> chooses \(u\) at
state \(w'\). Finally, a simple calculation shows that \(w_1\in
-K_a(-K_b(U))\), as desired. Of course, there are other substantive
assumptions built-in to this new model (e.g., at \(w_1\), <em>b</em>
knows that <em>a</em> does not know he will choose \(l\)) which may
require additional modifications (cf. Roy &amp; Pacuit 2013). This
raises a number of interesting conceptual and technical issues which
we discuss in
 <a href="#ParaSelfRefeGameMode">Section 2.4</a>.</p>
 
<h4 id="AddiBeli">2.1.2 Adding Beliefs</h4>

<p>
There are different ways to extend an epistemic model of a game with
the players&rsquo; beliefs. We start by sketching an approach
motivated by research on belief revision (see van Benthem 2011; Baltag
&amp; Renne 2016; and Baltag &amp; Smets 2006 for an overview).</p>

<p>
An <strong>epistemic-plausibility model</strong> of a game \(G =
\langle N, (S_i)_{i\in N}, (u_i)_{i\in N}\rangle\) is a tuple
\(\langle W, (\Pi_i)_{i\in N }, (\succeq_i)_{i\in N },\sigma\rangle\)
where \(W\) is a nonempty finite set of states, \(\langle W,
(\Pi_i)_{i\in N },\sigma\rangle\) is an epistemic model of \(G\) and
for each \(i\in N \), \(\succeq_i\) is a reflexive and transitive
relation on \(W\) satisfying the following
 properties<sup>[<a href="notes.html#note-9" id="ref-9">9</a>]</sup>,
 for all \(w,v\in W\),</p>

<ol type="1">

<li>(plausibility implies possibility) if \(v\succeq_i w\) then \(v\in
\Pi_i(w)\), and</li>

<li>(locally-connected) if \(v\in \Pi_i(w)\) then either \(w\succeq_i
v\) or \(v\succeq_i w\).</li>
</ol>

<p>
The plausibility ordering not only describes the players&rsquo;
beliefs, but also how the players&rsquo; revise their beliefs in the
presence of new information (see Section 4.3 of Baltag &amp; Renne
2016 for a discussion). Different types of belief operators can be
defined using the plausibility ordering. We first need some notation.
First, for an event \(E\subseteq W\), let</p> 
\[\Max_{\succeq_i}(E)=\{v\in W\ |\ v\succeq_i w \text{ for all \(w\in E\) }\}\]

<p>
denote the set of maximal elements of \(E\) according to
\(\succeq_i\). Second, the plausibility relation \(\succeq_i\) can be
lifted to subsets of \(W\) as follows: \(X\succeq_i Y\text{ if, and
only if, \(x\succeq_i y\) for all \(x\in X\) and \(y\in Y\).}\)</p>

<ul>

<li>

<p>
<em>Belief:</em> For any event \(E\subseteq W\), let</p>

<p class="center">
\(B_i(E)=\{w \mid \Max_{\succeq_i}(\Pi_i(w))\subseteq E\}\)</p>

<p>
This is the usual notion of belief which satisfies the standard
properties discussed above (e.g., consistency and positive and
negative introspection).</p> </li>

<li>

<p>
<em>Robust Belief:</em> For any event \(E\subseteq W\), let</p>

<p class="center">
\(\textit{RB}_i(E)=\{w \mid v\in E, \mbox{ for all } v \mbox{ with } v
\succeq_i w\}\)</p>

<p>
So, \(E\) is robustly believed if it is true in all worlds at least as
plausible then the current world. This stronger notion of belief has
also been called <em>certainty</em> by some authors (cf. Leyton-Brown
&amp; Shoham 2008: sec. 13.7).</p> </li>

<li>

<p>
<em>Strong Belief:</em> For any event \(E\subseteq W\), let</p>

\[ \begin{multline}
\SB_i(E)=\{w \mid E \cap \Pi_i(w) \neq \emptyset \text{ and } \\
 (E \cap \Pi_i(w)) \succeq_{i} (- E \cap \Pi_i(w))\} 
\end{multline} \]

<p>
So, \(E\) is strongly believed provided it is epistemically possible
and player \(i\) considers <em>any</em> state in \(E\) more plausible
than <em>any</em> state in the complement of \(E\).</p> </li>

<li>

<p>
<em>Conditional Belief:</em> For events \(E, F\subseteq W\), let</p>

\[B_i^F(E)=\{w \mid \Max_{\succeq_i}(F\cap \Pi_i(w))\subseteq E\} \]

<p>
So, &lsquo;\(B_i^F\)&rsquo; encodes what agent \(i\) will believe upon
receiving (possibly misleading) evidence that \(F\) is true.</p> </li>
</ul>

<p>
The standard approach in epistemic game theory is to represent the
players&rsquo; beliefs using probabilities rather than using
plausibility orderings to represent the players&rsquo;
<em>qualitative</em> beliefs:</p>

<div class="indent avoid-break">

<p>
<strong>Definition 2.5 (Epistemic-Probability Model)</strong> Suppose
that</p> 
\[G = \langle N, (S_i)_{i\in N}, (u_i)_{i\in N}\rangle\]

<p>
is a game in strategic form. An <strong>epistemic-probabilistic
model</strong> for \(G\) is a tuple</p> 
\[ \langle W,(\Pi_i)_{i\in N },(P_i)_{i\in N },\sigma\rangle \]

<p>
where \(W\) is a nonempty finite set of states, \(\langle
W,(\Pi_i)_{i\in N },\sigma\rangle\) is an epistemic model for \(G\)
and for each \(i\in N\), \(P_i:W\rightarrow \Delta(W)\) assigns a
probability
 measure<sup>[<a href="notes.html#note-10" id="ref-10">10</a>]</sup>
 to each element of \(W\) satisfying the following two
assumptions:</p>

<ol>

<li>

<p>
For all \(v\in W\), if \(P_i(w)(v)&gt;0\) then \(P_i(w)=P_i(v)\);
and</p> </li>

<li>

<p>
For all \(v\not\in\Pi_i(w)\), \(P_i(w)(v)=0\).</p> </li>
</ol>

<p>
To simplify notation, for each \(i\in N\) and \(w\in W\), write
\(p_i^w\) for \(P_i(w)\).</p>
</div>

<p>
Property 1 says that if \(i\) assigns a non-zero probability to state
\(v\) at state \(w\) then the player is assigned the same probability
measure at both \(w\) and \(v\). This means that we can view \(P_i\)
as assigning a probability measure to each of \(i\)&rsquo;s
information cells. The second property says that any probability
measure assigned to an information cell must assign probability zero
to all states outside that information cell.</p>

<p>
In many applications, it is useful to view the player&rsquo;s
probability measures associate with each information cell as arising
from a single probability measure through conditionalization. For each
\(i\in N \), player \(i\)&rsquo;s <strong>(subjective) prior
probability</strong> is an element of \(p_i\in\Delta(W)\). Then, an
epistemic-probability model is defined by specifying for each \(i\in N
\), (1) a prior probability \(p_i\in\Delta(W)\) and (2) a partition
\(\Pi_i\) on \(W\) such that for each \(w\in W\), \(p_i(\Pi_i(w)) &gt;
0\). The probability measures for each \(i\in N \) associated with
each possible world are then defined as follows:</p> 
\[ P_i(w)(\cdot)= p_i(\cdot \mid \Pi_i(w)) = \frac{p_i(\cdot\cap \Pi_i(w))}{p_i(\Pi_i(w))} \]

<p>
Of course, the side condition that for each \(w\in W\),
\(p_i(\Pi_i(w)) &gt; 0\) is important since we cannot divide by
zero&mdash;this will be discussed in more detail in later
sections.</p>

<p>
A key observation (assuming that \(W\) is finite) is that for any
epistemic-probability model, for each player, there is a prior
probability (possibly different ones for different players) that
generates the model as described above. This means that an
epistemic-probability model assumes that the players&rsquo; beliefs
about the possible outcome of the game are fixed <em>ex ante</em> with
the <em>ex interim</em> beliefs derived through conditionalization on
the player&rsquo;s <em>hard information</em>. See Morris 1995 for an
extensive discussion of the situation when there is a <em>common</em>
prior (i.e., all players have the same prior).</p>

<p>
As above we can define belief operators, this time specifying the
precise degree to which an agent believes an event:</p>

<ul>

<li>

<p>
<em>Probabilistic belief:</em> For each \(r\in [0,1]\), let</p>

\[(B_i^r(E)=\{w \mid p_i^w(E)\ge r\}\]
 </li>

<li>

<p>
<em>Full belief:</em> \(B_i(E)=B_i^1(E)=\{w \mid p_i^w(E)=1\}\)
<br />
So, full belief is defined as belief with probability 1. This is a
standard assumption in this literature despite a number of well-known
conceptual difficulties (see Genin &amp; Huber 2020 [2022] for an
extensive discussion of this and related issues). It is sometimes
useful to work with the following alternative characterization of
full-belief (giving it a more &ldquo;modal&rdquo; flavor): Player
\(i\) believes \(E\) at state \(w\) provided that the <em>support</em>
of \(i\)&rsquo;s probability at \(w\) is a subset of \(E\). That
is,</p> 
\[ B_i(E)=\{w \mid \text{for all \(v\), if \(p_i^w(v)&gt;0\) then \(v\in E\)}\} \]
 </li>
</ul>

<p>
See Fagin, Halpern, &amp; Megiddo (1990); Heifetz &amp; Mongin (2001);
and Zhou (2010) for a logical analyses of these belief operators.</p>

<p>
We conclude this section with an example of an epistemic-probability
model. Recall the coordination game depicted in
 <a href="#coord-game2">Figure 4</a>:
 there are two actions for player Ann (<em>a</em>), \(u\) and \(d\),
and two actions for Bob (<em>b</em>), \(l\) and \(r\). The set of
strategy profiles is \(\{(u,l), (u,r), (d,l), (d,r)\}\). The
preferences (or utilities) of the players are not important at this
stage since we are only interested in describing the players&rsquo;
knowledge and beliefs.</p>

<div class="figure" id="ep-prob-model">
<img alt="a diagram: link to extended description below" src="fig7.png" style="padding-bottom:10px; width:25em" />

<p class="center">
<span class="figlabel">Figure 7</span> [An
 <a href="figdesc.html#ep-prob-model">extended description of figure 7</a>
 is in the supplement.]</p>
</div>

<p>
The solid lines represent Ann&rsquo;s partition and the dashed lines
represent Bob&rsquo;s partition. We further assume there is a common
prior \(p: W\rightarrow [0, 1]\) with the probabilities assigned to
each state written to the right of the state (e.g.,
\(p(w_2)=\frac{1}{8}\)). Let \(E=\{w_2,w_5,w_6\}\) be an event. Then,
we have</p>

<ul>

<li>

<p>
\(B_a^{\frac{1}{2}}(E)=\{w \mid p(E \mid
\Pi_a(w))=\frac{p(E\cap\Pi_a(w))}{p(\Pi_a(w))}\geq\frac{1}{2}\}\,=\) \(\{w_1,w_2,w_3,
w_4, w_5, w_6\}\): &ldquo;Ann assigns probability at least 1/2 to the
event \(E\) given her information at all states&rdquo;.</p> </li>

<li>

<p>
\(B_b(E)=B_b^1(E)=\{w_2,w_5,w_3,w_6\}\). In particular, note that at
\(w_6\), the agent believes (with probability 1) that \(E\) is true,
but does not <em>know</em> that \(E\) is true as
\(\Pi_b(w_6)\not\subseteq E\). So, there is a distinction between
states the agent considers possible (given their &ldquo;hard
information&rdquo;) and states to which players assign a non-zero
probability.</p> </li>

<li>

<p>
Let \(U=\{w_1,w_2,w_3\}\) be the event that Ann plays \(u\) and
\(L=\{w_1,w_4\}\) the event that Bob plays \(l\). Then, we have</p>

<ul>

<li>

<p>
\(K_a(U)=U\) and \(K_b(L)=L\): Both Ann and Bob know that strategy
they have chosen;</p> </li>

<li>

<p>
\(B_a^{\frac{1}{2}}(L)=U\): At all states where Ann plays \(u\), Ann
believes that Bob plays \(L\) with probability 1/2; and</p> </li>

<li>

<p>
\(B_a(B_b^{\frac{1}{2}}(U))=\{w_1,w_2,w_3\}=U\): At all states where
Ann plays \(u\), she believes that Bob believes with probability 1/2
that she is playing \(u\).</p> </li>
</ul> </li>
</ul>

<h4 id="RatiChoiEpisProbMode">2.1.3 Rational Choice in Epistemic-Probability Models</h4>

<p>
Each state in an epistemic-probability model of a game describes the
players&rsquo; choices and each player&rsquo;s belief about the other
players&rsquo; choices. Suppose that \(\langle N, (S_i)_{i\in N},
(u_i)_{i\in N}\rangle\) is a game in strategic form and \(\langle W,
(\Pi_i)_{i\in N}, (P_i)_{i\in N}, \sigma\rangle\) is an
epistemic-probability model for \(G\). For each strategy profile
\(s\in S\), let \(s_i\) be the action chosen by \(i\) in \(s\) (i.e.,
\(s_i\) is the <em>i</em>th component of \(s\)), and \(s_{-i}\) is the
tuple of the choices in \(s\) of all players except \(i\). Each
strategy profile \(s\) is associated with the following events:</p>

<ul>

<li>\([s_i]=\{w\mid \sigma(w)_i = s_i\}\) is the event that player
\(i\) chooses \(s_i\).</li>

<li>\([s_{-i}]=\{w\mid \sigma(w)_{-i} = s_{-i}\}=\bigcap_{j\ne i}
[s_j]\) is the event that all the players except \(i\) choose their
action in \(s_{-i}\).</li>

<li>\([s] = \{w\mid \sigma(w)=s\} = \bigcap_i [s_i]\) is the event
that the outcome of the game is \(s\).</li>
</ul>

<p>
For each player \(i\), let \(S_{-i} = \times_{j\ne i} S_j\) be all the
possible combinations of choices of all players except \(i\). For each
\(i\in N\) and each \(s_{-i}\in S_{-i}\), \(p_i^w([s_{-i}])\) is the
probability that player \(i\) assigns to the other players choosing
their strategies in \(s_{-i}\). Then, the <strong>expected
utility</strong> of player \(i\)&rsquo;s choice in state \(w\),
denoted \(\EU(i,w)\), is:</p> 
\[\sum_{s_{-i} \in S_{-i}} p_i^w([s_{-i}])u(\sigma(w)_i, s_{-i})\]

<p>
where \(u(\sigma(w)_i, s_{-i})\) is the utility assigned to the
strategy profile \(s^\prime\in S\) where \(s^\prime_i=\sigma(w)_i\)
and \(s^\prime_{-i}=s_{-i}\). Player \(i\) is
<strong>rational</strong> in state \(w\) when the expected utility of
\(i\)&rsquo;s choice in state \(w\) is maximal with respect to
\(i\)&rsquo;s other available choices (cf. Briggs 2014 [2019]). That
is, \(i\) is rational in \(w\) when for all \(s'\in S_i\),</p>

\[\sum_{s_{-i} \in S_{-i}} p_i^w([s_{-i}])u_i(\sigma(w)_i, s_{-i})\ge\sum_{s_{-i} \in S_{-i}} p_i^w([s_{-i}])u_i(s', s_{-i}) \]

<p>
Then, for each \(i\in N\), the event \(\Rat_i = \{w \mid \mbox{ \(i\)
is rational in state } w\}\) is the event that player \(i\) is
rational, and \(\Rat=\bigcap_{i\in N } \Rat_i\) is the event that all
players are rational.</p>

<p>
To illustrate the above definitions, consider the
epistemic-probability model depicted in
 <a href="#ep-prob-model">Figure 7</a>
 for the game depicted in
 <a href="#coord-game2">Figure 4</a>.
 The profile \((u, r)\) corresponds to the following events:</p>

<ul>

<li>\([(u,r)] = \{w_2, w_3\}\)</li>

<li>\([(u,r)_a] = [u] = \{w_1, w_2, w_3\}\)</li>

<li>\([(u,r)_{-a}] = [(u,r)_b]= [r] = \{w_2, w_3, w_5, w_6\}\)</li>
</ul>

<p>
For \(w\in \{w_1, w_2, w_3\}\), we have the following:</p>

\[ \begin{align*}
\EU(\sigma_a(w),w) &amp;= \EU(u, w)\\
 &amp; = p_a^{w}([l])u_a(u,l) + p_a^{w}([r])u_a(u,r) \\
 &amp;= \frac{1}{2} \cdot 3 + \frac{1}{2} \cdot 0 \\
 &amp;= \frac{3}{2} 
\end{align*} \]
 
\[ \begin{align*}
\EU(d,w) &amp;= p_a^{w}([l])u_a(d,l) + p_a^{w}([r])u_a(d,r) \\
 &amp;= \frac{1}{2}\cdot 0 + \frac{1}{2} \cdot 1 \\
 &amp;= \frac{1}{2} 
\end{align*} \]

<p>
For \(w\in \{w_4, w_5, w_6\}\), we have the following:</p>

\[ \begin{align*}
\EU(\sigma_a(w),w) &amp;= \EU(d, w)\\
 &amp; = p_a^{w}([l])u_a(d,l) + p_a^{w}([r])u_a(d,r) \\
 &amp;= \frac{1}{6} \cdot 0 +\frac{5}{6} \cdot 1 \\
 &amp;= \frac{5}{6} 
\end{align*} \]
 
\[ \begin{align*}
\EU(u,w) &amp;= p_a^{w}([l])u_a(u,l) + p_a^{w}([r])u_a(u,r) \\
 &amp;= \frac{1}{6} \cdot 3 +\frac{5}{6} \cdot 0 \\
 &amp;= \frac{1}{2} 
\end{align*} \]

<p>
Thus, we have that</p> 
\[\Rat_a = \{w_1, w_2, w_3, w_4, w_5, w_6\}.\]

<p>
A similar calculation shows that</p> 
\[\Rat_b = \{w_1, w_4, w_3, w_6\}.\]

<p>
Thus,</p> 
\[\Rat = \{w_1, w_4, w_3, w_6\}.\]

<h3 id="TypeSpac">2.2 Type Spaces</h3>

<p>
Type Spaces were initially introduced in Harsanyi&rsquo;s seminal
three-part paper, &ldquo;Games with Incomplete Information Played by
&lsquo;Bayesian&rsquo; Players&rdquo; (1967&ndash;68). Harsanyi aimed
to develop a model for games in which players</p>

<blockquote>

<p>
may lack full information about other players&rsquo; or even their own
payoff functions, about the physical facilities and strategies
available to other players or even to themselves, about the amount of
information the other players have about various aspects of the game
situation, etc. (1967: 163)</p>
</blockquote>

<p>
The primary issue Harsanyi sought to address was the seemingly
&ldquo;infinite regress of reciprocal expectations on the part of the
players&rdquo; (1967: 163). Harsanyi&rsquo;s proposed solution
involved assigning each player a &ldquo;type&rdquo;, which represents
their private information concerning any factors that could impact
their beliefs about the game&rsquo;s payoffs and the types of other
players. The main idea is that each player&rsquo;s type generates a
<em>hierarchy of beliefs</em> describing what that player believes,
believes that the other players&rsquo; believe, and so on. Thus, a
Type Space is a compact representation of players&rsquo; belief
hierarchies associated for a game.</p>

<p>
Consult Siniscalchi (2008) for an overview of Type Spaces and Myerson
(2004) for some historical remarks about Harsanyi&rsquo;s
(1967&ndash;68) groundbreaking contribution.</p>

<h4 id="BeliHier">2.2.1 Belief Hierarchies</h4>

<p>
A key component of an epistemic analysis of a game is the
players&rsquo; hierarchies of beliefs. For a game with a set \(S\) of
strategy profiles, a hierarchy of beliefs for player \(i\) is an
infinite sequence of probability measures \((p_i^1, p_i^2, p_i^3,
\ldots)\) where, for each \(k\ge 1\), \(p_i^k\) represents
<strong>player <em>i</em>&rsquo;s <em>k</em>th-order belief</strong>.
The formal definition of a hierarchy of belief is easiest to explain
for two players. Consider a game for two players <em>a</em> and
<em>b</em> with \(S_a\) the strategy set for <em>a</em> and \(S_b\)
the strategy set for <em>b</em>. Recall that \(S_{-b}=S_a\) and
\(S_{-a}=S_b\). Then, for \(i\in\{a,b\}\), player \(i\)&rsquo;s first-
and second-order beliefs are defined as follows:</p>

<ul>

<li>\(i\)&rsquo;s first-order beliefs are about what the other player
is going to do in the game. Thus, \(p_i^1\) is a probability measure
over the strategies of the other player: \(p_i^1\in
\Delta(S_{-i})\).</li>

<li>\(i\)&rsquo;s second-order beliefs are about what the other player
is going to do in the game and what the other player believes that
\(i\) is going to do in the game. Since the set \(S_{-i}\times
\Delta(S_{i})\) contains all pairs consisting of a choice for the
other player and a first-order belief for the other player, we have
that \(p_i^2\in \Delta(S_{-i}\times \Delta(S_i))\).</li>
</ul>

<p>
Continuing in this manner, player \(i\)&rsquo;s <em>k</em>th-order
belief \(p_i^k\) is defined as follows. For each \(i\in\{a,b\}\), for
all \(k\ge 1\), recursively define sets \(X_{-i}^{k}\) as follows: let
\(X_{-a}^0 = S_{b}\) and \(X_{-b}^0 = S_{a}\) and for \(k\ge 1\),
set</p> 
\[X_{-i}^k = X_{-i}^{k-1} \times \Delta(X_i^{k-1}),\]

<p>
where \(X_{i}^{k-1}\) is the domain of \(-i\)&rsquo;s \((k-1)\)-order
beliefs (e.g., \(S_a\) is the domain of <em>b</em>&rsquo;s first-order
beliefs). Then, we have that \(p_i^k\in \Delta(X_{-i}^{k})\). Thus,
the set of all hierarchies of beliefs for player \(i\) is the set
\(\times_{k\ge 0} \Delta(X_{-i}^k)\).</p>

<p>
It is important to keep in mind the following points regarding the
players hierarchies of beliefs:</p>

<ol>

<li>In the previous section when defining an epistemic-probability
model, we did not define a \(\sigma\)-algebra or mention any other
mathematical assumption needed to formally define probability
measures. This is because we have restricted attention to finite games
and epistemic-probability models with a finite set of states. However,
even if \(X\) is finite, the set \(\Delta(X)\) of probability measures
over \(X\) is infinite (indeed, it is uncountable). Thus, some care is
needed to formally define <em>k</em>th-order beliefs for \(k\geq 2\).
Consult Billingsley (1999) for the mathematical details.</li>

<li>A hierarchy of beliefs does not represent uncertainty about the
players&rsquo; own choices or beliefs. Note that \(p_i^2\in
\Delta(S_{-i}\times \Delta(S_i))\) and so \(p_i^2\) does assign
probability to elements of \(\Delta(S_i)\). However, the elements of
\(\Delta(S_i)\) are interpreted as beliefs of player \(-i\) rather
than a mixed strategy for player \(i\) or beliefs of player \(i\)
about her own strategy (cf.
 <a href="#EpisInteMixeStraEqui">Section 3.3.2</a>).
 The standard assumption in epistemic game theory is that the players
are certain of their own strategy and are fully introspective in the
sense that they are certain of their own beliefs.</li>

<li>There are two ways to define a player&rsquo;s <em>k</em>th-order
belief given a hierarchy of belief. For example, consider \(p_i^2\in
\Delta(S_{-i}\times \Delta(S_i))\). This probability measure generates
a probability over \(S_{-i}\) by taking the <em>marginal</em> with
respect to \(S_{-i}\) (i.e., by finding the expectation of each
element of \(S_{-i}\) with respect to \(\Delta(S_{-i})\)), denoted
\(\textrm{marg}_{S_{-i}} p_i^2\) (i.e., \(\textrm{marg}_{S_{-i}}
p_i^2\in \Delta(S_{-i})\)). A natural assumption is to require that
\(\textrm{marg}_{S_{-i}} p_i^2\) and \(p_i^1\) are the same
probability measure. More generally, say that a hierarchy of belief
\((p_i^1, p_i^2, \ldots)\) is <strong>coherent</strong> when for all
\(k\geq 2\), \(\textrm{marg}_{X^{k-1}_{-i}}p_i^k = p_i^{k-1}\).</li>

<li>Given the previous comment, one may wonder why \(p_i^2\) is
defined to be a probability over the \(S_{-i}\times \Delta(S_i)\)
rather than using the simpler definition \(p_i^2\in
\Delta(\Delta(S_i))\). The main observation is that in order to assess
the probability that \(i\) assigns to player \(-i\) being rational, we
need \(i\)&rsquo;s probability that \(-i\) will choose a strategy
<em>when</em> \(-i\) has such-and-such belief. It is not enough to
represent \(i\)&rsquo;s belief about what \(-i\) is going to do (an
element of \(\Delta(S_{-i})\)) and separately what \(i\) believes that
\(-i\) believes that \(i\) is going to do (an element of
\(\Delta(\Delta(S_i))\)). A belief about rationality involves beliefs
about the correct matching of choices with beliefs.</li>
</ol>

<p>
Rather than using a set of hierarchies of beliefs as a model of a
game, much of the epistemic game theory literature uses a model,
called a type space, introduced by Harsanyi in his seminal paper
(1967&ndash;68) to represent the players&rsquo; hierarchies of beliefs
(consult Brandenburger &amp; Dekel 1993; Mertens &amp; Zamir 1985; and
Perea &amp; Kets 2016, for an extended discussion about representing
hierarchies of beliefs in Harsanyi&rsquo;s model).</p>

<h4 id="QualTypeSpac">2.2.2 Qualitative Type Spaces</h4>

<p>
We start by defining a non-probabilistic version of a Type Space.</p>

<div class="indent" id="qual-type">

<p>
<strong>Definition 2.6 (Qualitative Type Space)</strong> Suppose
that</p> 
\[G=\langle N, (S_i)_{i\in N}, (u_i)_{i\in N}\rangle\]

<p>
is a game in strategic form. A <strong>qualitative type space</strong>
for \(G\) is a tuple \(\langle S, (T_i)_{i\in N}, (\lambda_i)_{i\in
N}\rangle\) where for each \(i\in N \), \(T_i\) is a nonempty set
(elements of which are called types), \(S\) is the set of strategy
profiles in \(G\), and</p> 
\[ \lambda_i:T_i\rightarrow \wp(T_{-i} \times S_{-i}). \]

<p>
where \(T=\times_i T_i\), \(T_{-i}=\times_{j\ne i} T_j\), \(S=\times_i
S_i\), and \(S_{-i}=\times_{j\ne i} S_j\).</p>
</div>

<p>
So, for each player \(i\in N\), the \(\lambda_i\) function assigns
each type \(t\in T_i\) a set of tuples describing both the types and
the choices of the other players.</p>

<p>
Consider the initial example of the coordination game between Ann
(<em>a</em>) and Bob (<em>b</em>) pictured in
 <a href="#coord-game-first">Figure 1</a>.
 In this case, the set of strategy profiles is
\(S=\{(u,l),(d,l),(u,r),(d,r)\}\). Then, \(S_{-b} = S_a=\{u,d\}\) and
\(S_{-a}=S_b = \{l,r\}\). Suppose that there are two types for each
player: \(T_a=\{t_1,t_2\}\) and \(T_b=\{t'_1,t'_2\}\). Suppose that
the functions \(\lambda_a\) and \(\lambda_b\) are defined as
follows:</p>

<ul>

<li>\(\lambda_a:T_a\rightarrow \wp(T_b\times S_b)\) is the function
where
<br />
\(\lambda_a(t_1) = \{(t'_1, l), (t'_2, l)\}\) and \(\lambda_a(t_2) =
\{(t'_2, l)\}\)</li>

<li>\(\lambda_b:T_b\rightarrow \wp(T_a\times S_a)\) is the function
where
<br />
\(\lambda_b(t'_1) = \{(t_1, u)\}\) and \(\lambda_b(t'_2) = \{(t_2,
d)\}\)</li>
</ul>

<p>
A convenient way to represent these functions is as follows:</p>

<div class="figure" id="fig8-qualitative-type-space">

<div class="centered" style="padding-bottom:10px;max-width:22em">

<div style="width:10em;display: inline-block;">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid">
<thead>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody>
<tr>
<th rowspan="2">\(\lambda_a(t_{1})\)</th>
<th>\(t'_1\)</th>
  <td>1</td>
  <td>0</td> </tr>
<tr>
<th>\(t'_2\)</th>
  <td>1</td>
  <td>0</td> </tr> </tbody>
</table>
</div>

<div style="width:10em;display: inline-block">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid">
<thead>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody>
<tr>
<th rowspan="2">\(\lambda_a(t_{2})\)</th>
<th>\(t'_1\)</th>
  <td>0</td>
  <td>0</td> </tr>
<tr>
<th>\(t'_2\)</th>
  <td>1</td>
  <td>0</td> </tr> </tbody>
</table>
</div>

<div style="width:10em;display: inline-block">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid">
<thead>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>u</em></th>
<th><em>d</em></th> </tr> </thead>
<tbody>
<tr>
<th rowspan="2">\(\lambda_b(t'_{1})\)</th>
<th>\(t_1\)</th>
  <td>1</td>
  <td>0</td> </tr>
<tr>
<th>\(t_2\)</th>
  <td>0</td>
  <td>0</td> </tr> </tbody>
</table>
</div>

<div style="width:10em;display: inline-block">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid">
<thead>
<tr>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td><em>u</em></td>
  <td><em>d</em></td> </tr> </thead>
<tbody>
<tr>
<th rowspan="2">\(\lambda_b(t'_{2})\)</th>
<th>\(t_1\)</th>
  <td>0</td>
  <td>0</td> </tr>
<tr>
<th>\(t_2\)</th>
  <td>0</td>
  <td>1</td> </tr> </tbody>
</table>
</div>
</div>

<p class="center">
<span class="figlabel">Figure 8</span></p>
</div>

<p>
where for each \(i\in \{a, b\}\) and for each \(t\in T_i\), a 1 in the
\((t',s)\) entry of the above matrices means that
\((t',s)\in\lambda_i(t)\). Before giving the formal definition of
beliefs in a qualitative type space, we make the following
observations about the above type structure:</p>

<ol>

<li>

<p>
Both of Ann&rsquo;s types believes that Bob will choose \(l\): In both
matrices, \(\lambda_a(t_1)\) and \(\lambda_a(t_2)\), the only places
where a 1 appears is under the \(l\) column.</p> </li>

<li>

<p>
The type \(t_2\) believes that Bob believes that she will choose
\(d\):The only row assigned a 1 by the type \(t_2\) is \(t'_2\), and
the only column assigned a 1 by \(t'_2\) is \(d\).</p> </li>

<li>

<p>
Both of Bob&rsquo;s types believe that Ann believes that he will
choose \(l\). The only row assigned a 1 by \(t'_1\) is \(t_1\) and the
only row assigned a 1 by \(t'_2\) is \(t_2\), and, as noted in item 1,
both of Ann&rsquo;s types believe that Bob will choose \(l\).</p>
</li>
</ol>

<p>
These informal observations can be made more precise using the
following notions: Fix a qualitative type space \(\langle (T_i)_{i\in
N}, (\lambda_i)_{i\in N}, S\rangle\) for a game \(G=\langle N,
(S_i)_{i\in N}, (u_i)_{i\in N}\rangle\).</p>

<ul>

<li>

<p>
A <strong>(global) state</strong>, or <strong>possible world</strong>,
is a tuple \((t_1,t_2,\ldots,t_n,s)\) where \(t_i\in T_i\) for each
\(i\in N\) and \(s\in S\). It is convenient to write a possible world
as: \((t_1,s_1,t_2,s_2,\ldots,t_n,s_n)\) where \(s_i\in S_i\) for each
\(i\in N\).</p> </li>

<li>

<p>
Type spaces describe the players beliefs about the other
players&rsquo; choices (and beliefs), so an <em>event</em> needs to be
relativized to a player. An <strong>event for player \(i\)</strong> is
a subset of \(\times_{j\ne i}T_j\times S_{-i}\).</p> </li>

<li>

<p>
Suppose that \(E\) is an event for player \(i\), then we say that
<strong>\(i\) believes \(E\) at \((t_1,t_2,\ldots,t_n,s)\)</strong>
provided that \(\lambda(t_i)\subseteq E\).</p> </li>
</ul>

<p>
In the example above, an event for Ann is a subset of \(T_b\times
S_b\) and an event for Bob is a subset of \(T_a\times S_a\). Then, we
have the following formal versions of the above informal observations
about the qualitative type space in
 <a href="#fig8-qualitative-type-space">Figure 8</a>.</p>
 
<ol>

<li>

<p>
Let \(L=\{(t'_1, l), (t'_2, l)\}\) be the event that Bob chooses
strategy \(l\). Then, since</p> 
\[\lambda_a(t_1) = \{(t'_1, l), (t'_2, l)\} \subseteq L\]

<p>
and</p> 
\[\lambda_a(t_2) = \{(t'_2, l)\}\subseteq L,\]

<p>
we have that</p> 
\[B_a(L)=\{(t_1, u), (t_1, d), (t_2, u), (t_2,d)\}\]
 </li>

<li>

<p>
Let \(D=\{(t_1, d), (t_2, d)\}\) be the event that Ann chooses
strategy \(d\). Then</p> 
\[B_b(D)=\{(t'_2, l), (t'_2, r)\}.\]

<p>
Since</p> 
\[\lambda_a(t_1)=\{(t'_1, l), (t'_2, l)\}\not\subseteq B_b(D)\]

<p>
and</p> 
\[\lambda_a(t_2)=\{(t'_2, l)\}\subseteq B_b(D),\]

<p>
we have that</p> 
\[B_a(B_b(D)) = \{(t_2,u), (t_2, d)\}.\]
 </li>

<li>

<p>
Recall that \(L=\{(t'_1, l), (t'_2, l)\}\) and</p> 
\[B_a(L) = \{(t_1, u), (t_1, d), (t_2, u), (t_2,d)\}.\]

<p>
Then, it is straightforward to check that</p> 
\[B_b(B_a(L)) = \{(t'_1, l), (t'_2, r), (t'_2, l), (t'_2, r)\}\]
 </li>
</ol>

<p>
Note that the event \(B_a(L)\) is an event for Bob and the event
\(B_b(D)\) is an event for Ann.</p>

<h4 id="ProbTypeSpac">2.2.3 Probabilistic Type Spaces</h4>

<p>
A small change to the definition of a qualitative type space
 (<a href="#qual-type">Definition 2.6</a>)
 allows us to represent <em>probabilistic</em> beliefs:</p>

<div class="indent" id="type">

<p>
<strong>Definition 2.7 (Type Space)</strong> Suppose that \(G=\langle
N, (S_i)_{i\in N}, (u_i)_{i\in N}\rangle\) is a game in strategic
form. A <strong>type space</strong> for \(G\) is a tuple \(\langle S,
(T_i)_{i\in N}, (\lambda_i)_{i\in N}\rangle\) where for each \(i\in N
\), \(T_i\) is a nonempty set (elements of which are called types),
\(S\) is the set of strategy profiles in \(G\), and</p> 
\[ \lambda_i:T_i\rightarrow \Delta(\times_{j\ne i} T_j\times S_{-i}). \]

</div>

<p>
Types and their associated image under \(\lambda_i\) encode the
players&rsquo; hierarchies of beliefs. For instance, if \(t\in T_i\),
then \(\lambda_i(t)\) is a probability on \(T_{-i}\times S_{-i}\), and
so \(\textrm{marg}_{S_{-i}}\lambda_i(t)\in \Delta(S_{-i})\) is
\(i\)&rsquo;s first-order belief. For a type \(t\in T_i\), let
\(p^1_t\) denote the first-order belief for player \(i\) associated
with \(t\) (i.e., \(p^1_t = \textrm{marg}_{S_{-i}} \lambda_i(t)\)). We
illustrate how to define higher-order beliefs with an example.</p>

<h5 id="ExTypeSpace">Example 2.8</h5>

<p>
Returning again to our running example games where Ann (<em>a</em>)
has two available actions \(\{u,d\}\) and Bob (<em>b</em>) has two
available actions \(\{l,r\}\). Suppose that there is one type for Ann
\(T_a=\{t_1\}\) and two types for Bob \(T_b=\{t_1', t'_2\}\) with the
definition of \(\lambda_a\) and \(\lambda_b\) given in the following
matrices:</p>

<div class="figure" id="fig11">

<table class="cell-center cellpad-small-dense centered inner-boxTH nocaption vert-mid">
<thead>
<tr>
  <td>&nbsp;</td>
  <td>&nbsp;</td>
  <td><em>l</em></td>
  <td><em>r</em></td> </tr> </thead>
<tbody>
<tr>
<th rowspan="2">\(\lambda_a(t_1)\)</th>
<th>\(t^\prime_1\)</th>
  <td>0.5</td>
  <td>0</td> </tr>
<tr>
<th>\(t^\prime_2\)</th>
  <td>0.4</td>
  <td>0.1</td> </tr> </tbody>
</table>

<p class="center">
<span class="figlabel">Figure 9:</span> Ann&rsquo;s beliefs about
Bob</p>
</div>

<div class="figure">

<div class="centered" style="padding-bottom:10px;width:22em;">

<div style="width:10em; display: inline-block;">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid">
<thead>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>u</em></th>
<th><em>d</em></th> </tr> </thead>
<tbody>
<tr>
<th>\(\lambda_b(t^\prime_1)\)</th>
<th>\(t_1\)</th>
  <td>1</td>
  <td>0</td> </tr> </tbody>
</table>
</div>

<div style="display: inline-block;width:10em">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid">
<thead>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>u</em></th>
<th><em>d</em></th> </tr> </thead>
<tbody>
<tr>
<th>\(\lambda_b(t^\prime_2)\)</th>
<th>\(t_1\)</th>
  <td>0.2</td>
  <td>0.8</td> </tr> </tbody>
</table>
</div>
</div>

<p class="center">
<span class="figlabel">Figure 10:</span> Bob&rsquo;s belief about
Ann</p>
</div>

<p>
The first- and second-order beliefs for the players encoded in the
above type space are:</p>

<ul>

<li>

<p>
For Ann, we have that \(p^1_{t_1}\) is the probability with</p>

\[p^1_{t_1}(l) = \lambda_a(t_1)(l,t^\prime_1) + \lambda_a(t_1)(l,t^\prime_2) = 0.5 + 0.4 = 0.9\]

<p>
and</p> 
\[p^1_{t_1}(r) = \lambda_a(t_1)(r,t^\prime_1) + \lambda_a(t_1)(r,t^\prime_2) = 0 + 0.1 = 0.1.\]

<p>
For Bob, we have that \(p^1_{t^\prime_1}\) is the probability with
\(p^1_{t^\prime_1}(u) = 1.0\) and \(p^1_{t^\prime_1}(d) = 0.0\) and
\(p^1_{t^\prime_2}\) is the probability with \(p^1_{t^\prime_2}(u) =
0.2\) and \(p^1_{t^\prime_2}(d) = 0.8\)</p> </li>

<li>

<p>
Ann considers both of Bob&rsquo;s types equally probable (0.5):
Ann&rsquo;s probability that Bob is of type \(t^\prime_1\) is</p>

\[\lambda_a(t_1)(l, t^\prime_1) + \lambda_a(t_1)(r, t^\prime_1) = 0.5 + 0 = 0.5\]

<p>
and Ann&rsquo;s probability that Bob is of type \(t^\prime_2\) is</p>

\[\lambda_a(t_1)(l, t^\prime_2) + \lambda_a(t_1)(r, t^\prime_2) = 0.4 + 0.1 = 0.5.\]

<p>
This means that she believes that it is equally likely that Bob is
certain she plays \(u\) as Bob believing with probability 0.2 that she
plays \(u\). More precisely, the second-order probability for \(t_1\),
denoted \(p^2_{t_1}\), is defined as follows:</p>

<ul>

<li>\(p^2_{t_1}(l, p^1_{t^\prime_1}) = 0.5\),</li>

<li>\(p^2_{t_1}(r, p^1_{t^\prime_1}) = 0.0\),</li>

<li>\(p^2_{t_1}(l, p^1_{t^\prime_2}) = 0.4\), and</li>

<li>\(p^2_{t_1}(u, p^1_{t^\prime_2}) = 0.1\).</li>
</ul> </li>

<li>Since there is a unique type for Ann, Bob is certain that Ann is
of type \(t_1\), and so Bob&rsquo;s second-order (and higher-order)
probabilities are based only on his first-order beliefs.</li>
</ul>

<p>
The above type space is a very compact description of the
players&rsquo; beliefs. It is not hard to see that every type space
can be transformed into an epistemic-probability model. Suppose that
\(\cT= \langle S, (T_i)_{i\in N}, (\lambda_i)_{i\in N}\rangle\) is a
type space for a game \(G=\langle N, (S_i)_{i\in N}, (u_i)_{i\in
N}\rangle\). We can transform \(\cT\) into the epistemic-probability
model \(\cM^\cT = \langle W^\cT, (\sim^\cT_i)_{i\in N},
(P^\cT_i)_{i\in N}\rangle\), where</p>

<ul>

<li>\(W^\cT = T\times S\), where \(T=\times_{i\in N}T_i\) and
\(S=\times_{i\in N} S_i\)</li>

<li>For \((t,s), (t', s')\in W^\cT\), we have \((t,s)\sim^\cT_i
(t',s')\) if and only if \(t_i=t'_i\) and \(s_i = s'_i\)</li>

<li>

<p>
\(P^\cT_i\) is the function where for \((t,s)\in W^\cT\),
\(P^\cT_i(t,s)\) is the following probability:</p> 
\[P^\cT_i(t,s)(t',s') = \begin{cases}
\lambda_i(t)(t'_{-i}, s'_{-i}) &amp; \mbox{ if \((t',s')\in [(t,s)]_i\)}\\
 0 &amp; \mbox{ otherwise} 
\end{cases}\]
 </li>
</ul>

<p>
It is immediate that \(\cT\) and \(\cM^\cT\) are equivalent game
models in the sense that they generate the same hierarchies of
beliefs. To illustrate the above construct, the following
epistemic-probability model is \(\cM^\cT\), where \(\cT\) is the type
space from the above
 <a href="#ExTypeSpace">Example 2.8</a>.
 (In the the figure below, rather than representing the function
\(P_i\) for each player \(i\in \{a,b\}\), prior probabilities \(p_a\)
and \(p_b\) are given and the functions \(P_a\) and \(P_b\) are
derived by conditioning as explained in
 <a href="#AddiBeli">Section 2.1.2</a>.)</p>
 
<div class="figure wide">
<img alt="a diagram: link to extended description below" src="fig11.png" style="padding-bottom:10px; width:100%" />

<p class="center">
<span class="figlabel">Figure 11</span> [An
 <a href="figdesc.html#fig11">extended description of figure 11</a>
 is in the supplement.]</p>
</div>

<p>
Some simple (but instructive!) calculations shows that the above
epistemic-probability model describes the same beliefs as the type
space from the above
 <a href="#ExTypeSpace">Example 2.8</a>.
 Constructing and equivalent type space from an epistemic-probability
model is more complicated. See Galeazzi &amp; Lorini 2016 and
Bjorndahl &amp; Halpern 2017 for a discussion (cf. also Fagin,
Geanakoplos, et al. 1999; Brandenburger &amp; Dekel 1993; Heifetz
&amp; Samet 1998; and Klein &amp; Pacuit 2014 for further discussions
about the relationship between type spaces and epistemic-probability
models).</p>

<h4 id="RatiChoiTypeSpac">2.2.4 Rational Choice in Type Spaces</h4>

<p>
A state in a type space is a pair \((t, s)\) where \(t\) lists the
type for each player and \(s\) is a strategy profile in the underlying
game. Suppose that</p> 
\[G=\langle N, (S_i)_{i\in N}, (u_i)_{i\in N}\rangle\]

<p>
is a game in strategic form and</p> 
\[\langle S, (T_i)_{i\in N}, (\lambda_i)_{i\in N}\rangle\]

<p>
is a type space for \(G\).</p>

<p>
For each state \((t,s)\), for each player \(i\in N\), \(t\in T_i\),
player \(i\)&rsquo;s first-order belief \(p^1_{t_i}\in
\Delta(S_{-i})\) is defined as \(p^1_{t_i} = \textrm{marg}_{S_{-i}}
\lambda(t_i)\). When the sets of types and strategies are finite, this
means that \(p^1_{t_i}\) is defined as follows:</p> 
\[ p^1_{t_i}(s_{-i})= \sum_{t_{-i}\in T_{-i}}\lambda_i(t_i)(s_{-i},t_{-i}) \]

<p>
Given a state \((t,s)\), we say that \(i\) is rational in \((t,s)\)
when \(s_i\) maximizes player \(i\)&rsquo;s expected utility with
respect to \(i\)&rsquo;s first-order beliefs \(p_{t_i}^1\) (for a
strategy \(x\) and probability \(p\), we write \(\EU(x, p)\) for the
expected utility of \(x\) with respect to \(p\)). That is, \(i\) is
rational in \((t,s)\) when for all \(s'\in S_i\),</p> 
\[\begin{align*}
\EU(s_i, p^1_{t_i}) &amp; = \sum_{s'_{-i} \in S_{-i}} p^1_{t_i}(s'_{-i})u_i(s_i, s'_{-i})\\
 &amp; \ge\sum_{s'_{-i} \in S_{-i}} p^1_{t_i}(s'_{-i})u_i(s', s'_{-i}) \\
 &amp; = \EU(s', p^1_{t_i}) \\
 
\end{align*} \]

<p>
Let \(\Rat\subseteq T\times S\) be the set of states in which all
players are rational:</p> 
\[\Rat = \{(t,s) \mid (t,s)\in T\times S\mbox{ and \(i\) is rational in \((t,s)\) for all \(i\in N\) }\}\]

<p>
Given the set \(\Rat\) of states in which all players are rational, we
define the following sets:</p>

<ul>

<li>\(\Rat_i = \{(t_i, s_i)\mid (t,s)\in \Rat\}\)</li>

<li>\(\Rat_{-i} = \{(t_{-i}, s_{-i})\mid (t,s)\in \Rat\}\)</li>
</ul>

<p>
To illustrate the above definitions, consider the game in
 <a href="#coord-game2">Figure 4</a>
 and the type space from the above
 <a href="#ExTypeSpace">Example 2.8</a>.
 The following calculations show that \(u\) maximizes expected utility
for player <em>a</em> given her beliefs defined by \(t_1\):</p>

\[ \begin{align*}
\EU(u,p^1_{t_1}) &amp;= p^1_{t_a}(l)u_a(u,l) + p^1_{t_a}(r)u_a(u,r)\\
 &amp; = [\lambda_a(t_1)(l, t^\prime_1) + \lambda_a(t_1)(l ,t^\prime_2)]\cdot u_a(u,l) \\
 &amp;\qquad {} + [\lambda_a(t_1)(r, t^\prime_1) + \lambda_a(t_1)(r,t^\prime_2)] \cdot u_a(u,r) \\
 &amp;= (0.5 + 0.4) \cdot 3 + (0 + 0.1)\cdot 0 \\
 &amp;= 2.7 
\end{align*} \]
 
\[ \begin{align*}
\EU(d,p^1_{t_1}) &amp;= p^1_{t_a}(l)u_a(d,l) + p_{t_a}(r)u_a(d,r)\\
 &amp; = [\lambda_a(t_1)(l,t^\prime_1) + \lambda_a(t_1)(l,t^\prime_2)]\cdot u_a(d,l) \\
 &amp; \qquad {} + [\lambda_a(t_1)(r, t^\prime_1) + \lambda_a(t_1)(r, t^\prime_2)] \cdot u_a(d,r) \\
 &amp;= (0.5 + 0.4) \cdot 0 + (0 + 0.1)\cdot 1 \\
 &amp;= 0.1 
\end{align*}\]

<p>
Since \(\EU(u, p^1_{t_1}) &gt; \EU(d, p^1_{t_1})\), \(u\) maximizes
expected utility for the type \(t_1\). Similar calculations show that
\(\Rat = \{(t_1, t^\prime_1, u, l), (t_1, t^\prime_2, u, r)\}.\)</p>

<h3 id="CommKnowBeli">2.3 Common Knowledge and Belief</h3>

<p>
A standard assumption in game theory is that the players in a game are
rational and that it is commonly known or commonly believed that the
players are rational. Both game theorists and logicians have
extensively discussed different notions of knowledge and belief for a
group, such as common knowledge and belief. For more information and
pointers to the relevant literature, see Vanderschraaf &amp; Sillari
(2005 [2022]); Fagin, Halpern, et al. (1995: ch. 6); and Lederman
(2018a).</p>

<p>
Suppose that \(G\) is a game with players \(N\) and that \((K_i)_{i\in
N}\) are knowledge operators from some epistemic(-probability) model
for \(G\). We define the following notions of group knowledge:</p>

<ul>

<li>

<p>
An event \(E\) is <strong>mutual knowledge</strong> if all of the
players know that \(E\): For each event \(E\) let</p> 
\[ K(E)\ \ :=\ \ \bigcap_{i\in N}K_i(E). \]

</li>

<li>

<p>
For \(k\ge 0\), the <strong><em>k</em>th-level knowledge</strong> of
an event \(E\) is defined recursively as follows:</p> 
\[ K^0(E)=E \qquad{\text{and for \(k\ge 1\),}}\quad K^k(E)=K(K^{k-1}(E)) \]

</li>

<li>

<p>
If \(E\) is <strong>common knowledge</strong> for a group of players,
then not only does every player know that \(E\) is true, but this fact
is completely transparent to all the players. Then, following Aumann
(1976), <strong>common knowledge</strong> of \(E\) is defined as the
following infinite conjunction:</p> 
\[ \CK(E)=\bigcap_{k\ge 0}K^k(E) \]

<p>
Unpacking the definitions, we have</p> 
\[ \CK(E)=E\cap K(E) \cap K(K(E)) \cap K(K(K(E)))\cap \cdots \]

<p>
Consult Barwise 1988, Heifetz 1999a, Cubitt &amp; Sugden 2014, and
Lederman 2018b for a discussion of alternative definitions of common
knowledge.</p> </li>
</ul>

<p>
The approach to defining common knowledge outlined above can be viewed
as a recipe for defining common (robust/strong) belief (simply replace
the knowledge operators \(K_i\) with the appropriate belief operator).
For instance, the definition of common belief in a type space follows
a similar pattern.</p>

<p>
Suppose that \(G=\langle N, (S_i)_{i\in N}, (u_i)_{i\in N}\rangle\) is
a game in strategic form and \(\langle S, (T_i)_{i\in N},
(\lambda_i)_{i\in N}\rangle\) is a type space for \(G\). Suppose that
\(i\in N\) and that \(E\subseteq S_{-i}\times T_{-i}\) is an event for
player \(i\). We say that a type for player \(i\)
<strong>believes</strong> that \(E\) when the type assigns probability
1 to \(E\) (in the epistemic game theory literature, it is standard to
use &ldquo;belief&rdquo; for probability 1 rather than
&ldquo;certainty&rdquo;). Let \(B_i(E)\) be the set of strategy-type
pairs for player \(i\) such that the type assigns probability 1 to
\(E\):</p> 
\[B_i(E) = \{(s_i, t_i)\mid (s,t)\in S\times T\mbox{ and } \lambda_i(t_i)(E) = 1\}\]

<p>
Suppose that \((E_i)_{i\in N}\) is a sequence of event where for each
\(i\in N\), \(E_i\subseteq S_{-i}\times T_{-i}\). Let \(E=\times_{i\in
N} E_i\) and \(E_{-i} = \times_{j\ne i} E_j\). Then, <strong>mutual
belief</strong> of \(E\), denoted \(B(E)\), is defined as follows:</p>

\[B(E) = \times_{i\in N}B_i(E_{-i})\]

<p>
Note that \(B(E)_{-i} = \times_{j\ne i}B_j(E_{-j})\) and, after
applying the obvious transformation, we can treat this set as a subset
of \(S_{-i}\times T_{-i}\). Thus, we can abuse notation and write
\(B_i(B(E)_{-i})\) for the set of strategy-type pairs such that the
type assigns probability 1 to the mutual belief of \(E\). The
<strong><em>k</em>th-level belief</strong> of \(E\) is defined as
above:</p> 
\[ B^1(E)=B(E) \qquad{\text{and for \(k\geq 2\),}}\quad B^k(E)=B(B^{k-1}(E)) \]

<p>
Finally, <strong>common belief</strong> of \(E\) is also defined as
above:</p> 
\[\CB(E)=\bigcap_{k\geq 1}B^k(E)\]

<p>
See Bonanno (1996) and Lismont &amp; Mongin (1994, 2003) for a
discussion of the logic of common belief. Although we do not discuss
it in this entry, a probabilistic variant of common belief was
introduced by Monderer &amp; Samet (1989).</p>

<h3 id="ParaSelfRefeGameMode">2.4 A Paradox of Self-Reference in Game Models</h3>

<p>
The first step in any epistemic analysis of a game is to describe the
players&rsquo; knowledge and beliefs using (a variant of) one of the
models introduced in
 <a href="#GameMode">Section 2</a>.
 As we noted in
 <a href="#EpisMode">Section 2.1.1</a>,
 there will be statements about what the players know and believe
about the game situation and about each other that are commonly known
in some models but not in others:</p>

<blockquote>

<p>
In any particular [type] structure, certain beliefs, beliefs about
belief, &hellip;, will be present and others won&rsquo;t be. So, there
is an important implicit assumption behind the choice of a [type]
structure. This is that it is &ldquo;transparent&rdquo; to the players
that the beliefs in the type structure&mdash;and only those
beliefs&mdash;are possible &hellip;.The idea is that there is a
&ldquo;context&rdquo; to the strategic situation (e.g., history,
conventions, etc.) and this &ldquo;context&rdquo; causes the players
to rule out certain beliefs. (Brandenburger &amp; Friedenberg 2010:
801)</p>
</blockquote>

<p>
Ruling out certain configurations of beliefs constitute
<em>substantive assumptions</em> about the players&rsquo; reasoning
during the decision making process. In other words, substantive
assumptions are about what the players know and believe about the game
and each other over and above what is intrinsic to the mathematical
representation of the players&rsquo; knowledge and beliefs. It is not
hard to see that one always finds substantive assumptions in finite
game models: Given a countably infinite set of basic facts (e.g.,
atomic propositions in a propositional language), in any finite game
model it will be common knowledge that some logically consistent
combination of these basic facts are not realized, and <em>a
fortiori</em> for logically consistent configurations of
(higher-order) beliefs/knowledge about these basic facts. On the other
hand, monotonicity of the belief/knowledge operator is a typical
example of an assumption that is <em>not</em> substantive. More
generally, there are no models of games, as we defined in
 <a href="#GameMode">Section 2</a>,
 where it is not common knowledge that the players believe all the
logical consequences of their
 beliefs.<sup>[<a href="notes.html#note-11" id="ref-11">11</a>]</sup></p>
 
<p>
Are there models that make no, or at least as few as possible,
substantive assumptions? This question has been extensively discussed
in epistemic game theory&mdash;see, for instance, Dekel &amp; Gul
(1997), Aumann (1999a, 1999b), and Samuelson (1992). Intuitively, a
model without any substantive assumptions must represent all possible
states of (higher-order) knowledge and beliefs of the players. Whether
such a model exists will depend, in part, on how the players&rsquo;
informational attitudes are represented&mdash;e.g., as probability
measures or set-valued knowledge/belief functions.</p>

<p>
There are different ways to understand what it means for a model to
minimize the substantive assumptions about what the players know and
believe about each other and the game. We do not attempt a complete
overview of this interesting literature here (see Brandenburger &amp;
Keisler (2006: sec. 11) and Siniscalchi (2008: sec. 3) for discussion
and pointers to the relevant results). One approach considers the
space of all (Harsanyi type-/epistemic-/epistemic-probability-) models
and tries to find a single model that, in some suitable sense,
&ldquo;contains&rdquo; all other models. Such a model, often called
called a <em>universal structure</em> (or a <em>terminal object</em>
in the language of category theory), if it exists, incorporates any
substantive assumption that an analyst can imagine. A universal
structure has been shown to exists for probabilistic type spaces
(Mertens &amp; Zamir 1985; Brandenburger &amp; Dekel 1993). However,
there is no similar universal structure for epistemic models (Heifetz
&amp; Samet 1998; Fagin, Geanakoplos, Halpern, &amp; Vardi 1999; Meier
2005), with some qualifications regarding the language that is used to
describe the players&rsquo; knowledge (Heifetz 1999b; Roy &amp; Pacuit
2013).</p>

<p>
A second approach takes an internal perspective by asking whether,
<em>for a fixed set of states or types</em>, the players are making
any substantive assumptions about what their opponents know or
believe. The idea is to identify (in a given model) a set of possible
<em>conjectures</em> about the players. For example, in an epistemic
model based on a set of states \(W\) this might be the set of all
subsets of \(W\) or the set definable subsets of \(W\) in some
suitable logical language. A space is said to be <em>complete</em> if
each agent correctly takes into account each possible conjecture about
her opponents. A simple counting argument shows that there cannot
exist a complete structure when the set of conjectures is <em>all</em>
subsets of the set of states (Brandenburger 2003). However, there is a
deeper result which we discuss below.</p>

<h4 id="BranKeisPara">The Brandenburger-Keisler Paradox</h4>

<p>
Adam Brandenburger and H. Jerome Keisler (2006) introduce the
following Russell-style paradox. The statement of the paradox involves
two concepts: beliefs and assumptions. An <em>assumption</em> for a
player is that player&rsquo;s strongest belief: it is a set of states
that implies all other beliefs at a given state. We will say more
about the interpretation of an assumption below. Suppose there are two
players, Ann and Bob, and consider the following description of
beliefs.</p>

<dl class="sentag tag3em" id="tagS">
<dt>(S)</dt>
<dd>Ann believes that Bob assumes that Ann believes that Bob&rsquo;s
assumption is wrong.</dd>
</dl>

<p>
A paradox arises by asking the question:</p>

<dl class="sentag tag3em" id="tagQ">
<dt>(Q)</dt>
<dd>Does Ann believe that Bob&rsquo;s assumption is wrong?</dd>
</dl>

<p>
To ease the discussion, let \(C\) be Bob&rsquo;s assumption in (S):
that is, \(C\) is the statement:</p>

<dl class="sentag tag3em" id="tagC">
<dt>(C)</dt>
<dd>Ann believes that Bob&rsquo;s assumption is wrong.</dd>
</dl>

<p>
So, (Q) asks whether \(C\) is true or false. We will argue that \(C\)
is true if, and only if, \(C\) is false.</p>

<p>
Suppose that \(C\) is true. Then, Ann believes that Bob&rsquo;s
assumption is wrong, and, by (positive) introspection, she believes
that she believes this. That is, Ann believes that \(C\) is correct.
Furthermore, according to (S), Ann believes that Bob&rsquo;s
assumption is \(C\). So, Ann, in fact, believes that Bob&rsquo;s
assumption is correct (she believes Bob&rsquo;s assumption is \(C\)
and that \(C\) is correct). So, \(C\) is false.</p>

<p>
Suppose that \(C\) is false. So Ann does not believe that Bob&rsquo;s
assumption is wrong. That is, Ann does not believe that \(C\) is
wrong. By (negative) introspection, Ann believes that she does not
believe that \(C\) is wrong. Now, by (S), <em>Ann believes that
Bob&rsquo;s assumption is that she believes that \(C\) is wrong</em>
and Ann believes that she does not believe that \(C\) is wrong. Thus,
Ann believes that Bob&rsquo;s assumption is wrong. So, \(C\) is
true.</p>

<p>
Brandenburger and Keisler formalize the above argument in order to
prove a very strong impossibility result about the existence of
so-called <em>assumption-complete</em> structures. We need some
notation to state this result. It will be most convenient to work in
qualitative type spaces for two players
 (<a href="#qual-type">Definition 2.6</a>).
 A qualitative type space for two players \(N=\{a, b\}\) is a
structure (the set of states is not important for this argument, so we
leave them out) \(\langle (T_a, T_b), (\lambda_a, \lambda_b)\rangle\)
where</p> 
\[\lambda_a:T_a\rightarrow \wp(T_b)\qquad\lambda_b:T_b\rightarrow\wp(T_a)\]

<p>
A set of <strong>conjectures about Ann (<em>a</em>)</strong> is a
subset \(\cC_a\subseteq \wp(T_a)\) (similarly, the set of conjectures
about Bob is a subset \(\cC_b\subseteq \wp(T_b)\)). A structure
\(\langle (T_a, T_b), (\lambda_a, \lambda_b)\rangle\) is said to be
<strong>assumption-complete</strong> for the conjectures \(\cC_a\) and
\(\cC_b\) provided for each conjecture in \(\cC_a\) there is a type
that assumes that conjecture (similarly for Bob). Formally, for each
\(Y\in\cC_b\) there is a \(t\in T_a\) such that \(\lambda_a(t)=Y\),
and similarly for Bob. As we remarked above, a simple counting
argument shows that when \(\cC_a=\wp(T_a)\) and \(\cC_b=\wp(T_b)\),
then assumption-complete models only exist in trivial cases. A much
deeper result is:</p>

<div class="indent" id="bkparadox">

<p>
<strong>Theorem 2.9 (Brandenburger &amp; Keisler 2006: Theorem
5.4)</strong> There is no assumption-complete type structure for the
set of conjectures that contains the first-order definable
subsets.</p>
</div>

<p>
See the supplement for a discussion of the proof of this theorem
 (<a href="supplement.html#proof-bkparadox">see Supplement, Section 2</a>).</p>
 
<p>
Consult Pacuit (2007), Abramsky &amp; Zvesper (2015), and Ba&#351;kent
(2015, 2018) for an extensive analysis and generalization of this
result. But, it is not all bad news: Mariotti, Meier, &amp; Piccione
(2005) construct an assumption-complete structure where the set of
conjectures are compact subsets of some well-behaved topological
space.</p>

<h2 id="EpisCharSoluConc">3. Epistemic Characterizations of Solution Concepts</h2>

<p>
One of the central questions in epistemic game theory involves
determining the assumptions about the players&rsquo; rationality and
what the players recognize about each others&rsquo; rationality that
<em>guarantee</em> that the players&rsquo; decisions result in a
strategy profile defined by a given solution concept. In a game model
(either an Epistemic-Probability model or a Type Space), each state
corresponds to a strategy profile. The aim of an epistemic
characterization of a solution concept is to describe the set of
states in terms of the players&rsquo; rationality and their
higher-order beliefs and knowledge about the other players&rsquo;
rationality that corresponds to the strategy profiles identified by a
given solution concept.</p>

<h3 id="FundTheoEpisGameTheo">3.1 The Fundamental Theorem of Epistemic Game Theory</h3>

<p>
What has been called the fundamental theorem of epistemic game theory
is that rationality and common belief in rationality <em>implies</em>
that the players choose strategies that survive iterated elimination
of strictly dominated strategies (this result is also discussed in
Section 3.3 of Vanderschraaf &amp; Sillari 2005 [2022]). This result
is fundamental for several reasons. Historically, it marks the
beginning of the epistemic analysis of games as an alternative to the
equilibrium refinement program. Indeed, when Bernheim (1984) and
Pearce (1984) independently proposed &ldquo;rationalizable
strategies&rdquo; as a solution concept, they did so with the explicit
goal of bringing the equilibrium refinement program back to more
classical decision-theoretic foundations. The same motivation is also
present, with a formulation even closer to the contemporary result, in
Spohn (1982).</p>

<h4 id="StriDomi">3.1.1 Strict Dominance</h4>

<p>
A basic principle of rational choice is that a decision maker will not
choose an act that is <em>strictly dominated</em> (de Finetti 1974).
To apply this notion to players in a game, we need some notation.
Suppose that</p> 
\[G=\langle N, (S_i)_{i\in N}, (u_i)_{i\in N}\rangle\]

<p>
is a game in strategic form and \(m\in\Delta(S_i)\) is a mixed
strategy for player \(i\). If \(s_{-i}\in S_{-i}\) is a sequence of
strategies for the players other than \(i\), then</p> 
\[U_i(m, s_{-i})=\sum_{s\in S_i} m(s) * u_i(s,s_{-i}),\]

<p>
where \(u_i(s, s_{-i})\) is the utility of player \(i\) for the
strategy profile where \(i\) chooses \(s\) and the other players
choose as in \(s_{-i}\).</p>

<div class="indent">

<p>
<strong id="s-domstrong">Definition 3.1 (Strict Dominance)</strong>
Suppose that</p> 
\[G=\langle N, (S_i)_{i\in N}, (u_i)_{i\in N}\rangle\]

<p>
is a game in strategic form and \(X\subseteq S_{-i}\). Let \(m, m'\in
\Delta(S_i)\) be two mixed strategies for player \(i\). The strategy
\(m\) <strong>strictly dominates \(m'\) with respect to \(X\)</strong>
provided for all \(s_{-i}\in X\),</p> 
\[U_i(m,s_{-i}) &gt; U_i(m',s_{-i}). \]

<p>
We say \(m\) is <strong>strictly dominated</strong> provided there is
some \(m'\in \Delta(S_i)\) that strictly dominates \(m\).</p>
</div>

<p>
We say that a strategy \(m\in \Delta(S_i)\) strictly dominates \(m'\in
\Delta(S_i)\) when \(m\) strictly dominates \(m'\) with respect to
\(S_{-i}\). Thus, \(m\) strictly dominates \(m'\) when \(m\) is better
than \(m'\) (i.e., gives a higher expected payoff to player \(i\))
<em>no matter what</em> the other players do.</p>

<p>
The definition of strict dominance is given in terms of mixed
strategies for a player. Mixed strategies are important to define
strict dominance, because there are games in which some pure
strategies are strictly dominated by a mixed strategy, but not by any
pure
 strategies.<sup>[<a href="notes.html#note-12" id="ref-12">12</a>]</sup>
 Consult Apt (2007) and
 <a href="#IterWeakDomiCautBeli">Section 3.4</a>
 for further variants of the above notion of strict dominance.</p>

<p>
The parameter \(X\) in the definition of strict dominance is intended
to represent the set of choices of the other players that player \(i\)
takes to be &ldquo;live possibilities&rdquo;. An important special
case is when the players consider <em>all</em> of their
opponents&rsquo; strategies possible. It should be clear that a
rational player will <em>never</em> choose a strategy that is strictly
dominated with respect to \(S_{-i}\). That is, if \(s\) is strictly
dominated with respect that \(S_{-i}\), then there are no beliefs that
\(i\) can have about her opponents with respect to which it is
rational for player \(i\) to choose \(s\). More formally, given a
probability \(p\in \Delta(X)\) over a set \(X\subseteq S_{-i}\), we
say that \(s\in S_i\) is a <strong>best response to \(p\)</strong>
provide that for all \(s'\in S_i\)</p> 
\[ \sum_{s_{-i}\in S_{-i}} p(s_{-i}) * u_i(s, s_{-i})\geq \sum_{s_{-i}\in S_{-i}} p(s_{-i}) * u_i(s', s_{-i}).\]

<p>
We can now state the following well-known Lemma.</p>

<div class="indent" id="sdom-prob">

<p>
<strong>Lemma 3.2</strong> Suppose that \(G=\langle N, (S_i)_{i\in N},
(u_i)_{i\in N}\rangle\) is a game in strategic form. A strategy \(s\in
S_i\) for player \(i\) is strictly dominated (possibly by a mixed
strategy) with respect to \(X\subseteq S_{-i}\) iff there is no
probability measure \(p\in \Delta(X)\) such that \(s\) is a best
response with respect to \(p\).</p>
</div>

<p>
The proof of this Lemma is given in the
 <a href="supplement.html#supp1">supplement, Section 1</a>.</p>
 
<p>
A second important feature of strict dominance is that if a strategy
is strictly dominated, it remains so if the player gets more
information about what her opponents (might) do. That is, we have the
following monotonicity property:</p>

<div class="indent" id="mon-sdom">

<p>
<strong>Observation 3.3</strong> Suppose that \(G=\langle N,
(S_i)_{i\in N}, (u_i)_{i\in N}\rangle\) is a game in strategic form.
For all strategies \(s\in S_i\), if \(s\) is strictly dominated with
respect to \(X\subseteq S_{-i}\) and \(X'\subseteq X\), then \(s\) is
strictly dominated with respect to \(X'\).</p>
</div>

<h4 id="CommBeliRatiIterElimStriDomiStra">3.1.2 Common Belief in Rationality and Iterated Elimination of Strictly Dominated Strategies</h4>

<p>
Common belief of rationality has long been used as an informal
explanation of the idealizations underlying classical game-theoretical
analyses (see, e.g., Myerson 1991). The results in this section show
that, once formalized, this assumption does lead to a classical
solution concept, namely iterated elimination of strictly dominated
strategies. It does not, however, suffice to ensure that the players
will play a Nash equilibrium (see
 <a href="#NashEqui">Section 3.3</a>
 for a discussion of the epistemic characterization of the Nash
equilibrium).</p>

<p>
<em>Iterated elimination of strictly dominated strategies</em> (IESDS)
is a solution concept that runs as follows. First, for each player
\(i\), remove from the original game any strategy that is strictly
dominated (with respect to all of the opponents&rsquo; strategy
profiles). In the subgame that arises after removing all of the
strictly dominated strategies in the original game, remove all of the
strategies which have become strictly dominated in the subgame. Repeat
this process until the elimination does not remove any strategies. The
profiles that survive this process are said to be <em>iteratively
non-dominated</em>.</p>

<p>
For example, consider the following strategic game:</p>

<div class="figure avoid-break" id="coord-gameBB">

<table class="cell-center cellpad-small-dense centered inner-boxTH nocaption vert-mid">
<thead style="line-height:1.1em">
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th colspan="3">Bob</th> </tr>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
  <td><em>l</em></td>
  <td><em>c</em></td>
  <td><em>r</em></td> </tr> </thead>
<tbody class="cellpad-small">
<tr>
<th rowspan="3">Ann</th>
<th><em>x</em></th>
  <td>3,3</td>
  <td>1,1</td>
  <td>0,0</td> </tr>
<tr>
<th><em>y</em></th>
  <td>1,1</td>
  <td>3,3</td>
  <td>1,0</td> </tr>
<tr>
<th><em>z</em></th>
  <td>0,4</td>
  <td>0,0</td>
  <td>4,0</td> </tr> </tbody>
</table>

<p class="center">
<span class="figlabel">Figure 12</span></p>
</div>

<p>
Strategy \(r\) is strictly dominated by \(l\) for Bob. Once \(r\) is
removed from the game, \(z\) becomes strictly dominated for Ann. Thus,
\(\{(x,l), (x,c), (y,l), (y,c)\}\) are iteratively undominated. That
is, iteratively removing strictly dominated strategies generates the
following sequence of games:</p>

<div class="figure" id="coord-gameB3">

<div class="centered" style="padding-bottom:10px;max-width:100%;width:max-content;">

<div style="display:inline-block; vertical-align:middle;">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid">
<thead>
<tr>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>c</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody class="cellpad-small">
<tr>
<th><em>x</em></th>
  <td>3,3</td>
  <td>1,1</td>
  <td>0,0</td> </tr>
<tr>
<th><em>y</em></th>
  <td>1,1</td>
  <td>3,3</td>
  <td>1,0</td> </tr>
<tr>
<th><em>z</em></th>
  <td>0,4</td>
  <td>0,0</td>
  <td>4,0</td> </tr> </tbody>
</table>
</div> \(\ \rightarrowtail\ \)

<div style="display:inline-block; vertical-align:middle;">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid">
<thead>
<tr>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>c</em></th> </tr> </thead>
<tbody class="cellpad-small">
<tr>
<th><em>x</em></th>
  <td>3,3</td>
  <td>1,1</td> </tr>
<tr>
<th><em>y</em></th>
  <td>1,1</td>
  <td>3,3</td> </tr>
<tr>
<th><em>z</em></th>
  <td>0,4</td>
  <td>0,0</td> </tr> </tbody>
</table>
</div> \(\ \rightarrowtail\ \)

<div style="display:inline-block; vertical-align:middle;">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid">
<thead>
<tr>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>c</em></th> </tr> </thead>
<tbody class="cellpad-small">
<tr>
<th><em>x</em></th>
  <td>3,3</td>
  <td>1,1</td> </tr>
<tr>
<th><em>y</em></th>
  <td>1,1</td>
  <td>3,3</td> </tr> </tbody>
</table>
</div>
</div>

<p class="center">
<span class="figlabel">Figure 13</span></p>
</div>

<p>
For arbitrary large (finite) strategic games, if all players are
<em>rational</em> and there is <strong>common belief that all players
are rational</strong>, then the players&rsquo; choices will be a
strategy profile that is iteratively non-dominated. Before stating the
formal result, we illustrate it with an example. Consider a type
space</p> 
\[\cT=\langle (T_a, T_b), (\lambda_a,\lambda_b), S\rangle,\]

<p>
where \(N=\{a, b\}\) is the set of players (<em>a</em> for Ann and
<em>b</em> for Bob) and \(S\) is the set of strategy profiles in the
game depicted in
 <a href="#coord-gameBB">Figure 12</a>.
 Suppose that there are two types for Ann \((T_a=\{a_1, a_2\})\) and
three types for Bob \((T_b=\{b_1, b_2, b_3\})\). The type functions
\(\lambda_a\) and \(\lambda_b\) are defined as follows:</p>

<div class="figure" id="coord-gameB4">

<div class="centered" style="padding-bottom:10px;width:max-content;max-width:100%;">

<div style="display: inline-block; padding-left:1em">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid">
<thead>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>c</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody>
<tr>
<th rowspan="3">\(\lambda_a(a_1)\)</th>
<th>\(b_1\)</th>
  <td>0.5</td>
  <td>0.5</td>
  <td>0</td> </tr>
<tr>
<th>\(b_2\)</th>
  <td>0</td>
  <td>0</td>
  <td>0</td> </tr>
<tr>
<th>\(b_3\)</th>
  <td>0</td>
  <td>0</td>
  <td>0</td> </tr> </tbody>
</table>
</div>

<div style="display: inline-block; padding-left:1em">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid">
<thead>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>c</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody>
<tr>
<th rowspan="3">\(\lambda_a(a_2)\)</th>
<th>\(b_1\)</th>
  <td>0</td>
  <td>0.5</td>
  <td>0</td> </tr>
<tr>
<th>\(b_2\)</th>
  <td>0</td>
  <td>0</td>
  <td>0.5</td> </tr>
<tr>
<th>\(b_3\)</th>
  <td>0</td>
  <td>0</td>
  <td>0</td> </tr> </tbody>
</table>
</div>

<div style="display: inline-block; padding-left:1em">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid">
<thead>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>x</em></th>
<th><em>y</em></th>
<th><em>z</em></th> </tr> </thead>
<tbody>
<tr>
<th rowspan="2">\(\lambda_b(b_1)\)</th>
<th>\(a_1\)</th>
  <td>0.5</td>
  <td>0.5</td>
  <td>0</td> </tr>
<tr>
<th>\(a_2\)</th>
  <td>0</td>
  <td>0</td>
  <td>0</td> </tr> </tbody>
</table>
</div>

<div style="display: inline-block; padding-left:1em">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid">
<thead>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>x</em></th>
<th><em>y</em></th>
<th><em>z</em></th> </tr> </thead>
<tbody>
<tr>
<th rowspan="2">\(\lambda_b(b_2)\)</th>
<th>\(a_1\)</th>
  <td>0.25</td>
  <td>0.25</td>
  <td>0</td> </tr>
<tr>
<th>\(a_2\)</th>
  <td>0.25</td>
  <td>0.25</td>
  <td>0</td> </tr> </tbody>
</table>
</div>

<div style="display: inline-block; padding-left:1em">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid">
<thead>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>x</em></th>
<th><em>y</em></th>
<th><em>z</em></th> </tr> </thead>
<tbody>
<tr>
<th rowspan="2">\(\lambda_b(b_3)\)</th>
<th>\(a_1\)</th>
  <td>0.5</td>
  <td>0</td>
  <td>0</td> </tr>
<tr>
<th>\(a_2\)</th>
  <td>0</td>
  <td>0</td>
  <td>0.5</td> </tr> </tbody>
</table>
</div>
</div>

<p class="center">
<span class="figlabel">Figure 14</span></p>
</div>

<p>
We then consider the pairs \((s,t)\) where \(s\in S_i\) and \(t\in
T_i\) and identify all the rational pairs as in
 <a href="#RatiChoiTypeSpac">Section 2.2.4</a>
 (i.e., where \(s\) is a best response to \(\lambda_i(t)\)).</p>

<ul>

<li>

<p>
\(\Rat_a=\{(x, a_1), (y, a_1), (z, a_2)\}\)</p> </li>

<li>

<p>
\(\Rat_b=\{(l, b_1), (c, b_1), (l, b_2), (c, b_2), (l, b_3) \}\)</p>
</li>
</ul>

<p>
The next step is to identify the types that <em>believe</em> that the
other players are rational. For the type \(a_1\), we have
\(\lambda_a(a_1)(\Rat_b)=1\); however, \(\lambda_a(a_2)(b_2,r)=0.5\)
but \((r,b_2)\not\in \Rat_b\). Thus, type \(b_2\) does not believe
that player <em>b</em> is rational. This can be turned into an
iterative process based on the definition of common belief for Type
Spaces from
 <a href="#CommKnowBeli">Section 2.3</a>:
 For each \(i\in N\), let \(R_i^1=\Rat_i\). Suppose that for each
\(i\in N\), \(R_i^n\) has been defined. Then, define \(R_{-i}^n\) as
follows:</p> 
\[R_{-i}^n=\{(s,t) \mid \text{\(s\in S_{-i}\), \(t\in T_{-j}\), and for each \(j\ne i\), \((s_j,t_j)\in R_j^n\)}\}. \]

<p>
For each \(n&gt;1\), define \(R_i^n\) inductively as follows:</p>

\[R_i^{n+1}=\{(s,t) \mid (s,t)\in R_i^n \text{ and \(\lambda_i(t)\) assigns probability 1 to \(R_{-i}^n\)}\} \]

<p>
Thus, we have \(R_a^2=\{(x, a_1), (y, a_1)\}\). Note that \(b_2\)
assigns non-zero probability to the pair \((y,a_2)\) which is not in
\(R_a^1\), so \(b_2\) does not believe that <em>a</em> is rational.
Thus, we have \(R_b^2=\{(l,b_1), (c,b_1),(l,b_3)\}\). Continuing with
this process, we have \(R_a^2=R_a^3\). However, \(b_3\) assigns
non-zero probability to \((z,a_2)\) which is not in \(R_a^2\), so
\(R_b^3=\{(l, b_1), (c,b_1)\}\). Putting everything together, we
have</p> 
\[\bigcap_{n\ge 1}R^n_a\ \times \ \bigcap_{n\ge 1}R^n_b=\{(x, a_1), (y, a_1)\}\times \{(l, b_1), (c, b_1)\}. \]

<p>
Thus, all the profiles that survive iterative removal of strictly
dominated strategies, i.e. \((x,l), (y,l), (x,c)\) and \((y,c)\) are
consistent with states where the players are rational and commonly
believe they are rational.</p>

<p>
Note that, the above process need not generate <em>all</em> strategies
that survive iteratively removing strictly dominated strategies. For
example, consider a type space with a single type \(a_1\) for Ann and
a single type \(b_1\) for Bob. Suppose that \(\lambda_a(l, b_1)= 1 =
\lambda_b(u, a_1)\). Then, \((u,l)\) is the only strategy profile in
this model and obviously rationality and common belief of rationality
is satisfied. However, for any type space, if a strategy profile is
consistent with rationality and common belief of rationality, then it
must be a strategy that is in the set of strategies that survive
iteratively removing strictly dominated strategies (Brandenburger
&amp; Dekel 1987; Tan &amp; Werlang 1988):</p>

<div class="indent">

<p>
<strong>Theorem 3.4</strong> Suppose that \(G\) is a strategic game
and \(\cT\) is any type space for \(G\). If \((s,t)\) is a state in
\(\cT\) in which all the players are rational and there is common
belief of rationality&mdash;formally, for each \(i\),</p> 
\[(s_i, t_i)\in \bigcap_{n\ge 1} R_i^n\]

<p>
&mdash;then \(s\) is a strategy profile that survives iteratively
removal of strictly dominated strategies.</p>
</div>

<p>
This result, which establishes a <em>sufficient</em> condition that a
strategy profile survives iteratively elimination of strictly
dominated strategies, also has a converse direction. Given any
strategy profile that survives iterated elimination of strictly
dominated strategies, there is a model in which this profile is played
where all players are rational and this is common belief. In other
words, one can always interpret the choice of a strategy profile that
would survive the iterative elimination procedure as one that is
played by rational players under common belief of rationality.</p>

<p>
This converse direction can be strengthened to show that the entire
set of strategy profiles that survive iteratively removal of strictly
dominated strategies is consistent with rationality and common belief
in rationality (Brandenburger &amp; Dekel 1987; Tan &amp; Werlang
1988):</p>

<div class="indent">

<p>
<strong>Theorem 3.5</strong> For any game \(G\), there is a type
structure for that game in which the strategy profiles consistent with
rationality and common belief in rationality is the set of strategies
that survive iterative removal of strictly dominated strategies.</p>
</div>

<p>
See Friedenberg &amp; Keisler (2021) for the strongest version of the
above result. Analogues of the above results have been proven using
different game models. For example, Apt &amp; Zvesper (2010), Halpern
&amp; Moses (2017), Bonanno (2015), and Lorini (2016) prove analogous
results using Epistemic(-Probability) models.</p>

<h4 id="BeliAbouCorrChoi">3.1.3 Beliefs about Correlated Choices</h4>

<p>
There are two crucial assumptions needed for the proof of
 <a href="#sdom-prob">Lemma 3.2</a>.
 The first assumption is that the players believe that their choices
are <em>independent</em>. It is well-known that it may be rational to
choose a strictly-dominated act when there is <em>act-state
dependence</em> (cf. Schervish, Seidenfeld, &amp; Kadane 1990). To
illustrate, consider the so-called Prisoner&rsquo;s Dilemma depicted
in
 <a href="#pd-game">Figure 15</a>
 (see S. Kuhn 1997 [2019] for a complete discussion of the
Prisoner&rsquo;s Dilemma).</p>

<div class="figure" id="pd-game">

<table class="cell-center cellpad-small-dense centered inner-boxTH nocaption vert-mid">
<thead style="line-height:1.1em">
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th colspan="2">Bob</th> </tr>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>c</em></th>
<th><em>d</em></th> </tr> </thead>
<tbody class="cellpad-small">
<tr>
<th rowspan="2">Ann</th>
<th><em>c</em></th>
  <td>3,3</td>
  <td>0,4</td> </tr>
<tr>
<th><em>d</em></th>
  <td>4,0</td>
  <td>1,1</td> </tr> </tbody>
</table>

<p class="center">
<span class="figlabel">Figure 15:</span> A Prisoner&rsquo;s
Dilemma</p>
</div>

<p>
In the Prisoner&rsquo;s Dilemma, \(c\) is strictly dominated by \(d\)
for both players. According to
 <a href="#sdom-prob">Lemma 3.2</a>,
 there is no probability over the choices of the Bob that makes \(c\)
a best response. However, if Ann believes that the Bob&rsquo;s choice
is correlated with her choice (i.e., Bob will match her choice by
choosing \(c\) if she does and choosing \(d\) if she does) and that
her choice is <em>transparent</em> to Bob, then \(c\) may be a
rational choice with respect to this belief (cf. Brams 1975; Davis
1977; Capraro &amp; Halpern 2016; Halpern &amp; Pass 2018). Thus,
 <a href="#sdom-prob">Lemma 3.2</a>
 only holds when it is assumed that each player believes that the
choices of the other players do not depend on the player&rsquo;s own
 choice.<sup>[<a href="notes.html#note-13" id="ref-13">13</a>]</sup></p>
 
<p>
The second assumption needed for the proof of
 <a href="#sdom-prob">Lemma 3.2</a>
 involves games with more than two players. With three or more
players,
 <a href="#sdom-prob">Lemma 3.2</a>
 only holds if it is possible for the players to believe that the
choices of the <em>other</em> players <em>are</em> correlated
(Brandenburger &amp; Dekel 1987; Brandenburger &amp; Friedenberg
2008). The following example from Brandenburger &amp; Friedenberg
(2008) illustrates this point. Consider the following three person
game where Ann&rsquo;s strategies are \(S_a=\{u,d\}\), Bob&rsquo;s
strategies are \(S_b=\{l,r\}\) and Charles&rsquo; strategies are
\(S_c=\{x,y,z\}\) and their respective preferences for each outcome
are given in the corresponding cell (where Ann&rsquo;s utility is the
number in the first component, Bob&rsquo;s utility is the number in
the second component, and Charles&rsquo; utility is the number in the
third component):</p>

<div class="figure" id="coord-game-firstCCC">

<div class="centered" style="padding-bottom:10px;max-width:100%;width:max-content;">

<div style="display:inline-block;padding-left:1em;">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid shortcap-plain">
<caption>\(x\)</caption>
<thead>
<tr>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody>
<tr>
<th><em>u</em></th>
  <td>1,1,3</td>
  <td>1,0,3</td> </tr>
<tr>
<th><em>d</em></th>
  <td>0,1,0</td>
  <td>0,0,0</td> </tr> </tbody>
</table>
</div>

<div style="display:inline-block; padding-left:1em;">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid shortcap-plain">
<caption>\(y\)</caption>
<thead>
<tr>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody>
<tr>
<th><em>u</em></th>
  <td>1,1,2</td>
  <td>1,0,0</td> </tr>
<tr>
<th><em>d</em></th>
  <td>0,1,0</td>
  <td>1,1,2</td> </tr> </tbody>
</table>
</div>

<div style="display:inline-block; padding-left:1em;">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid shortcap-plain">
<caption>\(z\)</caption>
<thead>
<tr>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody>
<tr>
<th><em>u</em></th>
  <td>1,1,0</td>
  <td>1,0,0</td> </tr>
<tr>
<th><em>d</em></th>
  <td>0,1,3</td>
  <td>0,0,3</td> </tr> </tbody>
</table>
</div>
</div>

<p class="center">
<span class="figlabel">Figure 16</span></p>
</div>

<p>
Note that \(y\) is not strictly dominated for Charles. As expected
from
 <a href="#sdom-prob">Lemma 3.2</a>,
 it is easy to find a probability measure \(p\in\Delta(S_a\times
S_b)\) such that \(y\) is a best response to \(p\). Suppose that
\(p(u,l)=p(d,r)=0.5\). Then,</p> 
\[\begin{align*}
\EU(x,p) &amp; =3 * 0.5 + 0 * 0.5 \\
 &amp; =1.5\\
 &amp; = 0*0.5 + 3* 0.5 \\
 &amp; = \EU(z,p)\\
 
\end{align*} \]

<p>
while \(\EU(y,p)=2\). However, there is no probability measure \(p\in
\Delta(S_a\times S_b)\) such that \(y\) is a best response to \(p\)
and \(p(u,l)=p(u)\cdot p(l)\) (i.e., Charles believes that Ann and
Bob&rsquo;s choices are independent). To see this, suppose that \(p\)
is any probability representing Charles&rsquo; beliefs about Ann and
Bob&rsquo;s choices such that \(\alpha\) is the probability assigned
to \(u\) and \(\beta\) is the probability assigned to \(l\) and
\(p(u,l) = p(u)p(l)=\alpha\beta\). Note that this means that: \(p(u,
r) = \alpha(1-\beta),\) \(p(d, l) = (1-\alpha)\beta\), and \(p(d,
r)=(1-\alpha)(1-\beta)\). Then, we have:</p>

<ul>

<li>

<p>
The expected utility of \(x\) is</p> 
\[\begin{align*}
\EU(x, p) &amp; = 3\alpha\beta +3\alpha(1-\beta)\\
 &amp; =3\alpha(\beta+(1-\beta))\\
 &amp; =3\alpha;\\
 
\end{align*} \]
 </li>

<li>

<p>
The expected utility of \(y\) is</p> 
\[\EU(y, p) = 2\alpha\beta + 2(1-\alpha)(1-\beta);\]

<p>
and</p> </li>

<li>

<p>
The expected utility of \(z\) is</p> 
\[ \begin{align*}
\EU(z, p) &amp; = 3(1-\alpha)\beta+3(1-\alpha)(1-\beta) \\
 &amp;= 3(1-\alpha)(\beta+(1-\beta))\\
 &amp; =3(1-\alpha). 
\end{align*}\]
 </li>
</ul>

<p>
There are two cases:</p>

<ol>

<li>

<p>
Suppose that \(1-\alpha \leq \alpha\). Then,</p> 
\[\begin{align*}
\EU(y, p) &amp; = 2\alpha \beta + 2(1-\alpha)(1-\beta) \\
 &amp;\leq 2\alpha \beta + 2\alpha(1-\beta) \\
 &amp; =2\alpha \\
 &amp; &lt; 3\alpha \\
 &amp; = \EU(x,p).\\
 
\end{align*}\]

<p>
Hence, \(y\) is not a best response since \(\EU(x,p) &gt; \EU(y,
p)\).</p> </li>

<li>

<p>
Suppose that \(\alpha &lt; 1-\alpha\). Then,</p> 
\[\begin{align*}
\EU(y, p) &amp; = 2\alpha \beta + 2(1-\alpha)(1-\beta)\\
 &amp;&lt;2(1-\alpha) \beta + 2(1-\alpha)(1-\beta) \\
 &amp; =2(1-\alpha) \\
 &amp; &lt; 3(1-\alpha) \\
 &amp; = \EU(z,p). \\
 
\end{align*}\]

<p>
Hence, \(y\) is not a best response since \(\EU(z,p) &gt;
\EU(y,p)\).</p> </li>
</ol>

<p>
In either case, \(y\) is not a best response to \(p\). Thus, although
\(y\) is strictly dominated for Charles, there is no probability over
the choices of Ann and Bob such that Ann and Bob&rsquo;s choices are
independent and \(y\) is a best response to that probability.</p>

<h3 id="SubgPerfEqui">3.2 Subgame Perfect Equilibrium</h3>

<p>
The shift from simultaneous-move games to sequential games, where
players can observe the other players&rsquo; decisions prior to making
their own, raises many interesting questions in epistemic game theory.
The most well-known solution concept for sequential games is the
<em>subgame perfect equilibrium</em>, first proposed by Selten (1975).
This equilibrium is computed using the well-known <em>backward
induction</em> algorithm.</p>

<p>
The plausibility or even meaningfulness of the subgame perfect
equilibrium as a solution concept for extensive games has been debated
by philosophers and game theorists at least since the work of Binmore
(1987). See Perea (2007b) and Kuechle (2009) for historical overviews.
The epistemic perspective on games has shed light on this debate by
focusing on the question of whether assuming that there is common
knowledge of rationality among the players is sufficient for the
outcome of the game to be the subgame perfect equilibrium. Numerous,
and apparently contradictory answers to that question have been given.
These answers, as it turns out, rest on different views about how the
players should change their beliefs when they observe unexpected
moves.</p>

<h4 id="GameExteForm">3.2.1 Games in Extensive Form</h4>

<p>
Sequential games, called games in extensive form, describe the order
that the players move. In this entry, we focus on games with
<em>perfect information</em>, in which there are no simultaneous
choices and no uncertainty about the choices made earlier in the
game.</p>

<div class="indent" id="def36">

<p>
<strong>Definition 3.6 (Perfect Information Game in Extensive
Form)</strong> A perfect information game in extensive form is a
tuple</p> 
\[\langle N, T, \Act, \tau, (u_i)_{i\in N}\rangle,\]

<p>
where</p>

<ul>

<li>

<p>
\(N\) is a finite set of players;</p> </li>

<li>

<p>
\(T\) is a tree describing the order of choices for each player:
Formally, \(T\) consists of a set of nodes and an immediate successor
relation \(\rightarrowtail\) (i.e., if \(v\) and \(v'\) are nodes,
then \(v\rightarrowtail v'\) means that \(v'\) is the node immediately
following \(v\), called the successor of \(v\)). Suppose that \(Z\) is
the set of terminal nodes (i.e., nodes without any successors) and
\(V\) is the remaining nodes (called decision nodes). Let \(v_0\)
denote the initial node (i.e., the <strong>root</strong> of the tree).
Each transition from a node \(v\) to a successor node \(v'\) is
labeled by an <strong>action</strong> from the set \(\Act\). We write
\(\Act(v)\) denote the set of actions available at \(v\).</p> </li>

<li>

<p>
\(\tau\) is a turn function assigning a player to each decision node
\(v\in V\). For each player \(i\in N\), let \(V_i=\{v\in V \mid
\tau(v)=i\}\) be the set of nodes where \(i\) is moving.</p> </li>

<li>

<p>
\(u_i: Z\rightarrow \mathbb{R}\) is the utility function for player
\(i\) assigning real numbers to each terminal node.</p> </li>
</ul>
</div>

<p>
A strategy is a plan that tells a player what to do at all of her
decision nodes, even those which are excluded by the strategy
itself.</p>

<div class="indent">

<p>
<strong>Definition 3.7 (Strategies)</strong> Suppose that \(G=\langle
N, T, \Act, \tau, (u_i)_{i\in N}\rangle\) is a game in extensive form.
A <strong>strategy</strong> for player \(i\) in \(G\) is a function
\(s:V_i \rightarrow \Act\) where for all \(v\in V_i\), \(s(v)\in
\Act(v)\). For each player \(i\), let \(S_i\) be the set of strategies
for player \(i\) in \(G\). A <strong>strategy profile</strong> for
\(G\), denoted \({\mathbf{s}}\), is an element of \(\times_{i\in N}
S_i\). Given a strategy profile \({\mathbf{s}}\), we write
\({\mathbf{s}}_i\) for player \(i\)&rsquo;s component of
\({\mathbf{s}}\) and \({\mathbf{s}}_{-i}\) for the sequence of
strategies from \({\mathbf{s}}\) for all players except \(i\).</p>
</div>

<p>
Each strategy profile \({\mathbf{s}}\) for an extensive game
\(G=\langle N, T, \Act, \tau, (u_i)_{i\in N}\rangle\) generates a
<strong>path</strong> through \(T\), where a path is a sequence of
nodes \(v_0, v_1, \ldots, v_k\), where \(v_k\) is a terminal node and
for all \(0\leq j &lt; k\), \(v_{i+1} = \mathbf{s}_{\tau(v_i)}(v_i)\).
We say that \(v\) is <strong>reached</strong> by a strategy profile
\({\mathbf{s}}\) if \(v\) is on the path generated by
\({\mathbf{s}}\). Suppose that \(v\) is any node in an extensive game.
Let \(\out(v,{\mathbf{s}})\) be the terminal node that is reached if,
starting at node \(v\), all the players move according to their
respective strategies in the profile \({\mathbf{s}}\). Given a
decision node \(v\in V_i\) for player \(i\), a strategy \(s\in S_i\)
for player \(i\), and a set \(X\subseteq S_{-i}\) of strategy profiles
of the opponents of \(i\), let \(\Out_i(v,s, X)=\{\out(v, (s, s_{-i}))
\mid s_{-i}\in X\}\). That is, \(\Out_i(v, s, X)\) is the set of
terminal nodes that may be reached if, starting at node \(v\), player
\(i\) uses strategy \(s\) and \(i\)&rsquo;s opponents use a strategy
profile from \(X\).</p>

<p>

 <a href="#fig17">Figure 17</a>
 shows an example of a game in extensive form (this game from
Rosenthal (1981) is called the <strong>centipede game</strong>).</p>

<div class="figure wide" id="fig17">
<img alt="a diagram: link to extended description below" src="fig17.png" style="max-width:100%; padding-bottom:10px; width:25em" />

<p class="center">
<span class="figlabel">Figure 17:</span> A centipede game [An
 <a href="figdesc.html#fig17">extended description of figure 17</a>
 is in the supplement.]</p>
</div>

<p>
The decision nodes for <em>a</em> and <em>b</em> are \(V_A=\{v_1,
v_3\}\) and \(V_B=\{v_2\}\); and the terminal nodes are \(O=\{o_1,
o_2, o_3, o_4\}\). The labels of the edges are the actions of each
player. For instance, \(\Act(v_1)=\{O_1, I_1\}\). There are four
strategies for <em>a</em> and two strategies for <em>b</em>. To
simplify notation, we denote the players&rsquo; strategies by the
sequence of choices at each of their decision nodes. For example,
<em>a</em>&rsquo;s strategy \(s_A^1\) defined as \(s_A^1(v_1)=O_1\)
and \(s_A^1(v_3)=O_3\) is denoted by the sequence \(O_1O_3\). Thus,
<em>a</em>&rsquo;s strategies are:</p>

<ul>

<li>\(s_A^1=O_1O_3\),</li>

<li>\(s_A^2=O_1I_3\),</li>

<li>\(s_A^3=I_1O_3\) and</li>

<li>\(s_A^4=I_1I_3\).</li>
</ul>

<p>
Note that <em>a</em>&rsquo;s strategy \(s_A^2\) specifies a move at
\(v_3\), even though the earlier move at \(v_1\), \(O_1\), means that
<em>a</em> will not be given a chance to move at \(v_3\). Similarly,
Bob&rsquo;s strategies will be denoted by \(s_B^1=O_2\) and
\(s_B^2=I_2\), giving the actions chosen by <em>b</em> at his decision
node. Then, for example, \(\out(v_2,(s_A^2, s_B^2))=o_4\). Finally, if
\(X=\{s_A^1, s_A^4\}\), then</p> 
\[\Out_B(v_2,s_B^2, X)=\{o_3, o_4\}.\]

<p>
Given a game in extensive form \(G=\langle N, T, \Act, \tau,
(u_i)_{i\in N}\rangle\) and a decision node \(v\), the
<strong>subgame</strong> generated by \(v\) is the game in extensive
form defined by restricting \(G\) to \(v\) and all nodes reachable
from \(v\) (so \(v\) is the root in the subgame of \(G\) generated by
\(v\)). For instance, in addition of the full game in
 <a href="#fig17">Figure 17</a>,
 there are two subgames: one generated by \(v_2\) and the other
generated by \(v_3\). A strategy profile \(\mathbf{s}\) is a subgame
perfect equilibrium of a game in extensive form \(G\) if, for any
subgame of \(G\), no player \(i\) has an incentive to deviate from
\(\mathbf{s}_i\) given that the other players are following
\(\mathbf{s}_{-i}\). That is, there is no \(s'\in S_i\) such that</p>

\[u_i(\out(s', \mathbf{s}_{-i})) &gt; u_i(\out(\mathbf{s}))\]

<p>
For the game in
 <a href="#fig17">Figure 17</a>
 the unique subgame perfect equilibrium is \((O_1O_3, O_2)\).</p>

<p>
The so-called backward induction algorithm can be used to compute the
unique subgame perfect equilibrium in perfect information games in
extensive form in which no player receives the same payoff at two
different
 nodes.<sup>[<a href="notes.html#note-14" id="ref-14">14</a>]</sup>
 The algorithm runs as follows:</p>

<div class="indent">

<p>
<strong>BI Algorithm</strong> At terminal nodes, all nodes are marked
with the players&rsquo; utilities. At a non-terminal node \(v\), once
all immediate successors are marked, the node is marked as follows:
find the immediate successor \(v'\) that has the highest utility for
player \(\tau(v)\) (the players whose turn it is to move at \(v\)).
Copy the utilities from \(v\) onto \(v'\). Repeat this procedure until
all nodes are marked with the players&rsquo; utilities.</p>
</div>

<p>
Given an extensive game where all nodes are marked, the unique path
that leads from the root \(v_0\) of the game tree to the outcome with
the utilities that match the utilities assigned to \(v_0\) is called
the <strong>backward induction path</strong>. The backward induction
algorithm defines, for every non-terminal node, a path from that node
to a terminal node. These paths can be used to define strategies for
each player: At each decision node \(v\), choose the action that is
consistent with the path from \(v\). The resulting combination of
strategies is the <strong>backward induction profile</strong> (where
each player is following the strategy given by the backward induction
algorithm). This profile is a subgame perfect equilibrium.</p>

<p>
We focus on extensive games with perfect information in this section
in which no player receives the same payoff at two different terminal
nodes, but backward induction reasoning is applicable to a broader
class of extensive games where information might be imperfect or even
incomplete (see, for example, Bonanno 2014; Perea 2014a; and Catonini
&amp; Penta 2022
 [<a href="#Oth">Other Internet Resources</a>]).</p>
 
<h4 id="ModeGameExteForm">3.2.2 Models of Games in Extensive Form</h4>

<p>
There are many ways to describe the players&rsquo; knowledge and
beliefs in games in extensive form (see Battigalli &amp; Bonanno 1999
and Bonanno 2015 for surveys). These game models build upon those
discussed in
 <a href="#GameMode">Section 2</a>
 by describing how players are disposed to revise their beliefs during
a play of the game. See Samet (1996); Stalnaker (1999); Battigalli
&amp; Siniscalchi (2002); Baltag, Smets, &amp; Zvesper (2009); and
Battigalli, Di Tillio, &amp; Samet (2013) for a sample of different
approaches to describing the players changing beliefs in an extensive
form game. In this section, we present the models used in Halpern
(2001) to facilitate our discussion of the implications of assuming
that there is common knowledge of rationality in extensive form games.
We start by adapting the Epistemic Models from
 <a href="#def21">Definition 2.1</a>
 to games in extensive form:</p>

<div class="indent" id="def38">

<p>
<strong>Definition 3.8 (Epistemic model for games in extensive
form)</strong> An <strong>epistemic model of a game in extensive
form</strong></p> 
\[G=\langle N, T, \Act, \tau, (u_i)_{i \in N}\rangle\]

<p>
is a tuple \(\langle W, (\Pi_i)_{i\in N}, \sigma\rangle \) where \(W\)
is a nonempty set of states; for each \(i\in N\), \(\Pi_i\) is a
partition on \(W\); and \(\sigma:W\rightarrow \times_{i\in N} S_i\) is
a function assigning to each state \(w\), a strategy profile for
\(G\). If \(\sigma(w)={\mathbf{s}}\), then we write \(\sigma_i(w)\)
for \({\mathbf{s}}_i\) and \(\sigma_{-i}(w)\) for
\({\mathbf{s}}_{-i}\). As usual, we assume that players know their own
strategies: for all \(w\in W\), if \(w'\in \Pi_i(w)\), then
\(\sigma_i(w)=\sigma_i(w')\).</p>
</div>

<p>
The rationality of a strategy at a decision node depends both on what
actions the strategy prescribes at all future decision nodes
<em>and</em> what the players know or believe about the strategies
that their opponents are following. Since we are working with
non-probabilistic models of knowledge in this section, we use a
corresponding qualitative notion of rational choice.</p>

<p>
Let \(S_{-i}(w)=\{\sigma_{-i}(w') \mid w'\in \Pi_i(w)\}\) be the set
of strategy profiles of player \(i\)&rsquo;s opponents that \(i\)
thinks are possible at state \(w\). Then, \(\Out_i(v, s, S_{-i}(w))\)
is the set of outcomes that player \(i\) thinks are possible starting
at node \(v\) if she follows strategy \(s\).</p>

<div class="indent">

<p>
<strong>Definition 3.9 (Rationality at a decision node)</strong>
Suppose that \(G=\langle N, T, \Act, \tau, (u_i)_{i \in N}\rangle\) is
a game in extensive form with perfect information (see
 <a href="#def36">Definition 3.6</a>)
 and \(\cM = \langle W, (\Pi_i)_{i\in N}, \sigma\rangle \) is a model
of \(G\) (see
 <a href="#def38">Definition 3.8</a>).
 Player \(i\) is <strong>rational at node \(v\in V_i\) in state
\(w\)</strong> provided that, for all strategies \(s\in S_i\) such
that \(s\ne \sigma_i(w)\), there is are terminal nodes \(o'\in
\Out_i(v, s, S_{-i}(w))\) and \(o\in \Out_i(v, \sigma_i(w),
S_{-i}(w))\) such that \(u_i(o)\ge u_i(o')\).</p>
</div>

<p>
Thus, a player \(i\) is rational at a decision node \(v\in V_i\) in
state \(w\) provided that \(i\) does not know that there is an
alternative strategy that would always give her a strictly higher
payoff.</p>

<div class="indent" id="def310">

<p>
<strong>Definition 3.10 (Substantive rationality)</strong> Suppose
that</p> 
\[G=\langle N, T, \Act, \tau, (u_i)_{i \in N}\rangle\]

<p>
is a game in extensive form with perfect information and \(\cM =
\langle W, (\Pi_i)_{i\in N}, \sigma\rangle \) is a model of \(G\).
Player \(i\) is <strong>substantively rational at state \(w\)</strong>
provided for all decision nodes \(v\in V_i\), \(i\) is rational at
\(v\) in state \(w\).</p>
</div>

<p>
Note player \(i\) is substantively rational at state \(w\) when \(i\)
is rational at <em>all</em> of \(i\)&rsquo;s decision nodes, even
those that are ruled-out at previous decision nodes of player \(i\)
according to \(i\)&rsquo;s strategy at \(w\). The event that player
\(i\) is substantively rational is defined as follows: \(\SRat_i=\{w
\mid \mbox{player } i\) is substantively rational at state \(w\}\);
and so, the event that all players are substantively rational is
\(\SRat=\bigcap_{i\in N} \SRat_i\). Common knowledge of (substantive)
rationality is then defined as in
 <a href="#CommKnowBeli">Section 2.3</a>.
 In the remainder of this section, &ldquo;common knowledge of
rationality&rdquo; will mean common knowledge of substantive
rationality.</p>

<h4 id="CommKnowRatiSubgPerfEqui">3.2.3 Common Knowledge of Rationality and Subgame Perfect Equilibrium</h4>

<p>
There is a longstanding debate on whether common knowledge of
rationality implies that the players will play their component of the
subgame perfect equilibrium in extensive form games with perfect
information. In this section, we start with arguments that question
whether common knowledge of rationality is sufficient for the players
to choose their components of a subgame preference equilibrium. We
then turn to the view that common knowledge of rationality, or more
precisely common knowledge of <em>future</em> rationality, entails
that players will choose their component of the subgame perfect
equilibrium in perfect information games. These apparently
contradictory views rest on different assumptions regarding how the
players change their mind upon observing deviations from the subgame
perfect equilibrium path.</p>

<h5 id="CommKnowRatiNotSuffForSubgPerfEqui">Common Knowledge of Rationality is Not Sufficient for the Subgame Perfect Equilibrium</h5>

<p>
Arguments against the sufficiency of common knowledge of rationality
for the subgame perfect equilibrium in perfect information games can
be divided in two broad groups. The first group argues that common
knowledge of rationality is <em>incoherent</em> at nodes that are not
on the subgame perfect equilibrium path. The second group defends the
view that although common knowledge of rationality is coherent even at
nodes not on the subgame perfect equilibrium path, it is also
consistent with profiles of strategies that do not form a subgame
prefect equilibrium.</p>

<p>
Arguments from the first group have been pioneered by Bicchieri
(1988b), Basu (1990), and Reny (1988, 1993). They are best illustrated
by an example. Consider the centipede game in
 <a href="#fig17">Figure 17</a>.
 We start by arguing that if</p>

<ol id="centass" type="i">

<li id="ass1">both players are rational,</li>

<li id="ass2"><em>b</em> knows that <em>a</em> is rational,</li>

<li id="ass3"><em>a</em> knows that <em>b</em> is rational, and</li>

<li id="ass4"><em>a</em> knows that <em>b</em> knows that she is
rational, then the players will play their component of the subgame
perfect equilibrium.</li>
</ol>

<p>
In particular, <em>a</em> will choose \(O_1\) at her first decision
node (\(v_1\)). No matter what she believes or knows, if <em>a</em> is
rational then <em>a</em> would never play \(I_3\) at her final
decision node (\(v_3\)). Since <em>b</em> knows that <em>a</em> is
rational and her only rational choice at \(v_3\) is \(I_3\),
<em>b</em> knows that <em>a</em> will choose \(I_3\) at \(v_3\). Thus,
if he is rational, then he will play \(O_2\) at his decision node
(\(v_2\)). Therefore, by assumptions
 <a href="#ass3">(iii)</a>
 and
 <a href="#ass4">(iv)</a>,
 <em>a</em> knows that <em>b</em> will choose his only rational choice
\(O_2\) at \(v_2\), and so, since <em>a</em> is rational, <em>a</em>
will choose \(O_1\) at her first decision node (\(v_1\)).</p>

<p>
Bicchieri (1988b) and Reny (1988, 1993), have argued that this
reasoning breaks down if we add just one level of knowledge of
rationality, and so <em>a fortiori</em> if we assume that rationality
is common knowledge (cf. Section 3.4 of the entry on
 <a href="../common-knowledge/">common knowledge</a>).
 Suppose that, alongside the assumptions
 <a href="#centass">(i)&ndash;(iv)</a>
 that we saw lead to <em>a</em> and <em>b</em> to play their subgame
perfect equilibrium strategies, <em>b</em> knows what <em>a</em>
knows. That is, he knows that <em>a</em> knows that he is rational,
and he knows that <em>a</em> knows that he knows that she is rational.
Then <em>b</em> also knows that the only rational choice for
<em>a</em> at the first node is \(O_1\). Since he knows that
<em>a</em> is rational, he also knows that the decision node \(v_2\),
where he was planning to play \(O_2\), will not be reached. Taking the
contrapositive of the previous statement, if <em>b</em> knows that
\(v_2\) has been reached&mdash;i.e., that <em>a</em> chose \(I_1\) at
\(v_1\)&mdash;then given what he otherwise knows about what <em>a</em>
knows, he must conclude that her choice at the previous node was
irrational, and so that common knowledge of rationality cannot hold.
So <em>b</em> cannot simultaneously know that rationality is common
knowledge and that \(v_2\) has been reached.</p>

<p>
The key idea is that the additional assumption that <em>b</em> knows
what <em>a</em> knows gives him too much knowledge: it appears to
undermine the very reasoning that leads to the subgame perfect
equilibrium solution. Reny (1992) strengthened this observation by
arguing that common knowledge of rationality is consistent only in
trivial games where <em>every</em> node is reached by the subgame
perfect equilibrium. Basu (1990) and later de Bruin (2008) provide
similar results, all of which can be interpreted as showing the
impossibility of common knowledge of rationality to hold at states in
which players make choices off the subgame perfect equilibrium
path.</p>

<p>
These impossibility results can, however, be re-interpreted in a way
that has allowed several authors to defend the claim that common
knowledge of rationality might not be inconsistent with the players
choosing their components in the subgame perfect equilibrium, but also
that it is not sufficient for the players to make these choices. The
main idea is that observing deviations from the subgame perfect
equilibrium strategies might trigger changes in what some players
expect the others to do later on in the game. This, in turn, might
rationalize deviations from the subgame perfect equilibrium profile.
This line of thought goes back at least to Binmore (1987) and
Bicchieri (1988a), and has been articulated in subsequent literature
(Bonanno 1991, Aumann 1998, Stalnaker 1996, 1999). To illustrate this
idea consider the extensive game in
 <a href="#fig18">Figure 18</a>,
 developed by Halpern (2001) in order to illustrate the result
reported in (Stalnaker 1999). The subgame perfect equilibrium profile
is \((I_1, I_3, I_2)\) leading to the outcome \(o_4\) with both
players receiving a payoff of 3.</p>

<div class="figure wide" id="fig18">
<img alt="a diagram: link to extended description below" src="fig18.png" style="max-width:100%; padding-bottom:10px; width:25em" />

<p class="center">
<span class="figlabel">Figure 18:</span> An extensive game [An
 <a href="figdesc.html#fig18">extended description of figure 18</a>
 is in the supplement.]</p>
</div>

<div class="indent" id="ex3.11">

<p>
<strong>Example 3.11 (Epistemic model for the game in
 <a href="#fig18">Figure 18</a>)
 </strong> Suppose that the set of states is \(\{w_1, w_2, w_3, w_4,
w_5\}\) with \(\sigma\) defined as follows:</p>

<ul>

<li>\(\sigma(w_1) = (O_1I_3, O_2)\)</li>

<li>\(\sigma(w_2) = (I_1I_3, O_2)\)</li>

<li>\(\sigma(w_3) = (I_1O_3, O_2)\)</li>

<li>\(\sigma(w_4) = (I_1I_3, I_2)\)</li>

<li>\(\sigma(w_5) = (I_1O_3, I_2)\)</li>
</ul>

<p>
Let us assume that <em>a</em> always knows what state she is in:
\(\Pi_A(w_i) = \{w_i\}\) for all \(i \in \{1,2,3, 4,5\}\). In states
\(w_1, w_4,\) and \(w_5\), <em>b</em> knows what state he is in
(\(\Pi_B(w_i) = \{w_i\}\) for all \(i \in \{1,4,5\}\)), but <em>b</em>
cannot distinguish states \(w_2\) and \(w_3\) \((\Pi_B(w_2) =
\Pi_B(w_3) = \{w_2,w_3\}).\)</p>
</div>

<p>
The idea that players might change their mind upon observing
deviations from the subgame perfect equilibrium solution has been
captured in various ways. In the remainder of this section, following
Stalnaker (1996, 1999) and Halpern (2001), we add a <strong>selection
function</strong> to the epistemic model from
 <a href="#def38">Definition 3.8</a>.
 See Bicchieri (1988a) for a similar approach to representing how the
players revise their beliefs in a game in extensive form.</p>

<p>
Suppose that \(G=\langle N, T, \Act, \tau, (u_i)_{i \in N}\rangle\) is
a game in extensive form with perfect information and \(\cM = \langle
W, (\Pi_i)_{i\in N}, \sigma\rangle \) is a model of \(G\). A selection
function for \(\cM\) is a function \(f:W\times V\rightarrow W\), where
\(V\) is the set of decision nodes in \(T\), mapping pairs \((w, v)\)
consisting of a state \(w \in W\) and a node \(v\) from \(T\) to a
state \(f(w, v)\in W\). Intuitively, \(f(w,v)=w'\) means that if the
players would reach state \(v\) by the strategy profile \(\sigma(w)\)
(we say <strong>\(v\) is reached in the state \(w\)</strong>), then
the players would change their knowledge from what is described at
state \(w\) to what is described at \(w'\). Of course not every such
selection function captures rational belief revision policies.
Stalnaker (1996) imposes the following three postulates for the
selection function \(f\), inspired by classical belief revision theory
(Alchourr&oacute;n, G&auml;rdenfors, &amp; Makinson 1985).</p>

<ol>

<li>(<em>success</em>): The node \(v\) is reached in \(f(w,v)\).</li>

<li>(<em>centering</em>): If \(v\) is reachable in \(w\) then \(f(w,v)
= w\).</li>

<li>(<em>minimality</em>): \(\sigma(f(w,v)) = \sigma(w)\) for the
sub-tree starting at \(v\).</li>
</ol>

<p>
The key idea is to adapt the definition of substantive rationality
 (<a href="#def310">Definition 3.10</a>)
 to take into account the possibility that players may change what
they know about the other players in response to observed choices.</p>

<div class="indent" id="def312">

<p>
<strong>Definition 3.12 (Substantive rationality with selection
functions)</strong> Suppose that \(G=\langle N, T, \Act, \tau,
(u_i)_{i \in N}\rangle\) is a game in extensive form with perfect
information and \(\cM = \langle W, (\Pi_i)_{i\in N}, \sigma\rangle \)
is a model of \(G\), and \(f\) is a selection function for \(\cM\).
Player \(i\) is <strong>substantively rational at state \(w\)</strong>
provided for all decision nodes \(v\in V_i\), \(i\) is rational at
\(v\) in state \(f(w,v)\).</p>
</div>

<p>
There is a unique function \(f\) satisfying the above three postulates
for the model described in
 <a href="#ex3.11">Example 3.11</a>.
 Crucially, we have that \(f(w_1, v_2) = w_2\) and \(f(w_1, v_3) =
w_4\): from the perspective of \(w_1\), if \(v_3\) was reached then
<em>a</em> would still play \(I_3\) and this would be common knowledge
(since \(\Pi_A(w_4) = \Pi_B(w_4) = \{w_4\}\)). If, however, \(v_2\)
was reached in \(w_1\), then <em>b</em> would still play \(O_2\).
Observe that this choice is not irrational for <em>b</em>. The reason
is that \(f(w_1, v_2) = w_2\), and at \(w_2\), we have that <em>b</em>
is uncertain of what <em>a</em> will do at \(v_3\): Since,
\(\Pi_B(w_2) = \{w_2,w_3\}\), he considers it possible that <em>a</em>
will play either \(I_3\) or \(O_3\). In this case it is not irrational
for <em>b</em> to play \(O_2\). Now, since \(\Pi_A(w_1) = \Pi_B(w_1) =
\{w_1\}\), it is common knowledge at \(w_1\) that both players are
substantively rational at all nodes according to
 <a href="#def312">Definition 3.12</a>.
 Yet, \(\sigma(w_1)\) is not the subgame perfect equilibrium of that
game.</p>

<p>
This example is representative of many arguments showing that common
knowledge of rationality is not sufficient for the players to choose
their components of the subgame prefect equilibrium. The key aspect of
these arguments involve explicitly modeling how deviations from the
subgame perfect equilibrium path might trigger belief changes. Note,
however, that these arguments do not necessarily rule out that common
knowledge of rationality can entail that the subgame perfect
equilibrium <em>path</em> will be played, as opposed to players
adopting the complete subgame perfect equilibrium strategies (see, for
example, Bonanno 1991 and Aumann 1998). Furthermore, strengthening the
rationality constraints that are imposed on the belief revision
policies for the players can lead the players to adopt the complete
subgame perfect equilibrium strategies (Rich 2015).</p>

<h5 id="CommKnowRatiSuffForSubgPerfEqui">Common Knowledge of Rationality is Sufficient for the Subgame Perfect Equilibrium</h5>

<p>
The primary argument that players choose their component of the
subgame perfect equilibrium in a perfect information games is based on
the idea of common knowledge of both current and <em>future</em>
rationality. For brevity, we will refer to this as &ldquo;common
knowledge of future rationality&rdquo;. This concept implies players
act as if any node they reach is the start of a new game, disregarding
what must have happened to arrive at that node. A different approach
to argue for the subgame perfect equilibrium <em>path</em>, but not
the full profile, uses the notion of extensive form rationalizability,
a type of forward induction reasoning, discussed briefly in
 <a href="#IterWeakDomiCautBeli">Section 3.4</a>.</p>
 
<p>
The idea that common knowledge of future rationality entails that
player choose their components of the subgame perfect equilibrium has
been shown by Aumann (1995), and has subsequently been formalized in
different frameworks, see, for example, (Balkenborg &amp; Winter 1997;
Stalnaker 1998; Asheim 2002; Clausing 2003, 2004; Asheim &amp; Perea
2005; Feinberg 2005; Perea 2007b, 2014a; Samet 2013; Baltag, Smets,
&amp; Zvesper 2009). Consult Perea (2007a) and Kuechle (2009) for
detailed overviews of these arguments.</p>

<p>
We illustrate the main ideas of these arguments using the epistemic
model described in
 <a href="#ex3.11">Example 3.11</a>
 with the selection function described above. The key observation is
that common knowledge of future rationality fails at state \(w_1\).
Recall that at \(v_3\) the only rational choice for <em>a</em> is
\(I_3\), and that this fact is common knowledge since
<em>a</em>&rsquo;s choice at \(v_3\) is not dependent on what she
knows about <em>b</em>. However, if \(v_2\) were reached in \(w_1\),
then <em>b</em> considers it possible that <em>a</em> will play
\(O_3\) if he chooses \(I_2\). This rationalizes his choice of \(O_2\)
at \(f(w_1, v_2)\), but contradicts common knowledge of future
rationality.</p>

<p>
Focusing on common knowledge of future rationality bypasses the
impossibility results presented above. Recall that these impossibility
results point out that, while deciding what to do at nodes that are
off the subgame perfect equilibrium path, the players are required to
assume that the off-path nodes are reached yet common knowledge of
rationality rules out that assumption (Bicchieri 1988b; Basu 1990; and
Reny 1988, 1993). Common knowledge of future rationality avoids this
problem. It does not require the players to have any specific beliefs
about how they have reached a particular node, and in particular about
the rationality of previous choices. All that common knowledge of
future rationality entails is that the players know that, <em>from now
on</em>, all players will be rational.</p>

<p>
Common knowledge of future rationality can be seen as a limited and
perhaps implausible belief revision policy in extensive games. Indeed,
we have already seen that some assumptions about the rationality of
other players at past nodes no longer hold at nodes that are not on
the subgame perfect equilibrium path. For instance, in the game
depicted in
 <a href="#fig17">Figure 17</a>,
 we argued that <em>b</em> cannot simultaneously know that \(v_2\) is
reached and that rationality was common knowledge at \(v_1\). However,
<em>b</em> can maintain the hypothesis that, from \(v_2\) onward
rationality is and will remain common knowledge, and this is
sufficient to ensure that he will follow his subgame perfect
equilibrium strategy at that node. This hypothesis might be acceptable
for <em>b</em> following a single observed deviation, but it becomes
less intuitive in games where such deviations are frequent or
systematic. Importantly, it disregards belief changes suggested by
early literature on subgame perfect equilibrium where players adapt
future strategies based on past behaviors of others (Binmore 1987 and
Bicchieri 1988b).</p>

<p>
Before closing this section we mention Aumann&rsquo;s (1995)
characterization of subgame-perfect equilibrium. This well-known
result is one of the first epistemic characterizations of the subgame
perfect equilibrium in terms of common knowledge of rationality.
Aumann&rsquo;s result is explicitly formulated as a reply to the
impossibility results presented in the previous section, and indeed
assumes common knowledge of rationality at all nodes, past, present or
future, in a game. How can this be? The answer is that in
Aumann&rsquo;s models the players contemplate what they will do
&ldquo;<em>if</em>&rdquo; some off-paths nodes are reached, while at
the same time having common knowledge that these nodes are indeed not
reached. In our example, for instance, this boils down to assessing
the rationality of <em>b</em>&rsquo;s choices at \(v_2\) in the state
of knowledge described by \(w_1\) where, recall, it is common
knowledge that \(v_2\) is not reached.</p>

<p>
Although mathematically consistent, there is some debate about the
nature of knowledge described in Aumann&rsquo;s models. Aumann himself
describes the choices off the subgame perfect equilibrium as
&ldquo;substantive conditionals&rdquo;, which he claims are neither
material nor counterfactual. Perea (2007b) re-interprets the off-path
choices in terms of forward-looking rationality, and de Bruin (2008)
describes them in terms of a &ldquo;one-shot&rdquo; interpretation of
what the player know in the extensive game. Under these
interpretations, Aumann&rsquo;s model describes the knowledge of the
players about what will happen at different nodes before the game
starts, not at specific nodes after observing moves in the game.</p>

<p>
More generally, the difference between common knowledge of rationality
in Aumann&rsquo;s (1995) sense and the models that we have presented
in the previous section can be seen as a quantifier switch. Common
knowledge of rationality in Aumann&rsquo;s sense follows an
&ldquo;exists-forall&rdquo; pattern: It holds at a state \(w\)
whenever <em>there exists</em> a state of knowledge, namely the one
described in the epistemic model of the game, such that <em>for
all</em> nodes \(v\), reached or not by \(\sigma(w)\), the
player&rsquo;s choice at \(v\) is rational with respect to the state
of knowledge. Allowing the players&rsquo; beliefs or states of
knowledge to change off the subgame perfect equilibrium path boils
down to switching to a &ldquo;forall-exists&rdquo; pattern. For
instance, Stalnaker&rsquo;s (1999) notion of common knowledge of
rationality holds at a state \(w\) whenever <em>for all</em> nodes
\(v\) <em>there exists</em> a state of knowledge, described by the
state \(f(w,v)\), under which the player&rsquo;s choice at that node
is rational. We have seen that the state of knowledge described by
\(f(w,v)\) may vary at nodes that are not reached at \(w\).</p>

<h3 id="NashEqui">3.3 Nash Equilibrium</h3>

<p>
A <strong>Nash equilibrium</strong> is a strategy profile in which no
player has an incentive to unilaterally deviate from her strategy
choice. In other words, a Nash equilibrium is a combination of
(possibly mixed) strategies such that all players play their best
response given the strategy choices of the others. For example, in the
coordination game depicted in
 <a href="#coord-game-first">Figure 1</a>,
 \((u,l)\) and \((d,r)\) are the only pure-strategy equilibria. There
is also an equilibrium in mixed strategy, where both Ann and Bob play
each of their pure strategies with equal probabilities. See Osborne
(2004: ch. 2&ndash;4) for a more detailed introduction to Nash
equilibrium.</p>

<h4 id="EpisCharEquiPlay">3.3.1 Epistemic Characterizations of Equilibrium Play</h4>

<p>
Many authors have observed that equilibrium play involve the players
having <em>correct</em> beliefs about, or even knowledge of the
<em>choices</em> of the others, and not necessarily about their
rationality. Early statements of this observation can be found in
Armbruster &amp; B&ouml;ge (1979), Spohn (1982), and Tan &amp; Werlang
(1988). A well-known statement of this result is from Aumann &amp;
Brandenburger (1995). Before stating their result, we discuss an
example that illustrates the key ideas. Consider the following
coordination game, often called &ldquo;HiLo&rdquo; game.</p>

<div class="figure avoid-break" id="hi-lo">

<table class="cell-center cellpad-small-dense centered inner-boxTH nocaption vert-mid">
<thead style="line-height:1.1em">
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th colspan="2"><em>B</em></th> </tr>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody class="cellpad-small">
<tr>
<th rowspan="2"><em>A</em></th>
<th><em>u</em></th>
  <td>2,2</td>
  <td>0,0</td> </tr>
<tr>
<th><em>d</em></th>
  <td>0,0</td>
  <td>1,1</td> </tr> </tbody>
</table>

<p class="center">
<span class="figlabel">Figure 19</span></p>
</div>

<p>
The game has two pure-strategy Nash equilibria: \((u,l)\) and
\((d,r)\), where \((u, l)\) Parteo-dominates \((d, r)\) (both players
strictly prefer the outcome \((u,l)\) to the outcome \((d, r)\)).
There is also a mixed-strategy equilibrium where <em>a</em> and
<em>b</em> play, respectively, \(u\) and \(l\) with probability 1/3
(we denote this mixed-strategy for <em>a</em> by \((1/3u, 2/3d)\) and
for <em>b</em> by \((1/3l, 2/3r)\)). Suppose that \(\cT\) is a type
space for the game with three types for each player \(T_A=\{a_1,a_2,
a_3\}\) and \(T_B=\{b_1,b_2,b_3\}\) with the following type
functions:</p>

<div class="figure centered">

<div class="centered" style="padding-bottom:10px;max-width:100%;width:max-content;">

<div style="display:inline-block;padding-left:1em">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid shortcap-plain">
<caption>\(\lambda_A(a_1)\)</caption>
<thead>
<tr>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody>
<tr>
<th>\(b_1\)</th>
  <td>0.5</td>
  <td>0.5</td> </tr>
<tr>
<th>\(b_2\)</th>
  <td>0</td>
  <td>0</td> </tr>
<tr>
<th>\(b_3\)</th>
  <td>0</td>
  <td>0</td> </tr> </tbody>
</table>
</div>

<div style="display:inline-block;padding-left:1em">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid shortcap-plain">
<caption>\(\lambda_A(a_2)\)</caption>
<thead>
<tr>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody>
<tr>
<th>\(b_1\)</th>
  <td>0.5</td>
  <td>0</td> </tr>
<tr>
<th>\(b_2\)</th>
  <td>0</td>
  <td>0</td> </tr>
<tr>
<th>\(b_3\)</th>
  <td>0</td>
  <td>0.5</td> </tr> </tbody>
</table>
</div>

<div style="display:inline-block;padding-left:1em">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid shortcap-plain">
<caption>\(\lambda_A(a_3)\)</caption>
<thead>
<tr>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody>
<tr>
<th>\(b_1\)</th>
  <td>0</td>
  <td>0</td> </tr>
<tr>
<th>\(b_2\)</th>
  <td>0</td>
  <td>0.5</td> </tr>
<tr>
<th>\(b_3\)</th>
  <td>0</td>
  <td>0.5</td> </tr> </tbody>
</table>
</div> &nbsp;

<div style="display:inline-block;padding-left:1em">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid shortcap-plain">
<caption>\(\lambda_B(b_1)\)</caption>
<thead>
<tr>
<th>&nbsp;</th>
<th><em>u</em></th>
<th><em>d</em></th> </tr> </thead>
<tbody>
<tr>
<th>\(a_1\)</th>
  <td>0.5</td>
  <td>0</td> </tr>
<tr>
<th>\(a_2\)</th>
  <td>0</td>
  <td>0.5</td> </tr>
<tr>
<th>\(a_3\)</th>
  <td>0</td>
  <td>0</td> </tr> </tbody>
</table>
</div>

<div style="display:inline-block;padding-left:1em">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid shortcap-plain">
<caption>\(\lambda_B(b_2)\)</caption>
<thead>
<tr>
<th>&nbsp;</th>
<th><em>u</em></th>
<th><em>d</em></th> </tr> </thead>
<tbody>
<tr>
<th>\(a_1\)</th>
  <td>0.5</td>
  <td>0</td> </tr>
<tr>
<th>\(a_2\)</th>
  <td>0</td>
  <td>0</td> </tr>
<tr>
<th>\(a_3\)</th>
  <td>0</td>
  <td>0.5</td> </tr> </tbody>
</table>
</div>

<div style="display:inline-block;padding-left:1em">

<table class="cell-center cellpad-small-dense inner-boxTH vert-mid shortcap-plain">
<caption>\(\lambda_B(b_3)\)</caption>
<thead>
<tr>
<th>&nbsp;</th>
<th><em>u</em></th>
<th><em>d</em></th> </tr> </thead>
<tbody>
<tr>
<th>\(a_1\)</th>
  <td>0</td>
  <td>0</td> </tr>
<tr>
<th>\(a_2\)</th>
  <td>0</td>
  <td>0.5</td> </tr>
<tr>
<th>\(a_3\)</th>
  <td>0</td>
  <td>0.5</td> </tr> </tbody>
</table>
</div>
</div>

<p class="center">
<span class="figlabel">Figure 20</span></p>
</div>

<p>
Consider the state \((d,r,a_3,b_3)\). Both \(a_3\) and \(b_3\)
correctly believe (i.e., assign probability 1 to) that the outcome is
\((d,r)\) (we have \(\lambda_A(a_3)(r)=\lambda_B(b_3)(d)=1\)). This
fact is not common knowledge. Type \(a_3\) of <em>a</em> assigns a 0.5
probability to <em>b</em> being of type \(b_2\), and type \(b_2\) of
<em>b</em> assigns a 0.5 probability to <em>a</em> playing \(l\).
Thus, <em>a</em> is not certain whether <em>b</em> is certain that she
is playing \(r\). Furthermore, while it is true that both <em>a</em>
and <em>b</em> are rational, it is not common knowledge that they are
rational. Indeed, the type \(a_3\) assigns a 0.5 probability to
<em>b</em> being of type \(b_2\) and choosing \(r\). However, this is
an irrational type-strategy pair, since \(b_2\) believes that both of
<em>a</em>&rsquo;s options are equally probable.</p>

<p>
The example above is a situation where there is mutual knowledge of
the choices of the players, both players are rational, and they play a
Nash equilibrium. The latter follows from the first two facts. Recall
that rationality boils down to playing a best response given
one&rsquo;s belief about the strategy choices of the others. If these
beliefs turn out to be correct&mdash;i.e., the other player is
actually playing what the opponent believes she will play&mdash;then
we have recovered the definition of the Nash equilibrium in terms of
mutual best response.</p>

<p>
This observation also holds for mixed strategies, although it is
crucial that <em>both</em> players (note that we are only considering
the case of two players) play a best response to correct belief about
the others. For instance, if Ann believes with probability
\(\frac{2}{3}\) that Bob will play \(r\), then she is indifferent
between <em>any</em> of her strategies, pure or mixed. In other words,
any strategy choice is a best response to this belief of Ann, not just
her corresponding component of the mixed-strategy Nash equilibrium
\((1/3u, 2/3d)\). However, if Bob&rsquo;s belief about what Ann does
is also correct, and \((1/3l, 2/3r)\) is a best response to that, then
she must indeed be playing \((1/3u, 2/3d)\). Any higher probability on
\(u\), for instance, would make Bob prefer to play his pure strategy
\(l\). <!--The precise statement of this observation is as follows.</p>

<div class="indent">

<p>
<strong>Theorem 3.13 </strong> Suppose that <i class="m">G</i> is a
2-person strategic form game, and \(\cT\) is a type space for <i class="m">G</i>.
If \((\mathbf{s},\mathbf{t})\) is a state in \(\cT\)
where for \(i=1,2\) (a) stragety \(\mathbf{s}_i\) of player <i class="m">i</i>
is a best response to \(\mathbf{t}_i\) and (b) <i class="m">i</i>
assigns probability 1 to the event that the other
player <i class="m">j</i> plays \(\mathbf{s}_j\), then \(\mathbf{s}\)
is a Nash equilibrium.</p>
</div> --> </p>

<p>
Although we focus on complete information games in this article, the
result in fact also holds in cases of incomplete information. See, for
instance, Aumann &amp; Brandenburger (1995) and Bach &amp; Perea
(2020) for details.</p>

<p>
Extending this result to three or more players raises complications
(Tan &amp; Werlang 1988; Bicchieri 1995). Rationality and mutual
knowledge of strategy choice is no longer sufficient to ensure the
Nash equilibrium. Some results for an arbitrary finite number of
players use <em>common knowledge</em> of the strategies that are
played, as well assuming that there is a <em>common prior belief</em>.
We return to this latter assumption in the next section, where we
discuss the epistemic interpretation of mixed strategy Nash
equilibria. See Aumann &amp; Brandenburger (1995: Theorem B) for
precise formulation of the result, and, again, Spohn (1982) for an
early version. See, also, Perea (2007b) and Tan &amp; Werlang (1988),
Bach &amp; Tsakas (2014), Barelli (2009) and Brandenburger &amp; Dekel
(1987) for similar results or alternative characterizations of the
Nash equilibrium.</p>

<p>
Both the two player and the <em>n</em>-player characterizations of
Nash equilibrium no longer hold when the players can be mistaken about
the strategy choice of the others. Suppose, for instance, that in our
example Ann assigns probability 1 to Bob playing \(r\), and Bob
probability 1 to Ann playing \(u\). Their respective best response,
\((d,l)\), is indeed not a Nash equilibrium.</p>

<p>
The use of mutually correct beliefs in the epistemic characterization
of the Nash equilibrium has lead to criticisms of the Nash equilibrium
as a solution concept. The question is how do players ever come to
have such correct beliefs or common knowledge about what the other
players are choosing (cf. Skyrms 1990). This seems to go against the
very idea of a game in strategic form, where the players choose
simultaneously, without knowing the choices of the other players. Tan
&amp; Werlang (1988) were among the first to express this concern,
which has become increasingly prevalent in epistemic game theory (see,
for instance, Gintis 2009, de Bruin 2010, and Perea 2012). However,
one might justify the strong correctness assumption by citing
exogenous factors such as the broader historical, evolutionary, or
cultural context within which the game is situated, particularly for
coordination games. Bicchieri (1995) offers an insightful and nuanced
discussion of this argument and the epistemic characterization of Nash
equilibrium.</p>

<p>
There is another important lesson to draw from the epistemic
characterization of Nash equilibrium play. The widespread idea that
game theory assumes common knowledge of rationality, perhaps in
conjunction with the extensive use of equilibrium concepts in
game-theoretic analysis, has lead to the misconception that the Nash
Equilibrium either <em>requires</em> common knowledge of rationality,
or that common knowledge of rationality is sufficient for the players
to play according to a Nash equilibrium (see Bicchieri 1995 for a
discussion of this point). The above result shows that both of these
ideas are incorrect. Common knowledge of rationality is neither
necessary nor sufficient for Nash Equilibrium play. In fact, as we
just stressed, the Nash equilibrium can be played under full
uncertainty, and <em>a fortiori</em> under higher-order uncertainty,
about the rationality of others.</p>

<h4 id="EpisInteMixeStraEqui">3.3.2 Epistemic Interpretation of Mixed Strategy Equilibrium</h4>

<p>
A seminal result in game theory is that every finite game in strategic
form has a Nash equilibrium (Nash 1951). It is crucial for this result
to allow players to adopt <em>mixed</em> strategies. Indeed, it is not
hard to find games in which there are no pure-strategy Nash
equilibria.
 <a href="#matching-pennies">Figure 21</a>
 is a well-known example of a <em>zero-sum</em> game in which there
are no pure-strategy Nash equilibria (this game is called <em>matching
pennies</em>).</p>

<div class="figure" id="matching-pennies">

<table class="cell-center cellpad-small-dense centered inner-boxTH nocaption vert-mid">
<thead style="line-height:1.1em">
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th colspan="2"><em>B</em></th> </tr>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody class="cellpad-small">
<tr>
<th rowspan="2"><em>A</em></th>
<th><em>u</em></th>
  <td>1,&minus;1</td>
  <td>&minus;1,1</td> </tr>
<tr>
<th><em>d</em></th>
  <td>&minus;1,1</td>
  <td>1,&minus;1</td> </tr> </tbody>
</table>

<p class="center">
<span class="figlabel">Figure 21:</span> The matching pennies game</p>
</div>

<p>
It is not hard to see that the mixed strategy profile in which
<em>a</em> adopts the mixed-strategy that assigns probability 0.5 to
\(u\) and <em>b</em> adopts the mixed strategy that assigns
probability 0.5 to \(l\) is a Nash equilibrium: Neither <em>a</em> nor
<em>b</em> has an incentive to unilaterally deviate from their mixed
 strategy.<sup>[<a href="notes.html#note-15" id="ref-15">15</a>]</sup></p>
 
<p>
The interpretation of mixed-strategy Nash equilibria, especially in
one-shot games, has been much debated. The traditional interpretation
of a mixed strategy Nash equilibria is in terms of genuine
randomization. When a player adopts a mixed strategy, she commits to
using some type of randomizing device, which picks one of her pure
strategies with the probabilities specified by the mixed strategy.
probabilities. One classical defense of this interpretation can be
found already in von Neumann and Morgenstern: randomization allows
players to obfuscate their choices to their
 opponents.<sup>[<a href="notes.html#note-16" id="ref-16">16</a>]</sup>
 While this idea makes sense for zero-sum games such as the matching
pennies game depicted in
 <a href="#matching-pennies">Figure 21</a>,
 it is less compelling when players are not in direct competition. For
instance, in the coordination game from
 <a href="#hi-lo">Figure 19</a>,
 the players seems to have an incentive to reveal their choice to the
other player to ensure a beneficial outcome. Furthermore, a number of
authors have expresses reservations about the idea of delegating
one&rsquo;s choice to a randomizing device (consult Rubinstein 1991,
Icard 2021, and Zollman 2022 for different perspectives about
this).</p>

<p>
The <em>epistemic</em> interpretation of mixed strategies has emerged,
in part, as a reaction to worries about the traditional interpretation
as genuine randomization. The idea for an epistemic interpretation of
a mixed-strategy Nash equilibrium can be traced to three sources:
Harsanyi&rsquo;s (1973) purification theorem, Aumann&rsquo;s work on
correlated equilibrium (Aumann 1974, 1987), and early work in
epistemic game theory (Armbruster &amp; B&ouml;ge 1979; Spohn 1982;
Tan &amp; Werlang 1988). Starting in the mid 1990s, corresponding
roughly with the publication of (Aumann &amp; Brandenburger 1995)
where the epistemic interpretation is prominently stated, the
epistemic interpretation of mixed-strategies has been widely adopted
in the epistemic game theory literature.</p>

<p>
The epistemic interpretation of mixed strategy equilibrium, as
presented in (Aumann &amp; Brandenburger 1995), consists of three
claims:</p>

<ol>

<li>The players do not randomize;</li>

<li>The probabilities in a mixed strategy for a player represent
uncertainty about what that player will do;</li>

<li>The probabilities in the mixed strategy for player \(i\) are the
subjective credences of the other players about what player \(i\) will
do.</li>
</ol>

<p>
Given this, a mixed strategy Nash equilibrium is interpreted as a set
of commonly known expectations with the property that all players play
best response to those expectations.</p>

<p>
The first claim is that players only choose pure strategies. This
claim by itself need not lead to an epistemic interpretation of mixed
strategies. One popular, non-epistemic interpretation of a mixed
strategy Nash equilibrium, the steady-state interpretation, views
mixed strategies as reflecting distributions of pure strategies in
large populations of players (Weibull 1995). On this interpretation
the players do not randomize either, but the mixed strategies are not
interpreted as subjective probabilities.</p>

<p>
The core of the epistemic interpretation is the second claim that a
mixed strategy for a player represents uncertainty about what that
player will do. Harsanyi&rsquo;s (1973) purification theorem was one
of the earliest formulations of this claim. This theorem interprets
mixed strategies as expressing payoff uncertainties in a
&lsquo;perturbed game&rsquo;, where the players&rsquo; utilities may
slightly fluctuate due to exogenous factors viewed as each
players&rsquo; &lsquo;mood&rsquo;. Each player knows his or her own
mood but not those of the other players. So, the perturbed games are
games of incomplete information (cf.
 <a href="#IncoInfo">Section 1.4</a>).
 According to the theorem, for almost all mixed strategy Nash
equilibrium in a strategic form game, one can construct a sequence of
perturbed games of incomplete information where all the equilibria
involve pure strategies, and these equilibria converge to the mixed
strategy equilibrium as the size of the payoff perturbations goes to
zero (see Morris 2006 for an overview of this important theorem). The
upshot of this theorem is that the mixed strategies in a Nash
equilibrium represent uncertainty about each players&rsquo; private
inclination to choose one action or
 another.<sup>[<a href="notes.html#note-17" id="ref-17">17</a>]</sup></p>
 
<p>
Harsanyi&rsquo;s purification theorem provides an epistemic
interpretation of mixed strategy Nash equilibria by augmenting the
underlying description of the game with payoff-relevant
factors&mdash;i.e., by moving from complete information games to
incomplete information games. Aumann (1974) developed a similar
interpretation of mixed strategies using exogenous but payoff
irrelevant signals. The idea is that the players condition their
strategy choice on some private external <em>signal</em>. The signals
received by the players are drawn from a commonly known probability
distribution and are private in the sense that each player knows her
own signal but not the signal received by the other players. Aumann
(1974, 1987) has shown that if the players are rational and the
signals received by each player are independent, then the probability
distribution on the players&rsquo; respective pure strategies that is
naturally constructed from the distributions on signals and the
player&rsquo;s conditional strategies is a mixed strategy Nash
equilibrium. In the more general case, when the signals may be
correlated, the players will end up playing a <em>Correlated
Equilibrium</em> (see Vanderschraaf, 2001, for a excellent discussion
of this and related results).</p>

<p>
The final step to arrive at the contemporary epistemic interpretation
of mixed strategies is to do away with exogenous components such as
&lsquo;moods&rsquo; or &lsquo;signals&rsquo;, and focus exclusively on
the strategic uncertainty of the players. This was achieved by Tan and
Werlang (1988)&mdash;who also credit Armbruster &amp; B&ouml;ge (1979)
for the result&mdash;for two players, and generalized to three or more
players by Aumann and Brandenburger (1995). The first key idea is to
endogenize, in game models, the role that was played by the commonly
known probability on the player&rsquo;s signals from Aumann (1974,
1987). This is typically done by assuming that the players have
<em>common prior beliefs</em> on the underlying set of states in a
type space or an epistemic(-probability) model. The player&rsquo;s
posterior at the <em>ex interim</em> stage is then computed by
conditioning this common prior on the player&rsquo;s private
information, which typically includes her type and her choice of pure
strategy. The second key idea is to make sense of the notion of
<em>the</em> subjective credence of the other players about a
player&rsquo;s pure-strategy choice. In two-player games this is not a
problem, since there is just one opponent we can read off the
subjective credences from a mixed strategy. However, with more than
two players, nothing in principle prevents different opponents from
having different posterior beliefs about what some player will do,
even if their is a common prior belief. Thus, with more than two
players, the notion of <em>the</em> credence of the other players does
not make sense. The assumption that the posterior probabilities are
commonly known, under a common prior, circumvents this difficulty
(Aumann 1976). Putting everything together, we have the following
theorem, which captures the epistemic interpretation of mixed
strategies (Tan &amp; Werlang 1988; Aumann &amp; Brandenburger
1995).</p>

<p>
We first need some notation. Suppose that \(G=\langle N, (S_i)_{i\in
N}, (u_i)_{i\in N}\rangle\) is a game in strategic form. A
<strong>conjecture</strong> for player \(i\) is a probability on the
strategies of the other players: i.e., a conjecture for player \(i\)
is an element of \(\Delta(\times_{j\neq i} S_j)\). Suppose that \(p\in
\Delta(\times_{j\neq i} S_j)\) is a conjecture for player \(i\). Then,
for each player \(j\neq i\), the conjecture \(p\) induces a
probability over \(S_j\) (formally, by taking the marginal of \(p\)
with respect to \(S_j\)) that represents the conjecture of \(i\) about
\(j\) induced by \(p\). We can associate a state \(w\) in a model for
the game \(G\) (either an epistemic-probability model or a type
space), with a conjecture for player \(i\) denoted by \(\phi_{w,i}\)
(so \(\phi_{w,i}\in \Delta(\times_{j\neq i} S_j)\)). For all players
\(i\) and states \(w\) in the game model and all players \(j\neq i\),
let \(\phi^j_{w,i}\) be \(i\)&rsquo;s conjecture about \(j\) induced
by \(\phi_{w,i}\) (so \(\phi^j_{w,i}\in \Delta(S_j)\)).</p>

<div class="indent">

<p>
<strong>Theorem 3.13 </strong> Let \(G\) be a game in strategic form
and \(w\) be a state in a model for \(G\) (either an
epistemic-probability model or a type space). Suppose that</p>

<ol>

<li>there is a common prior (i.e., a single probability measure) on
the set of states in the game model that assumes that the choices of
all the players are independent,</li>

<li>all players are rational at \(w\),</li>

<li>all players assign probability 1 to the other players being
rational at \(w\), and</li>

<li>the players&rsquo; conjectures at \(w\) about the other players
are common knowledge (i.e., the event that each player \(i\)&rsquo;s
conjecture is \(\phi_{w,i}\) is common knowledge),</li>
</ol> Then, for all players \(j\), each player&rsquo;s induced
conjecture about \(j\) are the same (i.e., for all players \(i\),
\(j\), and \(k\), if \(k\neq i\) and \(k\neq j\), then
\(p_{w,i}^j=p_{w,k}^j\)). Furthermore, the conjectures about each
player induced by the other players&rsquo; conjecture at \(w\) form a
mixed strategy Nash equilibrium.
</div>

<p>
If we lift the assumption that the common prior beliefs are
uncorrelated then the conjectures about each player induced by the
other players&rsquo; conjecture form a mixed strategy correlated
equilibrium (Brandenburger &amp; Dekel 1987), and if we lift the
common prior assumption altogether we obtain that the conjectures
about each player induced by the other players&rsquo; conjecture
constitute <em>rationalizable</em> mixed strategies (cf.
 <a href="#CommBeliRatiIterElimStriDomiStra">Section 3.1.2</a>).</p>
 
<p>
It is important to emphasize that this result is not a
characterization of equilibrium <em>play</em>. Recall that in a mixed
strategy Nash equilibrium any strategy in the support of that mixed
strategy is a best response to the mixed strategy played by the
 others.<sup>[<a href="notes.html#note-18" id="ref-18">18</a>]</sup>
 Thus, in any state in a model of game satisfying the assumptions of
the above Theorem, any strategy for a player \(i\) in the support of
the other players&rsquo; beliefs about her choice is a best response
to \(i\)&rsquo;s belief about what the others will do. For example,
if, in the HiLo game from
 <a href="#hi-lo">Figure 19</a>,
 Ann believes that Bob will play \(l\) with probability 1/3, then she
is indifferent between \(u\) and \(d\), and similarly for Bob. So, it
is possible to construct a state where the conditions of the above
Theorem hold while Ann plays \(u\) and Bob plays \(r,\) which is
<em>not</em> a Nash equilibrium play of the game. Some authors have
argued that this puts into question the predictive power of a Nash
equilibrium as a solution concept (cf. Bicchieri 1995; Rubinstein,
1991).</p> <!--  <p>
On the basis of the previous observation, it can be argued that the
Nash equilibrium, under the epistemic interpretation, loses most of
its predictive power. Indeed, as we just seen, if mixed strategies
equilibria express mutual conjectures of the players, then in many
games it leaves quite open which pure strategy are going to be chosen,
even by rational players under common prior and common knowledge of
their mutual conjectures. The theory does not predict anymore that an
equilibrium in pure strategies will be chosen by rational players,
sometimes not even a combination of pure strategies in the support of
the underlying mixed strategy equilibrium. On the basis of that one
could raise doubts about the foundation of Nash equilibrium altogether
(Bicchieri 1995), or bite the bullet and grant that the theory has
very limited predictive power (Rubinstein 1991). </p>-->

<h3 id="IterWeakDomiCautBeli">3.4 Iterated Weak Dominance and Cautious Beliefs</h3>

<p>
The fundamental theorem of epistemic game theory
 (<a href="#FundTheoEpisGameTheo">Section 3.1</a>)
 is an epistemic characterization of the strategy profiles that
survive iterated removal of strictly dominated strategies. Another
important iterative procedure in game theory is iteratively removing
strategies that are <em>weakly</em> dominated strategies.</p>

<div class="indent">

<p>
<strong id="s-domweak">Definition 3.14 (Weak Dominance)</strong>
Suppose that</p> 
\[G=\langle N, (S_i)_{i\in N}, (u_i)_{i\in N}\rangle\]

<p>
is a game in strategic form and \(X\subseteq S_{-i}\). Let \(m, m'\in
\Delta(S_i)\) be two mixed strategies for player \(i\). The strategy
\(m\) <strong>weakly dominates \(m'\) with respect to \(X\)</strong>
provided</p>

<ol>

<li>for all \(s_{-i}\in X\), \(U_i(m,s_{-i}) \geq U_i(m',s_{-i})\),
and</li>

<li>there is some \(s_{-i}\in X\) such that \(U_i(m,s_{-i}) &gt;
U_i(m',s_{-i})\).</li>
</ol>

<p>
We say \(m\) is <strong>weakly dominated</strong> provided there is
some \(m'\in \Delta(S_i)\) that weakly dominates \(m\).</p>
</div>

<p>
There is an analogue of
 <a href="#sdom-prob">Lemma 3.2</a>
 stating that a strategy in a game is strictly dominated if, and only
if, that strategy is not a best response to any probability over the
other players&rsquo; choices. Given a set \(X\), say that a
probability measure \(p\in \Delta(X)\) has <strong>full
support</strong> with respect to \(X\) if \(p\) assigns positive
probability to every element of \(X\) (i.e., for all \(x\in X\),\(p(x)
&gt; 0\)). Let \(\Delta^{&gt;0}(X)\) be the set of full support
probability measures on \(X\). A full support probability on
\(S_{-i}\) means that player \(i\) does not completely rule out (in
the sense, that she assigns zero probability to) any strategy profile
of her opponents.</p>

<div class="indent" id="wdom-prob">

<p>
<strong>Lemma 3.15</strong> Suppose that \(G=\langle N, (S_i)_{i\in
N}, (u_i)_{i\in N}\rangle\) is a game in strategic form. A strategy
\(s\in S_i\) is weakly dominated (possibly by a mixed strategy) with
respect to \(X\subseteq S_{-i}\) iff there is no full support
probability measure \(p\in \Delta^{&gt;0}(X)\) such that \(s_i\) is a
best response with respect to \(p\).</p>
</div>

<p>
The proof of this Lemma is more involved than the proof of
 <a href="#sdom-prob">Lemma 3.2</a>:
 See Bernheim (1984: Appendix A) for a proof.</p>

<p>
Iterated elimination of weakly dominated strategies proceeds as
follows: iteratively remove all weakly dominated strategies from a
game until there are no strategies that are weakly dominated (cf. the
definition of iterated elimination of strictly dominated strategies
from
 <a href="#CommBeliRatiIterElimStriDomiStra">Section 3.1.2</a>).
 Clearly, since strict dominance implies weak dominance, any strategy
that is removed during the iterated removal of strictly dominated
strategies is also removed during the iterated removal of weakly
dominated strategies. However, it is not hard to find games in which
there are strategy profiles that do not survive iterated removal of
weakly dominated strategies yet they do survive iterated removal of
strictly dominated strategies (e.g., the game in
 <a href="#samuelson-game">Figure 22</a>
 in which no strategies are strictly dominated in the full game yet
the only strategy that survives iterated removal of weakly dominated
strategies is \((u,l)\)).</p>

<p>
There are three crucial differences between iterated removal of weakly
dominated strategies and iterated removal of strictly dominated
strategies. The first difference is that iterative elimination of
strictly dominated strategies is <em>order-independent</em> but
iteratively removal of weakly dominated strategies is not
order-independent. This means that, in contrast to iterated strict
dominance, the sequence of eliminating weakly dominated strategies can
make a difference to the end result. That is, there are games in which
a strategy profile survives iterated removal of some sequence of
weakly dominated strategies but does not survive if the weakly
dominated strategies are removed in a different order (see, for
instance, Apt 2011 for a discussion of this well-known fact). There is
an interesting question about the significance of order-independence
for the epistemic characterization of an iterative procedure (Trost
2014). To avoid this complication, it is important that <em>all</em>
weakly dominated strategies for all players are removed at each step
of the iterative procedure.</p>

<p>
The second difference between weak and strict dominance poses an
intriguing problem for the epistemic characterization of iterated
elimination of weakly dominated strategies. Compare the
characterization of strict dominance in
 <a href="#sdom-prob">Lemma 3.2</a>
 with the characterization of weak dominance in
 <a href="#wdom-prob">Lemma 3.15</a>:
 A strategy is strictly dominated if it is never a best response to
<em>any</em> probability over the opponents strategies while a
strategy is weakly dominated if it is never a best response to any
full support probability over the opponents strategies. Thus, avoiding
weakly dominated strategies with respect to \(X\) requires the player
to have <em>cautious beliefs</em> about their opponents that does not
rule-out any strategy profile in \(X\).</p>

<p>
The third difference is that there is no analogue of
 <a href="#mon-sdom">Observation 3.3</a>
 for weak dominance. If a strategy is strictly dominated, it remains
so if the player gets more information about what her opponents
(might) do. However, if a strategy \(s\) is weakly dominated with
respect to \(X\) then it need not be the case that \(s\) is weakly
dominated with respect to some \(X'\subsetneq X\).</p>

<p>
Many authors have pointed out that these differences between weak and
strict dominance creates a puzzle for the epistemic characterization
of iterated removal of weakly dominated strategies (Samuelson 1992;
Asheim &amp; Dufwenberg 2003; Brandenburger, Friedenberg &amp; Keisler
2008; Cubitt &amp; Sugden 1994). To illustrate the puzzle, consider
the following game (Samuelson, 1992):</p>

<div class="figure avoid-break" id="samuelson-game">

<table class="cell-center cellpad-small-dense centered inner-boxTH nocaption vert-mid">
<thead style="line-height:1.1em">
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th colspan="2">Bob</th> </tr>
<tr>
<th>&nbsp;</th>
<th>&nbsp;</th>
<th><em>l</em></th>
<th><em>r</em></th> </tr> </thead>
<tbody class="cellpad-small">
<tr>
<th rowspan="2">Ann</th>
<th><em>u</em></th>
  <td>1,1</td>
  <td>1,0</td> </tr>
<tr>
<th><em>d</em></th>
  <td>1,0</td>
  <td>0,1</td> </tr> </tbody>
</table>

<p class="center">
<span class="figlabel">Figure 22</span>: Game from Samuelson
(1992).</p>
</div>

<p>
In this game \(d\) is weakly dominated by \(u\) for Ann. If Bob knows
that she does not choose weakly dominated strategies, then he can rule
out her playing \(d\). In the smaller game, \(r\) is now strictly
dominated by \(l\) for Bob. If Ann knows that Bob is rational and that
Bob knows that she does not choose weakly dominated strategies (and
so, rules out option \(d\)), then she can rule out option \(r\).
Assuming that the above reasoning is transparent to both Ann and Bob,
it is common knowledge that Ann will play \(u\) and Bob will play
\(l\). But now, what is the reason for Bob to rule out the possibility
that Ann will play \(d\)? He knows that Ann knows that he is going to
play \(l\) and both \(u\) and \(d\) are best responses to \(l\). The
problem is that assuming that the players&rsquo; beliefs are cautious
conflicts with the logic of iteratively removing weakly dominated
strategies. This issue is nicely described in a well-known
microeconomics textbook:</p>

<blockquote>

<p>
[T]he argument for deletion of a weakly dominated strategy for player
\(i\) is that he contemplates the possibility that every strategy
combination of his rivals occurs with positive probability. However,
this hypothesis clashes with the logic of iterated deletion, which
assumes, precisely that eliminated strategies are not expected to
occur. (Mas-Colell, Whinston, &amp; Green 1995: 240)</p>
</blockquote>

<p>
The extent of this tension is nicely illustrated by Samuelson (1992),
who shows that there is no epistemic-probability
 model<sup>[<a href="notes.html#note-19" id="ref-19">19</a>]</sup>
 of the above game where, on the one hand, it is common knowledge that
players do not choose strategies that are iteratively weakly dominated
but also, on the other hand, that the players do not know
<em>more</em> than that. This second requirement is a strengthening of
the notion of cautious beliefs described above. Not knowing more than
the fact that the others do not choose weakly dominated strategies
means, for Samuelson (1992), that in case two strategies have the same
expected utility for a player, her opponents cannot <em>know</em>
which options she will
 <em>pick</em><sup>[<a href="notes.html#note-20" id="ref-20">20</a>]</sup>.
 In game depicted in
 <a href="#samuelson-game">Figure 22</a>,
 if Ann knows that Bob is choosing \(l\), then Ann is indifferent
between \(u\) and \(d\). So according to this stronger notion of
cautious belief Bob cannot know that Ann is choosing \(u\). This
suggests an additional constraint on a game model. Suppose that \(w\)
is a state in a model for a game \(G\) (either an
epistemic-probability model or a type space), \(i\) is a player in
\(G\) and \(s\) is strategy for player \(i\). If \(s\) is rational for
player \(i\) at state \(w\), then for all players \(j\neq i\), \(j\)
cannot know that \(i\) does not choose \(s\) (i.e., \(j\) cannot
assign probability 0 to the event that player \(i\) chooses \(s\)).
This property is called &ldquo;privacy of tie-breaking&rdquo; by
Cubitt and Sugden (2011: 8) and &ldquo;no extraneous beliefs&rdquo; by
Asheim and Dufwenberg
 (2003).<sup>[<a href="notes.html#note-21" id="ref-21">21</a>]</sup>
 Thus, Samuelson (1992) showed that there is a fundamental tension
between common knowledge of not playing strategies that do not survive
iterated weakly dominated strategies and a strong form of cautiousness
of belief that includes privacy of tie-breaking (see Cubitt &amp;
Sugden 2011, for a discussion).</p>

<p>
The epistemic characterization of iterated weak dominance is not a
straightforward adaptation of the analysis of iterated strict
dominance discussed presented in
 <a href="#CommBeliRatiIterElimStriDomiStra">Section 3.1.2</a>.
 In particular, any such analysis must resolve the conflict between
strategic reasoning where players <em>rule out</em> certain strategy
choices of their opponent(s) and some form of cautiousness where
players all rational choices of the other players are consider
<em>possible</em>. A number of authors have developed frameworks that
resolve this conflict (Brandenburger, Friedenberg, &amp; Keisler 2008;
Asheim &amp; Dufwenberg 2003; Halpern &amp; Pass 2019; Lorini 2013;
Catonini &amp; De Vito 2023
 [<a href="#Oth">Other Internet Resources</a>];
 Stahl 1995; Hillas &amp; Samet 2020). In the remainder of this
section, we sketch one of these solutions from (Brandenburger,
Friedenberg, &amp; Keisler 2008)</p>

<p>
The key idea is to represent the players&rsquo; beliefs as a
<em>lexicographic probability system</em> (LPS). An LPS is a finite
sequence of probability measures \((p_1,p_2,\ldots,p_n)\) with
supports (the <strong>support</strong> of a probability measure \(p\)
defined on a set of states \(W\) is the set of all states that have
nonzero probability; formally, \(Supp(p)=\{w \mid p(w)&gt;0\}\)) that
do not overlap. This is interpreted as follows: if
\((p_1,\ldots,p_n)\) represents Ann&rsquo;s beliefs, then \(p_1\) is
Ann&rsquo;s &ldquo;initial hypothesis&rdquo; about what Bob is going
to do, \(p_2\) is Ann&rsquo;s secondary hypothesis, and so on. For
example, in the game from
 <a href="#samuelson-game">Figure 22</a>,
 we can describe Bob&rsquo;s beliefs as follows: his initial
hypothesis is that Ann will choose \(u\) with probability 1 and his
secondary hypothesis is that she will choose \(d\) with probability 1.
The interpretation is that, although Bob does not completely rule out
the possibility that Ann will choose \(d\), he considers it
<em>infinitely less likely</em> than her choosing \(u\).</p>

<p>
Representing beliefs as lexicographic probability measures brings us
one step closer to resolving the conflict between strategic reasoning
and the assumption that players do not play strategies that do not
survive iterated removal of weakly dominated strategies. However,
there is another, more fundamental, issue that arises in the epistemic
analysis of iterated weak dominance:</p>

<blockquote>

<p>
Under admissibility, Ann considers everything possible. But this is
only a decision-theoretic statement. Ann is in a game, so we imagine
she asks herself: &ldquo;What about Bob? What does he consider
possible?&rdquo; If Ann truly considers everything possible, then it
seems she should, in particular, allow for the possibility that Bob
does not! Alternatively put, it seems that a full analysis of the
admissibility requirement should include the idea that other players
do not conform to the requirement. (Brandenburger, Friedenberg, &amp;
Keisler 2008: 313)</p>
</blockquote>

<p>
There are two main ingredients to the epistemic characterization of
iterated weak dominance. The first is to represent the players&rsquo;
beliefs as lexicographic probability systems. The second is to use a
stronger notion of belief: A player <strong>assumes</strong> an event
\(E\) provided \(E\) is infinitely more likely than \(\overline{E}\)
(on finite spaces, this means each state in \(E\) is infinitely more
likely than states not in \(E\)) (see Brandenburger, Friedenberg,
&amp; Keisler 2023, for a recent discussion of this notion of belief).
The key question is: What is the precise relationship between the
event &ldquo;rationality and common assumption of rationality&rdquo;
and the strategies that survive iterated removal of weakly dominated
strategies? The details of the answer are beyond the scope of this
article (see Brandenburger, Friedenberg, &amp; Keisler 2008 for the
answer).</p>

<h3 id="ForwInduExteFormRati">3.5 Forward Induction and Extensive Form Rationalizability</h3>

<p>
Unlike backward induction, <em>forward induction</em> is not a
well-defined solution concept for games in extensive form, but rather
an umbrella term for the idea that players draw inferences about the
strategies and the beliefs of others at current and future decision
nodes based on observations about what they chose in the past. Indeed,
the term &ldquo;induction&rdquo; in &ldquo;backward induction&rdquo;
evokes the concept of mathematical induction. &ldquo;Forward
induction&rdquo;, on the other hand, brings to mind inductive
reasoning in a more Humean sense: the decision maker draws conclusions
about future observations based on a limited number of past
observations. A key aspect of any solution concept for game in
extensive form that incorporates forward induction reasoning is a
representation of how players react to observing surprising moves in a
game:</p>

<blockquote>

<p>
Faced with surprising behavior in the course of a game, the players
must decide what then to believe. Their strategies will be based on
how their beliefs would be revised, which will in turn be based on
their epistemic priorities&mdash;whether an unexpected action should
be regarded as an isolated mistake that is thereby epistemically
independent of beliefs about subsequent actions, or whether it
reveals, intentionally or inadvertently, something about the
player&rsquo;s expectations, and so about the way she is likely to
behave in the future. (Stalnaker 1998: 54)</p>
</blockquote>

<p>
Examples of forward induction methods include explainable equilibrium
(Reny 1992) and strong \(\Delta\)-rationalizability, which is a form
of rationalizability under constraints (Battigalli 2003; Battigalli
&amp; Siniscalchi 2003, Catonini 2019). In this section, we focus on
extensive form rationalizability (Pearce 1984; Battigalli 1997), which
is arguably the most well-studied forward induction method.</p>

<p>
The core idea of extensive form rationalizability is that players
should try, as much as possible, to interpret past choices of the
other players as rational. Here, &ldquo;interpret&rdquo; means
attribute beliefs to the other players for which their past choices
are rational (Battigalli 1997). To illustrate, consider the well-known
game in which player <em>a</em> initially chooses to end the game with
a payout of 2 for both players or to play the strategic form game
(Kohlberg &amp; Mertens 1986; van Damme 1989). Note that this is an
example of an <em>extensive game with simultaneous moves</em> since
neither player observes the other players move at the second decision
node.</p>

<div class="figure" id="fi-game">
<img alt="a diagram: link to extended description below" src="fig23.png" style="padding-bottom:10px; width:20em" />

<p class="center">
<span class="figlabel">Figure 23</span> [An
 <a href="figdesc.html#fi-game">extended description of figure 23</a>
 is in the supplement.]</p>
</div>

<p>
In the game in
 <a href="#fi-game">Figure 23</a>,
 <em>a</em> first chooses between playing normal form game with
<em>b</em>, or choosing an &ldquo;outside option&rdquo; and ending the
game at the first node. <em>a</em> cannot rationally choose \(I\)
unless she assigns a probability of at least 2/3 that <em>b</em> will
choose \(l\). Otherwise, whatever she chooses in the normal form game,
her expected utility is lower than the guaranteed 2 that she gets from
the outside option \(O\). So, if <em>b</em> observes <em>a</em>
choosing \(I\) and he believes that this was a rational choice, then
he must conclude that <em>a</em> believes with degree at least 2/3
that he will choose \(l\). Then, he also concludes that the only
rational choice in the normal form game for <em>a</em> is \(u\),
leading him to choose \(l\) (assuming that he is rational). In other
words, extensive-form rationalizability requires <em>b</em> to rule
out certain beliefs of <em>a</em> after he observes her choosing
\(I\), from which he can conclude that she must choose \(u\) in the
normal form game. If this reasoning is transparent to both players,
then <em>a</em> will choose \(I\) followed by \(u\) and <em>b</em>
will choose \(l\).</p>

<p>
The main epistemic characterization of extensive form
rationalizability is in terms of common strong belief in rationality
(Battigalli &amp; Siniscalchi 2002). We briefly discussed
&ldquo;strong belief&rdquo; in the beginning of
 <a href="#AddiBeli">Section 2.1.2</a>.
 The mathematical representation of beliefs in Battigalli &amp;
Siniscalchi (2002) is different, although the underlying idea is the
same. A useful characterization of strong belief is that a player
strongly believes an event \(E\) provided she believes \(E\) is true
at the beginning of the game (in the sense that she assigns
probability 1 to \(E\)) and continues to believe \(E\) as long as it
is not ruled out by her evidence. The evidence available to a player
in an extensive form game consists of the observations of the previous
moves that are consistent with the structure of the game tree. So,
common strong belief in rationality means that the players commonly
believe that everyone rationalizes past moves, in the sense of ruling
out beliefs under which these moves are not rational.</p>

<p>
An important result about backward and forward induction is that in
extensive games of perfect information with no ties in the players
utilities, common strong belief in rationality and hence extensive
form rationalizability yield the <em>same</em> outcome as subgame
perfect equilibrium (Battigalli 1997). This is not to say that the two
solution concepts fully coincide in perfect information games. They
can make different predictions off the subgame perfect equilibrium
path. The underlying idea is that deviations from the subgame perfect
equilibrium path may not be rationalizable, and extensive form
rationalizability does not impose constraints in such cases. See
Heifetz &amp; Perea (2015), Catonini (2019), and Perea (2018) for
different proofs of this result and Arieli &amp; Aumann (2015) for a
proof in the special case where each player only moves once.</p>

<h2 id="AddiTopi">4. Additional Topics</h2>

<p>
This section provides a brief overview and references to relevant
research concerning topics that are related to the main ideas of
epistemic game theory discussed in the previous sections.</p>

<h3 id="IncoUnaw">4.1 Incorporating Unawareness</h3>

<p>
In all of the results presented in this article, the structure of the
game (who is playing, what are the preferences of the players, and
which actions are available) is assumed to be common knowledge among
the players. There are of course many situations where the players do
not have such complete information about the game. The models of games
presented in
 <a href="#GameMode">Section 2</a>
 can be used to describe the beliefs of players with incomplete
information about the game. However, these models cannot capture cases
where, for instance, a player cannot even conceive of the possibility
that her opponent will choose a certain action, or more generally that
different players have completely different views of the game that
they are playing. This type of <em>unawareness</em> goes beyond simply
believing that it is impossible for one&rsquo;s opponent to choose a
certain action. There is an extensive literature devoted to developing
models that can represent the players&rsquo; unawareness. See Schipper
(2015) for an overview of this extensive literature, and, for
instance, R&ecirc;go &amp; Halpern (2012) and Perea (2022) for a
discussion of how representing unawareness of the players affects key
results in epistemic game theory.</p>

<h3 id="AlteChoiRule">4.2 Alternative Choice Rules</h3>

<p>
In an epistemic analysis of a game, the specific recommendations or
predictions for the players&rsquo; choices are derived from
decision-theoretic choice rules. Maximization of expected utility, for
instance, underlies most of the results in the contemporary literature
in epistemic game theory. From a methodological perspective, however,
the choice rule that the modeler assumes the players are following is
simply a parameter that can be varied. In recent years, there have
been some initial attempts to develop epistemic analyses with
alternative choice rules. See, La Mura (2009) and Halpern &amp; Pass
(2012) for steps in this direction, and Galeazzi &amp; Marti (2023)
for a study of higher-order uncertainty with alternative choice
rules.</p>

<h3 id="DynaGameMode">4.3 Dynamic Game Models</h3>

<p>
The key results in epistemic game theory discussed in this entry
assume that the players are in some state of knowledge and belief,
such as common belief of rationality. This leaves open the question of
how the players arrive at such a state of knowledge and belief. This
question has been addressed from two perspectives. The first
perspective uses models from Dynamic Epistemic Logic (see, for
instance, Baltag &amp; Renne 2016) that represent
<em>announcements</em> and other epistemic actions that update all of
the players&rsquo; knowledge and beliefs in a game model. In such a
dynamic game model, for instance, the players can eliminate all
higher-order uncertainty regarding each others&rsquo; rationality by
repeatedly and publicly announcing that they are not irrational (van
Benthem 2003). See van Benthem (2007) for an early contribution, and
van Benthem, Pacuit, &amp; Roy (2011) and van Benthem &amp; Klein
(2019 [2022]) for surveys of this literature. The second perspective
develops models that explicitly representing the players&rsquo;
deliberation about what they will do in a game (Skyrms 1990; Binmore
1987, 1988; Cubitt &amp; Sugden 2011). For instance, Skyrms (1990)
interprets a player&rsquo;s mixed strategy as representing subjective
uncertainty about what that player will do at the end of deliberation.
Then, the players deliberate by calculating their expected utility and
then use this new information to recalculate their probabilities about
what they will do in the game and their expected utilities (cf. the
work on <em>learning</em> in games discussed in Fudenberg &amp;
Levine, 1998). See Pacuit (2015) for a survey that describes both
approaches to representing the players&rsquo; reasoning in games.</p>

<h3 id="FiniHierBeli">4.4 Finite Hierarchies of Belief</h3>

<p>
Many authors have pointed out the strength of the assumption of common
belief of rationality (see, e.g., Gintis 2009; de Bruin 2010). It
requires that the players not only believe that the others are
rational, but also to believe that everybody believes that the others
are rational, and everyone believes that everyone believes that
everyone believes that the others are rational, and so on. An
interesting line of research is to study the bounded version of each
of the results presented in the entry. That is, what are the
implications of assuming that the players are rational, believe that
the others are rational, and so on up to \(k\)-levels of belief but
not \((k+1)\)-levels of belief? See Rubinstein (1989); Kets (2012);
Colman (2003); de Weerd, Verbrugge, &amp; Verheij (2013);
Brandenburger, Danieli, &amp; Friedenberg (2021) for work on this
question.</p>

<h2 id="ConcRema">5. Concluding Remarks</h2>

<p>
Broadly speaking, much of the epistemic game theory literature is
focused on two types of projects. The goal of the first project is to
map out the relationship between different mathematical
representations of what the players know and believe about each other
in a game situation. Research along these lines not only raises
interesting technical questions about how to compare and contrast
different mathematical models of the players&rsquo; epistemic states,
but it also highlights the benefits and limits of an epistemic
analysis of games. The second project addresses the nature of rational
choice in game situations. The importance of this project is nicely
explained by Wolfgang Spohn:</p>

<blockquote>

<p>
&hellip;game theory&hellip;is, to put it strongly, confused about the
rationality concept appropriate to it, its assumptions about its
subjects (the players) are very unclear, and, as a consequence, it is
unclear about the decision rules to be applied&hellip;.The basic
difficulty in defining rational behavior in game situations is the
fact that in general each player&rsquo;s strategy will depend on his
expectations about the other players&rsquo; strategies. Could we
assume that his expectations were given, then his problem of strategy
choice would become an ordinary maximization problem: he could simply
choose a strategy maximizing his own payoff on the assumption that the
other players would act in accordance with his given expectations. But
the point is that game theory cannot regard the players&rsquo;
expectations about each other&rsquo;s behavior as given; rather, one
of the most important problems for game theory is precisely to decide
what expectations intelligent players can rationally entertain about
other intelligent players&rsquo; behavior. (Spohn 1982: 267)</p>
</blockquote>

<p>
Much of the work in epistemic game theory can be viewed as an attempt
to use precise representations of the players&rsquo; knowledge and
beliefs to help resolve some of the confusion alluded to in the above
quote.</p>

<p>
The reader interested in more extensive coverage of all or some of the
topics discussed in this entry should consult the following articles
and books.</p>

<ul class="hanging">

<li><em>Logic in Games</em>, by Johan van Benthem: This book uses the
tools of modal logic broadly conceived to discuss many of the issues
raised in this entry (2014, MIT Press).</li>

<li><em>The Language of Game Theory</em>, by Adam Brandenburger: A
collection of Brandenburger&rsquo;s key papers on epistemic game
theory (2014, World Scientific Series in Economic Theory).</li>

<li>&ldquo;Epistemic Foundations of Game Theory&rdquo;, by Giacomo
Bonanno: A survey paper aimed at logicians and computer scientists
covering the main technical results in epistemic game theory (Chapter
9 in the <em>Handbook of Logics for Knowledge and Belief</em>, 2015,
 <a href="https://faculty.econ.ucdavis.edu/faculty/bonanno/PDF/handbook.pdf" target="other">Bonanno 2015 available online</a>).</li>
 
<li>&ldquo;Rationality and Knowledge in Game Theory&rdquo;, by Eddie
Dekel and Faruk Gul: An early survey paper discussing important
foundational questions about rational choice and representing
knowledge in game-theoretic situations (Chapter 5 in <em>Advances in
Economics and Econometrics: Theory and Applications</em>, 1997,
Cambridge University Press,
 <a href="https://cet.econ.northwestern.edu/dekel/pdf/rationality-and-knowledge-in-game-theory.pdf" target="other">Dekel and Gul 1997 available online</a>).</li>
 
<li>&ldquo;Epistemic Game Theory&rdquo;, by Eddie Dekel and Marciano
Siniscalchi: A survey paper aimed at economists covering the main
technical results of epistemic game theory (Chapter 12 in the
<em>Handbook of Game Theory with Economic Applications</em>, 2015,
 <a href="http://faculty.wcas.northwestern.edu/~msi661/EpistemicGameTheory-131120.pdf" target="other">Dekel and Siniscalchi 2015 available online</a>).</li>
 
<li><em>Epistemic Game Theory: Reasoning and Choice</em>, by
Andr&eacute;s Perea: An introduction to epistemic game theory covering
many of the topics presented in this entry (2012, Cambridge University
Press).</li>

<li><em>The Bounds of Reason: Game Theory and the Unification of the
Behavioral Sciences</em>, by Herbert Gintis: This book offers a broad
overview of the social and behavioral science using the ideas of
epistemic game theory (2009, Princeton University Press).</li>
</ul>
</div>

<div id="bibliography">

<h2 id="Bib">Bibliography</h2>

<ul class="hanging">

<li>Abramsky, Samson and Jonathan Zvesper, 2015, &ldquo;From Lawvere
to Brandenburger&ndash;Keisler: Interactive Forms of Diagonalization
and Self-Reference&rdquo;, <em>Journal of Computer and System
Sciences</em>, 81(5): 799&ndash;812.
doi:10.1016/j.jcss.2014.12.001</li>

<li>Alchourr&oacute;n, Carlos E., Peter G&auml;rdenfors, and David
Makinson, 1985, &ldquo;On the logic of theory change: Partial meet
contraction and revision functions&rdquo;, <em>The Journal of Symbolic
Logic</em> 50.2: 510&ndash;530.</li>

<li>Apt, Krzysztof R., 2007, &ldquo;The Many Faces of
Rationalizability&rdquo;, <em>The B.E. Journal of Theoretical
Economics</em>, 7(1): 0000102202193517041339.
doi:10.2202/1935-1704.1339</li>

<li>&ndash;&ndash;&ndash;, 2011, &ldquo;Direct Proofs of Order
Independence&rdquo;, <em>Economics Bulletin</em>, 31(1):
106&ndash;115.</li>

<li>Apt, Krzysztof R. and Jonathan A. Zvesper, 2010, &ldquo;The Role
of Monotonicity in the Epistemic Analysis of Strategic Games&rdquo;,
<em>Games</em>, 1(4): 381&ndash;394. doi:10.3390/g1040381</li>

<li>Arieli, Itai and Robert J. Aumann, 2015, &ldquo;The Logic of
Backward Induction&rdquo;, <em>Journal of Economic Theory</em>, 159:
443&ndash;464. doi:10.1016/j.jet.2015.07.004</li>

<li>Armbruster, W. and W. B&ouml;ge, 1979, &ldquo;Bayesian Game
Theory&rdquo;, in <em>Game Theory and Related Topics: Proceedings of
the Seminar on Game Theory and Related Topics, Bonn/Hagen, 26&ndash;29
September, 1978</em>, Diethard Pallaschke and O. Moeschlin (eds.),
Amsterdam/New York: North-Holland.</li>

<li>Asheim, Geir B., 2002, &ldquo;On the Epistemic Foundation for
Backward Induction&rdquo;, <em>Mathematical Social Sciences</em>,
44(2): 121&ndash;144. doi:10.1016/S0165-4896(02)00011-2</li>

<li>Asheim, Geir B. and Martin Dufwenberg, 2003, &ldquo;Admissibility
and Common Belief&rdquo;, <em>Games and Economic Behavior</em>, 42(2):
208&ndash;234. doi:10.1016/S0899-8256(02)00551-1</li>

<li>Asheim, Geir B. and Andr&eacute;s Perea, 2005, &ldquo;Sequential
and Quasi-Perfect Rationalizability in Extensive Games&rdquo;,
<em>Games and Economic Behavior</em>, 53(1): 15&ndash;42.
doi:10.1016/j.geb.2004.06.015</li>

<li>Aumann, Robert J., 1974, &ldquo;Subjectivity and Correlation in
Randomized Strategies&rdquo;, <em>Journal of Mathematical
Economics</em>, 1(1): 67&ndash;96.
doi:10.1016/0304-4068(74)90037-8</li>

<li>&ndash;&ndash;&ndash;, 1976, &ldquo;Agreeing to Disagree&rdquo;,
<em>The Annals of Statistics</em>, 4(6): 1236&ndash;1239.
doi:10.1214/aos/1176343654</li>

<li>&ndash;&ndash;&ndash;, 1987, &ldquo;Correlated Equilibrium as an
Expression of Bayesian Rationality&rdquo;, <em>Econometrica</em>,
55(1): 1&ndash;18. doi:10.2307/1911154</li>

<li>&ndash;&ndash;&ndash;, 1995, &ldquo;Backward Induction and Common
Knowledge of Rationality&rdquo;, <em>Games and Economic Behavior</em>,
8(1): 6&ndash;19. doi:10.1016/S0899-8256(05)80015-6</li>

<li>&ndash;&ndash;&ndash;, 1998, &ldquo;On the Centipede Game&rdquo;,
<em>Games and Economic Behavior</em>, 23(1): 97&ndash;105.
doi:10.1006/game.1997.0605</li>

<li>&ndash;&ndash;&ndash;, 1999a, &ldquo;Interactive Epistemology I:
Knowledge&rdquo;, <em>International Journal of Game Theory</em>,
28(3): 263&ndash;300. doi:10.1007/s001820050111</li>

<li>&ndash;&ndash;&ndash;, 1999b, &ldquo;Interactive Epistemology II:
Probability&rdquo;, <em>International Journal of Game Theory</em>,
28(3): 301&ndash;314. doi:10.1007/s001820050112</li>

<li>Aumann, Robert and Adam Brandenburger, 1995, &ldquo;Epistemic
Conditions for Nash Equilibrium&rdquo;, <em>Econometrica</em>, 63(5):
1161&ndash;1180. doi:10.2307/2171725</li>

<li>Aumann, Robert J., Sergiu Hart, and Motty Perry, 1997, &ldquo;The
Absent-Minded Driver&rdquo;, <em>Games and Economic Behavior</em>,
20(1): 102&ndash;116. doi:10.1006/game.1997.0577</li>

<li>Bach, Christian W. and Andr&eacute;s Perea, 2020,
&ldquo;Generalized Nash Equilibrium without Common Belief in
Rationality&rdquo;, <em>Economics Letters</em>, 186: 108526.
doi:10.1016/j.econlet.2019.108526</li>

<li>Bach, Christian W. and Elias Tsakas, 2014, &ldquo;Pairwise
Epistemic Conditions for Nash Equilibrium&rdquo;, <em>Games and
Economic Behavior</em>, 85: 48&ndash;59.
doi:10.1016/j.geb.2014.01.017</li>

<li>Balkenborg, Dieter and Eyal Winter, 1997, &ldquo;A Necessary and
Sufficient Epistemic Condition for Playing Backward Induction&rdquo;,
<em>Journal of Mathematical Economics</em>, 27(3): 325&ndash;345.
doi:10.1016/S0304-4068(96)00776-8</li>

<li>Baltag, Alexandru and Sonja Smets, 2006, &ldquo;Conditional
Doxastic Models: A Qualitative Approach to Dynamic Belief
Revision&rdquo;, <em>Electronic Notes in Theoretical Computer
Science</em>, 165: 5&ndash;21. doi:10.1016/j.entcs.2006.05.034</li>

<li>Baltag, Alexandru, Sonja Smets, and Jonathan Alexander Zvesper,
2009, &ldquo;Keep &lsquo;Hoping&rsquo; for Rationality: A Solution to
the Backward Induction Paradox&rdquo;, <em>Synthese</em>, 169(2):
301&ndash;333. doi:10.1007/s11229-009-9559-z</li>

<li>Baltag, Alexandru and Bryan Renne, 2016, &ldquo;Dynamic Epistemic
Logic&rdquo;, in <em>The Stanford Encyclopedia of Philosophy</em>
(Winter 2016 edition), Edward N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/win2016/entries/dynamic-epistemic" target="other">https://plato.stanford.edu/archives/win2016/entries/dynamic-epistemic</a>&gt;.</li>
 
<li>Barelli, Paulo, 2009, &ldquo;Consistency of Beliefs and Epistemic
Conditions for Nash and Correlated Equilibria&rdquo;, <em>Games and
Economic Behavior</em>, 67(2): 363&ndash;375.
doi:10.1016/j.geb.2009.02.003</li>

<li>Barwise, Jon, 1988, &ldquo;Three views of common knowledge&rdquo;,
in <em>Proceedings of the 2nd Conference on Theoretical Aspects of
Reasoning about Knowledge (TARK 1988)</em>, San Francisco: Morgan
Kaufmann, California, 365&ndash;379.
 [<a href="http://www.tark.org/proceedings/tark_mar7_88/p365-barwise.pdf" target="other">Barwise 1988 available online (pdf)</a>]</li>
 
<li>Ba&#351;kent, Can, 2015, &ldquo;Some Non-Classical Approaches to
the Brandenburger&ndash;Keisler Paradox&rdquo;, <em>Logic Journal of
IGPL</em>, 23(4): 533&ndash;552. doi:10.1093/jigpal/jzv001</li>

<li>&ndash;&ndash;&ndash;, 2018, &ldquo;A Yabloesque Paradox in
Epistemic Game Theory&rdquo;, <em>Synthese</em>, 195(1):
441&ndash;464. doi:10.1007/s11229-016-1231-9</li>

<li>Basu, K., 1990, &ldquo;On the Non-Existence of a Rationality
Definition for Extensive Games&rdquo;, <em>International Journal of
Game Theory</em>, 19(1): 33&ndash;44. doi:10.1007/BF01753706</li>

<li>Battigalli, Pierpaolo, 1997, &ldquo;On Rationalizability in
Extensive Games&rdquo;, <em>Journal of Economic Theory</em>, 74(1):
40&ndash;61. doi:10.1006/jeth.1996.2252</li>

<li>&ndash;&ndash;&ndash;, 2003, &ldquo;Rationalizability in Infinite,
Dynamic Games with Incomplete Information&rdquo;, <em>Research in
Economics</em>, 57(1): 1&ndash;38.
doi:10.1016/S1090-9443(02)00054-6</li>

<li>Battigalli, Pierpaolo and Giacomo Bonanno, 1999, &ldquo;Recent
Results on Belief, Knowledge and the Epistemic Foundations of Game
Theory&rdquo;, <em>Research in Economics</em>, 53(2): 149&ndash;225.
doi:10.1006/reec.1999.0187</li>

<li>Battigalli, Pierpaolo and Marciano Siniscalchi, 2002,
&ldquo;Strong Belief and Forward Induction Reasoning&rdquo;,
<em>Journal of Economic Theory</em>, 106(2): 356&ndash;391.
doi:10.1006/jeth.2001.2942</li>

<li>&ndash;&ndash;&ndash;, 2003, &ldquo;Rationalization and Incomplete
Information&rdquo;, <em>Advances in Theoretical Economics</em>, 3(1).
doi:10.2202/1534-5963.1073</li>

<li>Battigalli, Pierpaolo, Alfredo Di Tillio, and Dov Samet, 2013,
&ldquo;Strategies and Interactive Beliefs in Dynamic Games&rdquo;, in
<em>Advances in Economics and Econometricsm, Tenth World Congress:
Volume 1, Economic Theory</em>, Daron Acemoglu, Manuel Arellano, and
Eddie Dekel (eds.), 1st ed., Cambridge University Press, 391&ndash;422
(chapter 12). doi:10.1017/CBO9781139060011.013</li>

<li>van Benthem, Johan, 2003, &ldquo;Rational dynamic and epistemic
logic in games&rdquo;, in S. Vannucci (ed.), <em>Logic, Game Theory
and Social Choice III</em>, Department of Political Economy,
University of Siena, pages 19&ndash;23. A version appeared as van
Benthem 2007.</li>

<li>&ndash;&ndash;&ndash;, 2007, &ldquo;Rational Dynamics and
Epistemic Logic in Games&rdquo;, <em>International Game Theory
Review</em>, 9(1): 13&ndash;45. doi:10.1142/S0219198907001254</li>

<li>&ndash;&ndash;&ndash;, 2010, <em>Modal Logic for Open Minds</em>,
(CSLI Lecture Notes 199), Stanford, CA: CSLI Publications.</li>

<li>&ndash;&ndash;&ndash;, 2011, <em>Logical Dynamics of Information
and Interaction</em>, Cambridge: Cambridge University Press.
doi:10.1017/CBO9780511974533</li>

<li>van Benthem, Johan and Dominik Klein, 2019 [2022], &ldquo;Logics
for Analyzing Games&rdquo;, <em>The Stanford Encyclopedia of
Philosophy</em> (Winter 2022 edition), Edward N. Zalta and Uri
Nodelman (eds), URL =
 &lt;<a href="https://plato.stanford.edu/archives/win2022/entries/logics-for-games/" target="other">https://plato.stanford.edu/archives/win2022/entries/logics-for-games/</a>&gt;.</li>
 
<li>van Benthem, Johan, Eric Pacuit, and Olivier Roy, 2011
&ldquo;Toward a theory of play: A logical perspective on games and
interaction&rdquo;, <em>Games</em> 2.1: 52&ndash;86.</li>

<li>Bernheim, B. Douglas, 1984, &ldquo;Rationalizable Strategic
Behavior&rdquo;, <em>Econometrica</em>, 52(4): 1007&ndash;1028.
doi:10.2307/1911196</li>

<li>Bicchieri, Cristina, 1988a, &ldquo;Strategic Behavior and
Counterfactuals&rdquo;, <em>Synthese</em>, 76(1): 135&ndash;169.
doi:10.1007/BF00869644</li>

<li>&ndash;&ndash;&ndash;, 1988b, &ldquo;Common Knowledge and Backward
Induction: A Solution to the Paradox&rdquo;, in <em>Proceedings of the
2nd Conference on Theoretical Aspects of Reasoning about Knowledge
(TARK 1988)</em>, Moshe Y. Vardi (ed.), San Francisco, CA: Morgan
Kaufmann, 381&ndash;393.</li>

<li>&ndash;&ndash;&ndash;, 1995, &ldquo;The Epistemic Foundations of
Nash Equilibrium&rdquo;, in <em>On the Reliability of Economic
Models</em>, Daniel Little (ed.), Dordrecht: Springer Netherlands,
91&ndash;146. doi:10.1007/978-94-011-0643-6_4</li>

<li>Billingsley, Patrick, 1999, <em>Convergence of Probability
Measures</em>, second edition, (Wiley Series in Probability and
Statistics. Probability and Statistics Section), New York: Wiley.
doi:10.1002/9780470316962</li>

<li>Binmore, Ken, 1987, &ldquo;Modeling Rational Players: Part
I&rdquo;, <em>Economics and Philosophy</em>, 3(2): 179&ndash;214.
doi:10.1017/S0266267100002893</li>

<li>&ndash;&ndash;&ndash;, 1988, &ldquo;Modeling Rational Players:
Part II&rdquo;, <em>Economics and Philosophy</em>, 4(1): 9&ndash;55.
doi:10.1017/S0266267100000328</li>

<li>&ndash;&ndash;&ndash;, 1996, &ldquo;A Note on Backward
Induction&rdquo;, <em>Games and Economic Behavior</em>, 17(1):
135&ndash;137. doi:10.1006/game.1996.0098</li>

<li>&ndash;&ndash;&ndash;, 1997, &ldquo;Rationality and Backward
Induction&rdquo;, <em>Journal of Economic Methodology</em>, 4(1):
23&ndash;41. doi:10.1080/13501789700000002</li>

<li>Bjorndahl, Adam and Joseph Y. Halpern, 2017, &ldquo;From Type
Spaces to Probability Frames and Back, via Language&rdquo;, in
<em>Proceedings of of the Sixteenth Conference on Theoretical Aspects
of Rationality and Knowledge (TARK 2017)</em> (EPTCS 251),
75&ndash;87. doi:10.4204/EPTCS.251.6</li>

<li>Board, Oliver, 2003, &ldquo;The Not-so-Absent-Minded
Driver&rdquo;, <em>Research in Economics</em>, 57(3): 189&ndash;200.
doi:10.1016/S1090-9443(03)00034-6</li>

<li>Bonanno, Giacomo, 1991, &ldquo;The Logic of Rational Play in Games
of Perfect Information&rdquo;, <em>Economics and Philosophy</em>,
7(1): 37&ndash;65. doi:10.1017/S0266267100000900</li>

<li>&ndash;&ndash;&ndash;, 1996, &ldquo;On the Logic of Common
Belief&rdquo;, <em>Mathematical Logic Quarterly</em>, 42(1):
305&ndash;311. doi:10.1002/malq.19960420126</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Memory and Perfect Recall in
Extensive Games&rdquo;, <em>Games and Economic Behavior</em>, 47(2):
237&ndash;256. doi:10.1016/j.geb.2003.06.002</li>

<li>&ndash;&ndash;&ndash;, 2014, &ldquo;A Doxastic Behavioral
Characterization of Generalized Backward Induction&rdquo;, <em>Games
and Economic Behavior</em>, 88: 221&ndash;241.
doi:10.1016/j.geb.2014.10.004</li>

<li>&ndash;&ndash;&ndash;, 2015, &ldquo;Epistemic Foundations of Game
Theory&rdquo;, in <em>Handbook of Epistemic Logic</em>, Hans van
Ditmarsch, Joseph Y. Halpern, W. van der Hoek, and Barteld Pieter Kooi
(eds.), UK: College Publications, 443&ndash;488.</li>

<li>Brams, Steven J., 1975, &ldquo;Newcomb&rsquo;s Problem and
Prisoners&rsquo; Dilemma&rdquo;, <em>Journal of Conflict
Resolution</em>, 19(4): 596&ndash;612.
doi:10.1177/002200277501900402</li>

<li>Brandenburger, Adam, 2003, &ldquo;On the Existence of a
&lsquo;Complete&rsquo; Possibility Structure&rdquo;, in <em>Cognitive
Processes and Economic Behaviour</em>, Marcello Basili, Nicola
Dimitri, and Itzhak Gilboa (eds.), London: Routledge,
30&ndash;34.</li>

<li>&ndash;&ndash;&ndash;, 2010, &ldquo;Origins of Epistemic Game
Theory&rdquo;, in <em>Epistemic Logic: 5 Questions</em>, Vincent F.
Hendricks and Olivier Roy (eds.), London: Automatic Press,
59&ndash;69.</li>

<li>Brandenburger, Adam and Eddie Dekel, 1987,
&ldquo;Rationalizability and Correlated Equilibria&rdquo;,
<em>Econometrica</em>, 55(6): 1391&ndash;1402.
doi:10.2307/1913562</li>

<li>&ndash;&ndash;&ndash;, 1993, &ldquo;Hierarchies of Beliefs and
Common Knowledge&rdquo;, <em>Journal of Economic Theory</em>, 59(1):
189&ndash;198. doi:10.1006/jeth.1993.1012</li>

<li>Brandenburger, Adam, and Amanda Friedenberg, 2008,
&ldquo;Intrinsic correlation in games&rdquo;, <em>Journal of Economic
Theory</em> 141.1 (2008): 28&ndash;67.</li>

<li>Brandenburger, Adam and Amanda Friedenberg, 2010,
&ldquo;Self-Admissible Sets&rdquo;, <em>Journal of Economic
Theory</em>, 145(2): 785&ndash;811. doi:10.1016/j.jet.2009.11.003</li>

<li>Brandenburger, Adam and H. Jerome Keisler, 2006, &ldquo;An
Impossibility Theorem on Beliefs in Games&rdquo;, <em>Studia
Logica</em>, 84(2): 211&ndash;240. doi:10.1007/s11225-006-9011-z</li>

<li>Brandenburger, Adam, Alexander Danieli, and Amanda Friedenberg,
2021, &ldquo;The Implications of Finite&#8208;order Reasoning&rdquo;,
<em>Theoretical Economics</em>, 16(4): 1605&ndash;1654.
doi:10.3982/TE2889</li>

<li>Brandenburger, Adam, Amanda Friedenberg, and H. Jerome Keisler,
2008, &ldquo;Admissibility in Games&rdquo;, <em>Econometrica</em>,
76(2): 307&ndash;352. doi:10.1111/j.1468-0262.2008.00835.x</li>

<li>&ndash;&ndash;&ndash;, 2023, &ldquo;The Relationship between
Strong Belief and Assumption&rdquo;, <em>Synthese</em>, 201(5): 175.
doi:10.1007/s11229-023-04167-6</li>

<li>Briggs, R. A., 2014 [2019], &ldquo;Normative Theories of Rational
Choice: Expected Utility&rdquo;, <em>The Stanford Encyclopedia of
Philosophy</em>, (Fall 2019 edition), Edward N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/fall2019/entries/rationality-normative-utility/" target="other">https://plato.stanford.edu/archives/fall2019/entries/rationality-normative-utility/</a>&gt;.</li>
 
<li>de Bruin, Boudewijn, 2008, &ldquo;Common Knowledge of Rationality
in Extensive Games&rdquo;, <em>Notre Dame Journal of Formal
Logic</em>, 49(3): 261&ndash;280. doi:10.1215/00294527-2008-011</li>

<li>&ndash;&ndash;&ndash;, 2010, <em>Explaining Games: The Epistemic
Programme in Game Theory</em>, Dordrecht: Springer Netherlands.
doi:10.1007/978-1-4020-9906-9</li>

<li>Catonini, Emiliano, 2019, &ldquo;Rationalizability and Epistemic
Priority Orderings&rdquo;, <em>Games and Economic Behavior</em>, 114:
101&ndash;117. doi:10.1016/j.geb.2018.12.004</li>

<li>Capraro, Valerio and Joseph Y. Halpern, 2016, &ldquo;Translucent
Players: Explaining Cooperative Behavior in Social Dilemmas&rdquo;, in
<em>Proceedings of the Fifteenth Conference on Theoretical Aspects of
Rationality and Knowledge (TARK 2015)</em> (EPCTS 215), 114&ndash;126.
doi:10.4204/EPTCS.215.9</li>

<li>Clausing, Thorsten, 2003, &ldquo;Doxastic Conditions for Backward
Induction&rdquo;, <em>Theory and Decision</em>, 54(4): 315&ndash;336.
doi:10.1023/B:THEO.0000004258.22525.f4</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Belief Revision in Games of
Perfect Information&rdquo;, <em>Economics and Philosophy</em>, 20(1):
89&ndash;115. doi:10.1017/S0266267104001269</li>

<li>Colman, Andrew M., 2003, &ldquo;Cooperation, Psychological Game
Theory, and Limitations of Rationality in Social Interaction&rdquo;,
<em>Behavioral and Brain Sciences</em>, 26(2): 139&ndash;198.
doi:10.1017/S0140525X03000050</li>

<li>Cubitt, Robin P. and Robert Sugden, 1994, &ldquo;Rationally
Justifiable Play and the Theory of Non-Cooperative Games&rdquo;,
<em>The Economic Journal</em>, 104(425): 798&ndash;803.
doi:10.2307/2234975</li>

<li>&ndash;&ndash;&ndash;, 2011, &ldquo;The Reasoning-Based Expected
Utility Procedure&rdquo;, <em>Games and Economic Behavior</em>, 71(2):
328&ndash;338. doi:10.1016/j.geb.2010.04.002</li>

<li>&ndash;&ndash;&ndash;, 2014, &ldquo;Common Reasoning in Games: A
Lewisian Analysis of Common Knowledge of Rationality&rdquo;,
<em>Economics and Philosophy</em>, 30(3): 285&ndash;329.
doi:10.1017/S0266267114000339</li>

<li>van Damme, Eric, 1983, <em>Refinements of the Nash Equilibrium
Concept</em>, (Lecture Notes in Economics and Mathematical Systems
219), Berlin/New York: Springer-Verlag.
doi:10.1007/978-3-642-49970-8</li>

<li>&ndash;&ndash;&ndash;, 1989, &ldquo;Stable Equilibria and Forward
Induction&rdquo;, <em>Journal of Economic Theory</em>, 48(2):
476&ndash;496. doi:10.1016/0022-0531(89)90038-0</li>

<li>Davis, Lawrence H., 1977, &ldquo;Prisoners, Paradox, and
Rationality&rdquo;, <em>American Philosophical Quarterly</em>, 14(4):
319&ndash;327.</li>

<li>Dekel, Eddie and Faruk Gul, 1997, &ldquo;Rationality and Knowledge
in Game Theory&rdquo;, in <em>Advances in Economics and Econometrics:
Theory and Applications</em>, David M. Kreps and Kenneth F. Wallis
(eds.), Cambridge: Cambridge University Press, 87&ndash;172.
doi:10.1017/CCOL521580110.005</li>

<li>Fagin, Ronald, John Geanakoplos, Joseph Y. Halpern, and Moshe Y.
Vardi, 1999, &ldquo;The Hierarchical Approach to Modeling Knowledge
and Common Knowledge&rdquo;, <em>International Journal of Game
Theory</em>, 28(3): 331&ndash;365. doi:10.1007/s001820050114</li>

<li>Fagin, Ronald, Joseph Y. Halpern, and Nimrod Megiddo, 1990,
&ldquo;A Logic for Reasoning about Probabilities&rdquo;,
<em>Information and Computation</em>, 87(1&ndash;2): 78&ndash;128.
doi:10.1016/0890-5401(90)90060-U</li>

<li>Fagin, Ronald, Joseph Y. Halpern, Yoram Moses, and Moshe Vardi,
1995, <em>Reasoning about Knowledge</em>, Cambridge, MA: MIT
Press.</li>

<li>Feinberg, Yossi, 2005, &ldquo;Subjective Reasoning&mdash;Dynamic
Games&rdquo;, <em>Games and Economic Behavior</em>, 52(1):
54&ndash;93. doi:10.1016/j.geb.2004.06.001</li>

<li>de Finetti, Bruno, 1974, <em>Theory of Probability: A Critical
Introductory Treatment</em>, Antonio Machi and Adrian Smith (trans.),
2 vols., (Wiley Series in Probability and Mathematical Statistics),
London/New York: Wiley.</li>

<li>Friedenberg, Amanda and H. Jerome Keisler, 2021, &ldquo;Iterated
Dominance Revisited&rdquo;, <em>Economic Theory</em>, 72(2):
377&ndash;421. doi:10.1007/s00199-020-01275-z</li>

<li>Fudenberg, Drew and David K. Levine, 1998, <em>The Theory of
Learning in Games</em>, (MIT Press Series on Economic Learning and
Social Evolution 2), Cambridge, MA: MIT Press.</li>

<li>Galeazzi, Paolo and Emiliano Lorini, 2016, &ldquo;Epistemic Logic
Meets Epistemic Game Theory: A Comparison between Multi-Agent Kripke
Models and Type Spaces&rdquo;, <em>Synthese</em>, 193(7):
2097&ndash;2127. doi:10.1007/s11229-015-0834-x</li>

<li>Galeazzi, Paolo and Johannes Marti, 2023, &ldquo;Choice Structures
in Games&rdquo;, <em>Games and Economic Behavior</em>, 140:
431&ndash;455. doi:10.1016/j.geb.2023.05.002</li>

<li>Genin, Konstantin and Franz Huber, 2020 [2022], &ldquo;Formal
Representations of Belief&rdquo;, <em>The Stanford Encyclopedia of
Philosophy</em> (Spring 2022 edition), Edward N. Zalta and Uri
Nodelman (eds), URL =
 &lt;<a href="https://plato.stanford.edu/archives/spr2022/entries/formal-belief/" target="other">https://plato.stanford.edu/archives/spr2022/entries/formal-belief/</a>&gt;.</li>
 
<li>Gintis, Herbert, 2009, &ldquo;The Local Best Response Criterion:
An Epistemic Approach to Equilibrium Refinement&rdquo;, <em>Journal of
Economic Behavior &amp; Organization</em>, 71(2): 89&ndash;97.
doi:10.1016/j.jebo.2009.03.008</li>

<li>Halpern, Joseph Y., 1997, &ldquo;On Ambiguities in the
Interpretation of Game Trees&rdquo;, <em>Games and Economic
Behavior</em>, 20(1): 66&ndash;96. doi:10.1006/game.1997.0557</li>

<li>&ndash;&ndash;&ndash;, 2001, &ldquo;Substantive Rationality and
Backward Induction&rdquo;, <em>Games and Economic Behavior</em>,
37(2): 425&ndash;435. doi:10.1006/game.2000.0838</li>

<li>Halpern, Joseph Y., Ron Van Der Meyden, and Moshe Y. Vardi, 2004,
&ldquo;Complete Axiomatizations for Reasoning about Knowledge and
Time&rdquo;, <em>SIAM Journal on Computing</em>, 33(3): 674&ndash;703.
doi:10.1137/S0097539797320906</li>

<li>Halpern, Joseph Y. and Yoram Moses, 2017, &ldquo;Characterizing
Solution Concepts in Terms of Common Knowledge of Rationality&rdquo;,
<em>International Journal of Game Theory</em>, 46(2): 457&ndash;473.
doi:10.1007/s00182-016-0535-9</li>

<li>Halpern, Joseph Y. and Rafael Pass, 2012, &ldquo;Iterated Regret
Minimization: A New Solution Concept&rdquo;, <em>Games and Economic
Behavior</em>, 74(1): 184&ndash;207.
doi:10.1016/j.geb.2011.05.012</li>

<li>&ndash;&ndash;&ndash;, 2018, &ldquo;Game Theory with Translucent
Players&rdquo;, <em>International Journal of Game Theory</em>, 47(3):
949&ndash;976. doi:10.1007/s00182-018-0626-x</li>

<li>&ndash;&ndash;&ndash;, 2019, &ldquo;A Conceptually Well-Founded
Characterization of Iterated Admissibility Using an &lsquo;All I
Know&rsquo; Operator&rdquo;, in <em>Proceedings of of the Seventeenth
Conference on Theoretical Aspects of Rationality and Knowledge (TARK
2019)</em> (EPTCS 297), 221&ndash;232. doi:10.4204/EPTCS.297.15</li>

<li>Harsanyi, John C., 1967&ndash;68, &ldquo;Games with Incomplete
Information Played by &lsquo;Bayesian&rsquo; Players,
I&ndash;III&rdquo;, <em>Management Science</em>,

<ul class="hanging">

<li>1967, &ldquo;Part I. The Basic Model&rdquo;, 14(3):
159&ndash;182.</li>

<li>1968a, &ldquo;Part II. Bayesian Equilibrium Points&rdquo;, 14(5):
320&ndash;334.</li>

<li>1968b, &ldquo;Part III. The Basic Probability Distribution of the
Game&rdquo;, 14(7): 486&ndash;502.</li>
</ul> </li>

<li>&ndash;&ndash;&ndash;, 1973, &ldquo;Games with Randomly Disturbed
Payoffs: A New Rationale for Mixed-Strategy Equilibrium Points&rdquo;,
<em>International Journal of Game Theory</em>, 2(1): 1&ndash;23.
doi:10.1007/BF01737554</li>

<li>Heifetz, Aviad, 1999a, &ldquo;Iterative and Fixed Point Common
Belief&rdquo;, <em>Journal of Philosophical Logic</em>, 28(1):
61&ndash;79. doi:10.1023/A:1004357300525</li>

<li>&ndash;&ndash;&ndash;, 1999b, &ldquo;How Canonical Is the
Canonical Model? A Comment on Aumann&rsquo;s Interactive
Epistemology&rdquo;, <em>International Journal of Game Theory</em>,
28(3): 435&ndash;442. doi:10.1007/s001820050118</li>

<li>Heifetz, Aviad and Philippe Mongin, 2001, &ldquo;Probability Logic
for Type Spaces&rdquo;, <em>Games and Economic Behavior</em>,
35(1&ndash;2): 31&ndash;53. doi:10.1006/game.1999.0788</li>

<li>Heifetz, Aviad and Andr&eacute;s Perea, 2015, &ldquo;On the
Outcome Equivalence of Backward Induction and Extensive Form
Rationalizability&rdquo;, <em>International Journal of Game
Theory</em>, 44(1): 37&ndash;59. doi:10.1007/s00182-014-0418-x</li>

<li>Heifetz, Aviad and Dov Samet, 1998, &ldquo;Knowledge Spaces with
Arbitrarily High Rank&rdquo;, <em>Games and Economic Behavior</em>,
22(2): 260&ndash;273. doi:10.1006/game.1997.0591</li>

<li>Hillas, John and Dov Samet, 2020, &ldquo;Dominance Rationality: A
Unified Approach&rdquo;, <em>Games and Economic Behavior</em>, 119:
189&ndash;196. doi:10.1016/j.geb.2019.11.001</li>

<li>Hu, Hong and Harborne W. Stuart Jr., 2002, &ldquo;An Epistemic
Analysis of the Harsanyi Transformation&rdquo;, <em>International
Journal of Game Theory</em>, 30(4): 517&ndash;525.
doi:10.1007/s001820200095</li>

<li>Icard, Thomas, 2021, &ldquo;Why Be Random?&rdquo;, <em>Mind</em>,
130(517): 111&ndash;139. doi:10.1093/mind/fzz065</li>

<li>Joyce, James M., 2012, &ldquo;Regret and Instability in Causal
Decision Theory&rdquo;, <em>Synthese</em>, 187(1): 123&ndash;145.
doi:10.1007/s11229-011-0022-6</li>

<li>Kadane, Joseph B. and Patrick D. Larkey, 1982, &ldquo;Subjective
Probability and the Theory of Games&rdquo;, <em>Management
Science</em>, 28(2): 113&ndash;120.
 [<a href="http://repository.cmu.edu/cgi/viewcontent.cgi?article=1035&amp;context=statistics" target="other">Kadane &amp; Larkey 1982 available online</a>]</li>
 
<li>Kaneko, Mamoru and J. Jude Kline, 1995, &ldquo;Behavior
Strategies, Mixed Strategies and Perfect Recall&rdquo;,
<em>International Journal of Game Theory</em>, 24(2): 127&ndash;145.
doi:10.1007/BF01240038</li>

<li>Kets, Willemien, 2012, &ldquo;Bounded Reasoning and Higher-Order
Uncertainty&rdquo;. SSRN Scholarly Paper, Rochester, NY, first online:
24 June 2012. doi:10.2139/ssrn.2116626</li>

<li>Klein, Dominik and Eric Pacuit, 2014, &ldquo;Changing Types:
Information Dynamics for Qualitative Type Spaces&rdquo;, <em>Studia
Logica</em>, 102(2): 297&ndash;319. doi:10.1007/s11225-014-9545-4</li>

<li>Kline, J. Jude, 2002, &ldquo;Minimum Memory for Equivalence
between <em>Ex Ante</em> Optimality and Time-Consistency&rdquo;,
<em>Games and Economic Behavior</em>, 38(2): 278&ndash;305.
doi:10.1006/game.2001.0888</li>

<li>Kohlberg, Elon and Jean-Francois Mertens, 1986, &ldquo;On the
Strategic Stability of Equilibria&rdquo;, <em>Econometrica</em>,
54(5): 1003&ndash;1037. doi:10.2307/1912320</li>

<li>Kuechle, Graciela, 2009, &ldquo;What Happened to the Three-Legged
Centipede Game?&rdquo;, <em>Journal of Economic Surveys</em>, 23(3):
562&ndash;585. doi:10.1111/j.1467-6419.2008.00572.x</li>

<li>Kuhn, Harold William, 1953, &ldquo;Extensive Games and the Problem
of Information&rdquo;, in <em>Contributions to the Theory of Games
(AM-28), Volume II</em>, Harold William Kuhn and Albert William Tucker
(eds.), Princeton, NJ: Princeton University Press, 193&ndash;216.
doi:10.1515/9781400881970-012</li>

<li>Kuhn, Steven, 1997 [2019], &ldquo;Prisoner&rsquo;s Dilemma&rdquo;,
<em>The Stanford Encyclopedia of Philosophy</em> (Winter 2019
edition), Edward N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/win2019/entries/prisoner-dilemma/" target="other">https://plato.stanford.edu/archives/win2019/entries/prisoner-dilemma/</a>&gt;.</li>
 
<li>La Mura, Pierfrancesco, 2009, &ldquo;Game Theory without
Decision-Theoretic Paradoxes&rdquo;, in <em>Algorithmic Decision
Theory: First International Conference, ADT 2009, Venice, Italy,
October 2009</em>, Francesca Rossi and Alexis Tsoukias (eds.),
(Lecture Notes in Computer Science 5783), Berlin/Heidelberg: Springer,
316&ndash;327. doi:10.1007/978-3-642-04428-1_28</li>

<li>Lederman, Harvey, 2018a, &ldquo;Common Knowledge&rdquo;, in
<em>The Routledge Handbook of Collective Intentionality</em>, Marija
Jankovic and Kirk Ludwig (eds.), New York: Routledge,
181&ndash;195.</li>

<li>&ndash;&ndash;&ndash;, 2018b, &ldquo;Uncommon Knowledge&rdquo;,
<em>Mind</em>, 127(508): 1069&ndash;1105. doi:10.1093/mind/fzw072</li>

<li>Levati, M. Vittoria, Matthias Uhl, and Ro&rsquo;i Zultan, 2014,
&ldquo;Imperfect Recall and Time Inconsistencies: An Experimental Test
of the Absentminded Driver &lsquo;Paradox&rsquo;&rdquo;,
<em>International Journal of Game Theory</em>, 43(1): 65&ndash;88.
doi:10.1007/s00182-013-0373-y</li>

<li>Leyton-Brown, Kevin and Yoav Shoham, 2008, <em>Essentials of Game
Theory: A Concise, Multidisciplinary Introduction</em>, (Synthesis
Lectures on Artificial Intelligence and Machine Learning), New York:
Morgan &amp; Claypool. doi:10.1007/978-3-031-01545-8</li>

<li>Lismont, Luc and Philippe Mongin, 1994, &ldquo;On the Logic of
Common Belief and Common Knowledge&rdquo;, <em>Theory and
Decision</em>, 37(1): 75&ndash;106. doi:10.1007/BF01079206</li>

<li>&ndash;&ndash;&ndash;, 2003, &ldquo;Strong Completeness Theorems
for Weak Logics of Common Belief&rdquo;, <em>Journal of Philosophical
Logic</em>, 32(2): 115&ndash;137. doi:10.1023/A:1023032105687</li>

<li>Lorini, Emiliano, 2013, &ldquo;On the Epistemic Foundation for
Iterated Weak Dominance: An Analysis in a Logic of Individual and
Collective Attitudes&rdquo;, <em>Journal of Philosophical Logic</em>,
42(6): 863&ndash;904. doi:10.1007/s10992-013-9297-z</li>

<li>&ndash;&ndash;&ndash;, 2016, &ldquo;A Minimal Logic for
Interactive Epistemology&rdquo;, <em>Synthese</em>, 193(3):
725&ndash;755. doi:10.1007/s11229-015-0960-5</li>

<li>Lorini, Emiliano and Fran&ccedil;ois Schwarzentruber, 2010,
&ldquo;A Modal Logic of Epistemic Games&rdquo;, <em>Games</em>, 1(4):
478&ndash;526. doi:10.3390/g1040478</li>

<li>Mariotti, Thomas, Martin Meier, and Michele Piccione, 2005,
&ldquo;Hierarchies of Beliefs for Compact Possibility Models&rdquo;,
<em>Journal of Mathematical Economics</em>, 41(3): 303&ndash;324.
doi:10.1016/j.jmateco.2003.11.009</li>

<li>Maschler, Michael, Eilon Solan, and Shmuel Zamir, 2013, <em>Game
Theory</em>, Ziv Hellman (trans.), Cambridge: Cambridge University
Press.</li>

<li>Mas-Colell, Andreu, Michael D. Whinston, and Jerry R. Green, 1995,
<em>Microeconomic theory</em>, New York: Oxford University Press.</li>

<li>Meier, Martin, 2005, &ldquo;On the Nonexistence of Universal
Information Structures&rdquo;, <em>Journal of Economic Theory</em>,
122(1): 132&ndash;139. doi:10.1016/j.jet.2003.07.003</li>

<li>Mertens, Jean-Fran&ccedil;ois and Shmuel Zamir, 1985,
&ldquo;Formulation of Bayesian Analysis for Games with Incomplete
Information&rdquo;, <em>International Journal of Game Theory</em>,
14(1): 1&ndash;29. doi:10.1007/BF01770224</li>

<li>Milano, Silvano and Andr&eacute;s Perea, 2023, &ldquo;Rational
updating at the crossroads&rdquo;, <em>Economics and Philosophy</em>,
1&ndash;22. doi:10.1017/S0266267122000360</li>

<li>Monderer, Dov and Dov Samet, 1989, &ldquo;Approximating Common
Knowledge with Common Beliefs&rdquo;, <em>Games and Economic
Behavior</em>, 1(2): 170&ndash;190.
doi:10.1016/0899-8256(89)90017-1</li>

<li>Morris, Stephen, 1995, &ldquo;The Common Prior Assumption in
Economic Theory&rdquo;, <em>Economics and Philosophy</em>, 11(2):
227&ndash;253. doi:10.1017/S0266267100003382</li>

<li>&ndash;&ndash;&ndash;, 2006, &ldquo;Purification&rdquo;, in
<em>The New Palgrave Dictionary of Economics</em>, Steven N. Durlauf
and Lawrence E. Blume (eds.), New York: Palgrave Macmillan,
779&ndash;782.</li>

<li> Myerson, Roger B., 1991, <em>Game Theory: Analysis of
Conflicts</em>, Harvard University Press.</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Comments on &lsquo;Games with
Incomplete Information Played by <em>Bayesian</em> Players,
I&ndash;III Harsanyi&rsquo;s Games with Incomplete
Information&rsquo;&rdquo;, <em>Management Science</em>,
50(12_supplement): 1818&ndash;1824. doi:10.1287/mnsc.1040.0297</li>

<li>Nash, John, 1951, &ldquo;Non-Cooperative Games&rdquo;, <em>The
Annals of Mathematics</em>, 54(2): 286&ndash;295.
doi:10.2307/1969529</li>

<li>Osborne, Martin J., 2004, <em>An Introduction to Game Theory</em>,
New York/Oxford: Oxford University Press.</li>

<li>Pacuit, Eric, 2007, &ldquo;Understanding the Brandenburger-Keisler
Paradox&rdquo;, <em>Studia Logica</em>, 86(3): 435&ndash;454.
doi:10.1007/s11225-007-9069-2</li>

<li>&ndash;&ndash;&ndash;, 2015, &ldquo;Dynamic Models of Rational
Deliberation in Games&rdquo;, in <em>Models of Strategic Reasoning:
Logics, Games, and Communities</em>, Johan Van Benthem, Sujata Ghosh,
and Rineke Verbrugge (eds.), (Lecture Notes in Computer Science 8972),
Berlin/Heidelberg: Springer Berlin Heidelberg, 3&ndash;33.
doi:10.1007/978-3-662-48540-8_1</li>

<li>&ndash;&ndash;&ndash;, 2017, <em>Neighborhood Semantics for Modal
Logic</em>, (Short Textbooks in Logic), Cham: Springer International
Publishing. doi:10.1007/978-3-319-67149-9</li>

<li>Pearce, David G., 1984, &ldquo;Rationalizable Strategic Behavior
and the Problem of Perfection&rdquo;, <em>Econometrica</em>, 52(4):
1029&ndash;1050. doi:10.2307/1911197</li>

<li>Perea, Andr&eacute;s, 2007a, &ldquo;Epistemic Foundations for
Backward Induction: An Overview&rdquo;, in <em>Interactive Logic:
Selected Papers from the 7th Augustus de Morgan Workshop, London</em>,
Johan van Benthem, Benedikt L&ouml;we, and Dov M. Gabbay (eds.),
(Texts in Logic and Games 1), Amsterdam: Amsterdam University Press,
159&ndash;193.</li>

<li>&ndash;&ndash;&ndash;, 2007b, &ldquo;A One-Person Doxastic
Characterization of Nash Strategies&rdquo;, <em>Synthese</em>, 158(2):
251&ndash;271. doi:10.1007/s11229-007-9217-2</li>

<li>&ndash;&ndash;&ndash;, 2012, <em>Epistemic Game Theory: Reasoning
and Choice</em>, Cambridge: Cambridge University Press.
doi:10.1017/CBO9780511844072</li>

<li>&ndash;&ndash;&ndash;, 2014a, &ldquo;Belief in the Opponents&#700;
Future Rationality&rdquo;, <em>Games and Economic Behavior</em>, 83:
231&ndash;254. doi:10.1016/j.geb.2013.11.008</li>

<li>&ndash;&ndash;&ndash;, 2014b, &ldquo;From Classical to Epistemic
Game Theory&rdquo;, <em>International Game Theory Review</em>, 16(1):
1440001. doi:10.1142/S0219198914400015</li>

<li>&ndash;&ndash;&ndash;, 2018, &ldquo;Why Forward Induction Leads to
the Backward Induction Outcome: A New Proof for Battigalli&rsquo;s
Theorem&rdquo;, <em>Games and Economic Behavior</em>, 110:
120&ndash;138. doi:10.1016/j.geb.2018.04.001</li>

<li>&ndash;&ndash;&ndash;, 2022, &ldquo;Common Belief in Rationality
in Games with Unawareness&rdquo;, <em>Mathematical Social
Sciences</em>, 119: 11&ndash;30.
doi:10.1016/j.mathsocsci.2022.05.005</li>

<li>Perea, Andr&eacute;s and Willemien Kets, 2016, &ldquo;When Do
Types Induce the Same Belief Hierarchy?&rdquo;, <em>Games</em>, 7(4):
article 28. doi:10.3390/g7040028</li>

<li>Piccione, Michele and Ariel Rubinstein, 1997a, &ldquo;On the
Interpretation of Decision Problems with Imperfect Recall&rdquo;,
<em>Games and Economic Behavior</em>, 20(1): 3&ndash;24.
doi:10.1006/game.1997.0536</li>

<li>&ndash;&ndash;&ndash;, 1997b, &ldquo;The Absent-Minded
Driver&rsquo;s Paradox: Synthesis and Responses&rdquo;, <em>Games and
Economic Behavior</em>, 20(1): 121&ndash;130.
doi:10.1006/game.1997.0579</li>

<li>Rabinowicz, Wlodzimierz, 1992, &ldquo;Tortuous Labyrinth:
Noncooperative Normal-Form Games between Hyperrational Players&rdquo;,
in <em>Knowledge, Belief, and Strategic Interaction</em>, Cristina
Bicchieri and Maria Luisa Dalla Chiara (eds.), (Cambridge Studies in
Probability, Induction, and Decision Theory), Cambridge/New York:
Cambridge University Press, 107&ndash;125.</li>

<li>R&ecirc;go, Leandro C. and Joseph Y. Halpern, 2012,
&ldquo;Generalized Solution Concepts in Games with Possibly Unaware
Players&rdquo;, <em>International Journal of Game Theory</em>, 41(1):
131&ndash;155. doi:10.1007/s00182-011-0276-8</li>

<li>Rendsvig, Rasmus and John Symons, 2019 [2021], &ldquo;Epistemic
Logic&rdquo;, <em>The Stanford Encyclopedia of Philosophy</em> (Summer
2021 edition), Edward N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/sum2021/entries/logic-epistemic/" target="other">https://plato.stanford.edu/archives/sum2021/entries/logic-epistemic/</a>&gt;.</li>
 
<li>Reny, Philip J., 1988, &ldquo;Common Knowledge and Games with
Perfect Information&rdquo;, in <em>PSA: Proceedings of the Biennial
Meeting of the Philosophy of Science Association, 1988</em>, volume 2,
363&ndash;369.</li>

<li>&ndash;&ndash;&ndash;, 1992, &ldquo;Backward Induction, Normal
Form Perfection and Explicable Equilibria&rdquo;,
<em>Econometrica</em>, 60(3): 627&ndash;649. doi:10.2307/2951586</li>

<li>&ndash;&ndash;&ndash;, 1993, &ldquo;Common Belief and the Theory
of Games with Perfect Information&rdquo;, <em>Journal of Economic
Theory</em>, 59(2): 257&ndash;274. doi:10.1006/jeth.1993.1017</li>

<li>Rich, Patricia, 2015, &ldquo;Rethinking Common Belief, Revision,
and Backward Induction&rdquo;, <em>Mathematical Social Sciences</em>,
75: 102&ndash;114. doi:10.1016/j.mathsocsci.2015.03.001</li>

<li>Rosenthal, R.W., 1981, &ldquo;Games of perfect information,
predatory pricing and the chain-store paradox&rdquo;, <em>Journal of
Economic theory</em>, 25(1), pp.92&ndash;100. </li>

<li>Ross, Don, 1997 [2024], &ldquo;Game Theory&rdquo;, <em>The
Stanford Encyclopedia of Philosophy</em> (Winter 2024 edition), Edward
N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/win2024/entries/game-theory/" target="other"> https://plato.stanford.edu/archives/win2024/entries/game-theory/ </a>&gt;.</li>
 
<li>Roy, Olivier and Eric Pacuit, 2013, &ldquo;Substantive Assumptions
in Interaction: A Logical Perspective&rdquo;, <em>Synthese</em>,
190(5): 891&ndash;908. doi:10.1007/s11229-012-0191-y</li>

<li>Rubinstein, Ariel, 1989, &ldquo;The Electronic Mail Game:
Strategic Behavior Under &lsquo;Almost Common Knowledge&rsquo;&rdquo;,
<em>The American Economic Review</em>, 79(3): 385&ndash;391.</li>

<li>&ndash;&ndash;&ndash;, 1991, &ldquo;Comments on the Interpretation
of Game Theory&rdquo;, <em>Econometrica</em>, 59(4): 909&ndash;924.
doi:10.2307/2938166</li>

<li>Samet, Dov, 1996, &ldquo;Hypothetical Knowledge and Games with
Perfect Information&rdquo;, <em>Games and Economic Behavior</em>,
17(2): 230&ndash;251. doi:10.1006/game.1996.0104</li>

<li>&ndash;&ndash;&ndash;, 2013, &ldquo;Common Belief of Rationality
in Games of Perfect Information&rdquo;, <em>Games and Economic
Behavior</em>, 79: 192&ndash;200. doi:10.1016/j.geb.2013.01.008</li>

<li>Samuelson, Larry, 1992, &ldquo;Dominated Strategies and Common
Knowledge&rdquo;, <em>Games and Economic Behavior</em>, 4(2):
284&ndash;313. doi:10.1016/0899-8256(92)90020-S</li>

<li>Selten, Reinhard, 1975, &ldquo;Reexamination of the Perfectness
Concept for Equilibrium Points in Extensive Games&rdquo;,
<em>International Journal of Game Theory</em>, 4(1): 25&ndash;55.
doi:10.1007/BF01766400</li>

<li>Schelling, Thomas C., 1960, <em>The Strategy of Conflict</em>,
Cambridge, MA: Harvard University Press.</li>

<li>Schervish, Mark J., Teddy Seidenfeld, and Joseph B. Kadane, 1990,
&ldquo;State-Dependent Utilities&rdquo;, <em>Journal of the American
Statistical Association</em>, 85(411): 840&ndash;847.
doi:10.1080/01621459.1990.10474948</li>

<li>Schwarz, Wolfgang, 2015, &ldquo;Lost Memories and Useless Coins:
Revisiting the Absentminded Driver&rdquo;, <em>Synthese</em>, 192(9):
3011&ndash;3036. doi:10.1007/s11229-015-0699-z</li>

<li>Schwitzgebel, Eric, 2006 [2021], &ldquo;Belief&rdquo;, <em>The
Stanford Encyclopedia of Philosophy</em> (Winter 2021 edition), Edward
N. Zalta and Uri Nodelman (eds), URL =
 &lt;<a href="https://plato.stanford.edu/archives/win2021/entries/belief/" target="other">https://plato.stanford.edu/archives/win2021/entries/belief/</a>&gt;.</li>
 
<li>Schipper, Burkhard C., 2015, &ldquo;Awareness&rdquo;, in
<em>Handbook of Epistemic Logic</em>, Hans van Ditmarsch, Joseph Y.
Halpern, W. van der Hoek, and Barteld Pieter Kooi (eds.), UK: College
Publications, 77&ndash;146.</li>

<li>Siniscalchi, Marciano, 2008, &ldquo;Epistemic Game Theory: Beliefs
and Types&rdquo;, in <em>The New Palgrave Dictionary of
Economics</em>, Steven N. Durlauf and Lawrence E. Blume (eds.), New
York: Palgrave Macmillan.</li>

<li>Skyrms, Brian, 1990, <em>The Dynamics of Rational
Deliberation</em>, Cambridge, MA: Harvard University Press.</li>

<li>Stahl, Dale O., 1995, &ldquo;Lexicographic Rationalizability and
Iterated Admissibility&rdquo;, <em>Economics Letters</em>, 47(2):
155&ndash;159. doi:10.1016/0165-1765(94)00530-F</li>

<li>Stalnaker, Robert, 1996, &ldquo;Knowledge, Belief and
Counterfactual Reasoning in Games&rdquo;, <em>Economics and
Philosophy</em>, 12(2): 133&ndash;163.
doi:10.1017/S0266267100004132</li>

<li>&ndash;&ndash;&ndash;, 1998, &ldquo;Belief Revision in Games:
Forward and Backward Induction&rdquo;, <em>Mathematical Social
Sciences</em>, 36(1): 31&ndash;56.
doi:10.1016/S0165-4896(98)00007-9</li>

<li>&ndash;&ndash;&ndash;, 1999, &ldquo;Extensive and Strategic Forms:
Games and Models for Games&rdquo;, <em>Research in Economics</em>,
53(3): 293&ndash;319. doi:10.1006/reec.1999.0200</li>

<li>Spohn, Wolfgang, 1982, &ldquo;How to Make Sense of Game
Theory&rdquo;, in <em>Philosophy of Economics</em>, Wolfgang
Stegm&uuml;ller, Wolfgang Balzer, and Wolfgang Spohn (eds.), (Studies
in Contemporary Economics 2), Berlin/Heidelberg: Springer Berlin
Heidelberg, 239&ndash;270. doi:10.1007/978-3-642-68820-1_14</li>

<li>Tan, Tommy Chin-Chiu and S&eacute;rgio Ribeiro da Costa Werlang,
1988, &ldquo;The Bayesian Foundations of Solution Concepts of
Games&rdquo;, <em>Journal of Economic Theory</em>, 45(2):
370&ndash;391. doi:10.1016/0022-0531(88)90276-1</li>

<li>Titelbaum, Michael G., 2013, &ldquo;Ten Reasons to Care About the
Sleeping Beauty Problem&rdquo;, <em>Philosophy Compass</em>, 8(11):
1003&ndash;1017. doi:10.1111/phc3.12080</li>

<li>Trost, Michael, 2014, &ldquo;An Epistemic Rationale for Order
Independence&rdquo;, <em>International Game Theory Review</em>, 16(1):
1440002. doi:10.1142/S0219198914400027</li>

<li>Ullmann-Margalit, Edna and Sidney Morgenbesser, 1977,
&ldquo;Picking and Choosing&rdquo;, <em>Social Research</em>, 44(4):
757&ndash;785.</li>

<li>Vanderschraaf, Peter, 2001, <em>Learning and Coordination:
Inductive Deliberation, Equilibrium, and Convention</em>, (Studies in
Ethics), New York: Routledge. doi:10.4324/9781315054797</li>

<li>Vanderschraaf, Peter and Giacomo Sillari, 2005 [2022],
&ldquo;Common Knowledge&rdquo;, <em>The Stanford Encyclopedia of
Philosophy</em> (Fall 2022 edition), Edward N. Zalta and Uri Nodelman
(eds), URL =
 &lt;<a href="https://plato.stanford.edu/archives/fall2022/entries/common-knowledge/" target="other">https://plato.stanford.edu/archives/fall2022/entries/common-knowledge/</a>&gt;.</li>
 
<li>Waugh, Kevin, Martin Zinkevich, Michael Johanson, Morgan Kan,
David Schnizlein, and Michael Bowling, 2009, &ldquo;A Practical Use of
Imperfect Recall&rdquo;, in <em>Proceedings of the Eighth Symposium on
Abstraction, Reformulation and Approximation (SARA)</em>.</li>

<li>de Weerd, Harmen, Rineke Verbrugge, and Bart Verheij, 2013,
&ldquo;How Much Does It Help to Know What She Knows You Know? An
Agent-Based Simulation Study&rdquo;, <em>Artificial Intelligence</em>,
199&ndash;200: 67&ndash;92. doi:10.1016/j.artint.2013.05.004</li>

<li>Weibull, J&ouml;rgen W., 1995, <em>Evolutionary Game Theory</em>,
Cambridge, MA: MIT Press.</li>

<li>Weirich, Paul, 2008 [2020], &ldquo;Causal Decision Theory&rdquo;,
in <em>The Stanford Encyclopedia of Philosophy</em> (Winter 2020
edition), Edward N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/win2020/entries/decision-causal/" target="other">https://plato.stanford.edu/archives/win2020/entries/decision-causal/</a>&gt;.</li>
 
<li>Weisberg, Jonathan, 2015 [2021], &ldquo;Formal
Epistemology&rdquo;, <em>The Stanford Encyclopedia of Philosophy</em>
(Spring 2021 edition), Edward N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/spr2021/entries/formal-epistemology/">https://plato.stanford.edu/archives/spr2021/entries/formal-epistemology/</a>&gt;.</li>
 
<li>Zhou, Chunlai, 2010, &ldquo;Probability Logic of Finitely Additive
Beliefs&rdquo;, <em>Journal of Logic, Language and Information</em>,
19(3): 247&ndash;282. doi:10.1007/s10849-009-9100-2</li>

<li>Zollman, Kevin J. S., 2022, &ldquo;On the Normative Status of
Mixed Strategies&rdquo;, in <em>Reflections on the Foundations of
Probability and Statistics: Essays in Honor of Teddy Seidenfeld</em>,
Thomas Augustin, Fabio Gagliardi Cozman, and Gregory Wheeler (eds),
(Theory and Decision Library A 54), Cham: Springer International
Publishing, 207&ndash;239. doi:10.1007/978-3-031-15436-2_10</li>
</ul>
</div> 

<div id="academic-tools">
<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=epistemic-game" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/epistemic-game/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=epistemic-game&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="https://philpapers.org/sep/epistemic-game/" target="other">Enhanced bibliography for this entry</a>
at <a href="https://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>
</div>

<div id="other-internet-resources">

<h2 id="Oth">Other Internet Resources</h2>

<ul>

<li>Catonini, Emiliano and Nicodemo De Vito, 2023,
 &ldquo;<a href="https://arxiv.org/abs/2305.15330" target="other">Cautious belief and iterated admissibility</a>&rdquo;,
 manuscript, arxiv.org.</li>

<li>Catonini, Emiliano and Antonio Penta, 2022, &ldquo;Backward
induction reasoning beyond backward induction&rdquo;, Economics
Working Paper Series, Working Paper No. 1815.
 [<a href="https://bse.eu/research/working-papers/backward-induction-reasoning-beyond-backward-induction" target="other">Catonini &amp; Penta 2022 available online</a>]</li>
 </ul>
</div>

<div id="related-entries">

<h2 id="Rel">Related Entries</h2>

<p>

 <a href="../belief/">belief</a> |
 <a href="../formal-belief/">belief, formal representations of</a> |
 <a href="../common-knowledge/">common knowledge</a> |
 <a href="../decision-causal/">decision theory: causal</a> |
 <a href="../formal-epistemology/">epistemology, formal</a> |
 <a href="../game-theory/">game theory</a> |
 <a href="../dynamic-epistemic/">logic: dynamic epistemic</a> |
 <a href="../logic-epistemic/">logic: epistemic</a> |
 <a href="../logics-for-games/">logic: for analyzing games</a> |
 <a href="../prisoner-dilemma/">prisoner&rsquo;s dilemma</a> |
 <a href="../rationality-normative-utility/">rational choice, normative: expected utility</a>
 </p>
</div>

<div id="acknowledgments">

<h3>Acknowledgments</h3>

<p>
The authors and editors would like to thank Boning Yu and Philippe van
Basshuysen for many comments that improved the readability of this
entry.</p>
</div>
<script type="text/javascript" src="local.js"></script>
<script type="text/javascript" src="../../MathJax/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2025</a> by

<br />
<a href="http://www.philosophy.umd.edu/people/pacuit" target="other">Eric Pacuit</a>
&lt;<a href="m&#97;ilto:epacuit&#37;40umd&#37;2eedu"><em>epacuit<abbr title=" at ">&#64;</abbr>umd<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;<br />
<a href="http://www.philosophie1.uni-bayreuth.de/en/team/roy/" target="other">Olivier Roy</a>
&lt;<a href="m&#97;ilto:Olivier&#37;2eRoy&#37;40uni-bayreuth&#37;2ede"><em>Olivier<abbr title=" dot ">&#46;</abbr>Roy<abbr title=" at ">&#64;</abbr>uni-bayreuth<abbr title=" dot ">&#46;</abbr>de</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
            <li role="menuitem"><a href="../../new.html">What's New</a></li>
            <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li role="menuitem"><a href="../../published.html">Chronological</a></li>
            <li role="menuitem"><a href="../../archives/">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
            <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
            <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
            <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
            <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
            <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
            <li role="menuitem"><a href="../../accessibility.html">Accessibility</a></li>
            <li role="menuitem"><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
            <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
            <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2025</a> by <a href="https://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>
</html>
