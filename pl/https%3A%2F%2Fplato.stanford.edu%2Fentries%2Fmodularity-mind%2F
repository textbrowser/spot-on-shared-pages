<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html lang="en"> <!-- <![endif]-->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Modularity of Mind (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Modularity of Mind" />
<meta property="citation_author" content="Robbins, Philip" />
<meta property="citation_author" content="Drayson, Zoe" />
<meta property="citation_publication_date" content="2009/04/01" />
<meta name="DC.title" content="Modularity of Mind" />
<meta name="DC.creator" content="Robbins, Philip" />
<meta name="DC.creator" content="Drayson, Zoe" />
<meta name="DCTERMS.issued" content="2009-04-01" />
<meta name="DCTERMS.modified" content="2025-07-08" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP home page" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
                    <li role="menuitem"><a href="../../new.html">What's New</a></li>
                    <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li role="menuitem"><a href="../../published.html">Chronological</a></li>
                    <li role="menuitem"><a href="../../archives/">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
                    <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
                    <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
                    <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
                    <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
                    <li role="menuitem"><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
                    <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
                    <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="../../search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit" aria-label="search"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/modularity-mind/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=modularity-mind">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Modularity of Mind</h1><div id="pubinfo"><em>First published Wed Apr 1, 2009; substantive revision Tue Jul 8, 2025</em></div>

<div id="preamble">

<p>
The concept of modularity has loomed large in philosophy of psychology
since the early 1980s, following the publication of Fodor&rsquo;s
landmark book <em>The Modularity of Mind</em> (1983). In the decades
since the term &lsquo;module&rsquo; and its cognates first entered the
lexicon of cognitive science, the conceptual and theoretical landscape
in this area has changed dramatically. Especially noteworthy in this
respect has been the development of evolutionary psychology, whose
proponents adopt a less stringent conception of modularity than the
one advanced by Fodor, and who argue that the architecture of the mind
is more pervasively modular than Fodor claimed. Where Fodor (1983,
2000) draws the line of modularity at the relatively low-level systems
underlying perception and language, post-Fodorian theorists such as
Sperber (2002) and Carruthers (2006) contend that the mind is modular
through and through, up to and including the high-level systems
responsible for reasoning, planning, decision making, and the like.
The concept of modularity has also figured in recent debates in
philosophy of science, epistemology, ethics, and philosophy of
language&mdash;further evidence of its utility as a tool for
theorizing about mental architecture.</p>
</div> 

<div id="toc"><!--Entry Contents-->
<ul>
	<li><a href="#WhatMentModu">1. What is a mental module?</a></li>
	<li><a href="#ModuFodoStylModeProp">2. Modularity, Fodor-style: A modest proposal</a>
	<ul>
		<li><a href="#ChalLowLeveModu">2.1 Challenges to low-level modularity</a></li>
		<li><a href="#FodoArguAgaiHighLeveModu">2.2 Fodor&rsquo;s argument against high-level modularity</a></li>
	</ul>
	</li>
	<li><a href="#PostFodoModu">3. Post-Fodorian modularity</a>
	<ul>
		<li><a href="#CaseForMassModu">3.1 The case for massive modularity</a></li>
		<li><a href="#CaseAgaiMassModu">3.2 The case against massive modularity</a></li>
		<li><a href="#DoubAbouDeba">3.3. Doubts about the debate</a></li>
	</ul>
	</li>
	<li><a href="#ModuBordBetwPercCogn">4. Modularity and the border between perception and cognition</a>
	<ul>
		<li><a href="#CharPercDebaViaModu">4.1 Characterizing the perception&ndash;cognition debate via modularity</a></li>
		<li><a href="#ChalPercBordViaModu">4.2 Challenging the perception&ndash;cognition border via modularity</a></li>
		<li><a href="#ModuBeyoPercCogn">4.3 Modularity beyond perception and cognition</a></li>
	</ul>
	</li>
	<li><a href="#ModuPhil">5. Modularity and philosophy</a></li>
	<li><a href="#Bib">Bibliography</a></li>
	<li><a href="#Aca">Academic Tools</a></li>
	<li><a href="#Oth">Other Internet Resources</a></li>
	<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->

<hr /></div>

<div id="main-text">

<h2 id="WhatMentModu">1. What is a mental module?</h2>

<p>
In his classic introduction to modularity, Fodor (1983) lists nine
features that collectively characterize the type of system that
interests him. In original order of presentation, they are:</p>

<ol>

<li>Domain specificity</li>

<li>Mandatory operation</li>

<li>Limited central accessibility</li>

<li>Fast processing</li>

<li>Informational encapsulation</li>

<li>&lsquo;Shallow&rsquo; outputs</li>

<li>Fixed neural architecture</li>

<li>Characteristic and specific breakdown patterns</li>

<li>Characteristic ontogenetic pace and sequencing</li>
</ol>

<p>
A cognitive system counts as modular in Fodor&rsquo;s sense if it is
modular &ldquo;to some interesting extent,&rdquo; meaning that it has
most of these features to an appreciable degree (Fodor, 1983, p. 37).
This is a weighted most, since some marks of modularity are more
important than others. Information encapsulation, for example, is more
or less essential for modularity, as well as explanatorily prior to
several of the other features on the list (Fodor, 1983, 2000).</p>

<p>
Each of the items on the list calls for explication. To streamline the
exposition, we will cluster most of the features thematically and
examine them on a cluster-by-cluster basis, along the lines of Prinz
(2006).</p>

<p>
<em>Encapsulation and inaccessibility.</em> Informational
encapsulation and limited central accessibility are two sides of the
same coin. Both features pertain to the character of information flow
across computational mechanisms, albeit in opposite directions.
Encapsulation involves restriction on the flow of information into a
mechanism, whereas inaccessibility involves restriction on the flow of
information out of it.</p>

<p>
A cognitive system is informationally encapsulated to the extent that
in the course of processing its inputs it cannot access information
stored elsewhere; all it has to go on is the information contained in
those inputs plus whatever information might be stored within the
system itself, for example, in a proprietary database (Fodor, 2000,
pp. 62&ndash;63). (Note that items of information drawn on by a system
in the course of its operations do not count as inputs to the system;
otherwise the encapsulation criterion of modularity would be trivially
satisfied.) In the case of language, for example:</p>

<blockquote>
A parser for [a language] <em>L</em> contains a grammar of <em>L</em>.
What it does when it does its thing is, it infers from certain
acoustic properties of a token to a characterization of certain of the
distal causes of the token (e.g., to the speaker&rsquo;s intention
that the utterance should be a token of a certain linguistic type).
Premises of this inference can include whatever information about the
acoustics of the token the mechanisms of sensory transduction provide,
whatever information about the linguistic types in <em>L</em> the
internally represented grammar provides, <em>and nothing else</em>.
(Fodor, 1984, pp. 245&ndash;246; italics in original)
</blockquote>

<p>
Similarly, in the case of perception&mdash;understood as a kind of
non-demonstrative (i.e., defeasible, or non-monotonic) inference from
sensory &lsquo;premises&rsquo; to perceptual
&lsquo;conclusions&rsquo;&mdash;the claim that perceptual systems are
informationally encapsulated is equivalent to the claim that
&ldquo;the data that can bear on the confirmation of perceptual
hypotheses includes, in the general case, considerably less than the
organism may know&rdquo; (Fodor, 1983, p. 69). The classic
illustration of this property comes from the study of visual
illusions, which tend to persist even after the viewer is explicitly
informed about the character of the stimulus. In the M&uuml;ller-Lyer
illusion, for example, the two lines continue to look as if they were
of unequal length even after one has convinced oneself otherwise,
e.g., by measuring them with a ruler (see Figure 1, below).</p>

<div class="figure">
<img src="mueller-lyer.png" alt="Two horizontal line segments of the same length with arrowheads on the left and right side; the upper line segment has arrowheads pointing inwards, towards the line segment; the lower line segment has arrowheads pointing outwards, away from the line segment." />

<p class="center">
<span class="figlabel">Figure 1.</span> <em>The M&uuml;ller-Lyer
illusion</em>.</p>
</div>

<p>
Informational encapsulation is related to what Pylyshyn (1984, 1999)
calls cognitive impenetrability, but the two properties are not the
same. To a first approximation, a system is cognitively impenetrable
if its operations are not subject to direct influence by information
stored in central memory, paradigmatically in the form of beliefs and
utilities. As such, information encapsulation entails cognitive
impenetrability, but not the other way around. For example, auditory
speech perception might be cognitively impenetrable but draw on visual
information, as suggested by the McGurk effect (but see
 <a href="#ChalLowLeveModu">&sect;2.1</a>).
 The relation between informational encapsulation and cognitive
impenetrability is, however, a matter of controversy (see
 <a href="#ModuBordBetwPercCogn">&sect;4</a>).</p>
 
<p>
The flip side of informational encapsulation is inaccessibility to
central monitoring. A system is inaccessible in this sense if the
intermediate-level representations that it computes prior to producing
its output are inaccessible to consciousness, and hence unavailable
for explicit report. In effect, centrally inaccessible systems are
those whose internal processing is opaque to introspection. Though the
outputs of such systems may be phenomenologically salient, their
precursor states are not. Speech comprehension, for example, likely
involves the successive elaboration of myriad representations (of
various types: phonological, lexical, syntactic, etc.) of the
stimulus, but of these only the final product&mdash;the representation
of the meaning of what was said&mdash;is consciously available.</p>

<p>
<em>Mandatoriness, speed, and superficiality.</em> In addition to
being informationally encapsulated and centrally inaccessible, modular
systems and processes are &ldquo;fast, cheap, and out of
control&rdquo; (to borrow a phrase by roboticist Rodney Brooks). These
features form a natural trio, as we&rsquo;ll see.</p>

<p>
The operation of a cognitive system is mandatory just in case it is
automatic, that is, not under conscious control (Bargh &amp;
Chartrand, 1999). This means that, like it or not, the system&rsquo;s
operations are switched on by presentation of the relevant stimuli and
those operations run to completion. For example, native speakers of
English cannot hear the sounds of English being spoken as mere noise:
if they hear those sounds at all, they hear them as English. Likewise,
it&rsquo;s impossible to see a 3D array of objects in space as 2D
patches of color, however hard one may try.</p>

<p>
Speed is arguably the mark of modularity that requires least in the
way of explication. But speed is relative, so the best way to proceed
here is by way of examples. Speech shadowing is generally considered
to be very fast, with typical lag times on the order of about 250 ms.
Since the syllabic rate of normal speech is about 4 syllables per
second, this suggests that shadowers are processing the stimulus in
syllabus-length bits&mdash;probably the smallest bits that can be
identified in the speech stream, given that &ldquo;only at the level
of the syllable do we begin to find stretches of wave form whose
acoustic properties are at all reliably related to their linguistic
values&rdquo; (Fodor, 1983, p. 62). Similarly impressive results are
available for vision: in a rapid serial visual presentation task
(matching picture to description), subjects were 70% accurate at 125
ms. exposure per picture and 96% accurate at 167 ms. (Fodor, 1983, p.
63). In general, a cognitive process counts as fast in Fodor&rsquo;s
book if it takes place in a half second or less.</p>

<p>
A further feature of modular systems is that their outputs are
relatively &lsquo;shallow&rsquo;. Exactly what this means is unclear.
But the depth of an output seems to be a function of at least two
properties: first, how much computation is required to produce it
(i.e., shallow means computationally cheap); second, how constrained
or specific its informational content is (i.e., shallow means
informationally general) (Fodor, 1983, p. 87). These two properties
are correlated, in that outputs with more specific content tend to be
more costly for a system to compute, and vice versa. Some writers have
interpreted shallowness to require non-conceptual character (e.g.,
Carruthers, 2006, p. 4). But this conflicts with Fodor&rsquo;s own
gloss on the term, in which he suggests that the output of a plausibly
modular system such as visual object recognition might be encoded at
the level of &lsquo;basic-level&rsquo; concepts, like DOG and CHAIR
(Rosch et al., 1976). What&rsquo;s ruled out here is not concepts
<em>per se</em>, then, but highly theoretical concepts like PROTON,
which are too informationally specific and too computationally
expensive to meet the shallowness criterion.</p>

<p>
All three of the features just discussed&mdash;mandatoriness, speed,
and shallowness&mdash;are associated with, and to some extent
explicable in terms of, informational encapsulation. In each case,
less is more, informationally speaking. Mandatoriness flows from the
insensitivity of the system to the organism&rsquo;s utilities, which
is one dimension of cognitive impenetrability. Speed depends upon the
efficiency of processing, which positively correlates with
encapsulation in so far as encapsulation tends to reduce the
system&rsquo;s informational load. Shallowness is a similar story:
shallow outputs are computationally cheap, and computational expense
is negatively correlated with encapsulation. In short, the more
informationally encapsulated a system is, the more likely it is to be
fast, cheap, and out of control.</p>

<p>
<em>Dissociability and localizability</em>. To say that a system is
functionally dissociable is to say that it can be selectively
impaired, that is, damaged or disabled with little or no effect on the
operation of other systems. As the neuropsychological record
indicates, selective impairments of this sort have frequently been
observed as a consequence of circumscribed brain lesions. Standard
examples from the study of vision include prosopagnosia (impaired face
recognition), achromatopsia (total color blindness), and akinetopsia
(motion blindness); examples from the study of language include
agrammatism (loss of complex syntax), jargon aphasia (loss of complex
semantics), alexia (loss of object words), and dyslexia (impaired
reading and writing). Each of these disorders have been found in
otherwise cognitively normal individuals, suggesting that the lost
capacities are subserved by functionally dissociable mechanisms.</p>

<p>
Functional dissociability is associated with neural localizability in
a strong sense. A system is strongly localized just in case it is (a)
implemented in neural circuitry that is both relatively circumscribed
in extent (though not necessarily in contiguous areas) and (b)
dedicated to the realization of that system alone. Localization in
this sense goes beyond mere implementation in local neural circuitry,
since a given bit of circuitry could subserve more than one cognitive
function (Anderson, 2010). Proposed candidates for strong localization
include systems for color vision (V4), motion detection (MT), face
recognition (fusiform gyrus), and spatial scene recognition
(parahippocampal gyrus).</p>

<p>
<em>Domain specificity</em>. A system is domain specific to the extent
that it has a restricted subject matter, that is, the class of objects
and properties that it processes information about is circumscribed in
a relatively narrow way. As Fodor (1983) puts it, &ldquo;domain
specificity has to do with the range of questions for which a device
provides answers (the range of inputs for which it computes
analyses)&rdquo; (p. 103): the narrower the range of inputs a system
can compute, the narrower the range of problems the system can
solve&mdash;and the narrower the range of such problems, the more
domain specific the device. Alternatively, the degree of a
system&rsquo;s domain specificity can be understood as a function of
the range of inputs that turn the system on, where the size of that
range determines the informational reach of the system (Carruthers,
2006; Samuels, 2000).</p>

<p>
Domains (and by extension, modules) are typically more fine-grained
than sensory modalities like vision and audition. This seems clear
from Fodor&rsquo;s list of plausibly domain-specific mechanisms, which
includes systems for color perception, visual shape analysis, sentence
parsing, and face and voice recognition (Fodor, 1983, p.
47)&mdash;none of which correspond to perceptual or linguistic
faculties in an intuitive sense. It also seems plausible, however,
that the traditional sense modalities (vision, audition, olfaction,
etc.), and the language faculty as a whole, are sufficiently domain
specific to count as displaying this particular mark of modularity
(McCauley &amp; Henrich, 2006).</p>

<p>
<em>Innateness</em>. The final feature of modular systems on
Fodor&rsquo;s roster is innateness, understood as the property of
&ldquo;develop[ing] according to specific, endogenously determined
patterns under the impact of environmental releasers&rdquo; (Fodor,
1983, p. 100). On this view, modular systems come on-line chiefly as
the result of a brute-causal process like triggering, rather than an
intentional-causal process like learning. (For more on this
distinction, see Cowie, 1999; for an alternative analysis of
innateness, based on the notion of canalization, see Ariew, 1999.) The
most familiar example here is language, the acquisition of which
occurs in all normal individuals in all cultures on more or less the
same schedule: single words at 12 months, telegraphic speech at 18
months, complex grammar at 24 months, and so on (Stromswold, 1999).
Other candidates include visual object perception (Spelke, 1994) and
low-level mindreading (Scholl &amp; Leslie, 1999).</p>

<h2 id="ModuFodoStylModeProp">2. Modularity, Fodor-style: A modest proposal</h2>

<p>
The hypothesis of modest modularity, as we shall call it, has two
strands. The first strand of the hypothesis is positive. It says that
input systems, such as systems involved in perception and language,
are modular. The second strand is negative. It says that central
systems, such as systems involved in belief fixation and practical
reasoning, are not modular.</p>

<p>
In this section, we assess the case for modest modularity. The next
section
 (<a href="#PostFodoModu">&sect;3</a>)
 will be devoted to discussion of the hypothesis of massive
modularity, which retains the positive strand of Fodor&rsquo;s
hypothesis while reversing the polarity of the second strand from
negative to positive&mdash;revising the concept of modularity in the
process.</p>

<p>
The positive part of the modest modularity hypothesis is that input
systems are modular. By &lsquo;input system&rsquo; Fodor (1983) means
a computational mechanism that &ldquo;presents the world to
thought&rdquo; (p. 40) by processing the outputs of sensory
transducers. A sensory transducer is a device that converts the energy
impinging on the body&rsquo;s sensory surfaces, such as the retina and
cochlea, into a computationally usable form, without adding or
subtracting information. Roughly speaking, the product of sensory
transduction is raw sensory data. Input processing involves
non-demonstrative inferences from this raw data to hypotheses about
the layout of objects in the world. These hypotheses are then passed
on to central systems for the purpose of belief fixation, and those
systems in turn pass their outputs to systems responsible for the
production of behavior.</p>

<p>
Fodor argues that input systems constitute a natural kind, defined as
&ldquo;a class of phenomena that have many scientifically interesting
properties over and above whatever properties define the class&rdquo;
(Fodor, 1983, p. 46). He argues for this by presenting evidence that
input systems are modular, where modularity is marked by a cluster of
psychologically interesting properties&mdash;the most interesting and
important of these being informational encapsulation. In the course of
that discussion, we reviewed a representative sample of this evidence,
and for present purposes that should suffice. (Readers interested in
further details should consult Fodor, 1983, pp. 47&ndash;101.)</p>

<h3 id="ChalLowLeveModu">2.1 Challenges to low-level modularity</h3>

<p>
Fodor&rsquo;s claim about the modularity of input systems has been
disputed by a number of philosophers and psychologists (Churchland,
1988; Arbib, 1987; Marslen-Wilson &amp; Tyler, 1987; McCauley &amp;
Henrich, 2006). The most wide-ranging philosophical critique is due to
Prinz (2006), who argues that perceptual and linguistic systems rarely
exhibit the features characteristic of modularity. In particular, he
argues that such systems are not informationally encapsulated. To this
end, Prinz adduces two types of evidence. First, there appear to be
cross-modal effects in perception, which would tell against
encapsulation at the level of input systems. The classic example of
this, also from the speech perception literature, is the McGurk effect
(McGurk &amp; MacDonald, 1976). Here, subjects watching a video of one
phoneme being spoken (e.g., /ga/) dubbed with a sound recording of a
different phoneme (/ba/) hear a third, altogether different phoneme
(/da/). Second, he points to what look to be top-down effects on
visual and linguistic processing, the existence of which would tell
against cognitive impenetrability, i.e., encapsulation relative to
central systems. Some of the most striking examples of such effects
come from research on speech perception. Probably the best-known is
the phoneme restoration effect, as in the case where listeners
&lsquo;fill in&rsquo; a missing phoneme in a spoken sentence (<em>The
state governors met with their respective legi*latures convening in
the capital city</em>) from which the missing phoneme (the /s/ sound
in <em>legislatures</em>) has been deleted and replaced with the sound
of a cough (Warren, 1970). By hypothesis, this filling-in is driven by
listeners&rsquo; understanding of the linguistic context.</p>

<p>
How convincing one finds this part of Prinz&rsquo;s critique, however,
depends on how convincing one finds his explanation of these effects.
The McGurk effect, for example, seems consistent with the claim that
speech perception is an informationally encapsulated system, albeit a
system that is multi-modal in character (cf. Fodor, 1983, p.132n.13).
If speech perception is a multi-modal system, the fact that its
operations draw on both auditory and visual information need not
undermine the claim that speech perception is encapsulated. Other
cross-modal effects, however, resist this type of explanation. In the
double flash illusion, for example, viewers shown a single flash
accompanied by two beeps report seeing two flashes (Shams et al.,
2000). The same goes for the rubber hand illusion, in which
synchronous brushing of a hand hidden from view and a
realistic-looking rubber hand seen at the usual location of the hand
that was hidden gives rise to the impression that the fake hand is
real (Botvinick &amp; Cohen, 1998). With respect to phenomena of this
sort, unlike the McGurk effect, there is no plausible candidate for a
single, domain-specific system whose operations draw on multiple
sources of sensory information.</p>

<p>
Regarding phoneme restoration, it could be that the effect is driven
by listeners&rsquo; drawing on information stored in a
language-proprietary database (specifically, information about the
linguistic types in the lexicon of English), rather than higher-level
contextual information. Hence, it&rsquo;s unclear whether the case of
phoneme restoration described above counts as a top-down effect. But
not all cases of phoneme restoration can be accommodated so readily,
since the phenomenon also occurs when there are multiple lexical items
available for filling in (Warren &amp; Warren, 1970). For example,
listeners fill the gap in the sentences <em>The *eel is on the
axle</em> and <em>The *eel is on the orange</em>
differently&mdash;with a /wh/ sound and a /p/ sound,
respectively&mdash;suggesting that speech perception is sensitive to
contextual information after all.</p>

<p>
A further challenge to modest modularity, not addressed by Prinz
(2006), comes from evidence that susceptibility to the
M&uuml;ller-Lyer illusion varies by both culture and age. For example,
it appears that adults in Western cultures are more susceptible to the
illusion than their non-Western counterparts; that adults in some
non-Western cultures, such as hunter-gatherers from the Kalahari
Desert, are nearly immune to the illusion; and that within (but not
always across) Western and non-Western cultures, pre-adolescent
children are more susceptible to the illusion than adults are (Segall,
Campbell, &amp; Herskovits, 1966). McCawley and Henrich (2006) take
these findings as showing that the visual system is diachronically (as
opposed to synchronically) penetrable, in that how one experiences the
illusion-inducing stimulus changes as a result of one&rsquo;s wider
perceptual experience over an extended period of time. They also argue
that the aforementioned evidence of cultural and developmental
variability in perception militates against the idea that vision is an
innate capacity, that is, the idea that vision is among the
&ldquo;endogenous features of the human cognitive system that are, if
not largely fixed at birth, then, at least, genetically
pre-programmed&rdquo; and &ldquo;triggered, rather than shaped, by the
newborn&rsquo;s subsequent experience&rdquo; (p. 83). However, they
also issue the following caveat:</p>

<blockquote>
[N]othing about any of the findings we have discussed establishes the
<em>synchronic</em> cognitive penetrability of the M&uuml;ller-Lyer
stimuli. Nor do the Segall et al. (1966) findings provide evidence
that <em>adults&rsquo;</em> visual input systems are
<em>diachronically</em> penetrable. They suggest that it is only
during a critical developmental stage that human beings&rsquo;
susceptibility to the M&uuml;ller-Lyer illusion varies considerably
and that that variation substantially depends on <em>cultural</em>
variables. (McCauley &amp; Henrich, 2006, p. 99; italics in original)
</blockquote>

<p>
As such, the evidence cited can be accommodated by friends of modest
modularity, provided that allowance is made for the potential impact
of environmental, including cultural, variables on
development&mdash;something that most accounts of innateness make room
for.</p>

<p>
A useful way of making this point invokes Segal&rsquo;s (1996) idea of
diachronic modularity (see also Scholl &amp; Leslie, 1999). Diachronic
modules are systems that exhibit parametric variation over the course
of their development. For example, in the case of language, different
individuals learn to speak different languages depending on the
linguistic environment in which they grew up, but they nonetheless
share the same underlying linguistic competence in virtue of their
(plausibly innate) knowledge of Universal Grammar. Given the observed
variation in how people see the M&uuml;ller-Lyer illusion, it may be
that the visual system is modular in much the same way, with its
development is constrained by features of the visual environment. Such
a possibility seems consistent with the claim that input systems are
modular in Fodor&rsquo;s sense.</p>

<p>
Another source of difficulty for proponents of input-level modularity
is neuroscientific evidence against the claim that perceptual and
linguistic systems are strongly localized. Recall that for a system to
be strongly localized, it must be realized in dedicated neural
circuitry. Strong localization at the level of input systems, then,
entails the existence of a one-to-one mapping between input systems
and brain structures. As Anderson (2010, 2014) argues, however, there
is no such mapping, since most cortical regions of any size are
deployed in different tasks across different domains. For instance,
activation of the fusiform face area, once thought to be dedicated to
the perception of faces, is also recruited for the perception of cars
and birds (Gauthier et al., 2000). Likewise, Broca&rsquo;s area, once
thought to be dedicated to speech production, also plays a role in
action recognition, action sequencing, and motor imagery (Tettamanti
&amp; Weniger, 2006). Functional neuroimaging studies generally
suggest that cognitive systems are at best weakly localized, that is,
implemented in distributed networks of the brain that overlap, rather
than discrete and disjoint regions.</p>

<p>
Arguably the most serious challenge to modularity at the level of
input systems, however, comes from evidence that vision is cognitively
penetrable, and hence, not informationally encapsulated. The concept
of cognitive penetrability, originally introduced by Pylyshyn (1984),
has been characterized in a variety of non-equivalent ways (Stokes,
2013), but the core idea is this: A perceptual system is cognitively
penetrable if and only if its operations are directly causally
sensitive, in a semantically coherent way, to the agent&rsquo;s
beliefs, desires, intentions, or other nonperceptual states.
Behavioral studies purporting to show that vision is cognitively
penetrable date back to the early days of New Look psychology (Bruner
and Goodman, 1947) and continue to the present day, with renewed
interest in the topic emerging in the early 2000s (Firestone &amp;
Scholl, 2016). It appears, for example, that vision is influenced by
an agent&rsquo;s motivational states, with experimental subjects
reporting that desirable objects look closer (Balcetis &amp; Dunning,
2010) and ambiguous figures look like the interpretation associated
with a more rewarding outcome (Balcetis &amp; Dunning, 2006). In
addition, vision seems to be influenced by subjects&rsquo; beliefs,
with racial categorization affecting reports of the perceived skin
tone of faces even when the stimuli are equiluminant (Levin &amp;
Banaji, 2006), and categorization of objects affecting reports of the
perceived color of grayscale images of those objects (Hansen et al.,
2006).</p>

<p>
Skeptics of cognitive penetrability point out, however, that
experimental evidence for top-down effects on perception can be
explained in terms of effects of judgment, memory, and relatively
peripheral forms of attention (Firestone &amp; Scholl, 2016; Machery,
2015). Consider, for example, the claim that throwing a heavy ball
(vs. a light ball) at a target makes the target look farther away,
evidence for which consists of subjects&rsquo; visual estimates of the
distance to the target (Witt, Proffitt, &amp; Epstein, 2004). While it
is possible that the greater effort involved in throwing the heavy
ball caused the target to look farther away, it is also possible that
the increased estimate of distance reflected the fact that subjects in
the heavy ball condition judged the target to be farther away because
they found it harder to hit (Firestone &amp; Scholl, 2016). Indeed,
reports by subjects in a follow-up study who were explicitly
instructed to make their estimates on the basis of visual appearances
only did not show the effect of effort, suggesting that the effect was
post-perceptual (Woods, Philbeck, &amp; Danoff, 2009). Other purported
top-down effects on perception, such as the effect of golfing
performance on size and distance estimates of golf holes (Witt et al.,
2008), can be explained as effects of spatial attention, such as the
fact that visually attended objects tend to appear larger and closer
(Firestone &amp; Scholl, 2016). These and related considerations
suggest that the case for cognitive penetrability&mdash;and by
extension, the case against low-level modularity&mdash;is weaker than
its proponents make it out to be.</p>

<h3 id="FodoArguAgaiHighLeveModu">2.2 Fodor&rsquo;s argument against high-level modularity</h3>

<p>
I turn now to the dark side of Fodor&rsquo;s hypothesis: the claim
that central systems are not modular.</p>

<p>
Among the principal jobs of central systems is the fixation of belief,
perceptual belief included, via non-demonstrative inference. Fodor
(1983) argues that this sort of process cannot be realized in an
informationally encapsulated system, and hence that central systems
cannot be modular. Spelled out a bit further, his reasoning goes like
this:</p>

<ol>

<li>Central systems are responsible for belief fixation.</li>

<li>Belief fixation is isotropic and Quinean.</li>

<li>Isotropic and Quinean processes cannot be carried out by
informationally encapsulated systems.</li>

<li>Belief fixation cannot be carried out by an informationally
encapsulated system. [from 2 and 3]</li>

<li>Modular systems are informationally encapsulated.</li>

<li>Belief fixation is not modular. [from 4 and 5]</li>
</ol>

<p class="indent">
Hence:</p>

<ol start="7">

<li>Central systems are not modular. [from 1 and 6]</li>
</ol>

<p>
The argument here contains two terms that call for explication, both
of which relate to the notion of confirmation holism in the philosophy
of science. The term &lsquo;isotropic&rsquo; refers to the epistemic
interconnectedness of beliefs in the sense that &ldquo;everything that
the scientist knows is, in principle, relevant to determining what
else he ought to believe. In principle, our botany constrains our
astronomy, if only we could think of ways to make them connect&rdquo;
(Fodor, 1983, p. 105). Antony (2003) presents a striking case of this
sort of long-range interdisciplinary cross-talk in the sciences,
between astronomy and archaeology; Carruthers (2006, pp.
356&ndash;357) furnishes another example, linking solar physics and
evolutionary theory. On Fodor&rsquo;s view, since scientific
confirmation is akin to belief fixation, the fact that scientific
confirmation is isotropic suggests that belief fixation in general has
this property.</p>

<p>
A second dimension of confirmation holism is that confirmation is
&lsquo;Quinean&rsquo;, meaning that:</p>

<blockquote>
[T]he degree of confirmation assigned to any given hypothesis is
sensitive to properties of the entire belief system &hellip;
simplicity, plausibility, and conservatism are properties that
theories have in virtue of their relation to the whole structure of
scientific beliefs <em>taken collectively</em>. A measure of
conservatism or simplicity would be a metric over <em>global</em>
properties of belief systems. (Fodor, 1983, pp. 107&ndash;108; italics
in original).
</blockquote>

<p>
Here again, the analogy between scientific thinking and thinking in
general underwrites the supposition that belief fixation is
Quinean.</p>

<p>
Both isotropy and Quineanness are features that preclude
encapsulation, since their possession by a system would require
extensive access to the contents of central memory, and hence a high
degree of cognitive penetrability. Put in slightly different terms:
isotropic and Quinean processes are &lsquo;global&rsquo; rather than
&lsquo;local&rsquo;, and since globality precludes encapsulation,
isotropy and Quineanness preclude encapsulation as well.</p>

<p>
By Fodor&rsquo;s lights, the upshot of this argument&mdash;namely, the
nonmodular character of central systems&mdash;is bad news for the
scientific study of higher cognitive functions. This is neatly
expressed by his &ldquo;First Law of the Non-Existence of Cognitive
Science,&rdquo; according to which &ldquo;[t]he more global (e.g., the
more isotropic) a cognitive process is, the less anybody understands
it&rdquo; (Fodor, 1983, p. 107). His grounds for pessimism on this
score are twofold. First, global systems are unlikely to be associated
with local brain architecture, thereby rendering them unpromising
objects of neuroscientific study:</p>

<blockquote>
We have seen that isotropic systems are unlikely to exhibit
articulated neuroarchitecture. If, as seems plausible,
neuroarchitecture is often a concomitant of constraints on information
flow, then neural equipotentiality is what you would expect in systems
in which every process has more or less uninhibited access to all the
available data. The moral is that, to the extent that the existence of
form/function correspondence is a precondition for successful
neuropsychological research, there is not much to be expected in the
way of a neuropsychology of thought (Fodor, 1983, pp. 127).
</blockquote>

<p>
Second, and more importantly, global processes are resistant to
computational explanation, making them unpromising objects of
psychological study:</p>

<blockquote>
The fact is that&mdash;considerations of their neural realization to
one side&mdash;global systems are per se bad domains for computational
models, at least of the sort that cognitive scientists are accustomed
to employ. The condition for successful science (in physics, by the
way, as well as psychology) is that nature should have joints to carve
it at: relatively simple subsystems which can be artificially isolated
and which behave, in isolation, in something like the way that they
behave <em>in situ</em>. Modules satisfy this condition;
Quinean/isotropic-wholistic-systems by definition do not. If, as I
have supposed, the central cognitive processes are nonmodular, that is
very bad news for cognitive science (Fodor, 1983, pp. 128).
</blockquote>

<p>
By Fodor&rsquo;s lights, then, considerations that militate against
high-level modularity also militate against the possibility of a
robust science of higher cognition&mdash;not a happy result, as far as
most cognitive scientists and philosophers of mind are concerned.</p>

<p>
Gloomy implications aside, Fodor&rsquo;s argument against high-level
modularity is difficult to resist. The main sticking points are these:
first, the negative correlation between globality and encapsulation;
second, the positive correlation between encapsulation and modularity.
Putting these points together, we get a negative correlation between
globality and modularity: the more global the process, the less
modular the system that executes it. As such, there seem to be only
three ways to block the conclusion of the argument:</p>

<ol>

<li>Deny that central processes are global.</li>

<li>Deny that globality and encapsulation are negatively
correlated.</li>

<li>Deny that encapsulation and modularity are positively
correlated.</li>
</ol>

<p>
Of these three options, the second seems least attractive, as it seems
something like a conceptual truth that globality and encapsulation
pull in opposite directions. The first option is slightly more
appealing, but only slightly. The idea that central processes are
relatively global, even if not as global as the process of
confirmation in science suggests, is hard to deny. And that is all the
argument really requires.</p>

<p>
That leaves the third option: denying that modularity requires
encapsulation. This is, in effect, the strategy pursued by Carruthers
(2006). More specifically, Carruthers draws a distinction between two
kinds of encapsulation: &ldquo;narrow-scope&rdquo;&nbsp;and
&ldquo;wide-scope.&rdquo;&nbsp;A system is narrow-scope encapsulated
if it cannot draw on <em>any</em> information held outside of it in
the course of its processing. This corresponds to encapsulation as
Fodor uses the term. By contrast, a system that is wide-scope
encapsulated can draw on exogenous information during the course of
its operations&mdash;it just cannot draw on <em>all</em> of that
information. (Compare: &ldquo;No exogenous information is
accessible&rdquo; vs. &ldquo;Not all exogenous information is
accessible.&rdquo;) This is encapsulation in a weaker sense of the
term than Fodor&rsquo;s. Indeed, Carruthers&rsquo;s use of the term
&ldquo;encapsulation&rdquo;&nbsp;in this context is somewhat
misleading, insofar as wide-scope encapsulated systems count as
unencapsulated in Fodor&rsquo;s sense (Prinz, 2006).</p>

<p>
Dropping the narrow-scope encapsulation requirement on modules raises
a number of issues, not the least of which being that it reduces the
power of modularity hypotheses to explain functional dissociations at
the system level (Stokes &amp; Bergeron, 2015). That said, if
modularity requires only wide-scope encapsulation, then Fodor&rsquo;s
argument against central modularity no longer goes through. But given
the importance of narrow-scope encapsulation to Fodorian modularity,
all this shows is that central systems might be modular in a
non-Fodorian way. The original argument that central systems are not
Fodor-modular&mdash;and with it, the motivation for the negative
strand of the modest modularity hypothesis&mdash;stands.</p>

<h2 id="PostFodoModu">3. Post-Fodorian modularity</h2>

<p>
According to the massive modularity hypothesis, the mind is modular
through and through, including the parts responsible for high-level
cognition functions like belief fixation, problem-solving, planning,
and the like. Originally articulated and advocated by proponents of
evolutionary psychology (Sperber, 1994, 2002; Cosmides &amp; Tooby,
1992; Pinker, 1997; Barrett, 2005; Barrett &amp; Kurzban, 2006), the
hypothesis has received its most comprehensive and sophisticated
defense at the hands of Carruthers (2006). Before proceeding to the
details of that defense, however, we need to consider briefly what
concept of modularity is in play.</p>

<p>
The main thing to note here is that the operative notion of modularity
differs significantly from the traditional Fodorian one. Carruthers is
explicit on this point:</p>

<blockquote>
[If] a thesis of massive mental modularity is to be remotely
plausible, then by &lsquo;module&rsquo; we cannot mean
&lsquo;Fodor-module&rsquo;. In particular, the properties of having
proprietary transducers, shallow outputs, fast processing, significant
innateness or innate channeling, and encapsulation will very likely
have to be struck out. That leaves us with the idea that modules might
be isolable function-specific processing systems, all or almost all of
which are domain specific (in the content sense), whose operations
aren&rsquo;t subject to the will, which are associated with specific
neural structures (albeit sometimes spatially dispersed ones), and
whose internal operations may be inaccessible to the remainder of
cognition. (Carruthers, 2006, p. 12)
</blockquote>

<p>
Of the original set of nine features associated with Fodor-modules,
then, Carruthers-modules retain at most only five: dissociability,
domain specificity, automaticity, neural localizability, and central
inaccessibility. Conspicuously absent from the list is informational
encapsulation, the feature most central to modularity in Fodor&rsquo;s
account. What&rsquo;s more, Carruthers goes on to drop domain
specificity, automaticity, and strong localizability (which rules out
the sharing of parts between modules) from his initial list of five
features, making his conception of modularity even more sparse
(Carruthers, 2006, p. 62). Other proposals in the literature are
similarly permissive in terms of the requirements a system must meet
in order to count as modular; an extreme case is Barrett and
Kurzban&rsquo;s conception of modules as functionally specialized
mechanisms (Barrett &amp; Kurzban, 2006).</p>

<p>
A second point, related to the first, is that defenders of massive
modularity have chiefly been concerned to defend the modularity of
central cognition, taking for granted that the mind is modular at the
level of input systems. Thus, the hypothesis at issue for theorists
like Carruthers might be best understood as the conjunction of two
claims: first, that input systems are modular in a way that requires
narrow-scope encapsulation; second, that central systems are modular,
but only in a way that does not require this feature. In defending
massive modularity, Carruthers focuses on the second of these claims,
and so will we.</p>

<h3 id="CaseForMassModu">3.1 The case for massive modularity</h3>

<p>
The centerpiece of Carruthers (2006) consists of three arguments for
massive modularity: the Argument from Design, the Argument from
Animals, and the Argument from Computational Tractability. Let&rsquo;s
briefly consider each of them in turn.</p>

<p>
The Argument from Design is as follows:</p>

<ol>

<li>Biological systems are designed systems, constructed
incrementally.</li>

<li>Such systems, when complex, need to be organized in a pervasively
modular way, that is, as a hierarchical assembly of separately
modifiable, functionally autonomous components.</li>

<li>The human mind is a biological system, and is complex.</li>

<li>Therefore, the human mind is (probably) massively modular in its
organization. (Carruthers, 2006, p. 25)</li>
</ol>

<p>
The crux of this argument is the idea that complex biological systems
cannot evolve unless they are organized in a modular way, where
modular organization entails that each component of the system (that
is, each module) can be selected for change independently of the
others. In other words, the evolvability of the system as a whole
requires the independent evolvability of its parts. The problem with
this assumption is twofold (Woodward &amp; Cowie, 2004). First, not
all biological traits are independently modifiable. Having two lungs,
for example, is a trait that cannot be changed without changing other
traits of an organism, because the genetic and developmental
mechanisms underlying lung numerosity causally depend on the genetic
and developmental mechanisms underlying bilateral symmetry. Second,
there appear to be developmental constraints on neurogenesis which
rule out changing the size of one brain area independently of the
others. This in turn suggests that natural selection cannot modify
cognitive traits in isolation from one another, given that evolving
the neural circuitry for one cognitive trait is likely to result in
changes to the neural circuitry for other traits.</p>

<p>
A further worry about the Argument from Design concerns the gap
between its conclusion (the claim that the mind is massively modular
<em>in organization</em>) and the hypothesis at issue (the claim that
the mind is massively modular <em>simpliciter</em>). The worry is
this. According to Carruthers, the modularity of a system implies the
possession of just two properties: functional dissociability and
inaccessibility of processing to external monitoring. Suppose that a
system is massively modular in organization. It follows from the
definition of modular organization that the components of the system
are functionally autonomous and separately modifiable. Though
functional autonomy guarantees dissociability, it&rsquo;s not clear
why separate modifiability guarantees inaccessibility to external
monitoring. According to Carruthers, the reason is that &ldquo;if the
internal operations of a system (e.g., the details of the algorithm
being executed) were available elsewhere, then they couldn&rsquo;t be
altered without some corresponding alteration being made in the system
to which they are accessible&rdquo; (Carruthers, 2006, p. 61). But
this is a questionable assumption. On the contrary, it seems plausible
that the internal operations of one system could be accessible to a
second system in virtue of a monitoring mechanism that functions the
same way regardless of the details of the processing being monitored.
At a minimum, the claim that separate modifiability entails
inaccessibility to external monitoring calls for more justification
than Carruthers offers.</p>

<p>
In short, the Argument from Design is susceptible to a number of
objections. Fortunately, there&rsquo;s a slightly stronger argument in
the vicinity of this one, due to Cosmides and Tooby (1992). It goes
like this:</p>

<ol>

<li>The human mind is a product of natural selection.</li>

<li>In order to survive and reproduce, our human ancestors had to
solve a number of recurrent adaptive problems (finding food, shelter,
mates, etc.).</li>

<li>Since adaptive problems are solved more quickly, efficiently, and
reliably by modular systems than by non-modular ones, natural
selection would have favored the evolution of a massively modular
architecture.</li>

<li>Therefore, the human mind is (probably) massively modular.</li>
</ol>

<p>
The force of this argument depends chiefly on the strength of the
third premise. Not everyone is convinced, to put it mildly (Fodor,
2000; Samuels, 2000; Woodward &amp; Cowie, 2004). First, the premise
exemplifies adaptationist reasoning, and adaptationism in the
philosophy of biology has more than its share of critics. Second, it
is doubtful whether adaptive problem-solving in general is easier to
accomplish with a large collection of specialized problem-solving
devices than with a smaller collection of general problem-solving
devices with access to a library of specialized programs (Samuels,
2000). Hence, insofar as the massive modularity hypothesis postulates
an architecture of the first sort&mdash;as evolutionary
psychologists&rsquo; &lsquo;Swiss Army knife&rsquo; metaphor of the
mind implies (Cosmides &amp; Tooby, 1992)&mdash;the premise seems
shaky.</p>

<p>
A related argument is the Argument from Animals. Unlike the Argument
from Design, this argument is never explicitly stated in Carruthers
(2006). But here is a plausible reconstruction of it, due to Wilson
(2008):</p>

<ol>

<li>Animal minds are massively modular.</li>

<li>Human minds are incremental extensions of animal minds.</li>

<li>Therefore, the human mind is (probably) massively modular.</li>
</ol>

<p>
Unfortunately for friends of massive modularity, this argument, like
the argument from design, is vulnerable to a number of objections
(Wilson, 2008). We&rsquo;ll mention two of them here. First,
it&rsquo;s not easy to motivate the claim that animal minds are
massively modular in the operative sense. Though Carruthers (2006)
goes to heroic lengths to do so, the evidence he cites&mdash;e.g., for
the domain specificity of animal learning mechanisms, &agrave; la
Gallistel, 1990&mdash;adds up to less than what&rsquo;s needed. The
problem is that domain specificity is not sufficient for
Carruthers-style modularity; indeed, it is not even one of the central
characteristics of modularity in Carruthers&rsquo; account. So the
argument falters at the first step. Second, even if animal minds are
massively modular, and even if single incremental extensions of the
animal mind preserve that feature, it&rsquo;s quite possible that a
series of such extensions of animal minds might have led to its loss.
In other words, as Wilson (2008) puts it, it can&rsquo;t be assumed
that the conservation of massive modularity is transitive. And without
this assumption, the Argument from Animals can&rsquo;t go through.</p>

<p>
Finally, we have the Argument from Computational Tractability
(Carruthers, 2006, pp. 44&ndash;59). For the purposes of this
argument, we assume that a mental process is computationally tractable
if it can be specified at the algorithmic level in such a way that the
execution of the process is feasible given time, energy, and other
resource constraints on human cognition (Samuels, 2005). We also
assume that a system is at wide-scope encapsulated if in the course of
its operations the system lacks access to at least some information
exogenous to it. (Recall from
 <a href="#FodoArguAgaiHighLeveModu">&sect;2.2</a>
 that wide-scope encapsulation is entailed by narrow-scope
encapsulation, but not conversely.)</p>

<ol>

<li>The mind is computationally realized.</li>

<li>All computational mental processes must be tractable.</li>

<li>Tractable processing is possible only in wide-scope encapsulated
systems.</li>

<li>Hence, the mind must consist entirely of wide-scope encapsulated
systems.</li>

<li>Hence, the mind is (probably) massively modular.</li>
</ol>

<p>
There are two problems with this argument, however. The first problem
has to do with the third premise, which states that tractability
requires encapsulation, that is, the inaccessibility of at least some
exogenous information to processing. What tractability actually
requires is something weaker, namely, that not all information is
accessed by the mechanism in the course of its operations (Samuels,
2005). In other words, it is possible for a system to have unlimited
access to a database without actually accessing all of its contents.
Though tractable computation rules out exhaustive search, for example,
unencapsulated mechanisms need not engage in exhaustive search, so
tractability does not require wide-scope encapsulation. The second
problem with the argument concerns the last step. Though one might
reasonably suppose that modular systems must be wide-scope
encapsulated, the converse doesn&rsquo;t follow, so it&rsquo;s unclear
how one gets from a claim about pervasive wide-scope encapsulation to
a claim about pervasive modularity.</p>

<p>
All in all, then, compelling general arguments for massive modularity
are hard to come by. This is not yet to dismiss the possibility of
modularity in high-level cognition, but it invites skepticism,
especially given the paucity of empirical evidence directly supporting
the hypothesis (Robbins, 2013). For example, it has been suggested
that the capacity to think about social exchanges is subserved by a
domain-specific, functionally dissociable, and innate mechanism (Stone
et al., 2002; Sugiyama et al., 2002). However, it appears that
deficits in social exchange reasoning do not occur in isolation, but
are accompanied by other social-cognitive impairments (Prinz, 2006).
Skepticism about modularity in other areas of central cognition, such
as high-level mindreading, also seems to be the order of the day
(Currie &amp; Sterelny, 2000). The type of mindreading impairments
characteristic of Asperger syndrome and high-functioning autism, for
example, co-occur with sensory processing and executive function
deficits (Frith, 2003). In general, there is little in the way of
neuropsychological evidence of high-level modularity.</p>

<h3 id="CaseAgaiMassModu">3.2 The case against massive modularity</h3>

<p>
Just as there are general theoretical arguments for massive
modularity, there are general theoretical arguments against it. One
argument takes the form of what Fodor (2000) calls the &ldquo;Input
Problem.&rdquo; The problem is this. Suppose that the architecture of
the mind is modular from top to bottom, and the mind consists entirely
of domain-specific mechanisms. In that case, the outputs of each
low-level (input) system will need to be routed to the appropriately
specialized high-level (central) system for processing. But that
routing can only be accomplished by a domain-general, non-modular
mechanism&mdash;contradicting the initial supposition. In response to
this problem, Barrett (2005) argues that processing in a massively
modular architecture does not require a domain-general routing device
of the sort envisaged by Fodor. An alternative solution, Barrett
suggests, involves what he calls &ldquo;enzymatic computation.&rdquo;
In this model, low-level systems pool their outputs together in a
centrally accessible workspace where each central system is
selectively activated by outputs that match its domain, in much the
same way that enzymes selectively bind with substrates that match
their specific templates. Like enzymes, specialized computational
devices at the central level of the architecture accept a restricted
range of inputs (analogous to biochemical substrates), perform
specialized operations on that input (analogous to biochemical
reactions), and produce outputs in a format useable by other
computational devices (analogous to biochemical products). This
obviates the need for a domain-general (hence, non-modular) mechanism
to mediate between low-level and high-level systems.</p>

<p>
A second challenge to massive modularity is posed by the &ldquo;Domain
Integration Problem&rdquo; (Carruthers, 2006). The problem here is
that reasoning, planning, decision making, and other types of
high-level cognition routinely involve the production of conceptually
structured representations whose content crosses domains. This means
that there must be some mechanism for integrating representations from
multiple domains. But such a mechanism would be domain general rather
than domain specific, and hence, non-modular. Like the Input Problem,
however, the Domain Integration Problem is not insurmountable. One
possible solution is that the language system has the capacity to play
the role of content integrator in virtue of its capacity to transform
conceptual representations that have been linguistically encoded
(Hermer &amp; Spelke, 1996; Carruthers, 2002, 2006). On this view,
language is the vehicle of domain-general thought. (For doubts about
the viability of this proposal, see Rice (2011) and&nbsp;Robbins
(2002).)</p>

<p>
Empirical objections to massive modularity take a variety of forms. To
start with, there is neurobiological evidence of developmental
plasticity, a phenomenon that tells against the idea that brain
structure is innately specified (Buller, 2005; Buller &amp;
Hardcastle, 2000). However, not all proponents of massive modularity
insist that modules are innately specified (Carruthers, 2006; Kurzban,
Tooby, &amp; Cosmides, 2001). Furthermore, it&rsquo;s unclear to what
extent the neurobiological record is at odds with nativism, given the
evidence that specific genes are linked to the normal development of
cortical structures in both humans and animals (Machery &amp; Barrett,
2008; Ramus, 2006).</p>

<p>
Another source of evidence against massive modularity comes from
research on individual differences in high-level cognition (Rabaglia,
Marcus, &amp; Lane, 2011). Such differences tend to be strongly
positively correlated across domains&mdash;a phenomenon known as the
&ldquo;positive manifold&rdquo;&mdash;suggesting that high-level
cognitive abilities are subserved by a domain-general mechanism,
rather than by a suite of specialized modules. There is, however, an
alternative explanation of the positive manifold. Since post-Fodorian
modules are allowed to share parts (Carruthers, 2006), the
correlations observed may stem from individual differences in the
functioning of components spanning multiple domain-specific
mechanisms.</p>

<h3 id="DoubAbouDeba">3.3. Doubts about the debate</h3>

<p>
As noted earlier, proponents of the massive modularity hypothesis
argue that the architecture of the mind is modular through and
through. Opponents of massive modularity, on the other hand, argue
that at least some components of mental architecture are not modular.
Meaningful disagreement about the extent to which the mind is modular,
however, can only take place against a background of agreement about
what it means for a component of the mind to be modular. And given the
lack of consensus in the cognitive science literature about what
features are criterial of modularity, one might worry that partisans
in the debate over massive modularity are talking past each other.</p>

<p>
A version of this worry animates a recent critique of the massive
modularity debate, according to which the controversy stems from a
confusion between two levels of analysis: a functional level and an
intentional level (Pietraszewski &amp; Wertz, 2022). (While
Pietraszewski and Wertz describe these as different levels of analysis
in the sense of Marr (1982), their exposition also draws
on&nbsp;Dennett&rsquo;s (1987)&nbsp;idea of stances, which are better
understood as strategies for prediction and explanation.) The crux of
Pietraszewski and Wertz&rsquo;s critique is as follows. At a
functional level of analysis, modules are functionally specialized
mechanisms. Since proponents of massive modularity operate at this
level of analysis, they understand modularity in terms of functional
specialization (Barrett &amp; Kurzban, 2006). At an intentional level
of analysis, by contrast, modules are parts of the mind that operate
outside the sphere of influence of a central agency. At this level of
analysis, the essence of modularity is informational encapsulation, a
property that exists only at the intentional level. (The logic behind
this restriction is that informational encapsulation entails
independence from a central agency, and the concept of a central
agency is meaningful only at an intentional level.) Since opponents of
massive modularity operate at an intentional level of analysis, they
understand modularity primarily in terms of informational
encapsulation (Fodor, 1984, 2000). According to Pietraszewski and
Wertz, the debate over massive modularity persists because proponents
and opponents of massive modularity are operating at different levels
of analysis (functional and intentional, respectively), and these
different levels of analysis presuppose fundamentally different
criteria of modularity (functional specialization and informational
encapsulation, respectively).</p>

<p>
Responding to this critique, Egeland (2024) takes issue with
Pietraszewski and Wertz&rsquo;s characterization of the massive
modularity debate (Egeland, 2024). For starters, Egeland contests
their claim that partisans on the affirmative side of the debate
typically conceive of modules as nothing more than functionally
specialized mechanisms. In fact, he says, most proponents of massive
modularity adopt a thicker conception of modularity, according to
which modules are both functionally specialized and domain specific
(Boyer &amp; Barrett, 2015; Coltheart, 1999; Cosmides &amp; Tooby,
1994; Sperber, 2002; Villena, 2023; Zerilli, 2017). As for the
negative side of the debate, Egeland argues against the idea that
opponents of massive modularity always conceive of modules as
informationally encapsulated, noting that some of them regard domain
specificity, rather than informational encapsulation, as the principal
criterion of modularity (Bolhuis &amp; Macphail, 2001; Chiappe &amp;
Gardner, 2012; Reader et al., 2011). Based on these considerations,
Egeland concludes that Pietraszewski and Wertz&rsquo;s dismissal of
the massive modularity debate as the product of conceptual error is
both unwarranted and counterproductive, insofar as it glosses over
important questions about the extent to which the architecture of the
mind is composed of domain-specific mechanisms (Margolis &amp;
Laurence, 2023).</p>

<h2 id="ModuBordBetwPercCogn">4. Modularity and the border between perception and cognition</h2>

<p>
The hypothesis of modest modularity
 (<a href="#ModuFodoStylModeProp">&sect;2</a>)
 says that input systems are modular while central systems are
non-modular. This section explores how philosophers have drawn on the
hypothesis of modest modularity to either endorse or oppose the idea
of a scientifically grounded distinction between perception and
cognition.</p>

<p>
That there is a common-sense distinction between seeing and believing
is not in doubt. It is debatable, however, whether this commonsense
distinction tracks a joint in nature: is there a border between
perception and cognition that can be captured by the sciences of the
mind? One way to defend the existence of such a border is to appeal to
the hypothesis of modest modularity. If perception is modular and
cognition is non-modular, then we can give an account of the border in
terms of the brain&rsquo;s information-processing architecture. This
view is discussed in
 <a href="#CharPercDebaViaModu">&sect;4.1</a>.</p>
 
<p>
On certain ways of characterizing the information-processing
architecture of the brain, however, it is unclear whether we can make
sense of a border between perception and cognition. Proponents of
predictive processing architectures, for example, emphasize the
continuity between cognition and perception, and the ubiquity of
top-down influences on the processing of sensory information. This
leads some theorists to deny the existence of an architectural border
between perception and cognition on the grounds that perception cannot
be modular. Their arguments are considered in
 <a href="#ChalPercBordViaModu">&sect;4.2</a>.</p>
 
<h3 id="CharPercDebaViaModu">4.1 Characterizing the perception&ndash;cognition debate via modularity</h3>

<p>
The idea that there is an architectural border between perception and
cognition takes its inspiration from the work of Fodor and Pylyshyn,
although it is important to notice that neither makes this exact
claim. Fodor&rsquo;s (1983) architectural distinction is between two
families of systems: modular systems performing input analysis, which
constitute a natural kind, and non-modular central systems, which
exploit the information provided by these input systems. Fodorian
input systems include linguistic processing as well as perceptual
processing, and Fodorian central systems are engaged in the rational
fixation of belief by non-demonstrative inference rather than
cognition as it more broadly understood by cognitive psychology.
Pylyshyn&rsquo;s (1999) interest is specifically in the cognitive
impenetrability of early visual processing rather than perception more
generally, and he avoids using the term &lsquo;modular&rsquo; to refer
to cognitively impenetrable systems because he thinks it conflates
several independent concepts. Technically, therefore, neither Fodor
nor Pylyshyn is attempting to characterize a border between perception
and cognition as they are standardly understood by the mind-sciences.
Contemporary proponents of the architectural approach to the
perception&ndash;cognition border draw on the insights of Fodor and
Pylyshyn to defend the claim that that there is a joint in nature that
constitutes a border between perception and cognition, and that this
border exists because perception is modular and cognition is
non-modular. Versions of this claim are put forward by Firestone and
Scholl (2016), Mandelbaum (2017), Green (2020), Quilty-Dunn (2020),
and Clarke (2021).</p>

<p>
Some defenders of the architectural approach to the
perception&ndash;cognition border remain committed to the idea that
modularity is incompatible with cognitive penetration. Firestone and
Scholl, for example, claim that the nature of the joint between
perception and cognition is &ldquo;such that perception proceeds
without any direct, unmediated influence from cognition&rdquo;
(Firestone &amp; Scholl, 2016, p.17). They propose that the standard
purported examples of cognitive penetration are based on
misinterpretations of the empirical data. Similarly, Quilty-Dunn
(2020) also takes seriously the idea that perception is modular
because it relies on the cognitive impenetrability of stores of
proprietary information, and this is what makes it distinct from
cognition. He allows that perception is influenced by the effects of
attention but denies that such influences violate the cognitive
impenetrability of perception.</p>

<p>
Some defenders of the architectural joint between perception and
cognition, however, defend a version of the modularity of perception
on which it is compatible with perception being cognitively
penetrated. Green&rsquo;s (2020) &ldquo;dimension restriction
hypothesis&rdquo; is an updated take on the modularity of perception,
on which perceptual processes are constrained in a way that cognitive
processes are not: the cognitive penetration of perception can occur,
but only within strict limits. Green (2020) understands perception and
cognition as separate psychological systems with <em>restricted</em>
patterns of information flow between them. Clarke (2021) proposes that
the joints between perceptual modules within a perceptual modality can
be modified by cognitive processing without challenging the modularity
of perception. He suggests that mental imagery, for example, can
influence the inputs to a perceptual module via the visual buffer
without altering the module&rsquo;s proprietary database.</p>

<p>
One reason to prefer stronger formulations of modularity, on which it
is incompatible with cognitive penetration, concerns the tractability
of perceptual processing. It is sometimes proposed that perceptual
processing would be computationally intractable if it were cognitive
penetrable. Green (2020) proposes that his dimensionally restricted
account of modularity is consistent with the tractability constraint
due to its strict limitations on information flow between perceptual
and cognitive systems, and Clarke (2021) proposes that as long as no
cognitive information has been added to a perceptual module&rsquo;s
proprietary database, worries about intractability do not arise.
Brooke-Wilson (2023) denies that tractability concerns motivate
informational encapsulation in the first place: he argues that
informational encapsulation is neither necessary nor sufficient for
tractability, and thus that informational encapsulation is less
important than many have thought. If we reject informational
encapsulation as an essential feature of modularity, however, it
becomes more difficult to use modularity to characterize an
architectural distinction between perception and cognition, since some
paradigmatic cognitive processes may end up on the modular side of the
distinction rather than the non-modular side (Clarke &amp; Beck,
2023).</p>

<p>
It is possible to defend the claim that there is a joint in nature
between perception and cognition while denying that the correct way to
characterize the joint is by appealing to modularity. One way to do
this is by focusing instead on the difference in format between
perceptual representations and cognitive representations. Block
(2023), for example, argues that perceptual representations are
nonpropositional, nonconceptual, and iconic, while cognitive
representations are propositional, conceptual, and discursive.
Characterizing the perception&ndash;cognition border in terms of
representational format is not necessarily in tension with an
architectural view of the border in terms of modularity. Those who
take the perception&ndash;cognition border to be identifiable via
representational format also tend to be sympathetic to modularity
(e.g., Burnston, 2017). Block (2023) proposes that there is
substantial truth to the modularity hypothesis, although he thinks
that the border between perception and cognition is best captured in
terms of representational format.</p>

<p>
Another way to defend the claim that there is a
perception&ndash;cognition border without relying on modularity is to
distinguish between mental states that depend on proximal stimulation
and those that do not. Phillips (2017) and Beck (2018) propose that
perception is stimulus-dependent while cognition is
stimulus-independent, for example. For further discussion of different
ways to defend the idea of a border between perception and cognition,
see the overviews by Watzl, Sundberg, and Nes (2021) and Clarke and
Beck (2023).</p>

<h3 id="ChalPercBordViaModu">4.2 Challenging the perception&ndash;cognition border via modularity</h3>

<p>
The claim that there is a perception&ndash;cognition boundary has come
into question (Shea, 2014). One way to do this is to appeal to
empirical evidence of cognitive penetration, infer that perception is
not informationally encapsulated, and conclude that perception is not
modular. This section focuses on an alternative way to challenge the,
modularity of perception, which involves arguing that our best
theories of mental architecture rule out modularity in principle. This
strategy is primarily associated with &lsquo;neural reuse&rsquo;
architectures and &lsquo;predictive processing&rsquo;
architectures.</p>

<p>
Proponents of neural reuse architectures emphasize the extent to which
neural mechanisms which originally evolved or developed for one
cognitive function can be deployed to service different cognitive
functions (Anderson, 2010; Hurley, 2008). Zerilli (2020) argues that
the only kinds of dissociable units we encounter in the brain have
little in common with the modules posited by psychology and cognitive
science, and thus that neural reuse architectures have disruptive
implications for the forms of functional modularity adopted by Fodor
or Carruthers. While it is true that neural reuse theories suggest
that the same individual brain regions can implement multiple
functional modules, this is a challenge primarily to anatomical
modularity in the form of neural localizability (see
 <a href="#WhatMentModu">&sect;1</a>).
 Anderson (2010) proposes that the sort of functional modularity
characterized by domain specificity and informational encapsulation
does not require anatomical modularity, and thus that the lack of
anatomical modularity in neural reuse architectures does not provide a
straightforward challenge to the modularity of mind.</p>

<p>
Proponents of predictive processing architectures claim that the brain
is a hierarchically structured engine of top-down prediction-error
minimization, in which higher-level generative models predict the
information in lower-level generative models (Clark, 2013; Hohwy,
2013). At the lowest level, the generative model is predicting the
sensory input. The only information passed from lower to higher levels
in hierarchy is in the form of prediction errors that capture how the
actual input to each layer or model differs from the predicted input.
Higher-level models provide Bayesian priors to lower-level models and
are updated by prediction errors at lower levels in accordance with
Bayes&rsquo; rule. Such a heavily top-down architecture, in which
there is &ldquo;no theoretical or anatomical border preventing
top-down projections from high to low levels of the perceptual
hierarchy&rdquo; (Hohwy, 2013, p.122), seems liable to cognitive
penetration. Vetter and Newen (2014), Lupyan (2015), and
Cerme&ntilde;o-A&iacute;nsa (2021) argue that the top-down nature of
predictive processing architectures must lead to cognitive
penetration, and Vance and Stokes (2017) take this as evidence that
such architectures are necessarily non-modular. Clark (2013) concurs,
holding that that according to the predictive processing approach,
perception is theory-laden and knowledge-driven; he proposes that
&ldquo;[t]o perceive the world just is to use what you know to explain
away the sensory signal&rdquo; (Clark, 2013, p. 190).</p>

<p>
These concerns lead Clark (2013) to doubt whether there is a border
between perception and cognition. He proposes that predictive
architecture &ldquo;makes the lines be&shy;tween perception and
cognition fuzzy, perhaps even vanishing&rdquo; (Clark, 2013, p. 190)
and suggests that perception and cognition are &ldquo;profoundly
unified and, in important respects, continuous&rdquo; (Clark, 2013, p.
187). Philosophers have responded to these concerns by arguing that
while predictive processing architectures may allow cognitive
penetration, they don&rsquo;t necessitate it (Macpherson, 2015). Hohwy
(2013) suggests that the top-down processing associated with
predictive architectures builds in a certain kind of evidential
insulation, such that cognitive penetration will occur only under
conditions of noisy input or uncertainty. Drayson (2017) argues that
the probabilistic causal influence from one level in the hierarchy to
the level below need not be transitive, and so we can accept that each
level in the predictive hierarchy is causally influenced by the level
above it without having to accept that each level is causally
influenced by <em>all</em> the levels above it. In addition to arguing
that predictive processing architectures do not necessitate the
cognitive penetration of perception, some philosophers go so far as to
claim that predictive processing architectures do in fact exhibit
modularity (Beni, 2022; Burnston, 2021; Drayson, 2017).</p>

<p>
Even if Clark is right that predictive processing architectures do not
allow for modularity, however, it would not follow from this that
there is no distinction between perception and cognition.
Clark&rsquo;s claim that predictive processing architectures provide
&ldquo;a genuine departure from many of our previous ways of thinking
about perception, cognition, and the human cognitive
architecture&rdquo; (Clark, 2013, 187) seems to rely on the idea that
modularity is the default view of perception. This position is
challenged at length by Stokes (2021). Furthermore, modularity is not
the only candidate for drawing a joint in nature between perception
and cognition: see the alternative approaches to the
perception&ndash;cognition border discussed in
 <a href="#CharPercDebaViaModu">&sect;4.1</a>.</p>
 
<h3 id="ModuBeyoPercCogn">4.3 Modularity beyond perception and cognition</h3>

<p>
Discussions of modularity in philosophy and cognitive science tend to
focus on two aspects of the mind: sensing and perceiving the world
(e.g., vision, audition, olfaction), and thinking about the world
(e.g., reasoning, planning, decision making). As important and
fundamental as these capacities are, they do not exhaust the
psychological domain, which also includes affective capacities (e.g.,
pain) and agentive capacities (e.g., motor control). Though the
modularity of these further capacities has been much less well
investigated, a growing literature in this area testifies to the
importance of modularity beyond the perception&ndash;cognition
divide.</p>

<p>
Regarding the pain system, the received view, at least until recently,
has been that pain is not modular. This hypothesis is based primarily
on evidence that pain is cognitively penetrable, such as the apparent
modulation of pain by expectations (Gligorov, 2017) and the phenomenon
of placebo analgesia (Shevlin &amp; Friesen, 2021). Together with the
assumption that cognitive penetrability precludes informational
encapsulation, and the assumption that modularity requires information
encapsulation, this evidence suggests that the pain system is
non-modular. Pushing back against this consensus, Casser and Clarke
(2023) argue that evidence for the cognitive penetrability of pain is
inconclusive. They also argue that evidence for the judgment
independence of pain from studies of the Thermal Grill Illusion, for
example&mdash;which militates against cognitive penetrability and in
favor of informational encapsulation, hence in favor of
modularity&mdash;is robust. But even if Casser and Clarke&rsquo;s
argument goes through, there may be other ways to motivate the
conclusion that pain is not modular. For example, Skrzypulec (2023)
argues that central cognitive mechanisms are partly constitutive of
the pain system, which in turn suggests that pain may not be modular
after all. In short, it appears that on the question of whether the
pain system is modular, the jury is still out.</p>

<p>
As for the modularity of motor control, Mylopoulos (2021) argues that
despite being cognitively penetrable, the motor system is
informationally encapsulated, hence modular in the Fodorian sense. On
her view, motor control is (a) cognitively penetrable because it takes
states of central cognition (i.e., intentions or action plans) as
inputs, and (b) informationally encapsulated because in processing its
inputs it accesses only motor schemas stored in a proprietary database
and sensory information selected for by attention. There are two
problems with this argument, however. First, the fact that a system
takes states of central cognition <em>as inputs</em> does not show
that in processing its inputs, the system is directly causally
sensitive to states of central cognition. (Recall the distinction
between information drawn on by a system in the course of its
operations, on the one hand, and inputs to the system carrying out
those operations, on the other; see
 <a href="#WhatMentModu">&sect;1</a>
 above.) Hence, even if the motor system took intentions as inputs,
that would not show that the system is cognitively penetrable, except
in a trivial sense. Second, and more importantly, information
encapsulation requires that when computing an input&ndash;output
function, a system draws only on information contained in its inputs
and information stored in a proprietary database, and nothing else.
But on Mylopoulos&rsquo;s proposal, the motor system does not meet
this requirement. As a result, the case she makes for the modularity
of motor control is less than compelling.</p>

<h2 id="ModuPhil">5. Modularity and philosophy</h2>

<p>
Interest in modularity is not confined to cognitive science and the
philosophy of mind; it extends well into a number of allied fields. In
epistemology, modularity has been invoked to defend the legitimacy of
a theory-neutral type of observation, and hence the possibility of
some degree of consensus among scientists with divergent theoretical
commitments (Fodor, 1984). The ensuing debate on this issue
(Churchland, 1988; Fodor, 1988; McCauley &amp; Henrich, 2006) holds
lasting significance for the general philosophy of science,
particularly for controversies regarding the status of scientific
realism. Relatedly, evidence of the cognitive penetrability of
perception has given rise to worries about the justification of
perceptual beliefs (Siegel, 2012; Stokes, 2012). In ethics, evidence
of this sort has been used to cast doubt on ethical intuitionism as an
account of moral epistemology (Cowan, 2014). In philosophy of
language, modularity has figured in theorizing about linguistic
communication, for example, in relevance theorists&rsquo; suggestion
that speech interpretation, pragmatic warts and all, is a modular
process (Sperber &amp; Wilson, 2002). It has also been used demarcate
the boundary between semantics and pragmatics, and to defend a
strikingly austere version of semantic minimalism (Borg, 2004). Though
the success of these deployments of modularity theory is subject to
dispute (e.g., see Robbins, 2007, for doubts about the modularity of
semantics), their existence testifies to the relevance of the concept
of modularity to philosophical inquiry in a variety of domains.</p>
</div>

<div id="bibliography">

<h2 id="Bib">Bibliography</h2>

<ul class="hanging">

<li>Anderson, M. L., 2010. Neural reuse: A fundamental organizational
principle of the brain. <em>Behavioral and Brain Sciences</em>, 33:
245&ndash;313.</li>

<li>&ndash;&ndash;&ndash;, 2014. <em>After phrenology: Neural reuse
and the interactive brain</em>, Cambridge, MA: MIT Press.</li>

<li>Antony, L. M., 2003. Rabbit-pots and supernovas: On the relevance
of psychological data to linguistic theory. In A. Barber (ed.),
<em>Epistemology of Language</em>, Oxford, UK: Oxford University
Press, pp. 47&ndash;68.</li>

<li>Arbib, M., 1987. Modularity and interaction of brain regions
underlying visuomotor coordination. In J. L. Garfield (ed.),
<em>Modularity in Knowledge Representation and Natural-Language
Understanding</em>, Cambridge, MA: MIT Press, pp. 333&ndash;363.</li>

<li>Ariew, A., 1999. Innateness is canalization: In defense of a
developmental account of innateness. In V. G. Hardcastle (ed.),
<em>Where Biology Meets Psychology</em>, Cambridge, MA: MIT Press, pp.
117&ndash;138.</li>

<li>Balcetis, E. and Dunning, D., 2006. See what you want to see:
Motivational influences on visual perception. <em>Journal of
Personality and Social Psychology</em>, 91: 612&ndash;625.</li>

<li>&ndash;&ndash;&ndash;, 2010. Wishful seeing: More desired objects
are seen as closer. <em>Psychological Science</em>, 21:
147&ndash;152.</li>

<li>Bargh, J. A. and Chartrand, T. L., 1999. The unbearable
automaticity of being. <em>American Psychologist</em>, 54:
462&ndash;479.</li>

<li>Barrett, H. C., 2005. Enzymatic computation and cognitive
modularity. <em>Mind &amp; Language</em>, 20: 259&ndash;287.</li>

<li>Barrett, H. C. and Kurzban, R., 2006. Modularity in cognition:
Framing the debate. <em>Psychological Review</em>, 113:
628&ndash;647.</li>

<li>Beck, J., 2018. Marking the perception&ndash;cognition boundary:
The criterion of stimulus-dependence. <em>Australasian Journal of
Philosophy</em>, 96: 319&ndash;334.</li>

<li>Beni, M. D., 2022. A tale of two architectures. <em>Consciousness
and Cognition</em>, 98 (C): 103257.</li>

<li>Block, N., 2023. <em>The Border Between Seeing and Thinking</em>,
New York, NY: Oxford University Press.</li>

<li>Bolhuis, J. J. and Macphail, E. M., 2001. A critique of the
neuroecology of learning and memory. <em>Trends in Cognitive
Sciences</em>, 5: 426&ndash;433.</li>

<li>Borg, E., 2004. <em>Minimal Semantics</em>, Oxford, UK: Oxford
University Press.</li>

<li>Boyer, P. and Barrett, H. C., 2015. Intuitive ontologies and
domain specificity. In D. M. Buss (ed.), <em>Handbook of Evolutionary
Psychology</em>, Hoboken, NJ: Wiley, pp. 1&ndash;19.</li>

<li>Brooke-Wilson, T., 2023. How is perception tractable?
<em>Philosophical Review</em>, 132: 239&ndash;292.</li>

<li>Bruner, J. and Goodman, C. C., 1947. Value and need as organizing
factors in perception. <em>Journal of Abnormal and Social
Psychology</em>, 42: 33&ndash;44.</li>

<li>Buller, D., 2005. <em>Adapting Minds</em>, Cambridge, MA: MIT
Press.</li>

<li>Buller, D. and Hardcastle, V. G., 2000. Evolutionary psychology,
meet developmental neurobiology: Against promiscuous modularity.
<em>Brain and Mind</em>, 1: 302&ndash;325.</li>

<li>Burnston, D. C., 2017. Cognitive penetration and the
cognition&ndash;perception interface. <em>Synthese</em>, 194:
3645&ndash;3668.</li>

<li>&ndash;&ndash;&ndash;, 2021. Bayes, predictive processing, and the
cognitive architecture of motor control. <em>Consciousness and
Cognition</em>, 96 (C): 103218.</li>

<li>Carruthers, P., 2002. The cognitive functions of language.
<em>Behavioral and Brain Sciences</em>, 25: 657&ndash;725.</li>

<li>&ndash;&ndash;&ndash;, 2006. <em>The Architecture of the
Mind</em>, Oxford, UK: Oxford University Press.</li>

<li>Casser, L. and Clarke, S., 2023. Is pain modular? <em>Mind &amp;
Language</em>, 38: 828&ndash;846.</li>

<li>Cerme&ntilde;o-A&iacute;nsa, S., 2021. Predictive coding and the
strong thesis of cognitive penetrability. <em>Theoria</em>, 36:
341&ndash;360.</li>

<li>Chiappe, D. and Gardner, R., 2012. The modularity debate in
evolutionary psychology. <em>Theory &amp; Psychology</em>, 22:
669&ndash;692.</li>

<li>Churchland, P., 1988. Perceptual plasticity and theoretical
neutrality: A reply to Jerry Fodor. <em>Philosophy of Science</em>,
55: 167&ndash;187.</li>

<li>Clark, A., 2013. Whatever next? Predictive brains, situated
agents, and the future of cognitive science. <em>Behavioral and Brain
Sciences</em>, 36:181&ndash;204.</li>

<li>Clarke, S., 2021. Cognitive penetration and informational
encapsulation: Have we been failing the module? <em>Philosophical
Studies</em>, 178: 2599&ndash;2620.</li>

<li>Clarke, S. and Beck, J., 2023. Border disputes: Recent debates
along the perception&ndash;cognition border. <em>Philosophy
Compass</em>, 18: e12936.</li>

<li>Coltheart, M., 1999. Modularity and cognition. <em>Trends in
Cognitive Sciences</em>, 3: 115&ndash;120.</li>

<li>Cosmides, L. and Tooby, J., 1992. Cognitive adaptations for social
exchange. In J. Barkow, L. Cosmides, and J. Tooby, eds., <em>The
Adapted Mind</em>, Oxford, UK: Oxford University Press, pp.
163&ndash;228.</li>

<li>&ndash;&ndash;&ndash;, 1994. Origins of domain specificity: The
evolution of functional organization. In L. A. Hirschfeld and S. A.
Gelman (eds.), <em>Mapping the Mind</em>, Cambridge, UK: Cambridge
University Press, pp. 85&ndash;116.</li>

<li>Cowan, R., 2014. Cognitive penetrability and ethical perception.
<em>Review of Philosophy and Psychology</em>, 6: 665&ndash;682.</li>

<li>Cowie, F., 1999. <em>What&rsquo;s Within? Nativism
Reconsidered</em>, Oxford, UK: Oxford University Press.</li>

<li>Currie, G. and Sterelny, K., 2000. How to think about the
modularity of mind-reading. <em>Philosophical Quarterly</em>, 50:
145&ndash;160.</li>

<li>Dennett, D., 1987. <em>The Intentional
Stance,</em>&nbsp;Cambridge, MA: MIT Press.</li>

<li>Drayson, Z., 2017. Modularity and the predictive mind. In T.
Metzinger and W. Weise (eds.), <em>Philosophy and Predictive
Processing</em>, Frankfurt am Main, Germany: MIND Group.</li>

<li>Egeland, J., 2024. Making sense of the modularity debate. <em>New
Ideas in Psychology</em>, 75: 101108.</li>

<li>Firestone, C. and Scholl, B. J., 2016. Cognition does not affect
perception: Evaluating the evidence for &ldquo;top-down&rdquo;
effects. <em>Behavioral and Brain Sciences</em>, 39: 1&ndash;27.</li>

<li>Fodor, J. A., 1983. <em>The Modularity of Mind</em>, Cambridge,
MA: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 1984. Observation reconsidered.
<em>Philosophy of Science</em>, 51: 23&ndash;43.</li>

<li>&ndash;&ndash;&ndash;, 1988. A reply to Churchland&rsquo;s
&ldquo;Perceptual plasticity and theoretical neutrality.&rdquo;
<em>Philosophy of Science</em>, 55: 188&ndash;198.</li>

<li>&ndash;&ndash;&ndash;, 2000. <em>The Mind Doesn&rsquo;t Work That
Way</em>, Cambridge, MA: MIT Press.</li>

<li>Frith, U., 2003. <em>Autism: Explaining the enigma</em>, 2nd
edition, Malden, MA: Wiley-Blackwell.</li>

<li>Gauthier, I., Skudlarski, P., Gore, J.C., and Anderson, A. W.,
2000. Expertise for cars and birds recruits brain areas involved in
face recognition. <em>Nature Neuroscience</em>, 3: 191&ndash;197.</li>

<li>Gligorov, N., 2017. Don&rsquo;t worry, this will only hurt a bit:
The role of expectation and attention in pain intensity. <em>The
Monist</em>, 100: 501&ndash;513.</li>

<li>Green, E. J., 2020. The perception-cognition border: A case for
architectural division. <em>Philosophical Review</em>, 129:
323&ndash;393.</li>

<li>Hansen, T., Olkkonen, M., Walter, S., and Gegenfurtner, K. R.,
2006. Memory modulates color appearance. <em>Nature Neuroscience</em>,
9: 1367&ndash;1368.</li>

<li>Hermer, L. and Spelke, E. S., 1996. Modularity and development:
The case of spatial reorientation. <em>Cognition</em>, 61:
195&ndash;232.</li>

<li>Hohwy, J., 2013. <em>The Predictive Mind</em>, Oxford, UK: Oxford
University Press.</li>

<li>Hurley, S., 2008. The shared circuits model (SCM): How control,
mirroring, and simulation can enable imitation, deliberation, and
mindreading. <em>Behavioral and Brain Sciences</em>, 31:
1&ndash;22.</li>

<li>Kurzban, R., Tooby, J., and Cosmides, L., 2001. Can race be
erased? Coalitional computation and social categorization.
<em>Proceedings of the National Academy of Sciences</em>, 98:
15387&ndash;15392.</li>

<li>Levin, D. and Banaji, M., 2006. Distortions in the perceived
lightness of faces: The role of race categories. <em>Journal of
Experimental Psychology: General</em>, 135: 501&ndash;512.</li>

<li>Lupyan, G., 2015. Cognitive penetrability of perception in the age
of prediction: Predictive systems are penetrable systems. <em>Review
of Philosophy and Psychology</em>, 6: 547&ndash;569.</li>

<li>Machery, E., 2015. Cognitive penetrability: A no-progress report.
In J. Zeimbekis and A. Raftopoulos (eds.), <em>The Cognitive
Penetrability of Perception: New Philosophical Perspectives</em>,
Oxford, UK: Oxford University Press.</li>

<li>Macpherson, F., 2015. Cognitive penetration and predictive coding:
A commentary on Lupyan. <em>Review of Philosophy and Psychology</em>,
6: 571&ndash;584.</li>

<li>Machery, E. and Barrett, H. C., 2006. Debunking <em>Adapting
Minds</em>. <em>Philosophy of Science</em>, 73: 232&ndash;246.</li>

<li>Mandelbaum, E., 2017. Seeing and conceptualizing: Modularity and
the shallow contents of perception. <em>Philosophy and
Phenomenological Research</em>, 97: 267&ndash;283.</li>

<li>Margolis, E. and Laurence, S., 2023. Making sense of domain
specificity. <em>Cognition</em>, 240: 105583.</li>

<li>Marr, D., 1982. <em>Vision: A Computational Investigation into the
Human Representation and Processing of Visual
Information,</em>&nbsp;Cambridge, MA: MIT Press.</li>

<li>Marslen-Wilson, W. and Tyler, L. K., 1987. Against modularity. In
J. L. Garfield (ed.), <em>Modularity in Knowledge Representation and
Natural-Language Understanding</em>, Cambridge, MA: MIT Press.</li>

<li>McCauley, R. N. and Henrich, J., 2006. Susceptibility to the
M&uuml;ller-Lyer illusion, theory-neutral observation, and the
diachronic penetrability of the visual input system. <em>Philosophical
Psychology</em>, 19: 79&ndash;101.</li>

<li>McGurk, H. and Macdonald, J., 1976. Hearing lips and seeing
voices. <em>Nature</em>, 391: 756.</li>

<li>Mylopoulos, M., 2021. The modularity of the motor system.
<em>Philosophical Explorations</em>, 24: 376&ndash;393.</li>

<li>Phillips, B., 2017. The shifting border between perception and
cognition. <em>No&ucirc;s</em>, 53: 316&ndash;346.</li>

<li>Pietraszewski, D. and Wertz, A. E., 2022. Why evolutionary
psychology should abandon modularity. <em>Perspectives on
Psychological Science</em>, 17: 465&ndash;490.</li>

<li>Pinker, S., 1997. <em>How the Mind Works</em>, New York, NY: W. W.
Norton &amp; Company.</li>

<li>Prinz, J. J., 2006. Is the mind really modular? In R. Stainton
(ed.), <em>Contemporary Debates in Cognitive Science</em>, Oxford, UK:
Blackwell, pp. 22&ndash;36.</li>

<li>Pylyshyn, Z., 1984. <em>Computation and Cognition</em>, Cambridge,
MA: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 1999. Is vision continuous with cognition?
The case for cognitive penetrability of vision. <em>Behavioral and
Brain Sciences</em>, 22: 341&ndash;423.</li>

<li>Quilty-Dunn, J., 2020. Attention and encapsulation. <em>Mind &amp;
Language</em>, 35: 335&ndash;349.</li>

<li>Rabaglia, C. D., Marcus, G. F., and Lane, S. P., 2011. What can
individual differences tell us about the specialization of function?
<em>Cognitive Neuropsychology</em>, 28: 288&ndash;303.</li>

<li>Ramus, F., 2006. Genes, brain, and cognition: A roadmap for the
cognitive scientist. <em>Cognition</em>, 101: 247&ndash;269.</li>

<li>Reader, S. M., Hager, Y., and Laland, K. N., 2011. The evolution
of primate general and cultural intelligence. <em>Philosophical
Transactions of the Royal Society B: Biological Sciences</em>, 366:
1017&ndash;1027.</li>

<li>Rice, C., 2011. Massive modularity, content integration, and
language. <em>Philosophy of Science</em>, 78: 800&ndash;812.</li>

<li>Robbins, P., 2002. What domain integration could not be.
<em>Behavioral and Brain Sciences</em>, 25: 696&ndash;697.</li>

<li>&ndash;&ndash;&ndash;, 2007. Minimalism and modularity. In G.
Preyer and G. Peter, eds., <em>Context-Sensitivity and Semantic
Minimalism</em>, Oxford, UK: Oxford University Press, pp.
303&ndash;319.</li>

<li>&ndash;&ndash;&ndash;, 2013. Modularity and mental architecture.
<em>WIREs Cognitive Science</em>, 4: 641&ndash;649.</li>

<li>Rosch, E., Mervis, C., Gray, W., Johnson, D., and Boyes-Braem, P.
(1976). Basic objects in natural categories. <em>Cognitive
Psychology</em>, 8: 382&ndash;439.</li>

<li>Samuels, R., 2000. Massively modular minds: Evolutionary
psychology and cognitive architecture. In P. Carruthers and A.
Chamberlain, eds., <em>Evolution and the Human Mind</em>, Cambridge,
UK: Cambridge University Press, pp. 13&ndash;46.</li>

<li>&ndash;&ndash;&ndash;, 2005. The complexity of cognition:
Tractability arguments for massive modularity. In P. Carruthers, S.
Laurence, and S. Stich, eds., <em>The Innate Mind: Structure and
Contents</em>, Oxford, UK: Oxford University Press, pp.
107&ndash;121.</li>

<li>Scholl, B. J. and Leslie, A. M., 1999. Modularity, development and
&lsquo;theory of mind&rsquo;. <em>Mind &amp; Language</em>, 14:
131&ndash;153.</li>

<li>Shevlin, H. and Friesen, P., 2021. Pain, placebo, and cognitive
penetration. <em>Mind &amp; Language</em>, 36: 771&ndash;797.</li>

<li>Skrzypulec, B., 2023. Pain: Modularity and cognitive constitution.
<em>British Journal for the Philosophy of Science</em>, 727001.</li>

<li>Segal, G., 1996. The modularity of theory of mind. In P.
Carruthers and P. K. Smith, eds., <em>Theories of Theories of
Mind</em>, Cambridge, UK: Cambridge University Press, pp.
141&ndash;157.</li>

<li>Segall, M., Campbell, D. and Herskovits, M. J., 1966. <em>The
Influence of Culture on Visual Perception</em>, New York:
Bobbs-Merrill.</li>

<li>Shams, L., Kamitani, Y., and Shimojo, S., 2000. Illusions: What
you see is what you hear. <em>Nature</em>, 408: 788.</li>

<li>Shea, N., 2014. Distinguishing top-down from bottom-up effects. In
D. Stokes, M. Matthen, and S. Biggs (eds.), <em>Perception and Its
Modalities,</em> New York, NY: Oxford University Press, pp.
73&ndash;91.</li>

<li>Siegel, S., 2012. Cognitive penetrability and perceptual
justification. <em>Nous</em>, 46: 201&ndash;222.</li>

<li>Spelke, E., 1994. Initial knowledge: Six suggestions.
<em>Cognition</em>, 50: 435&ndash;445.</li>

<li>Sperber, D., 1994. The modularity of thought and the epidemiology
of representations. In L. A. Hirschfeld and S. A. Gelman (eds.),
<em>Mapping the Mind</em>, Cambridge, UK: Cambridge University Press,
pp. 39&ndash;67.</li>

<li>&ndash;&ndash;&ndash;, 2002. In defense of massive modularity. In
I. Dupoux (ed.), <em>Language, Brain, and Cognitive Development</em>,
Cambridge, MA: MIT Press, pp. 47&ndash;57.</li>

<li>Sperber, D. and Wilson, D., 2002. Pragmatics, modularity and
mind-reading. <em>Mind &amp; Language</em>, 17: 3&ndash;23.</li>

<li>Stokes, D., 2012. Perceiving and desiring: A new look at the
cognitive penetrability of experience. <em>Philosophical Studies</em>,
158: 479&ndash;492.</li>

<li>&ndash;&ndash;&ndash;, 2013. Cognitive penetrability of
perception. <em>Philosophy Compass</em>, 8: 646&ndash;663.</li>

<li>&ndash;&ndash;&ndash;, 2021. <em>Thinking and Perceiving: On the
Malleability of the Mind</em>. London, UK: Routledge.</li>

<li>Stokes, D. and Bergeron, V., 2015. Modular architectures and
informational encapsulation: A dilemma. <em>European Journal for the
Philosophy of Science</em>, 5: 315&ndash;338.</li>

<li>Stone, V. E., Cosmides, L., Tooby, J., Kroll, N., and Knight, R.
T., 2002. Selective impairment of reasoning about social exchange in a
patient with bilateral limbic system damage. <em>Proceedings of the
National Academy of Sciences</em>, 99: 11531&ndash;11536.</li>

<li>Stromswold, K., 1999. Cognitive and neural aspects of language
acquisition. In E. Lepore and Z. Pylyshyn, eds., <em>What Is Cognitive
Science?</em>, Oxford, UK: Blackwell, pp. 356&ndash;400.</li>

<li>Sugiyama, L. S., Tooby, J., and Cosmides, L., 2002. Cross-cultural
evidence of cognitive adaptations for social exchange among the
Shiwiar of Ecuadorian Amazonia. <em>Proceedings of the National
Academy of Sciences</em>, 99: 11537&ndash;11542.</li>

<li>Tettamanti, M. and Weniger, D., 2006. Broca&rsquo;s area: A
supramodal hierarchical processor? <em>Cortex</em>, 42:
491&ndash;494.</li>

<li>Vance, J. and Stokes, D., 2017. Noise, uncertainty, and interest:
Predictive coding and cognitive penetration. <em>Consciousness and
Cognition</em>, 47: 86&ndash;98.</li>

<li>Vetter, P. and Newen, A., 2014. Varieties of cognitive penetration
in visual perception. <em>Consciousness and Cognition</em>, 27:
62&ndash;75.</li>

<li>Villena, D., 2023. Massive modularity: An ontological hypothesis
or an adaptationist discovery heuristic? <em>International Studies in
the Philosophy of Science</em>, 36: 317&ndash;334.</li>

<li>Warren, R. M., 1970. Perceptual restoration of missing speech
sounds. <em>Science</em>, 167: 392&ndash;393.</li>

<li>Warren, R. M. and Warren, R. P., 1970. Auditory illusions and
confusions. <em>Scientific American</em>, 223: 30&ndash;36.</li>

<li>Watzl, S., Sundberg, K., and Nes, A., 2021. The
perception/cognition distinction. <em>Inquiry</em>, 66:
165&ndash;195.</li>

<li>Wilson, R. A., 2008. The drink you&rsquo;re having when
you&rsquo;re not having a drink. <em>Mind &amp; Language</em>, 23:
273&ndash;283.</li>

<li>Witt, J. K., Linkenauger, S. A., Bakdash, J. Z. and Proffitt, D.
R., 2008. Putting to a bigger hole: Golf performance relates to
perceived size. <em>Psychonomic Bulletin and Review</em>, 15:
581&ndash;585.</li>

<li>Witt, J. K., Proffitt, D. R. and Epstein, W., 2004. Perceiving
distances: A role of effort and intent. <em>Perception</em>, 33:
577&ndash;590.</li>

<li>Woods, A. J., Philbeck, J. W., and Danoff, J. V., 2009. The
various perceptions of distance: An alternative view of how effort
affects distance judgments. <em>Journal of Experimental Psychology:
Human Perception and Performance</em>, 35: 1104&ndash;1117.</li>

<li>Woodward, J. F. and Cowie, F., 2004. The mind is not (just) a
system of modules shaped (just) by natural selection. In C. Hitchcock,
ed., <em>Contemporary Debates in Philosophy of Science</em>, Malden,
MA: Blackwell, pp. 312&ndash;334.</li>

<li>Zerilli, J., 2017. Against the &ldquo;system&rdquo; module.
<em>Philosophical Psychology</em>, 30: 235&ndash;250.</li>

<li>&ndash;&ndash;&ndash;, 2020. <em>The Adaptable Mind: What
Neuroplasticity and Neural Reuse Tell Us About Language and
Cognition</em>. New York, NY: Oxford University Press.</li>
</ul>
</div> 

<div id="academic-tools">
<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=modularity-mind" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/modularity-mind/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=modularity-mind&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="https://philpapers.org/sep/modularity-mind/" target="other">Enhanced bibliography for this entry</a>
at <a href="https://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>
</div>

<div id="other-internet-resources">

<h2 id="Oth">Other Internet Resources</h2>

<ul>

 <li><a href="https://philpapers.org/browse/modularity-in-cognitive-science" target="other">Modularity in Cognitive Science</a>,
 bibliography category at philpapers.org.</li>

 <li><a href="http://gral.ip.rm.cnr.it/rcalabretta/modularity.html" target="other">The Modularity Home Page</a>,
 maintained by Raffaele Calabretta (Institute of Cognitive Sciences
and Technologies, Italian National Research Council).</li>
</ul>
</div>

<div id="related-entries">

<h2 id="Rel">Related Entries</h2>

<p>

 <a href="../cognitive-science/">cognitive science</a> |
 <a href="../innateness-cognition/">innateness: and contemporary theories of cognition</a> |
 <a href="../computational-mind/">mind: computational theory of</a> |
 <a href="../neuroscience/">neuroscience, philosophy of</a> |
 <a href="../perception-justification/">perception: experience and justification</a> |
 <a href="../evolutionary-psychology/">psychology: evolutionary</a>
</p>
</div> 
</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2025</a> by

<br />
<a href="http://philosophy.missouri.edu/index.php/people/15-/40-philip-robbins" target="other">Philip Robbins</a>
&lt;<a href="m&#97;ilto:robbinsp&#37;40missouri&#37;2eedu"><em>robbinsp<abbr title=" at ">&#64;</abbr>missouri<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;<br />
Zoe Drayson
&lt;<a href="m&#97;ilto:zdrayson&#37;40ucdavis&#37;2eedu"><em>zdrayson<abbr title=" at ">&#64;</abbr>ucdavis<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
            <li role="menuitem"><a href="../../new.html">What's New</a></li>
            <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li role="menuitem"><a href="../../published.html">Chronological</a></li>
            <li role="menuitem"><a href="../../archives/">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
            <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
            <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
            <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
            <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
            <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
            <li role="menuitem"><a href="../../accessibility.html">Accessibility</a></li>
            <li role="menuitem"><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
            <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
            <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2025</a> by <a href="https://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>
</html>
