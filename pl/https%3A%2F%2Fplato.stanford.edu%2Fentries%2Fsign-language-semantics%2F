<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html lang="en"> <!-- <![endif]-->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Sign Language Semantics (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Sign Language Semantics" />
<meta property="citation_author" content="Schlenker, Philippe" />
<meta property="citation_author" content="Kuhn, Jeremy" />
<meta property="citation_author" content="Lamberton, Jonathan" />
<meta property="citation_publication_date" content="2024/09/09" />
<meta name="DC.title" content="Sign Language Semantics" />
<meta name="DC.creator" content="Schlenker, Philippe" />
<meta name="DC.creator" content="Kuhn, Jeremy" />
<meta name="DC.creator" content="Lamberton, Jonathan" />
<meta name="DCTERMS.issued" content="2024-09-09" />
<meta name="DCTERMS.modified" content="2024-09-09" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP home page" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
                    <li role="menuitem"><a href="../../new.html">What's New</a></li>
                    <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li role="menuitem"><a href="../../published.html">Chronological</a></li>
                    <li role="menuitem"><a href="../../archives/">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
                    <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
                    <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
                    <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
                    <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
                    <li role="menuitem"><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
                    <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
                    <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="../../search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit" aria-label="search"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/sign-language-semantics/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=sign-language-semantics">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Sign Language Semantics</h1><div id="pubinfo"><em>First published Mon Sep 9, 2024</em></div>

<div id="preamble">

<p>
Sign languages (in the plural: there are many) arise naturally as soon
as groups of deaf people have to communicate with each other. Sign
languages became institutionally established starting in the late
eighteenth century, when schools using sign languages were founded in
France, and spread across different countries, gradually leading to a
golden age of Deaf culture (we capitalize <em>Deaf</em> when talking
about members of a cultural group, and use <em>deaf</em> for the
audiological status). This came to a partial halt in 1880, when the
Milan Congress declared that oral education was superior to sign
language education (Lane 1984)&mdash;a view that is amply refuted by
research (Napoli et al. 2015). While sign languages continued to be
used in Deaf education in some countries (e.g., the United States), it
was only in the 1970s that a Deaf Awakening gave renewed prominence to
sign languages in the western world (see Lane 1984 for a broader
history).</p>

<p>
Besides their essential role in Deaf culture and education, sign
languages have a key role to play for linguistics in general and for
semantics in particular. Despite earlier misconceptions that denied
them the status of full-fledged languages, their grammar, their
expressive possibilities, and their brain implementation are overall
strikingly similar to those of spoken languages (Sandler &amp;
Lillo-Martin 2006; MacSweeney et al. 2008). In other words, human
language exists in two modalities, signed and spoken, and any general
theory must account for both, a view that is accepted in all areas of
linguistics.</p>

<p>
Cross-linguistic semantics is thus naturally concerned with sign
languages. In addition, sign languages (or &lsquo;sign&rsquo; for
short) raise several foundational questions. These include cases of
&lsquo;Logical Visibility&rsquo;, cases of iconicity, and the
potential universal accessibility of certain properties of the sign
modality.</p>

<p>
Historically, a number of notable early works in sign language
semantics have taken a similar argumentative form, proposing that
certain key components of Logical Forms that are covert in speech
sometimes have an overt reflex in sign (&lsquo;Logical
Visibility&rsquo;). Such arguments have been formulated for diverse
phenomena such as variables, context shift, and telicity. Their
semantic import is clear: if a logical element is indeed overtly
realized, it has ramifications for the inventory of the logical
vocabulary of human language, and indirectly for the types of entities
that must be postulated in semantic models (&lsquo;natural language
ontology&rsquo;, Moltmann 2017). Moreover, when a given element has an
overt reflex, one can directly manipulate it in order to investigate
its interaction with other parts of the grammar.</p>

<p>
Arguments based on Logical Visibility are certainly not unique to sign
language (e.g., see for instance Matthewson 2001 and Cable 2011 (see
Other Internet Resources) for the importance of semantic fieldwork for
spoken languages), nor do they entail that sign languages as a class
will make visible the same set of logical elements. Nevertheless, a
notable finding from cross-linguistic work on sign languages is that a
number of the logical elements implicated in these discussions do
indeed appear with a similar morphological expression across a large
number of historically unrelated sign languages. Such observations
invite deeper speculation about what it is about the signed modality
that makes certain logical elements likely to appear in a given
form.</p>

<p>
A second thread of semantically-relevant research relates to the
observation that sign languages make rich use of iconicity (Liddell
2003; Taub 2001; Cuxac &amp; Sallandre 2007), the property by which a
symbol resembles its denotation by preserving some its structural
properties. Sign language iconicity raises three foundational
questions. First, some of the same semantic elements that are
implicated in arguments for Logical Visibility turn out to be employed
and manipulated in the expression of concrete or abstract iconic
relations (e.g., pictorial uses of individual-denoting expressions;
scalar structure; mereological structure), thus suggesting that
logical and iconic notions are intertwined at the core of sign
language. Second, sign languages have designated conventional words
(&lsquo;classifier predicates&rsquo;) whose position or movement must
be interpreted iconically; this calls for an integration of techniques
from pictorial semantics into natural language semantics (Schlenker
2018a; Schlenker &amp; Lamberton forthcoming). Finally, this high
degree of iconicity raises questions about the comparison between
speech and sign, with the possibility that, along iconic dimensions,
the latter is expressively richer (Goldin-Meadow &amp; Brentari 2017;
Schlenker 2018a).</p>

<p>
Possibly due in part to the above factors, sign languages&mdash;even
when historically unrelated&mdash;behave as a coherent language
family, with several semantic properties in common that are not
generally shared with spoken languages (Sandler &amp; Lillo-Martin
2006). Furthermore, some of these properties occasionally seem to be
&lsquo;known&rsquo; by individuals that do not have access to sign
language; these include hearing non-signers and also deaf homesigners
(i.e., deaf individuals that are not in contact with a Deaf community
and thus have to invent signs to communicate with their hearing
environment). Explaining this convergence is a key theoretical
challenge.</p>

<p>
Besides semantics proper, sign raises important questions for the
analysis of information structure, notably topic and focus. These are
often realized by way of facial articulators, including raised
eyebrows, which have sometimes been taken to play the same role as
some intonational properties of speech (e.g., Dachkovsky &amp; Sandler
2009). For reasons of space, we leave these issues aside in what
follows.</p>
</div> 

<div id="toc">
<!--Entry Contents-->
<ul>
 <li><a href="#LogiVisiILoci">1. Logical Visibility I: Loci</a>
<ul>
 <li><a href="#LociVisiVari">1.1 Loci as visible variables?</a></li>
 <li><a href="#TimeWorlDenoLoci">1.2 Time and world-denoting loci</a></li>
 <li><a href="#DegrDenoLoci">1.3 Degree-denoting loci</a></li>
 </ul></li>
 <li><a href="#LogiVisiIIBeyoLoci">2. Logical Visibility II: Beyond Loci</a>
<ul>
 <li><a href="#Teli">2.1 Telicity</a></li>
 <li><a href="#ContShif">2.2 Context shift</a></li>
 </ul></li>
 <li><a href="#IconIOptiIconModu">3. Iconicity I: Optional Iconic Modulations</a>
<ul>
 <li><a href="#IconModu">3.1 Iconic modulations</a></li>
 <li><a href="#EvenStru">3.2 Event structure</a></li>
 <li><a href="#PlurPlur">3.3 Plurals and pluractionals</a></li>
 <li><a href="#IconLoci">3.4 Iconic loci</a></li>
 </ul></li>
 <li><a href="#IconIIClasPred">4. Iconicity II: Classifier Predicates</a>
<ul>
 <li><a href="#DemoAnalClasPred">4.1 The demonstrative analysis of classifier predicates</a></li>
 <li><a href="#PictAnalClasPred">4.2 The pictorial analysis of classifier predicates</a></li>
 <li><a href="#CompRefi">4.3 Comparison and refinements</a></li>
 </ul></li>
 <li><a href="#SignIconVersSpeeGest">5. Sign with Iconicity versus Speech with Gestures</a>
<ul>
 <li><a href="#ReinGestSignComp">5.1 Reintegrating gestures in the sign/speech comparison</a></li>
 <li><a href="#TypoIconContSpeeSign">5.2 Typology of iconic contributions in speech and in sign</a></li>
 <li><a href="#ClasPredProSpeeGest">5.3 Classifier predicates and pro-speech gestures</a></li>
 </ul></li>
 <li><a href="#UnivPropSignModa">6. Universal Properties of the Signed Modality</a>
<ul>
 <li><a href="#SignLangTypoSignLangEmer">6.1 Sign language typology and sign language emergence</a></li>
 <li><a href="#SignLangGramGestGram">6.2 Sign language grammar and gestural grammar</a></li>
 <li><a href="#WhyConv">6.3 Why convergence?</a></li>
 </ul></li>
 <li><a href="#N7FutuIssu"> 7. Future Issues</a></li>
 <li><a href="#Bib">Bibliography</a></li>
 <li><a href="#Aca">Academic Tools</a></li>
 <li><a href="#Oth">Other Internet Resources</a></li>
 <li><a href="#Rel">Related Entries</a></li>
 </ul>

<!--Entry Contents-->
<hr />

</div>

<div id="main-text">

<h2 id="LogiVisiILoci">1. Logical Visibility I: Loci</h2>

<p>
In several cases of foundational interest, sign languages don&rsquo;t
just have the same types of Logical Forms as spoken languages; they
may make overt key parts of the logical vocabulary that are usually
covert in spoken language. These have been called instances of
&lsquo;Logical Visibility&rsquo; (Schlenker 2018a; following the
literature, we use the term &lsquo;logical&rsquo; loosely, to refer to
primitive distinctions that play a key role in a semantic
analysis).</p>

<dl class="sentag tag2em">
<dt>(1)</dt>
<dd> <strong>Hypothesis: Logical Visibility</strong>
<br />
Sign languages can make overt parts of the logical/grammatical
vocabulary which (i) have been posited in the analysis of the Logical
Form of spoken language sentences, but (ii) are not morphologically
realized in spoken languages.</dd>
</dl>

<p>
Claims of Logical Visibility have been made for logical variables
associated with syntactic indices (Lillo-Martin &amp; Klima 1990;
Schlenker 2018a), for context shift operators (Quer 2005, 2013;
Schlenker 2018a), and for verbal morphemes relevant to telicity
(Wilbur 2003, 2008; Wilbur &amp; Malaia 2008). In each case, the claim
of Logical Visibility has been debated, and many questions remain
open.</p>

<p>
In this section, we discuss cases in which logical variables of
different types have been argued to sometimes be overt in sign&mdash;a
claim that has consequences of foundational interest for semantics; we
will discuss further potential cases of Logical Visibility in the next
section.</p>

<p>
In English and other languages, sentences such as
 <a href="#ex2a">(2a)</a>
 and
 <a href="#ex3a">(3a)</a>
 can be read in three ways (see
 <a href="#ex2b">(2b)</a>&ndash;<a href="#ex3b">(3b)</a>),
 depending on whether the embedded pronoun is understood to depend on
the subject, on the object, or to refer to some third person. </p>

<dl class="sentag tag2em">
<dt id="ex2">(2)</dt>
<dd>

<dl class="sentag tag15em">
<dt id="ex2a">a.</dt>
<dd> Sarkozy<sub><i>i</i></sub> told Obama<sub><i>k</i></sub> that
he<sub><i>i/k/m</i></sub> would be re-elected.</dd>
<dt id="ex2b">b.</dt>
<dd> Sarkozy \(\lambda i\) Obama \(\lambda k\, t_i\) told \(t_k\) that
he<sub><i>i/k/m</i></sub> would be re-elected.</dd>
</dl> </dd>
<dt id="ex3">(3)</dt>
<dd>

<dl class="sentag tag15em">
<dt id="ex3a">a.</dt>
<dd> [A representative]<sub><i>i</i></sub> told [a
senator]<sub><i>k</i></sub> that he<sub><i>i/k/m</i></sub> would be
re-elected.</dd>
<dt id="ex3b">b.</dt>
<dd> [a representative]<sub><i>i</i></sub> \(\lambda i\) [a
senator]<sub><i>k</i></sub> \(\lambda k\, t_i\) told \(t_k\) that
he<sub><i>i/k/m</i></sub> would be re-elected</dd>
</dl> </dd>
</dl>

<p>
A claim of Logical Visibility relative to variables has been made in
sign because one can introduce a separate position in signing space,
or &lsquo;locus&rsquo; (plural &lsquo;loci&rsquo;), for each of the
antecedents (e.g., Sarkozy on the left and Obama on the right for
 <a href="#ex2">(2)</a>),
 and one can then point towards these loci (towards the left or
towards the right) to realize the pronoun: loci thus mirror the role
of variables in these examples.</p>

<h3 id="LociVisiVari">1.1 Loci as visible variables?</h3>

<p>
Sign languages routinely use loci to represent objects or individuals
one is talking about. Pronouns can be realized by pointing towards
these positions. The signer and addressee are represented in a fixed
position that corresponds to their real one, and similarly for third
persons that are present in the discourse situation: one points at
them to refer to them. But in addition, arbitrary positions can be
created for third persons that are not present in the discourse. The
maximum number of loci that can be simultaneously used seems to be
determined by considerations of performance (e.g., memory) rather than
by rigid grammatical conditions (there are constructed examples with
up to 7 loci in the literature).</p>

<dl class="sentag tag3em">
<dt id="ex04">(4)</dt>
<dd>

<p>
Loci corresponding to the signer (1), the addressee (2), and different
third persons (3a and 3b) (from Pfau, Salzmann, &amp; Steinbach 2018:
Figure 1)</p>

<div class="center" id="ex4">
<img src="image001-s.svg" style="width:12em" alt="signer with a dot labeled (1) faces forward with a dot labeled (2), the addressee, directly in front. Dots labeled (3a) and (3b) are to the front right and front left of the signer." />
</div> </dd>
</dl>

<p>
We focus on the description of loci in American Sign Language (ASL)
and French Sign Language (LSF, for &lsquo;<em>Langue des Signes
Fran&ccedil;aise</em>&rsquo;), but these properties appear in a
similar form across the large majority of sign languages. Singular
pronouns are signed by directing the index finger towards a point in
space; plural pronouns can be signed with a variety of strategies,
including using the index finger to trace a semi-circle around an area
of space, and are typically used to refer to groups of at least three
entities. Other pronouns specify a precise number of participants with
an incorporated numeral (e.g., dual, trial), and move between two or
more points in space. In addition, some verbs, called &lsquo;agreement
verbs&rsquo;, behave as if they contain a pronominal form in their
realization, pertaining to the subject and/or to the object. For
instance, <em>TELL</em> in ASL targets different positions depending
on whether the object is second person
 <a href="#fig5aii">(5a)</a>
 or third person
 <a href="#fig5bii">(5b)</a>.</p>
 
<dl class="sentag tag3em avoid-break">
<dt id="fig5">(5)</dt>
<dd>An object agreement verb in ASL

<div class="figures" id="fig5a">

<div class="inner-fig" id="fig5ai">
<img src="image002.jpg" style="height:12em" alt="start of 'I tell you'. In a human picture, dominant hand's index finger extended and near mouth." />
</div>

<div class="inner-fig" id="fig5aii">
<img src="image003.png" style="height:12em" alt="end of 'I tell you'. the dominant hand with index finger extended, palm up, is pointing to a point in front of the signer." />
</div>

<p class="center">
(a) I tell you.</p>
</div>

<div class="figures" id="fig5b">

<div class="inner-fig" id="fig5bi">
<img src="image004.png" style="height:12em" alt="start of 'I tell him/her'. In a human picture, dominant hand's index finger extended and near mouth." />
</div>

<div class="inner-fig" id="fig5bii">
<img src="image005.png" style="height:12em" alt="end of 'I tell him/her'. the hand with index finger extended, palm up, is pointing to a point to the side of the signer." />
</div>

<p class="center">
(b) I tell him/her </p>
</div> <em>Credits:</em> &copy; Dr. Bill Vicars:
 <a href="https://www.lifeprint.com/asl101/pages-signs/t/tell.htm" target="other">TELL in ASL (description with short video clip, no audio)</a>
 </dd>
</dl>

<p>
Loci often make it possible to disambiguate pronominal reference. For
instance, the ambiguity of the example in
 <a href="#ex2">(2)</a>
 can be removed in LSF, where the sentence comes in two versions. In
both, Sarkozy is assigned a locus on the signer&rsquo;s left (by way
of the index of the left hand held upright, <span class="nobr">&lsquo;&#128070;<sub>left</sub>&rsquo;</span>
below), and
Obama a locus on the right (using the index of the right hand held
upright, <span class="nobr">&lsquo;&#128070;<sub>right</sub>&rsquo;</span>
below).
The verb <em>tell</em> in <em>he (Sarkozy) tells him (Obama)</em> is
realized as a single sign linking the Sarkozy locus on the left to the
Obama locus on the right (unlike the ASL version, which just displays
object agreement, the LSF version displays both subject and object
agreement: &lsquo;<sub>left</sub>TELL<sub>right</sub>&rsquo; indicates
that the sign moves from the Sarkozy locus on the left to the Obama
locus on the right). If <em>he</em> refers to Sarkozy, the signer
points towards the Sarkozy locus on the left <span class="nobr">(&lsquo;&#128073;<sub>left</sub>&rsquo;);</span>
if
<em>he</em> refers to Obama, the signer points towards the Obama locus
on the right <span class="nobr">(&lsquo;&#128073;<sub>right</sub>&rsquo;).</span></p>

<dl class="sentag tag2em">
<dt id="ex6">(6)</dt>
<dd>

<p>
SARKOZY &#128070;<sub>left</sub> OBAMA &#128070;<sub>right</sub>
<sub>left</sub>TELL<sub>right</sub>
<br />
&lsquo;Sarkozy told Obama&hellip; </p>

<dl class="sentag tag15em">
<dt>a.</dt>
<dd> &#128073;<sub>left</sub> WILL WIN ELECTION.
<br />
that he, Sarkozy, would win the election.&rsquo;</dd>
<dt>b.</dt>
<dd>&#128073;<sub>right</sub> WILL WIN ELECTION.
<br />
that he, Obama, would win the election.&rsquo;</dd>
</dl>

<p>

 <a href="https://youtu.be/4u8GoVjvn4g" target="other">Short video clip of the sentence, no audio</a>
 </p> </dd>
</dl>

<p>
In sign language linguistics, signs are transcribed in capital
letters, as was the case above, and loci are encoded by way of letters
(<i>a</i>, <i>b</i>, <i>c</i>, &hellip;), starting from the
signer&rsquo;s dominant side (right for a right-handed signer, left
for a left-handed signer). The upward fingers used to establish
positions for Sarkozy and Obama are called &lsquo;classifiers&rsquo;
and are glossed here as <em>CL</em> (with the conventions of
 <a href="#PictAnalClasPred">Section 4.2</a>.
 the gloss would be <em>PERSON-cl</em>; classifiers are just one way
to establish the position of antecedents, and they are not essential
here). Pronouns involving pointing with the index finger are glossed
as <em>IX</em>. With these conventions, the sentence in
 <a href="#ex6">(6)</a>
 can be represented as in
 <a href="#ex7">(7)</a>.
 (Examples are followed by the name of the language, as well as the
reference of the relevant video when present in the original source;
thus &lsquo;LSF 4, 235&rsquo; indicates that the sentence is from LSF,
and can be found in the video referenced as 4, 235.) </p>

<dl class="sentag tag2em">
<dt id="ex7">(7)</dt>
<dd> SARKOZY CL<sub><i>b</i></sub> OBAMA CL<sub><i>a</i></sub>
<i>b</i>-TELL-<i>a</i> {IX-<i>b</i> / IX-<i>a</i>} WILL WIN ELECTION.
<br />
&lsquo;Sarkozy told Obama that he, {Sarkozy/Obama}, would win the
election.&rsquo; (LSF 4, 235)</dd>
</dl>

<p>
The ambiguity of quantified sentences such as
 <a href="#ex3">(3)</a>
 can also be removed in sign, as illustrated in an LSF sentence in
 <a href="#ex8">(8)</a>.</p>
 
<dl class="sentag tag2em">
<dt id="ex8">(8)</dt>
<dd> DEPUTY<sub><i>b</i></sub> SENATOR<sub><i>a</i></sub>
CL<sub><i>b</i></sub>-CL<sub><i>a</i></sub> IX-<i>b</i>
<i>a</i>-TELL-<i>b</i> {IX-<i>a</i> / IX-<i>b</i>} WIN ELECTION
<br />
&lsquo;An MP<sub><i>b</i></sub> told a senator<sub><i>a</i></sub> that
he<sub><i>a</i></sub> / he<sub><i>b</i></sub> (= the deputy) would win
the election.&rsquo; (LSF 4, 233)</dd>
</dl>

<p>
In light of these data, the claim of Logical Visibility is that sign
language loci (when used&mdash;for they need not be) are an overt
realization of logical variables.</p>

<p>
One potential objection is that pointing in sign might be very
different from pronouns in speech: after all, one points when
speaking, but pointing gestures are not pronouns. However this
objection has little plausibility in view of formal constraints that
are shared between pointing signs and spoken language pronouns. For
example, pronouns in speech are known to follow grammatical
constraints that determine which terms can be used in which
environments (e.g., the non-reflexive pronoun <em>her</em> when the
antecedent is &lsquo;far enough&rsquo; vs. the reflexive pronoun
<em>herself</em> when the antecedent is &lsquo;close enough&rsquo;).
Pointing signs obey similar rules, and enter into an established
typology of cross-linguistic variation. For instance, the ASL
reflexive displays the same kinds of constraints as the Mandarin
reflexive pronoun in terms of what counts as &lsquo;close
enough&rsquo; (see Wilbur 1996; Koulidobrova 2009; Kuhn 2021).</p>

<p>
It is thus generally agreed that pronouns in sign are part of the same
abstract system as pronouns in speech. It is also apparent that loci
play a similar function to logical variables, disambiguating
antecedents and tracking reference. This being said, the claim that
loci are a direct morphological spell-out of logical variables
requires a more systematic evaluation of the extent to which sign
language loci have the formal properties of logical variables. As a
concrete counterpoint, one observes that gender features in English
<em>also</em> play a similar function, disambiguating antecedents and
tracking reference. For instance, <em>Joe Biden told Kamala Harris
that he would be elected</em> has a rather unambiguous reading
(<em>he</em> = <em>Biden),</em> while <em>Joe Biden told Kamala Harris
that she would be elected</em> has a different one (<em>she</em> =
<em>Harris</em>). Such parallels have led some linguists to propose
that loci should best be viewed as grammatical features akin to gender
features (Neidle et al. 2000; Kuhn 2016).</p>

<p>
As it turns out, sign language loci seem to share some properties with
logical variables, and some properties with grammatical features. On
the one hand, the flexibility with which loci can be used seems closer
to the nature of logical variables than to grammatical features.
First, gender features are normally drawn from a finite inventory,
whereas there seems to be no upper bound to the number of loci used
except for reasons of performance. Second, gender features have a
fixed form, whereas loci can be created &lsquo;on the fly&rsquo; in
various parts of signing space. On the other hand, loci may sometimes
be disregarded in ways that resemble gender features. A large part of
the debate has focused on sign language versions of sentences such as:
<em> Only Ann did her homework</em>. This has a salient (&lsquo;bound
variable&rsquo;) reading that entails that <em>Bill didn&rsquo;t do
<strong>his</strong> homework</em>. In order to derive this reading,
linguists have proposed that the gender features of the pronoun
<em>her</em> must be disregarded, possibly because they are the result
of grammatical agreement. Loci can be disregarded in the very same
kind of context, suggesting that they are features, not logical
variables (Kuhn 2016). In light of this theoretical tension, a
possible synthesis is that loci are a visible realization of logical
variables, but mediated by a featural level (Schlenker 2018a). The
debate continues to be relatively open. </p>

<p>
While there has been much theoretical interest in cases in which
reference is disambiguated by loci, this is usually an option, not an
obligation. In ASL, for instance, it is often possible to realize
pronouns by pointing towards a neutral locus that need not be
introduced explicitly by nominal antecedents, and in fact several
antecedents can be associated with this default locus. This gives rise
to instances of referential ambiguity that are similar to those found
in English in (2)&ndash;(3) above (see Frederiksen &amp; Mayberry
2022; for an account that treats loci as corresponding to entire
regions of signing space, and also allows for sign language pronouns
without locus specification, see Steinbach &amp; Onea 2016).</p>

<h3 id="TimeWorlDenoLoci">1.2 Time and world-denoting loci</h3>

<p>
Regardless of implementation, the flexible nature of sign language
loci allows one to revisit foundational questions about anaphora and
reference.</p>

<p>
In the analysis of temporal and modal constructions in speech, there
are two broad directions. One goes back to quantified tense logic and
modal logic, and takes temporal and modal expressions of natural
language to be fundamentally different from individual-denoting
expressions: the latter involve the full power of variables and
quantifiers, whereas no variables exist in the temporal and modal
domain, although operators manipulate implicit parameters. The
opposite view is that natural language has in essence the same logical
vocabulary across the individual, the temporal and the modal domains,
with variables (which may take different forms across different
domains) and quantifiers that may bind them (see for instance von
Stechow 2004). This second tradition was forcefully articulated by
Partee (1973) for tense and Stone (1997) for mood. Partee&rsquo;s and
Stone&rsquo;s argument was in essence that tense and mood have
virtually all the uses that pronouns do. This suggests,
theory-neutrally, that pronouns, tenses and moods have a common
semantic core. With the additional assumption that pronouns should be
associated with variables, this suggests that tenses and moods should
be associated with variables as well, perhaps with time- and
world-denoting variables, or with a more general category of
situation-denoting variables.</p>

<p>
As an example, pronouns can have a deictic reading on which they refer
to salient entities in the context; if a person sitting alone with
their head in their hands utters: <em>She left me</em>, one will
understand that <em>she</em> refers to the person&rsquo;s former
partner. Partee argued that tense has deictic uses too. For instance,
if an elderly author looks at a picture selected by their publisher
for a forthcoming book, and says: <em>I wasn&rsquo;t young</em>, one
will understand that the author wasn&rsquo;t young <em>when the
picture was taken</em>. Stone similarly argued that mood can have
deictic readings, as in the case of someone who, while looking at a
high-end stereo in a store, says: <em>My neighbors would kill me</em>.
The interpretation is that the speaker&rsquo;s neighbors would
(metaphorically) kill them &ldquo;if the speaker bought the stereo and
played it a &lsquo;satisfying&rsquo; volume&rdquo;, in Stone&rsquo;s
words. A wide variety of other uses of pronouns can similarly be
replicated with tense and mood, such as cross-sentential binding with
indefinite antecedents. (In the individual domain: <em>A woman will go
to Mars. She [=the woman who goes to Mars] will be famous</em>. In the
temporal domain: <em>I sometimes go to China. I eat Peking duck [=in
the situations in which I visit China]</em>.)</p>

<p>
While strong, these arguments are indirect because the <em>form</em>
of tense and mood looks nothing like pronouns. In several sign
languages, including at least ASL (Schlenker 2018a) and Chinese Sign
Language (Lin et al. 2021), loci provide a more direct argument
because in carefully constructed examples, pointing to loci can be
used not just to refer to individuals, but also to temporal and modal
situations, with a meaning akin to that of the word <em>then</em> in
English. It follows that the logical system underlying the ASL
pronominal system (e.g., as variables) extends to temporal and modal
situations.</p>

<p>
A temporal example appears in
 <a href="#ex9">(9)</a>.
 In the first sentence, <em>SOMETIMES WIN</em> is signed in a locus
<i>a</i>. In the second sentence, the pointing sign <em>IX-a</em>
refers back to the situations in which I win. The resulting meaning is
that I am happy <em>in those situations in which I win</em>, not in
general; this corresponds to the reading obtained with the word
<em>then</em> in English: &lsquo;then I am happy&rsquo;. (Here and
below, &lsquo;re&rsquo; glosses raised eyebrows, with a line above the
words over which eyebrow raising occurs.)</p>

<dl class="sentag tag2em">
<dt id="ex9">(9)</dt>
<dd>

<p>
<em>Context:</em> Every week I play in a lottery.</p> IX-1 [SOMETIMES
WIN]<sub><i>a</i></sub>. IX-<i>a</i><sup>re</sup> IX-1 HAPPY.
<br />
&lsquo;Sometimes I win. Then I am happy.&rsquo; (ASL 7, 202) </dd>
</dl>

<p>
Formally, <em>SOMETIMES</em> can be seen as an existential quantifier
over temporal situations, so the first sentence is semantically
existential: <em>there are situations in which I win</em>. The
pointing sign thus displays cross-sentential anaphora, depending on a
temporal existential quantifier that appears in a preceding sentence.
A further point made by Chinese Sign Language (but not by the ASL
example above) is that loci may be ordered on a temporal line, with
the result that not just the loci but also their ordering can be made
visible (Lin et al. 2021). </p>

<p>
A related argument can be made about anaphoric reference to modal
situations: in
 <a href="#ex10">(10)</a>,
 the second sentence just asserts that there are possible situations
in which I am infected, associating the locus <i>a</i> with situations
of infection. The second sentence makes reference to them: in those
situations (not in general), I have a problem. Here too, the reading
obtained corresponds to a use of the word <em>then</em> in
English.</p>

<dl class="sentag tag2em">
<dt id="ex10">(10)</dt>
<dd> FLU SPREAD. IX-1 POSSIBLE INFECTED<sub><i>a</i></sub>.
IX-<i>a</i><sup>re</sup> IX-1 PROBLEM.
<br />
&lsquo;There was a flu outbreak. I might get infected. Then I have a
problem.&rsquo; (ASL 7, 186) </dd>
</dl>

<p>
In sum, temporal and modal loci make two points. First,
theory-neutrally, the pointing sign can have both the use of English
pronouns and of temporal and modal readings of the word <em>then</em>,
suggesting that a single system of reference underlies individual,
temporal and modal reference. Second, on the assumption that loci are
the overt realization of some logical variables, sign languages
provide a morphological argument for the existence of temporal and
modal variables alongside individual variables.</p>

<h3 id="DegrDenoLoci">1.3 Degree-denoting loci</h3>

<p>
In spoken language semantics, there is a related debate about the
existence of degree-denoting variables. The English sentences <em>Ann
is tall</em> and <em>Ann is taller than Bill</em> (as well as other
gradable constructions) can be analyzed in terms of reference to
degrees, for instance as in
 <a href="#ex11">(11)</a>.</p>
 
<dl class="sentag tag2em">
<dt id="ex11">(11)</dt>
<dd>

<dl class="sentag tag15em">
<dt>a.</dt>
<dd> Ann is tall.
<br />
<em>the maximal degree to which Ann is tall &ge; the threshold for
&lsquo;tall&rsquo;</em></dd>
<dt>b.</dt>
<dd>Ann is taller than Bill.
<br />
<em>the maximal degree to which Ann is tall &ge; the maximal degree to
which Bill is tall</em></dd>
</dl> </dd>
</dl>

<p>
To say that one <em>can</em> analyze the meaning in terms of reference
to degrees doesn&rsquo;t entail that one must (for discussion, see
Klein 1980). And even if one posits quantification over degrees, a
further question is whether natural language has counterparts of
pronouns that refer to degrees&mdash;if so, one would have an argument
that natural language is committed to degrees. Importantly, this
debate is logically independent from that about the existence of time-
and world-denoting pronominals, as one may consistently believe that
there are pronominals in one domain but not in the other. The question
must be asked anew, and here too sign language brings important
insights.</p>

<p>
Degree-denoting pronouns exist in some constructions of Italian Sign
Language (LIS; Aristodemo 2017). In
 <a href="#ex12">(12)</a>,
 the movement of the sign <em>TALL</em> ends at a particular location
on the vertical axis (which we call &alpha;, to avoid confusion with
the Latin characters used for individual loci in the horizontal
plane), which intuitively represents Gianni&rsquo;s degree of height.
In the second sentence, the pronoun points towards this
degree-denoting locus, and the rest of the sentence characterizes this
degree of height.</p>

<dl class="sentag tag3em">
<dt id="ex12">(12)</dt>
<dd>GIANNI TALL\(_{\alpha}\). IX-\(\alpha\) 1 METER 70
<br />
&lsquo;Gianni is tall. His height is 1.70 meters.&rsquo; (Aristodemo
2017: example 2.23)</dd>
</dl>

<p>
More complicated examples can be constructed in which <em>Ann is
taller than Bill</em> makes available two degree-denoting loci, one
corresponding to Ann&rsquo;s height and the other to Bill&rsquo;s.</p>

<p>
In sum, some constructions of LIS provide evidence for the existence
of degree-denoting pronouns in sign language, which in turn suggests
that natural language is sometimes committed to the existence of
degrees. And if one grants that loci are the realization of variables,
one obtains the further conclusion that natural language has at least
some degree-denoting variables. (It is a separate question whether all
languages <em>avail</em> themselves of degree variables; see Beck et
al. 2009 for the hypothesis that this is a parameter of semantic
variation.)</p>

<p>
Finally, we observe that, unlike the examples of individual-denoting
pronouns seen so far, the placement of degree pronouns along a
particular axis is semantically interpreted, reflecting the total
ordering of their denotations: not only are degrees visibly realized,
but so is their ordering (see also
 <a href="#DegrDenoLoci">Section 1.3</a>
 regarding the ordering on temporal loci on timelines in Chinese Sign
Language, and
 <a href="#IconLoci">Section 3.4</a>
 for a discussion of a structural iconicity). </p>

<p>
In sum, loci have been argued to be the overt realization of
individual, time, world, and degree variables. If one grants this
point, it follows that sign language is ontologically committed to
these object types. But the debate is still ongoing, with alternatives
that take loci to be similar to features rather than to variables. Let
us add that the loci-as-variable analysis has offered a new argument
in favor of dynamic semantics, where a variable can depend on a
quantifier without being in its syntactic scope; see the
 <a href="dynamic-loci.html">supplement on Dynamic Loci</a>.</p>
 
<h2 id="LogiVisiIIBeyoLoci">2. Logical Visibility II: Beyond Loci</h2>

<p>
There are further cases in which sign language arguably makes visible
some components of Logical Forms that are not always overt in spoken
language.</p>

<h3 id="Teli">2.1 Telicity</h3>

<p>
Semanticists traditionally classify event descriptions as
<em>telic</em> if they apply to events that have a natural endpoint
determined by that description, and they call them <em>atelic</em>
otherwise. <em>Ann arrived</em> and <em>Mary understood</em> have such
a natural endpoint, e.g., the point at which Ann reached her
destination, and that at which Mary saw the light, so to speak:
<em>arrive</em> and <em>understand</em> are telic. By contrast,
<em>Ann waited</em> and <em>Mary thought</em> lack such natural
endpoints: <em>wait</em> and <em>think</em> are atelic. As a standard
test (e.g., Rothstein 2004), a temporal modifier of the form <em>in X
time</em> modifies telic VPs while <em>for X time</em> modifies atelic
VPs (e.g., <em>Ann arrived in five minutes</em> vs. <em> Ann waited
for five minutes</em>, <em>Mary understood in a second</em> vs.
<em>Mary thought for a second</em>).</p>

<p>
Telicity is a property of predicates (i.e., verbs complete with
arguments and modifiers), not of verbs themselves. Whether a predicate
is telic or atelic may thus result from a variety of different
factors; these include adverbial modifiers that explicitly identify an
endpoint&mdash;<em>run 10 kilometers (in an hour)</em> is telic, but
<em>run back and forth (for an hour)</em> is atelic&mdash;and
properties of the nominal arguments&mdash;<em>eat an apple (in two
minutes)</em> is telic whereas <em>eat lentil soup (for two
minutes)</em> is atelic. But telicity also depends on properties of
the lexical semantics of the verb itself, as illustrated by the
intransitive verbs above, as well as transitive examples like
<em>found a solution (in an hour)</em> versus <em>look for a solution
(for an hour)</em>. In work on spoken language, some theorists have
posited that these lexical factors can be explained by a morphological
decomposition of the verb, and that inherently telic verbs like
<em>arrive</em> or <em>find</em> include a morpheme that specifies the
endstate resulting from a process (Pustejovsky 1991; Ramchand 2008).
This morpheme has been called various things in the literature,
including &lsquo;EndState&rsquo; (Wilbur 2003) and &lsquo;Res&rsquo;
(Ramchand 2008).</p>

<p>
In influential work, Wilbur (2003, 2008; Wilbur &amp; Malaia 2008) has
argued that the lexical factors related to telicity are often realized
overtly in the phonology of several sign languages: inherently telic
verbs tend to be realized with sharp sign boundaries; inherently
atelic verbs are realized without them (Wilbur 2003, 2008; Wilbur
&amp; Malaia 2008). For instance, the ASL sign <em>ARRIVE</em>
involves a sharp deceleration, as one hand makes contact with the
other, as shown in
 <a href="#ex13">(13)</a>.
 </p>

<dl class="sentag tag3em avoid-break">
<dt id="ex13">(13)</dt>
<dd>

<p style="margin-bottom:0">
ARRIVE in ASL (telic)</p>

<div class="center">
<img src="image006-crop.png" style="height:10em" alt="Drawing of a human with the open left hand is at the front lower chest with palm upwards. The open right hand is nearer the right should, palm facing towards the signer. An arrow indicates that the second hand moves down to the front lower chest where it stops when meeting the second hand." />
</div>

<p class="center">

 <a href="https://www.signingsavvy.com/sign/ARRIVE/12/1" target="other">Short video clip of ARRIVE (ASL), no audio </a>
 </p>

<p>
<em>Picture credits:</em> Valli, Clayton: 2005, <em>The Gallaudet
Dictionary of American Sign Language</em>, Gallaudet University
Press.</p> </dd>
</dl>

<p>
In contrast, <em>WAIT</em> is realized with a trilled movement of the
fingers and optional circular movement of the hands, without a sharp
boundary:</p>

<dl class="sentag tag3em">
<dt id="ex14">(14)</dt>
<dd>

<p style="margin-bottom:0">
WAIT in ASL (atelic)</p>

<div class="center">
<img src="image007-crop.png" style="height:10em" alt="both hands are open and in front of the upper chest, not touching, palms facing towards the signer and a symbol indicating the hand are moving " />
</div>

<p class="center">

 <a href="https://www.signingsavvy.com/sign/wait/463/4" target="other">Short video clip of WAIT (ASL), no audio</a>
 </p>

<p>
<em>Picture credits:</em> Valli, Clayton: 2005, <em>The Gallaudet
Dictionary of American Sign Language</em>, Gallaudet University
Press.</p> </dd>
</dl>

<p>
Similarly, in LSF <em>UNDERSTAND</em>, which is telic, is realized
with three fingers forming a tripod that ends up closing on the
forehead; the closure is realized quickly, and thus displays a sharp
boundary. By contrast, <em>REFLECT,</em> which is atelic, is realized
by the repeated movement of the curved index finger towards the
temple, without sharp boundaries.</p>

<dl class="sentag tag2em">
<dt id="ex15">(15)</dt>
<dd>

<dl class="sentag tag15em">
<dt id="ex15a">a.</dt>
<dd> UNDERSTAND (LSF)

<div class="center">
<img src="image008-crop.png" style="height:10em" alt="COMPRENDRE (UNDERSTAND): thumb and first two fingers apart then touch tips as they touch the forehead" />

<p>

 <a href="https://www.elix-lsf.fr/spip.php?page=signes&amp;id_article=146439&amp;lang=fr" target="other">Short video clip of UNDERSTAND (LSF), no audio</a>
 </p>
</div> </dd>
<dt id="ex15b">b.</dt>
<dd> REFLECT (LSF)

<div class="center">
<img src="image009-crop.png" style="height:10em" alt="REFL&Eacute;CHIR (REFLECT): curved index finger touches the forehead " />

<p>

 <a href="https://www.elix-lsf.fr/spip.php?page=signes&amp;id_article=206984&amp;lang=fr" target="other">Short video clip of REFLECT (LSF), no audio</a>
 </p>
</div> </dd>
</dl>

<p>
<em>Credits: La langue des signes - dictionnaire bilingue
LSF-fran&ccedil;ais</em>. IVT 1986</p> </dd>
</dl>

<p>
Wilbur (2008) posits that in ASL and other sign languages, this
phonological cue, the &ldquo;rapid deceleration of the movement to a
complete stop&rdquo;, is an overt manifestation of the morpheme
EndState, yielding inherently telic lexical predicates. If
Wilbur&rsquo;s analysis is correct, this is another possible instance
of visibility of an abstract component of Logical Forms that is not
usually overt in spoken languages. An alternative is that an abstract
version of iconicity is responsible for this observation (Kuhn 2015),
as we will see in
 <a href="#EvenStru">Section 3.2</a>.</p>
 
<p>
It is also possible that the analysis of this phonological cue varies
across languages. Of note, both ASL and LSF have exceptions to the
generalization (Davidson et al. 2019), for example ASL <em>SLEEP</em>
is atelic but ends with deceleration and contact between the fingers;
LSF <em>RESIDE</em> is similarly atelic but ends with deceleration and
contact. In contrast, in Croatian Sign Language (HZJ), endmarking
appears to be a regular morphological process, allowing a verb stem to
alternate between an end-marked and non-endmarked form (Milkovi&#263;
2011).</p>

<h3 id="ContShif">2.2 Context shift</h3>

<p>
In the classic analysis of indexicals developed by Kaplan (1989), the
value of an indexical (words like <em>I</em>, <em>here</em>, and
<em>now</em>) is determined by a context parameter that crucially
doesn&rsquo;t interact with time and world operators (in other words,
the context parameter is not shiftable). The empirical force of this
idea can be illustrated by the distinction between <em>I</em>, an
indexical, and <em>the person speaking</em>, which is indexical-free.
<em>The speaker is always late</em> may, on one reading, refer to
different speakers in different situations because <em>speaker</em>
can be evaluated relative to a time quantified by <em>always</em>.
Similarly, <em>The speaker must be late</em> can be uttered even if
one has no idea who the speaker is supposed to be; this is because
<em>speaker</em> can be evaluated relative to a world quantified by
<em>must</em>. By contrast, <em>I am always late</em> and <em>I must
be late</em> disallow such a dependency because <em>I</em> is
dependent on the context parameter alone, not on time and world
quantification. This analysis raises a question: are there any
operators that can manipulate the context of evaluation of indexicals?
While such operators can be defined for a formal language, Kaplan
famously argued that they do not exist in natural language and called
them, for this reason, &lsquo;monsters&rsquo;.</p>

<p>
Against this claim, an operator of &lsquo;context shift&rsquo; (a
Kaplanian monster) has been argued to exist in several spoken
languages (including Amharic and Zazaki). The key observation was that
some indexicals can be shifted in the scope of some attitude verbs,
and in the absence of quotation (e.g., Anand &amp; Nevins 2004; Anand
2006; Deal 2020). Schematically, in such languages, <em>Ann says that
I am a hero</em> can mean that Ann says that she herself is a hero,
with <em>I</em> interpreted from Ann&rsquo;s perspective. Several
researchers have argued that context shift can be overt in sign
language, and realized by an operation called &lsquo;Role
Shift&rsquo;, whereby the signer rotates her body to adopt the
perspective of another character (Quer 2005, 2013; Schlenker 2018a).
</p>

<p>
A simple example involves the sentence <em>WIFE SAY <strong>IX-2
FINE</strong></em>, where the boldfaced words are signed from the
rotated position, illustrated below. As a result, the rest of the
sentence is interpreted from the wife&rsquo;s perspective, with the
consequence that the second person pronoun <em>IX-2</em> refers to
whoever the wife is talking to, and not the addressee of the signer.
</p>

<dl class="sentag tag3em">
<dt id="ex16">(16)</dt>
<dd>

<p>
An example of Role Shift in ASL (<em>Credits:</em> Lillo-Martin
2012)</p>

<div class="center">
<img src="image011.jpg" alt="four pictures of the signer. The first two for 'WIFE SAY' looking one way then rotating to look another way to sign the last two 'IX-2 FINE'" style="width:100%" />

<p class="center">
WIFE SAY <strong>IX-2 FINE</strong></p>
</div> </dd>
</dl>

<p>
Role Shift exists in several languages, and in some cases (notably in
Catalan and German sign languages [Quer 2005; Herrmann &amp; Steinbach
2012]), it has been argued not to involve mere quotation. On the
context-shifting analysis of Role Shift (e.g., Quer 2005, 2013), the
point at which the signer rotates her body corresponds to the
insertion of a context-shifting operator C, yielding the
representation: WIFE SAY C [<strong>IX-2 FINE</strong>]. The boldfaced
words are signed in rotated position and are taken to be interpreted
in the scope of C.</p>

<p>
Interestingly, Role Shift differs from context-shifting operations
described in speech in that it can be used outside of attitude reports
(to distinguish the two cases, researchers use the term
&lsquo;Attitude Role Shift&rsquo; for the case we discussed before,
and &lsquo;Action Role Shift&rsquo; for the non-attitudinal case). For
example, if one is talking about an angry man who has been established
at locus <i>a</i>, one can use an English-strategy and say <em>IX-a
WALK-AWAY</em> to mean that he walked away. But an alternative
possibility is to apply Role Shift after the initial pointing sign,
and say the following (with the operator <i>C</i> realized by the
signer&rsquo;s rotation):</p>

<dl class="sentag tag3em">
<dt>(17)</dt>
<dd> IX-<i>a</i> C [<strong>1-WALK-AWAY</strong>].</dd>
</dl>

<p>
Here <strong><em>1-WALK-AWAY</em></strong> is a first person version
of &lsquo;walk away&rsquo;, but the overall meaning is just that the
angry person associated with locus <i>a</i> walked away. By performing
a body shift and adopting that person&rsquo;s position to sign
<em>1-WALK-AWAY</em>, the signer arguably makes the description more
vivid.</p>

<p>
Importantly, in ASL and LSF, Role Shift interacts with iconicity.
Attitude Role Shift has, at a minimum, a strong quotational component.
For instance, angry facial expressions under Role Shift must be
attributed to the attitude holder, not to the signer (Schlenker
2018a). This observation extends to ASL and LSF Action Role Shift:
disgusted facial expressions under Action Role Shift are attributed to
the agent rather than to the signer.</p>

<p>
As in other cases of purported Logical Visibility, the claim that Role
Shift is the visible reflex of an operation that is covert in speech
has been challenged. In the analysis of Davidson (2015, following
Supalla 1982), Role Shift falls under the category of classifier
predicates, specific constructions of sign language that are
interpreted in a highly iconic fashion (we discuss them in
 <a href="#IconIIClasPred">Section 4</a>).
 What is special about Role Shift is that the classifier is not signed
with a hand (as other classifiers are), but with the signer&rsquo;s
own body. The iconic nature of this classifier means that properties
of role-shifted expressions that can be iconically assigned to the
described situation must be. For Attitude Role Shift, the analysis
essentially derives a quotational reading via a
demonstration&mdash;for our example above, something like: <em>My wife
said this, &ldquo;You are fine&rdquo;</em>. Cases of Attitude Role
Shift that have been argued not to involve standard quotation ( in
Catalan and German sign language) require refinements of the analysis.
For Action Role Shift, the operation has the effect of demonstrating
those parts of signs that are not conventional, yielding in essence:
<em>He walked away like this,</em> where <em>this</em> refers to all
iconically interpretable components of the role-shifted construction
(including the signer&rsquo;s angry expression, if applicable).</p>

<p>
Debates about Role Shift have two possible implications. On one view,
Role Shift provides overt evidence for context shift, and extends the
typology of Kaplanian monsters beyond spoken languages and beyond
attitude operators (due to the existence of Action Role Shift
alongside Attitude Role Shift). On the alternative view developed by
Davidson, Role Shift suggests that some instances of quotation should
be tightly connected to a broader analysis of iconicity owing to the
similarity between Attitude Role Shift an Action Shift.</p>

<p>
In sum, it has been argued that telicity and context shift can be
overtly marked in sign language, hence instances of Logical Visibility
beyond loci, but alternative accounts exist as well. Let us add that
there are cases of Logical <em>non</em>-visibility, in which logical
elements that are often overt in speech can be covert in sign. See the
 <a href="coordination.html">supplement on Coordination</a>
 for the case of an ASL construction ambiguous between conjunction and
disjunction. </p>

<h2 id="IconIOptiIconModu">3. Iconicity I: Optional Iconic Modulations</h2>

<p>
On a standard (Saussurean) view, language is made of discrete
conventional elements, with iconic effects at the margins. Sign
languages cast doubt on this view because iconicity interacts in
complex and diverse ways with grammar.</p>

<p>
By iconicity, we mean a rule-governed way in which an expression
denotes something by virtue of its resemblance to it, as is for
instance the case of a photograph of a cat, or of a vocal imitation of
a cat call. By contrast, the conventional word <em>cat</em> does not
refer by resembling cats. There are also mixed cases in which an
expression has both a conventional and an iconic component. </p>

<p>
In this section and the next, we survey constructions that display
optional or obligatory iconicity in sign, and call for the development
of a formal semantics with iconicity. As we will see, some purported
cases of Logical Visibility might be better analyzed as more or less
abstract versions of iconicity, with the result that several phenomena
discussed above can be analyzed from at least two theoretical
perspectives.</p>

<h3 id="IconModu">3.1 Iconic modulations</h3>

<p>
As in spoken language, it is possible to modulate some conventional
words in an iconic fashion. In English, <em>the talk was looong</em>
suggests that the talk wasn&rsquo;t just long but <em>very</em> long.
Similarly, the conventional verb <em>GROW</em> in ASL can be realized
more quickly to evoke a faster growth, and with broader endpoints to
suggest a larger growth, as is illustrated below (Schlenker 2018b).
There are multiple potential levels of speed and endpoint breadth,
which suggests that a rule is genuinely at work in this case.</p> <!-- use second  <table>
<caption>(18) Different iconic modulations of the sign <em>GROW</em>
in ASL <em>Picture credits:</em> M. Bonnet</caption>
<thead>
<tr>
  <td></td>
<th><strong>Narrow endpoints</strong></th>
<th><strong>Medium endpoints</strong></th>
<th><strong>Broad endpoints</strong></th> </tr> </thead>
<tbody>
<tr>
<th> </th>
  <td>
<img src="image012.png" style="height:5em" alt="missing text, please inform" />
</td>
  <td>
<img src="image013.png" style="height:5em" alt="missing text, please inform" />
</td>
  <td>
<img src="image014.png" style="height:5em" alt="missing text, please inform" />
</td> </tr>
<tr>
<th><strong>Slow movement</strong></th>
  <td>small amount, slowly </td>
  <td>medium amount, slowly</td>
  <td>large amount, slowly</td> </tr>
<tr>
<th><strong>Fast movement</strong></th>
  <td>small amount, quickly</td>
  <td>medium amount, quickly</td>
  <td>large amount, quickly </td> </tr> </tbody>
</table> -->

<dl class="sentag tag3em">
<dt id="ex18">(18)</dt>
<dd>

<p>
Different iconic modulations of the sign <em>GROW</em> in ASL
(<em>Picture credits:</em> M. Bonnet)</p>

<table class="smaller">
<thead>
<tr>
  <td></td>
  <td></td>
<th><strong>Slow movement</strong></th>
<th><strong>Fast movement</strong></th> </tr> </thead>
<tbody>
<tr>
<th><strong>Narrow
<br />
endpoints</strong></th>
  <td>
<img src="image012-crop.png" style="height:6em" alt="two drawings of a human with the first showing their left hand clasping the clenched fist of the right in front of the upper chest region and the second with the two hands spread and separated horizontally but still in front of the chest." />
</td>
  <td>small amount,
<br />
slowly </td>
  <td>small amount,
<br />
quickly</td> </tr>
<tr>
<th><strong>Medium
<br />
endpoints</strong></th>
  <td>
<img src="image013-crop.png" style="height:6em" alt="two drawings of a human with the first showing their left hand clasping the clenched fist of the right in front of the upper chest region and the second with the two hands spread and separated horizontally and in front of the shoulders." />
</td>
  <td>medium amount,
<br />
slowly</td>
  <td>medium amount,
<br />
quickly</td> </tr>
<tr>
<th><strong>Broad
<br />
endpoints</strong></th>
  <td>
<img src="image014-crop.png" style="height:6em" alt="two drawings of a human with the first showing their left hand clasping the clenched fist of the right in front of the upper chest region and the second with the two hands spread and separated horizontally and far outside the chest region." />
</td>
  <td>large amount,
<br />
slowly</td>
  <td>large amount,
<br />
quickly </td> </tr> </tbody>
</table> </dd>
</dl>

<p>
In English, iconic modulations can arguably be at-issue and thus
interpreted in the scope of grammatical operators. An example is the
following sentence: <em>If the talk is loooong</em>, <em>I&rsquo;ll
leave before the end</em>. This means that if the talk is very long,
I&rsquo;ll leave before the end (but if it&rsquo;s only moderately
long, maybe not); here, the iconic contribution is interpreted in the
scope of the <em>if-</em>clause, just like normal at-issue
contributions. The iconic modulation of <em>GROW</em> has similarly
been argued to be at-issue (Schlenker 2018b). (See
 <a href="#TypoIconContSpeeSign">Section 5.2</a>
 for further discussion on the at-issue vs. non-at-issue semantic
contributions.)</p>

<p>
While conceptually similar to iconic modulations in English, the sign
language versions are arguably richer and more pervasive than their
spoken language counterparts. </p>

<h3 id="EvenStru">3.2 Event structure</h3>

<p>
Iconic modulation interacts with the marking of telicity noticed by
Wilbur
 (<a href="#Teli">Section 2.1</a>).
 <em>GROW</em>, discussed in the preceding sub-section, is an (atelic)
degree achievement; the iconic modifications above indicate the final
degree reached and the time it took to reach that degree. Similarly,
for telic verbs, the speed and manner in which the phonological
movement reaches its endpoint can indicate the speed and manner in
which the result state is reached. For example, if LSF
<em>UNDERSTAND</em> is realized slowly and then quickly, the resulting
meaning is that there was a difficult beginning, and then an easier
conclusion. Atelic verbs that don&rsquo;t involve degrees can also be
iconically modulated; for instance, if LSF <em>REFLECT</em> is signed
slowly and then quickly, the resulting meaning is that the
person&rsquo;s reflection intensified. Here too, the iconic
contribution has been argued to be at-issue (Schlenker 2018b).</p>

<p>
There are also cases in which the event structure is not just
specified but radically altered by a modulation, as in the case of
incompletive forms (also called unrealized inceptive, Liddell 1984;
Wilbur 2008). ASL <em>DIE</em>, a telic verb, is expressed by turning
the dominant hand palm-down to palm-up as shown below (the
non-dominant hand turns palm-up to palm-down). If the hands only turn
partially, the sign is roughly interpreted as &lsquo;almost
die&rsquo;.</p>

<dl class="sentag tag3em avoid-break">
<dt id="ex19">(19)</dt>
<dd>

<p>
Normal vs. incompletive form of <em>DIE</em> in ASL (<em>Credits:</em>
J. Kuhn)</p>

<div class="figures pad-small">

<div class="inner-fig-bottom" id="fig19a">
<img src="image015.png" style="width:13em" alt="an image of the non-dominant hand in before, palm up, and after, palm down, positions." />

<p class="center">
a. DIE in ASL</p>
</div>

<div class="inner-fig-bottom" id="fig19b">
<img src="image016.png" style="width:10em" alt="an image of the non-dominant hand in before, palm vertical, and after, palm down, positions." />

<p class="center">
b. ALMOST-DIE in ASL</p>
</div>
</div> </dd>
</dl>

<p>
Similarly to the fact that multiple levels of speed and size can be
indicated by the verb <em>GROW</em> in
 <a href="#ex18">(18)</a>,
 the incompletive form of verbs can be modulated to indicate
arbitrarily many degrees of completion, depending on how far the hand
travels; these examples thus seem to necessitate an iconic rule (Kuhn
2015). On the other hand, while the examples with <em>GROW</em> can be
analyzed by simple predicate modification (&lsquo;The group grew and
it happened like this: slowly&rsquo;), examples of incompletive
modification require a deeper integration in the semantics, similar to
the semantic analysis of the adverb <em>almost</em> or the progressive
aspect in English. (Notably, it&rsquo;s nonsense to say: &lsquo;My
grandmother died and it happened like this: incompletely.&rsquo;)</p>

<p>
The key theoretical question lies in the integration between iconic
and conventional elements in such cases. If one posits a
decompositional analysis involving a morpheme representing the
endstate (<em>EndState</em> or <em>Res</em>, see
 <a href="#Teli">Section 2.1</a>),
 one must certainly add to it an iconic component (with a non-trivial
challenge for incompletive forms, where the iconic component does not
just specify but radically alters the lexical meaning). Alternatively,
one may posit that a structural form of iconicity is all one needs,
without morphemic decomposition. An iconic analysis along these lines
has been proposed (Kuhn 2015: Section 6.5), although a full account
has yet to be developed.</p>

<h3 id="PlurPlur">3.3 Plurals and pluractionals</h3>

<p>
The logical notion of plurality is expressed overtly in some way in
many of the world&rsquo;s languages: pluralizing operations may apply
to nouns or verbs to indicate a plurality of objects or events (for
nouns: &lsquo;plurals&rsquo;; for verbs: &lsquo;pluractionals&rsquo;).
Historically, arguments of Logical Visibility have not been made for
plurals in sign languages, since&mdash;while overt plural marking
certainly exists in sign language&mdash;plural morphemes also appear
overtly in spoken languages (e.g., English singular <em>horse</em> vs.
plural <em>horses</em>).</p>

<p>
Nevertheless, mirroring areas of language in which arguments of
Logical Visibility <em>do</em> apply, plural formation in sign
language shows a number of unique and revealing properties. First, the
morphological expression of this logical concept is similar for both
nouns and verbs across a large number of unrelated sign languages: for
both plural nouns (Pfau &amp; Steinbach 2006) and pluractional verbs
(Kuhn &amp; Aristodemo 2017), plurality is expressed by repetition. We
note that repetition-based plurals and pluractionals also exist in
speech (Sapir 1921: 79).</p>

<p>
Second, in sign language, these repeated plural forms have been shown
to feed iconic processes. Modifications of the way in which the sign
is repeated may indicate the number of objects or events, or may
indicate the arrangement of these pluralities in space or time.
Relatedly, so-called &lsquo;punctuated&rsquo; repetitions (with clear
breaks between the iterations) refer to precise plural quantities
(e.g., three objects or events for three iterations), while
&lsquo;unpunctuated&rsquo; repetitions (without clear breaks between
the iterations) refer to plural quantities with vague thresholds, and
often &lsquo;at least&rsquo; readings (Pfau &amp; Steinbach 2006;
Schlenker &amp; Lamberton 2022).</p>

<p>
In the nominal domain, the number of repetitions may provide an
indication of the number of objects, and the arrangement of the
repetitions in signing space can provide a pictorial representation of
the arrangement of the denotations in real space (Schlenker &amp;
Lamberton 2022). For instance, the word <em>TROPHY</em> can be
iterated three times on a straight line to refer to a group of
trophies that are horizontally arranged; or the three iterations can
be arranged as a triangle to refer to trophies arranged in a
triangular fashion. A larger number of iterations serves to refer to
larger groups. Here too, the iconic contribution can be at-issue and
thus be interpreted in the scope of logical operators such as
<em>if</em>-clauses.</p>

<dl class="sentag tag2em">
<dt>(20)</dt>
<dd>

<dl class="sentag tag15em">
<dt>a.</dt>
<dd>

<p>
<em>TROPHY</em> in ASL, repetition on a line:</p>
<img src="image017.png" style="height:9em" alt="The TROPHY sign repeated to the signer's upper left, upper front, and upper right." />
</dd>
<dt>b.</dt>
<dd>

<p>
<em>TROPHY</em> in ASL, repetition as a triangle:</p>
<img src="image018.png" style="height:9em" alt="The TROPHY sign repeated to the signer's middle left, upper front, and middle right" />
</dd>
</dl>

<p>
<em>Credits:</em> M. Bonnet</p></dd>
</dl>

<p>
Punctuated (= easy to count) repetitions yield meanings with precise
thresholds (often with an &lsquo;exactly&rsquo; reading, e.g.,
&lsquo;exactly three trophies&rsquo; for three punctuated iterations);
unpunctuated repetitions yield vague thresholds and often &lsquo;at
least&rsquo; readings (e.g., &lsquo;several trophies&rsquo; for three
unpunctuated iterations). While one may take the distinction to be
conventional, it might have an iconic source. In essence, unpunctuated
iterations result in a kind of pictorial vagueness on which the
threshold is hard to discern; deriving the full range of
&lsquo;exactly&rsquo; and &lsquo;at least&rsquo; readings is
non-trivial, however (Schlenker &amp; Lamberton 2022).</p>

<p>
In the verbal domain, pluractionals (referring to pluralities of
events) can be created by repeating a verb, for instance in LSF and
ASL. A complete analysis seems to require both conventionalized
grammatical components and iconic components. The form of
reduplication&mdash;as identical reduplication or as alternating
two-handed reduplication&mdash;appears to conventionally communicate
the distribution of events with respect to either time or to
participants. But a productive iconic rule also appears to be
involved, as the number and speed of the repetitions gives an idea of
the number and speed of the denoted events (Kuhn &amp; Aristodemo
2017); again, the iconic contribution can be at-issue.</p>

<p>
Iconic plurals and pluractionals alike are now treated by way of mixed
lexical entries that include a grammatical/logical component and an
iconic component. For instance, if <i>N</i> is a (singular) noun
denoting a set of entities <i>S</i>, then the iconic plural
<em><i>N</i>-rep</em> denotes the set of entities <i>x</i> such
that:</p>

<ol style="list-style-type: lower-roman">

<li id="cond1"><i>x</i> is the sum of atomic elements in <i>S</i>
(i.e., \(x \in *S\)), and</li>

<li id="cond2"> the form of <em><i>N</i>-rep</em> iconically
represents <i>x</i>.</li>
</ol>

<p>

 <a href="#cond1">Condition (i)</a>
 is the standard definition of a plural;
 <a href="#cond2">condition (ii)</a>
 is the iconic part, which is itself in need of an elucidation using
general tools of pictorial semantics (see
 <a href="#IconIIClasPred">Section 4</a>).</p>
 
<h3 id="IconLoci">3.4 Iconic loci</h3>

<p>
Loci, which have been hypothesized to be (sometimes) the overt
realization of variables, can lead a dual life as iconic
representations. Singular loci may (but need not) be simplified
pictures of their denotations: if so, a person-denoting locus is a
structured area <em>I</em>, and pronouns are directed towards a point
<i>i</i> that corresponds to the upper part of the body. In ASL, when
the person is tall, one can thus point upwards (there are also
metaphorical cases in which one points upwards because the person is
powerful or important). When a person is understood to be in a rotated
position, the direction of the pronoun correspondingly changes, as
seen in
 <a href="#ex21">(21)</a>
 for a person standing upright or hanging upside down (Schlenker
2018a; see also Liddell 2003).</p>

<dl class="sentag tag3em">
<dt id="ex21">(21)</dt>
<dd> An iconic locus schematically representing an upright person
(left) or upside down person (right)

<div class="center">
<img src="image019.png" style="height:10em" alt="" />
</div> </dd>
</dl>

<p>
Iconic mappings involving loci may also preserve abstract structural
relations that have been posited to exist for various kinds of
ontological objects, including mereological relations, total
orderings, and domains of quantification.</p>

<p>
First, two plural loci&mdash;indexed over areas of space&mdash;may
(but need not) express mereological relations diagrammatically, with a
locus <i>a</i> embedded in a locus <i>b</i> if the denotation of
<i>a</i> is a mereological part of the denotation of <i>b</i>
(Schlenker 2018a). For example, in
 <a href="#ex22">(22)</a>,
 the ASL expression <em>POSS-1 STUDENT</em> (&lsquo;my
students&rsquo;) introduces a large locus (glossed as <em>ab</em> to
make it clear that it contains subloci <i>a</i> and <i>b</i>&mdash;but
initially just a large locus). <em>MOST</em> introduces a sublocus
<i>a</i> within this large locus because the plurality denoted by
<i>a</i> is a proper part of that denoted by <em>ab</em>. And
critically, diagrammatic reasoning also makes available a third
discourse referent: when a plural pronoun points towards
<i>b</i>&mdash;the complement of the sublocus <i>a</i> within the
large locus <i>ab</i>&mdash;the sentence is acceptable, and <i>b</i>
is understood to refer to the students who did <em>not</em> come to
class.</p>

<dl class="sentag tag3em">
<dt id="ex22">(22)</dt>
<dd> POSS-1 STUDENT IX-arc-<i>ab</i> MOST IX-arc-<i>a</i>
<i>a</i>-COME CLASS. IX-arc-<i>b</i> <i>b</i>-STAY HOME.
<br />
&lsquo;Most of my students came to class. They stayed home.&rsquo;
(ASL, 8, 196) </dd>
</dl>

<dl class="sentag tag3em">
<dt id="ex23">(23)</dt>
<dd>

<div class="center">
<img src="image020.svg" style="height:10em" alt="small oval containing 'Sublocus a: students that came to class'; larger oval containing the small oval and also the the text 'Complement locus b: students that didn't come'; text outside both 'Large locus ab: (relevant) students'." />
</div> </dd>
</dl>

<p>
In English, the plural pronoun <em>they</em> clearly lacks such a
reading when one says, <em>Most of my students came to class. They
stayed home</em>, which sounds contradictory. (One can communicate the
target interpretation by saying, <em>The others stayed home</em>, but
<em>the others</em> is not a pronoun.) Likewise, in ASL, if the same
discourse is uttered using default, non-localized plural pronouns, the
pattern of inferences is exactly identical to the English
translation.</p>

<p>
A second case of preservation of abstract orders pertains to
degree-denoting and sometimes time-denoting loci. In LIS,
degree-denoting loci are represented iconically, with the total
ordering mapped to an axis in space, as described in
 <a href="#DegrDenoLoci">Section 1.3</a>.
 Time-denoting loci may but need not give rise to preservation of
ordering on an axis, depending on whether normal signing space is used
(as in the ASL examples
 <a href="#ex9">(9)</a>
 above), or a specific timeline, as mentioned in
 <a href="#TimeWorlDenoLoci">Section 1.2</a>
 in relation to Chinese Sign Language. As in the case of diagrammatic
plural pronouns, the spatial ordering of degree- and time-denoting
loci generates an iconic inference&mdash;beyond the meaning of the
words themselves&mdash;about the relative degree of a property or
temporal order of events.</p>

<p>
A third case involves the partial ordering of domain restrictions of
nominal quantifiers: greater height in signing space may be mapped to
a larger domain of quantification, as is the case in ASL (Davidson
2015) and at least indefinite pronouns in Catalan Sign Language
(Barber&agrave; 2015).</p>

<h2 id="IconIIClasPred">4. Iconicity II: Classifier Predicates</h2>

<h3 id="DemoAnalClasPred">4.1 The demonstrative analysis of classifier predicates</h3>

<p>
A special construction type, classifier predicates
(&lsquo;classifiers&rsquo; for short), has raised difficult conceptual
questions because they involve a combination of conventional and
iconic meaning. Classifier predicates are lexical expressions that
refer to classes of animate or inanimate entities that share some
physical characteristics&mdash;e.g., objects with a flat surface,
cylindrical objects, upright individuals, sitting individuals, etc.
Their form is conventional; for instance, the ASL &lsquo;three&rsquo;
handshape, depicted below, represents a vehicle. But their position,
orientation and movement in signing space is interpreted iconically
and gradiently (Emmorey &amp; Herzig 2003), as illustrated in the
translation of the example below.</p>

<dl class="sentag">
<dt id="ex24">(24)</dt>
<dd> CAR CL-vehicle-DRIVE-BY. (ASL, Valli and Lucas 2000)

<div class="center">
<img src="image022.png" style="height:15em" alt="right hand with thumb, index, and middle fingers extended moves right to left across the chest" />
</div>

<p>
&lsquo;A car drove by [with a movement resembling that of the
hand]</p></dd>
</dl>

<p>
These constructions have on several occasions been compared to
gestures in spoken language, especially to gestures that fully replace
some words, as in: <em>This airplane is about to FLY-take-off</em>,
with the verb replaced with a a hand gesture representing an airplane
taking off. But there is an essential difference: classifier
predicates are stable parts of the lexicon, gestures are not.</p>

<p>
Early semantic analyses, notably by Zucchi 2011 and Davidson 2015,
took classifier predicates to have a self-referential demonstrative
component, with the result that the moving vehicle classifier in
 <a href="#ex24">(24)</a>
 means in essence &lsquo;move like this&rsquo;, where
&lsquo;this&rsquo; makes reference to the very form of the classifier
movement. As mentioned in
 <a href="#ContShif">Section 2.2</a>,
 this analysis has been extended to Role Shift by Davidson (Davidson
2015), who took the classifier to be in this case the signer&rsquo;s
rotated body.</p>

<h3 id="PictAnalClasPred">4.2 The pictorial analysis of classifier predicates</h3>

<p>
The demonstrative analysis of classifier predicates as stated has two
general drawbacks. First, it establishes a natural class containing
classifiers and demonstratives (like English <em>this</em>), but the
two phenomena possibly display different behaviors. Notably, while
demonstratives behave roughly like free variables that can pick up
their referent from any of a number of contextual sources, the iconic
component of classifiers can only refer to the position/movement and
configuration of the hand (any demonstrative variable is thus
immediately saturated). Second, the demonstrative analysis currently
relegates the iconic component to a black box. Without any
interpretive principles on what it means for an event to be
&lsquo;like&rsquo; the demonstrated representation, one cannot provide
any truth conditions for the sentence as a whole.</p>

<p>
Any complete analysis must thus develop an explicit semantics for the
iconic component. This is more generally necessary to derive explicit
truth conditions from other iconic constructions in sign language,
such as the repetition-based plurals discussed in
 <a href="#PlurPlur">Section 3.3</a>.
 above: in the metalanguage, the condition <em>[a certain expression]
iconically represents [a certain object]</em> was in need of
explication.</p>

<p>
A recent model has been offered by formal pictorial semantics,
developed by Greenberg and Abusch (e.g., Greenberg 2013, 2021; Abusch
2020). The basic idea is that a picture obtained by a given projection
rule (for instance, perspective projection) is true of precisely those
situations that can project onto the picture. Greenberg has further
extended this analysis with the notion of an object projecting onto a
picture part (in addition to a situation projecting onto a whole
picture). This notion proves useful for sign language applications
because they usually involve partial iconic representations, with one
iconic element representing a single object or event in a larger
situation. To illustrate, below, the picture in
 <a href="#ex25a">(25a)</a>
 is true of the situation in
 <a href="#ex25b">(25b)</a>,
 and the left-most shape in the picture in
 <a href="#ex25a">(25a)</a>
 denotes the top cube in the situation in
 <a href="#ex25b">(25b)</a>.</p>
 
<dl class="sentag tag3em">
<dt id="ex25">(25)</dt>
<dd>

<p>
Illustration of a projection rule relating (parts of) a picture to
(objects in) a world. (<em>Credits:</em> Gabriel Greenberg)</p>

<div class="figures">

<div class="inner-fig" id="ex25a">
<img src="picture-world-1.svg" style="height:10em" alt="Drawing of two cubes with the left (and front) one partially obscuring the back one." />

<p class="center">
(a) Picture</p>
</div>

<div class="inner-fig" id="ex25b">
<img src="picture-world-2.svg" style="height:10em" alt="a two dimensional view of (a) from above labeled 'world w'. On the left is a point labeled 'viewpoint v' on the right are three squares with the top (and left) one corresponding to the left block of (a), a bottom square, and to the right of both a small square. From viewpoint v, two lines extend to the top and bottom corners to the top left square which indicate that part of the bottom square and all of the small square are obscured." />

<p class="center">
(b) Situation</p>
</div>
</div> </dd>
</dl>

<p>
The full account makes reference to a notion of viewpoint relative to
which perspective projection is assessed, and a picture plane, both
represented in
 <a href="#ex25b">(25b)</a>.
 This makes it possible to say that the top cube (top-cube) projects
onto the left-hand shape (left-shape) relative to the viewpoint (call
it &pi;), at the time <i>t</i> and in the world <i>w</i> in which the
projection is assessed. In brief: </p> 
\[
\textrm{proj}(\textrm{top-cube}, \pi, t, w) = \textrm{left-shape}.
\]

<p>
Classifier predicates (as well as other iconic constructions, such as
repetition-based plurals) may be analyzed with a version of pictorial
semantics to explicate the truth-conditional contribution of iconic
elements.</p>

<p>
To illustrate, consider a pair of minimally different words in ASL
that can be translated as &lsquo;airplane&rsquo;: one is a normal
noun, glossed as <em>PLANE</em>, and the other is a classifier
predicate, glossed below as <em>PLANE-cl</em>. Both forms involve the
handshape in
 <a href="#ex26">(26)</a>,
 but the normal noun includes a tiny repetition (different from that
of plurals) which is characteristic of some nominals in ASL. As we
will see, the position of the classifier version is interpreted
iconically (&lsquo;an airplane in position such and such&rsquo;),
whereas the nominal version need not be.</p>

<dl class="sentag">
<dt id="ex26">(26)</dt>
<dd>

<p>
Handshape for both (i) ASL <em>PLANE</em> (= nominal version) and (ii)
ASL <em>PLANE-cl</em> (= classifier predicate version).
(<em>Credits:</em> J. Kuhn)</p>

<div class="center">
<img src="image026.png" style="width:10em" alt="hand with thumb, index, and little fingers extended and other two not." />
</div> </dd>
</dl>

<p>
Semantically, the difference between the two forms is that only the
classifier generates obligatory iconic inferences about the
plane&rsquo;s configuration and movement. This has clear semantic
consequences when several classifier predicates occur in the same
sentence. In
 <a href="#ex27b">(27b)</a>,
 two tokens of <em>PLANE-cl</em> appear in positions <i>a</i> and
<i>b</i>, and as the video makes clear, the two classifiers are signed
close to each other and in parallel. As a result, the sentence only
makes an assertion about cases in which two airplanes take off next to
each other or side by side. In contrast, with a normal noun in
 <a href="#ex27a">(27a)</a>,
 the assertion is that there is danger whenever two airplanes take off
at the same time, irrespective of how close the two airplanes are, or
how they are oriented relative to each other.</p>

<dl class="sentag tag3em">
<dt id="ex27">(27)</dt>
<dd> HERE ANYTIME __ SAME-TIME TAKE-OFF, DANGEROUS.
<br />
&lsquo;Here, whenever ___ take off at the same time, there is
danger.&rsquo;

<dl class="sentag tag15em">
<dt id="ex27a">a.</dt>
<dd> <sup>7</sup>PLANE<sub><i>a</i></sub> PLANE<sub><i>b</i></sub>
<br />
&lsquo;two planes&rsquo; </dd>
<dt id="ex27b">b.</dt>
<dd> <sup>7</sup>PLANE-cl<sub><i>a</i></sub>
PLANE-cl<sub><i>b</i></sub>
<br />
&lsquo;two planes side by side/next to each other&rsquo; </dd>
</dl>

<p>
(ASL, 35, 1916, 4 judgments;
 <a href="https://youtu.be/Wyt1AsP6ASk" target="other">short video clip of the sentences, no audio</a>)</p>
 </dd>
</dl>

<p>
To capture these differences, one can posit the following lexical
entries for the normal noun and for its classifier predicate version.
Importantly, the interpretation of <em>PLANE-cl</em> in
 <a href="#ex28b">(28b)</a>
 is defined for a particular token of the sign (not a type), produced
with a phonetic realization &Phi;.</p>

<dl class="sentag tag3em">
<dt id="ex28">(28)</dt>
<dd> For a context <i>c</i>, time of evaluation <i>t</i> and world of
evaluation <i>w</i>:

<dl class="sentag tag15em">
<dt id="ex28a">a.</dt>
<dd class="left"> PLANE, normal noun
<br />
[[PLANE]] <sup><i>c,t,w</i></sup> = \(\lambda x_{e}\) .
plane'<sub><i>t,w</i></sub>(<i>x</i>)</dd>
<dt id="ex28b">b.</dt>
<dd class="left"> PLANE-cl\(_{\Phi}\), classifier predicate [token
with phonetic realization \(\Phi\)]
<br />
[[PLANE-cl\(_{\Phi}\)]]<sup><i>c,t,w</i></sup> = \(\lambda x_{e}\) .
plane'<sub><i>t,w</i></sub>(x) and \(\boldsymbol{\textbf{proj}(x,
\pi_{c}, t, w) = \Phi}\)</dd>
</dl> </dd>
</dl>

<p>
Evaluation is relative to a context c that provides the viewpoint,
\(\pi_{c}\). In the lexical entry for the normal noun in
 <a href="#ex28a">(28a)</a>,
 <em>plane'<sub><i>t,w</i></sub></em> is a (metalanguage) predicate of
individuals that applies to anything that is an airplane at <i>t</i>
in <i>w</i>. The classifier predicate has the lexical entry in
 <a href="#ex28b">(28b)</a>.
 It has the same conventional component as the normal noun, but adds
to it an (iconic) projective condition: for a token of the predicate
<em>PLANE-cl</em> to be true of an object <i>x</i>, <i>x</i> should
project onto this very token.</p>

<h3 id="CompRefi">4.3 Comparison and refinements</h3>

<p>
With this pictorial semantics in hand, we can make a more explicit
comparison to the demonstrative analysis of classifiers. As described
above, a demonstrative analysis takes classifiers to include a
component of meaning akin to &lsquo;move like this&rsquo;. For Zucchi,
this is spelled out via a lexical entry very close to the one in
 <a href="#ex28">(28)</a>,
 but in which the second clause (in terms of projection above) is
instead a similarity function, asserting that the position of the
denoted object <i>x</i> is &lsquo;similar&rsquo; to that of the
airplane classifier; the proposal, however, leaves it entirely open
what it means to be &lsquo;similar&rsquo;. Of course, one may
supplement the analysis with a separate explication in which
similarity is defined in terms of projection, but this move
presupposes rather than replaces an explicit pictorial account. In
other words, the demonstrative analysis relegates the iconic component
to a black box, whose content can be specified by the pictorial
analysis. But once a pictorial analysis is posited, it become unclear
why one should make a detour through the demonstrative component,
rather than posit pictorial lexical entries in the first place.</p>

<p>
A number of further refinements need to be made to any analysis of
classifiers. First, to have a fully explicit iconic semantics, one
must contend with several differences between classifiers and
pictures. </p>

<ol style="list-style-type: decimal">

<li> Classifier predicates have a conventional shape; only their
position, orientation and movement is interpreted iconically
(sometimes modifications of the conventional handshape can be
interpreted iconically as well). This requires projection rules with a
partly conventional component (of the type: a certain symbol appears
in a certain position of the picture if an object of the right types
projects onto that position).</li>

<li> Many classifier predicates are dynamic (in the sense of involving
movement) rather than static; this requires the development of a
semantics for visual animations.</li>

<li> Sign language classifiers are not two-dimensional pictures, but
rather 3D representations. One can think of them as puppets whose
shape needn&rsquo;t be interpreted literally, but whose position,
orientation and movement can be iconically precise. This requires
formal means that go beyond pictorial semantics.</li>
</ol>

<p>
The interaction between iconic representations and the sentences they
appear in also requires further refinements. A first refinement
pertains to the semantics. For simplicity, we assumed above that the
viewpoint relative to which the iconic component of classifier
predicates is evaluated is fixed by the context. Notably, though, in
some cases, viewpoint choice can be dependent on a quantifier. In the
example below, the meaning obtained is that in all classes, during the
break, <em>for some salient viewpoint &pi; associated with the
class</em>, there is a student who leaves with the movement depicted
relative to &pi;; a recent proposal (Schlenker and Lamberton
forthcoming) has viewpoint variables in the object language, and they
may be left free or bound by default existential quantifiers, as
illustrated in
 <a href="#ex30">(30)</a>.
 (While there is a strong intuition that Role Shift manipulates
viewpoints as well, a formal account has yet to be developed.) </p>

<dl class="sentag tag3em">
<dt>(29)</dt>
<dd> <em>Context:</em> This school has 4 classrooms, one for each of 4
teachers (each teacher always teaches in the same classroom).
<br />
CLASS BREAK ALL ALWAYS HAVE STUDENT PERSON-walk-back_right-cl.
<br />
&lsquo;In all classes, during the break, there is always a student
that leaves toward the the back, to the right.&rsquo; (ASL, 35, 2254b;
 <a href="https://youtu.be/h7EnRK6poAE" target="other">short video clip of the sentence, no audio</a>)
 </dd>
<dt id="ex30">(30)</dt>
<dd> always \(\exists\pi\) there-is student
person-walk-cl<sup>&pi;</sup></dd>
</dl>

<p>
A second refinement pertains to the syntax. Across sign languages,
classifier constructions have been shown to sometimes override the
basic word order of the language; for instance, ASL normally has the
default word order SVO (Subject Verb Object), but classifier
predicates usually prefer preverbal objects instead. One possible
explanation is that the non-standard syntax of classifiers arises at
least in part from their iconic semantics; we revisit this point in
 <a href="#ClasPredProSpeeGest">Section 5.3</a>.</p>
 
<h2 id="SignIconVersSpeeGest">5. Sign with Iconicity versus Speech with Gestures</h2>

<h3 id="ReinGestSignComp">5.1 Reintegrating gestures in the sign/speech comparison</h3>

<p>
The iconic contributions discussed above are to some extent different
from those found in speech. Iconic modulations exist in speech (e.g.,
<em>looong</em> means &lsquo;very long&rsquo;) but are probably less
diverse than those found in sign. Repetition-based plurals and
pluractionals exist in speech (Rubino 2013), and it has been argued
for pluractional ideophones in some languages, that the number of
repetitions can reflect the number of denoted events (Henderson 2016).
But sign language repetitions can iconically convey a particularly
rich amount of information, including through their punctuated or
unpunctuated nature, and sometimes their arrangement in space
(Schlenker &amp; Lamberton 2022). As for iconic pronouns and
classifier predicates, they simply have no clear counterparts in
speech. From this perspective, speech appears to be &lsquo;iconically
deficient&rsquo; relative to sign.</p>

<p>
But Goldin-Meadow and Brentari (2017) have argued that a typological
comparison between sign language and spoken language makes little
sense if it does not take gestures into account: sign with iconicity
should be compared to speech with gestures rather than to speech
alone, since gestures are the main exponent of iconic enrichments in
spoken language. This raises a question: From a semantic perspective,
does speech with gesture have the same expressive effect and the same
grammatical integration as sign with iconicity?</p>

<h3 id="TypoIconContSpeeSign">5.2 Typology of iconic contributions in speech and in sign</h3>

<p>
This question has motivated a systematic study of iconic enrichments
across sign and speech, and has led to the discovery of fine-grained
differences (Schlenker 2018b). The key issue pertains to the place of
different iconic contributions in the typology of inferences, which
includes at-issue contributions and non-at-issue ones, notably
presuppositions and supplements (the latter are the semantic
contributions of appositive relative clauses).</p>

<p>
While detailed work is still limited, several iconic constructions in
sign language have been argued to make at-issue contributions
(sometimes alongside non-at-issue ones). This is the case of iconic
modulations of verbs, as for <em>GROW</em> in
 <a href="#ex18">(18)</a>,
 of repetition-based plurals and pluractionals, and of classifier
predicates.</p>

<p>
By contrast, gestures that accompany spoken words have been argued in
several studies (starting with the pioneering one by Ebert &amp; Ebert
2014 &ndash; see Other Internet Resources) to make primarily
non-at-issue contributions. Recent typologies (e.g., Schlenker 2018b;
Barnes &amp; Ebert 2023) distinguish between co-speech gestures, which
co-occur with the spoken words they modify (a slapping gesture
co-occurs with <em>punish</em> in
 <a href="#ex31a">(31a)</a>;
 post-speech gestures, which follow the words they modify (the gesture
follows <em>punish</em> in
 <a href="#ex31b"> (31b)</a>;
 and pro-speech gestures, which fully replace some words (the slapping
gestures has the function of a verb in
 <a href="#ex31c">(31c)</a>.</p>
 
<dl class="sentag tag2em">
<dt id="ex31">(31)</dt>
<dd>

<dl class="sentag tag15em">
<dt id="ex31a">a.</dt>
<dd>Co-speech: His enemy, Asterix will
<img src="image027-black.png" style="height:3em; vertical-align: baseline" alt="slapping gesture" />
_punish. </dd>
<dt id="ex31b">b.</dt>
<dd> Post-speech: His enemy, Asterix will punish&mdash;
<img src="image027-black.png" style="height:3em; vertical-align: baseline" alt="slapping gesture" />
.</dd>
<dt id="ex31c">c.</dt>
<dd> Pro-speech His enemy, Asterix will
<img src="image027-black.png" style="height:3em; vertical-align: baseline" alt="slapping gesture" />
.</dd>
</dl></dd>
</dl>

<p>
When different tests are applied, such as embedding under negation,
these three types display different semantic behaviors. Co-speech
gestures have been argued to trigger conditionalized presuppositions,
as in
 <a href="#ex32a">(32a)</a>.
 Post-speech gestures have been argued to display the behavior of
appositive relative clauses, and in particular to be deviant in some
negative environments, as illustrated in (32b)&ndash;(32b&prime;); in
addition, post-speech gestures, just like appositive relative clauses,
usually make non-at-issue contributions.</p>

<dl class="sentag tag2em">
<dt id="ex32">(32)</dt>
<dd>

<dl class="sentag tag15em">
<dt id="ex32a">a.</dt>
<dd> Co-speech: His enemy, Asterix won&rsquo;t
<img src="image027-black.png" style="height:3em; vertical-align: baseline" alt="slapping gesture" />
_punish.
<br />
\(\Rightarrow\) if Asterix were to punish his enemy, slapping would be
involved </dd>
<dt id="ex32b">b.</dt>
<dd> Post-speech: #His enemy, Asterix won&rsquo;t punish&mdash;
<img src="image027-black.png" style="height:3em; vertical-align: baseline" alt="slapping gesture" />
.</dd>
<dt id="ex32bprime">b&prime;.</dt>
<dd> #His enemy, Asterix won&rsquo;t punish, which will involve
slapping him.</dd>
<dt id="ex32c">c.</dt>
<dd> Pro-speech His enemy, Asterix won&rsquo;t
<img src="image027-black.png" style="height:3em; vertical-align: baseline" alt="slapping gesture" />
.
<br />
\(\Rightarrow\) Asterix won&rsquo;t slap his enemy</dd>
</dl>

<p>
(<em>Picture credits</em>: M. Bonnet)</p></dd>
</dl>

<p>
Only pro-speech gestures, as in
 <a href="#ex32c">(32c)</a>,
 make at-issue contributions by default (possibly in addition to other
contributions). In this respect, they &lsquo;match&rsquo; the behavior
of iconic modulations, iconic plurals and pluractionals, and
classifier predicates. But unlike these, pro-speech gestures are not
words and are correspondingly expressively limited. For instance,
abstract psychological verbs <em>UNDERSTAND</em>
 (=<a href="#ex15a">(15a)</a>)
 and especially <em>REFLECT</em>
 (=<a href="#ex15b">(15b)</a>)
 can be modulated in rich iconic ways in LSF&mdash;e.g., if the hand
movement of <em>REFLECT</em> starts slow and ends fast, this conveys
that the reflection intensified (Schlenker 2018a). But there are no
clear pro-speech gestures with the same abstract meanings, and thus
one cannot hope to emulate with pro-speech gestures the contributions
of <em>UNDERSTAND</em> and <em>REFLECT</em>, including when they are
enriched by iconic modulations.</p>

<p>
In sum, while the reintegration of gestures into the study of speech
opens new avenues of comparison between sign with iconicity and speech
with gestures, one shouldn&rsquo;t jump to the conclusion that these
enriched objects display precisely the same semantic behavior.</p>

<h3 id="ClasPredProSpeeGest">5.3 Classifier predicates and pro-speech gestures</h3>

<p>
Unlike gestures in general and pro-speech gestures in particular,
classifier predicates have a conventional form (only the position,
orientation, and movement are iconically interpreted, accompanied in
limited cases by aspects of the handshape). But there are still
striking similarities between pro-speech gestures and classifier
predicates.</p>

<p>
First, on a semantic level, the iconic semantics sketched for
classifier predicates in
 <a href="#PictAnalClasPred">Section 4.2</a>
 seems useful for pro-speech gestures as well, sometimes down to the
details&mdash;for instance, it has been argued that the dependency
between viewpoints and quantifiers illustrated in
 <a href="">(30)</a>
 has a counterpart with pro-speech gestures (Schlenker &amp; Lamberton
forthcoming).</p>

<p>
Second, on a syntactic level, classifier predicates often display a
different word order from other constructions, something that has been
found across languages (Pavli&#269; 2016). In ASL, the basic word
order is SVO, but preverbal objects are usually preferred if the verb
is a classifier predicate, for instance one that represents a
crocodile moving and eating up a ball (as is standard in syntax, the
&lsquo;basic&rsquo; or underlying word order may be modified on
independent grounds by further operations, for instance ones that
involve topics and focus; we are not talking about such modifications
of the word order here). </p>

<p>
It has been proposed that the non-standard word order is directly
related to the iconic properties of classifier predicates. The idea is
that these create a visual animation of an action, and preferably take
their argument in the order in which their denotations are visible
(Schlenker, Bonnet et al. 2024; see also Napoli, Spence, and
M&uuml;ller 2017). One would typically see a ball and a crocodile
before seeing the eating, hence the preference for preverbal objects
(note that the subject is preverbal anyway in ASL). A key argument for
this idea is that when one considers a minimally different sentence
involving a crocodile spitting out a ball it had previously ingested,
SVO order is regained, in accordance with the fact that an observer
would see the object after the action in this case.</p>

<p>
Strikingly, these findings carry over to pro-speech gestures.
Goldin-Meadow et al. (2008) famously noted that when speakers of
languages with diverse word orders are asked to use pantomime to
describe an event with an agent and a patient, they tend to go with
SOV order, including if this goes against the basic word order of
their language (as is the case in English). Similarly, pre-verbal
objects are preferred in sequences of pro-speech gestures in French
(despite the fact that the basic word order of the language is SVO);
this is for instance the case for a sequence of pro-speech gestures
that means that a crocodile ate up a ball. Remarkably, with
spit-out-type gestural predicates, an SVO order is regained, just as
is the case with ASL classifier predicates (Schlenker, Bonnet, et al.
2024, following in part by Christensen, Fusaroli, &amp; Tyl&eacute;n
2016; Napoli, Mellon, et al. 2017; Schouwstra &amp; de Swart 2014).
This suggests that iconicity, an obvious commonality between the two
constructions, might indeed be responsible for the non-standard word
order.</p>

<h2 id="UnivPropSignModa">6. Universal Properties of the Signed Modality</h2>

<h3 id="SignLangTypoSignLangEmer">6.1 Sign language typology and sign language emergence</h3>

<p>
Properties discussed above include: (i) the use of loci to realize
anaphora, (ii) the overt marking of telicity and (possibly) context
shift, (iii) the presence of rich iconic modulations interacting with
event structure, plurals and pluractionals, and anaphora, (iv) the
existence of classifier predicates, which have both a conventional and
an iconic dimension. Although the examples above involve a relatively
small number of languages, it turns out that these properties exist in
several and probably many sign languages. Historically unrelated sign
languages are thus routinely treated as a &lsquo;language
family&rsquo; because they share numerous properties that are not
shared by spoken languages (Sandler &amp; Lillo-Martin 2006). Of
course, this still allows for considerable variation across sign
languages, for instance with respect to word order (e.g., ASL is SVO,
LIS is SOV).</p>

<p>
Cases of convergence also exist in language emergence. Homesigners are
deaf individuals who are not in contact with an established sign
language and thus develop their own gesture systems to communicate
with their families. While homesigners do not invent a sign language,
they sometimes discover on their own certain properties of mature sign
languages. Loci and repetition-based plurals are cases in point
(Coppola &amp; So 2006; Coppola et al. 2013). Strikingly, Coppola and
colleagues (2013) showed in a production experiment that a group of
homesigners from Nicaragua used both punctuated and unpunctuated
repetitions, with the kinds of semantic distinctions found in mature
sign language. Coppola et al. further </p>

<blockquote>

<p>
examined a child homesigner and his hearing mother, and found that the
child&rsquo;s number gestures displayed all of the properties found in
the adult homesigners&rsquo; gestures, but his mother&rsquo;s gestures
did not. (Coppola, Spaepen, &amp; Goldin-Meadow 2013: abstract) </p>
</blockquote>

<p>
This provided clear evidence that this homesigner had invented this
strategy of plural-marking.</p>

<p>
In sum, there is striking typological convergence among historically
unrelated sign languages, and homesigners can in some cases discover
grammatical devices found in mature sign languages.</p>

<h3 id="SignLangGramGestGram">6.2 Sign language grammar and gestural grammar</h3>

<p>
It is arguably possible to have non-signers discover on the fly
certain non-trivial properties of sign languages (Strickland et al.
2015; Schlenker 2020). One procedure involves hybrids of words and
gestures. We saw a version of this in
 <a href="#ClasPredProSpeeGest">Section 5.3</a>,
 when we discussed similarities between pro-speech gestures and
classifier predicates. The result was that along several dimensions,
notably word order preferences and associated meanings, pro-speech
gestures resemble ASL classifier predicates (they also differ from
them in not having lexical forms).</p>

<p>
More generally, hybrid sequences of words and gestures suggest that
non-signers sometimes have access to a gestural grammar somewhat
reminiscent of sign languages. (It goes without saying that there is
no claim whatsoever that non-signers know the sophisticated grammars
of sign languages, any more than a naive monolingual English speaker
knows the grammar of Mandarin or Hebrew.) In one experimental study
(summarized in Schlenker 2020), gestures with a verbal meaning, such
as &lsquo;send kisses&rsquo;, targeted different positions,
corresponding to the addressee or some third person, as illustrated
below.</p>

<dl class="sentag tag3em">
<dt id="ex33">(33)</dt>
<dd> A gesture for &lsquo;send kisses to&rsquo; oriented towards the
addressee or some third person position

<div class="figures">

<div class="inner-fig">
<img src="image028.png" style="height:8em" alt="face with mouth in a kiss and a hand gesturing forward with face facing front" />

<p class="center">
a. send kisses to you</p>
</div>

<div class="inner-fig">
<img src="image029.png" style="height:8em" alt="face with mouth in a kiss and a hand gesturing forward but the whole oriented to the side" />

<p class="center">
b. send kisses to him/her</p>
</div>

<p>
<em>Credits</em>: J. Kuhn</p>
</div> </dd>
</dl>

<p>
The conditions in which these two forms can be used turn out to be
reminiscent of the behavior of the agreement verb <em>TELL</em> in
ASL: in
 <a href="#fig5">(5)</a>,
 the verb could target the addressee position to mean <em>I tell
you</em>, or some position to the side to mean <em>I tell
him/her</em>. The study showed that non-signers immediately perceived
a distinction between the second person object form and the third
person object form of the gestural verb, despite the fact that
English, unlike ASL, has no object agreement markers. In other words,
non-signers seemed to treat the directionality of the gestural verb as
a kind of agreement marker. More fine-grained properties of the ASL
object agreement construction were tested with gestures, again with
positive results.</p>

<p>
More broadly, it has been argued that aspects of gestural grammar
resemble the grammar of ASL in designated cases involving loci,
repetition-based plurals and pluractionals, Role Shift, and telicity
marking (e.g., Schlenker 2020 and references therein). These findings
have yet to be confirmed with experimental means, but if they are
correct, the question is why.</p>

<h3 id="WhyConv">6.3 Why convergence?</h3>

<p>
We have seen three cases of convergence in the visual modality:
typological convergence among unrelated sign languages,
homesigners&rsquo; ability to discover designated aspects of sign
language grammar, and possibly the existence of a gestural grammar
somewhat reminiscent of sign language in designated cases. None of
these cases should be exaggerated. While typologically they belong to
a language family, sign languages are very diverse, varying on all
levels of linguistic structure. As for homesigners, the gestural
systems they develop compensate for the <em>lack</em> of access to a
sign language; indeed, homesigners bear consequences of lack of access
to a native language (see for instance Morford &amp;
H&auml;nel-Faulhaber 2011; Gagne &amp; Coppola 2017). Finally,
non-signers cannot guess anything about sign languages apart from a
few designated properties.</p>

<p>
Still, these cases of convergence should be explained. There are at
least three conceivable directions, which might have different areas
of applicability. Chomsky famously argued that there exists an innate
Universal Grammar (UG) that underlies all human languages (see for
instance Chomsky 1965, Pinker 1994). One possibility is that UG
doesn&rsquo;t just specify abstracts features and rules (as is usually
assumed), but also certain form-to-meaning mappings in the visual
modality, for instance the fact that pronouns are realized by way of
pointing. A second possibility is that the iconic component of sign
language&mdash;possibly in more abstract forms than is usually
assumed&mdash;is responsible for some of the convergence. An example
was discussed in
 <a href="#ClasPredProSpeeGest">Section 5.3</a>
 in relation to the word order differences between classifier
predicates and normal signs, and between gesture sequences and normal
words. A third possibility is that, for reasons that have yet to be
determined, the visual modality sometimes makes it possible to realize
in a more uniform fashion some deeper cognitive properties of
linguistic expressions.</p>

<h2 id="N7FutuIssu">7. Future Issues</h2>

<p>
On a practical level, future research will have to find the optimal
balance between fine-grained studies and robust methods of data
collection (e.g., what are the best methods to collect fine-grained
data from a small number of consultants? how can large-scale
experiments be set up for sign language semantics?). A second issue
pertains to the involvement of native signers and Deaf researchers,
who should obviously play a central role in this entire research.</p>

<p>
On a theoretical level, the traditional view of human language as a
discrete system with iconicity at the margins is hard to maintain in
view of the analysis of sign with iconicity (and possibly also of
speech with gestures). Rather, human language is a hybrid system with
a discrete/logical component and an iconic component. But there are
multiple open issues. First, cases of Logical Visibility will no doubt
give rise to further debates. Second, a formal iconic semantics
appropriate for sign language has yet to be fully developed. Third,
the interaction between the discrete/logical component and the iconic
component must be investigated in greater detail. Fourth, the formal
semantics of sign language should be extended with an equally formal
pragmatics to investigate, among others, information structure, and
the rich typology of inferences that has been unearthed for spoken
languages (including implicatures, presuppositions, supplements,
expressives, etc.). Importantly, this formal pragmatics will have to
explore both the discrete/logical and the iconic component of sign
language. Fifth, consequences of the iconic component for the syntax
will have to be further explored, especially in view of the hypothesis
that classifier predicates display a non-standard syntax because they
have an iconic semantics. Last, but not least, the philosophy of
language should take sign languages into account. For the moment, it
almost never does so.</p>
</div>

<div id="bibliography">

<h2 id="Bib">Bibliography</h2>

<ul class="hanging">

<li>Abusch, Dorit, 2020, &ldquo;Possible&#8208;Worlds Semantics for
Pictures&rdquo;, in <em>The Wiley Blackwell Companion to
Semantics</em>, Daniel Gutzmann, Lisa Matthewson, C&eacute;cile Meier,
Hotze Rullmann, and Thomas Zimmermann (eds.), Hoboken, NJ: Wiley.
doi:10.1002/9781118788516.sem003</li>

<li>Anand, Pranav and Andrew Nevins, 2004, &ldquo;Shifty Operators in
Changing Contexts&rdquo;, in <em>Proceedings of Semantics and
Linguistic Theory (SALT 14)</em>, Robert B. Young (ed.), <em>Semantics
and Linguistic Theory</em> (Linguistics Society of America), pp.
20&ndash;37. doi:10.3765/salt.v14i0.2913</li>

<li>Anand, Pranav, 2006, &ldquo;De de Se&rdquo;, Ph.D. Thesis,
Massachusetts Institute of Technology, Cambridge, MA.
 [<a href="https://dspace.mit.edu/handle/1721.1/37418" target="other">Anand 2006 available online</a>]</li>
 
<li>Aristodemo, Valentina, 2017, <em>Gradable Constructions in Italian
Sign Language</em>, Ph.D. Thesis, Ecole des Hautes Etudes en Sciences
Sociales, Paris.</li>

<li>Barber&agrave; Altimira, Gemma, 2015, <em>The Meaning of Space in
Sign Language: Reference, Specificity and Structure in Catalan Sign
Language Discourse</em> (Sign Languages and Deaf Communities 4),
Boston: De Gruyter Mouton/Ishara Press. doi:10.1515/9781614518815</li>

<li>Barnes, Kathryn and Cornelia Ebert, 2023, &ldquo;The Information
Status of Iconic Enrichments: Modelling Gradient at-Issueness&rdquo;,
<em>Theoretical Linguistics</em>, 49(3&ndash;4): 167&ndash;223.
doi:10.1515/tl-2023-2009</li>

<li>Beck, Sigrid, Sveta Krasikova, Daniel Fleischer, Remus Gergel,
Stefan Hofstetter, Christiane Savelsberg, John Vanderelst, and
Elisabeth Villalta, 2009, &ldquo;Crosslinguistic Variation in
Comparison Constructions&rdquo;, <em>Linguistic Variation
Yearbook</em>, 9: 1&ndash;66. doi:10.1075/livy.9.01bec</li>

<li>Bellugi, Ursula and Susan Fischer, 1972, &ldquo;A Comparison of
Sign Language and Spoken Language&rdquo;, <em>Cognition</em>,
1(2&ndash;3): 173&ndash;200. doi:10.1016/0010-0277(72)90018-2</li>

<li>Chomsky, Noam, 1965, <em>Aspects of the Theory of Syntax</em>,
Cambridge, MA: MIT Press</li>

<li>Christensen, Peer, Riccardo Fusaroli, and Kristian Tyl&eacute;n,
2016, &ldquo;Environmental Constraints Shaping Constituent Order in
Emerging Communication Systems: Structural Iconicity, Interactive
Alignment and Conventionalization&rdquo;, <em>Cognition</em>, 146:
67&ndash;80. doi:10.1016/j.cognition.2015.09.004</li>

<li>Cogill-Koez, Dorothea, 2000, &ldquo;Signed Language Classifier
Predicates: Linguistic Structures or Schematic Visual
Representation?&rdquo;, <em>Sign Language &amp; Linguistics</em>,
3(2): 153&ndash;207. doi:10.1075/sll.3.2.03cog</li>

<li>Coppola, Marie and Wing Chee So, 2006, &ldquo;The Seeds of Spatial
Grammar: Spatial Modulation and Coreference in Homesigning and Hearing
Adults&rdquo;, in <em>Proceedings of the 30th Boston University
Conference on Language Development</em>, David Bamman, Tatiana
Magnitskaia, and Colleen Zaller (eds.), Boston: Cascadilla Press, 1:
119&ndash;130.</li>

<li>Coppola, Marie, Elizabet Spaepen, and Susan Goldin-Meadow, 2013,
&ldquo;Communicating about Quantity without a Language Model: Number
Devices in Homesign Grammar&rdquo;, <em>Cognitive Psychology</em>,
67(1&ndash;2): 1&ndash;25. doi:10.1016/j.cogpsych.2013.05.003</li>

<li>Corina, David and Nicole Spotswood, 2012,
&ldquo;Neurolinguistics&rdquo;, in
 <a href="#PSW2012">Pfau, Steinbach, and Woll 2012</a>:
 739&ndash;762 (ch. 31). doi:10.1515/9783110261325.739</li>

<li>Cresswell, M. J., 1990, <em>Entities and Indices</em> (Studies in
Linguistics and Philosophy 41), Dordrecht/Boston: Kluwer Academic
Publishers.</li>

<li>Cuxac, Christian and Marie-Anne Sallandre, 2007, &ldquo;Iconicity
and Arbitrariness in French Sign Language: Highly Iconic Structures,
Degenerated Iconicity and Diagrammatic Iconicity&rdquo;, in <em>Verbal
and Signed Languages: Comparing Structures, Constructs and
Methodologies</em> (Empirical Approaches to Language Typology 36),
Elena Pizzuto, Paola Pietrandrea, and Raffaele Simone (eds.),
Berlin/New York: Mouton de Gruyter, 13&ndash;33.</li>

<li>Dachkovsky, Svetlana and Wendy Sandler, 2009, &ldquo;Visual
Intonation in the Prosody of a Sign Language&rdquo;, <em>Language and
Speech</em>, 52(2&ndash;3): 287&ndash;314.
doi:10.1177/0023830909103175</li>

<li>Davidson, Kathryn, 2013, &ldquo;&lsquo;And&rsquo; or
&lsquo;or&rsquo;: General Use Coordination in ASL&rdquo;,
<em>Semantics and Pragmatics</em>, 6: article 4 (44 pages).
doi:10.3765/sp.6.4</li>

<li>&ndash;&ndash;&ndash;, 2015, &ldquo;Quotation, Demonstration, and
Iconicity&rdquo;, <em>Linguistics and Philosophy</em>, 38(6):
477&ndash;520. doi:10.1007/s10988-015-9180-1</li>

<li>Davidson, Kathryn and Deanna Gagne, 2022, &ldquo;&lsquo;More Is
up&rsquo; for Domain Restriction in ASL&rdquo;, <em>Semantics and
Pragmatics</em>, 15: article 1 (52 pages). doi:10.3765/sp.15.1</li>

<li>Davidson, Kathryn, Annemarie Kocab, Andrea D. Sims, and Laura
Wagner, 2019, &ldquo;The Relationship between Verbal Form and Event
Structure in Sign Languages&rdquo;, <em>Glossa: A Journal of General
Linguistics</em>, 4(1): 123. doi:10.5334/gjgl.924</li>

<li>Deal, Amy Rose, 2020, <em>A Theory of Indexical Shift: Meaning,
Grammar, and Crosslinguistic Variation</em> (Linguistic Inquiry
Monographs 82), Cambridge, MA: The MIT Press.
doi:10.7551/mitpress/12374.001.0001</li>

<li>Elbourne, Paul D., 2005, <em>Situations and Individuals</em>
(Current Studies in Linguistics 41), Cambridge, MA: MIT Press.</li>

<li>Emmorey, Karen, 2002, <em>Language, Cognition, and the Brain:
Insights from Sign Language Research</em>, Mahwah, NJ: Lawrence
Erlbaum Associates.</li>

<li>&ndash;&ndash;&ndash;, 2014, &ldquo;Iconicity as Structure
Mapping&rdquo;, <em>Philosophical Transactions of the Royal Society B:
Biological Sciences</em>, 369(1651): 20130301.
doi:10.1098/rstb.2013.0301</li>

<li>Emmorey, Karen and Melissa Herzig, 2003, &ldquo;Categorical versus
Gradient Properties of Classifier Constructions in ASL&rdquo;, in
<em>Perspectives on Classifer Constructions in Sign Language</em>,
Karen Emmorey (ed.), Mahwah, NJ: Lawrence Erlbaum Associates,
222&ndash;246.</li>

<li>Evans, Gareth, 1980, &ldquo;Pronouns&rdquo;, <em>Linguistic
Inquiry</em>, 11(2): 337&ndash;362.</li>

<li>Frederiksen, Anne Therese and Rachel I. Mayberry, 2022,
&ldquo;Pronoun Production and Comprehension in American Sign Language:
The Interaction of Space, Grammar, and Semantics&rdquo;, <em>Language,
Cognition and Neuroscience</em>, 37(1): 80&ndash;102.
doi:10.1080/23273798.2021.1968013</li>

<li>Gagne, Deanna L. and Marie Coppola, 2017, &ldquo;Visible Social
Interactions Do Not Support the Development of False Belief
Understanding in the Absence of Linguistic Input: Evidence from Deaf
Adult Homesigners&rdquo;, <em>Frontiers in Psychology</em>, 8: article
837. doi:10.3389/fpsyg.2017.00837</li>

<li>Geach, Peter T., 1962, <em>Reference and Generality: An
Examination of Some Medieval and Modern Theories</em> (Contemporary
Philosophy), Ithaca, NY: Cornell University Press.</li>

<li>Goldin-Meadow, Susan and Diane Brentari, 2017, &ldquo;Gesture,
Sign, and Language: The Coming of Age of Sign Language and Gesture
Studies&rdquo;, <em>Behavioral and Brain Sciences</em>, 40: e46.
doi:10.1017/S0140525X15001247</li>

<li>Goldin-Meadow, Susan, Wing Chee So, Asl&#305; &Ouml;zy&uuml;rek,
and Carolyn Mylander, 2008, &ldquo;The Natural Order of Events: How
Speakers of Different Languages Represent Events Nonverbally&rdquo;,
<em>Proceedings of the National Academy of Sciences</em>, 105(27):
9163&ndash;9168. doi:10.1073/pnas.0710060105</li>

<li>Greenberg, Gabriel, 2013, &ldquo;Beyond Resemblance&rdquo;,
<em>The Philosophical Review</em>, 122(2): 215&ndash;287.
doi:10.1215/00318108-1963716</li>

<li>&ndash;&ndash;&ndash;, 2021, &ldquo;Semantics of Pictorial
Space&rdquo;, <em>Review of Philosophy and Psychology</em>, 12(4):
847&ndash;887. doi:10.1007/s13164-020-00513-6</li>

<li>Heim, Irene, 1982, <em>The Semantics of Definite and Indefinite
Noun Phrases</em>, Ph.D. Thesis, University of Massachusetts, Amherst,
Amherst, MA.</li>

<li>&ndash;&ndash;&ndash;, 1990, &ldquo;E-Type Pronouns and Donkey
Anaphora&rdquo;, <em>Linguistics and Philosophy</em>, 13(2):
137&ndash;177. doi:10.1007/BF00630732</li>

<li>Henderson, Robert, 2016, &ldquo;A Demonstration-Based Account of
(Pluractional) Ideophones&rdquo;, in <em>Proceedings of Semantics and
Linguistic Theory (SALT 26)</em>, Mary Morony, Carol-Rose Little,
Jacob Collard, and Dan Burgdorf (eds.), 664&ndash;683.
doi:10.3765/salt.v26i0.3786</li>

<li>Herrmann, Annika and Markus Steinbach, 2012, &ldquo;Quotation in
Sign Languages: A Visible Context Shift&rdquo;, in <em>Converging
Evidence in Language and Communication Research</em> (Converging
Evidence in Language and Communication Research 15), Isabelle
Buchstaller and Ingrid Van Alphen (eds.), Amsterdam: John Benjamins
Publishing Company, 203&ndash;228. doi:10.1075/celcr.15.12her</li>

<li>Jacobson, Pauline, 1999, &ldquo;Towards a Variable Free
Semantics&rdquo;, <em>Linguistics and Philosophy</em>, 22(2):
117&ndash;185. doi:10.1023/A:1005464228727</li>

<li>&ndash;&ndash;&ndash;, 2012, &ldquo;Direct Compositionality and
&lsquo;Uninterpretability&rsquo;: The Case of (Sometimes)
&lsquo;Uninterpretable&rsquo; Features on Pronouns&rdquo;, <em>Journal
of Semantics</em>, 29(3): 305&ndash;343. doi:10.1093/jos/ffs005</li>

<li>Kamp, Hans, 1981 [1984], &ldquo;A Theory of Truth and Semantic
Representation&rdquo;, in <em>Formal Methods in the Study of
Language</em> (Mathematical Centre Tracts 135), Jeroen A. G.
Groenendijk, Theo M. V. Janssen, and Martin J. B. Stokhof (eds.),
Amsterdam: Mathematisch Centrum. Reprinted in <em>Truth,
Interpretation and Information: Selected Papers from the Third
Amsterdam Colloquium</em>, Jeroen Groenendijk, Theo M. V. Janssen, and
Martin Stokhof (eds.), Berlin/Boston: De Gruyter, 1&ndash;42.
doi:10.1515/9783110867602.1</li>

<li>Kaplan, David, 1989, &ldquo;Demonstratives. An Essay on the
Semantics, Logic, Metaphysics, and Epistemology of Demonstratives and
Other Indexicals&rdquo;, in <em>Themes from Kaplan</em>, Joseph Almog,
John Perry, and Howard Wettstein (eds.), New York: Oxford University
Press, 481&ndash;563.</li>

<li>Klein, Ewan, 1980, &ldquo;A Semantics for Positive and Comparative
Adjectives&rdquo;, <em>Linguistics and Philosophy</em>, 4(1):
1&ndash;45. doi:10.1007/BF00351812</li>

<li>Koulidobrova, Elena, 2009, &ldquo;SELF: Intensifier and
&lsquo;long distance&rsquo; effects in ASL&rdquo;, <em>21st European
Summer School in Logic, Language, and Information</em>. Bordeaux,
Association for Logic Language and Information (FoLLI).
 [<a href="https://esslli2009.labri.fr/documents/04%20Koulidobrova%20ESSLLI%202009.pdf" target="other">Koulidobrova 2009 available online</a>]
 </li>

<li>Kuhn, Jeremy, 2015, <em>Cross-Categorial Singular and Plural
Reference in Sign Language</em>, Ph.D. Thesis, New York
University.</li>

<li>&ndash;&ndash;&ndash;, 2016, &ldquo;ASL Loci: Variables or
Features?&rdquo;, <em>Journal of Semantics</em>, 33(3): 449&ndash;491.
doi:10.1093/jos/ffv005</li>

<li>&ndash;&ndash;&ndash;, 2021, &ldquo;Discourse Anaphora:
Theoretical Perspectives&rdquo;, in <em>The Routledge Handbook of
Theoretical and Experimental Sign Language Research</em>, Josep Quer,
Roland Pfau, and Annika Herrmann (eds.), Abingdon/New York: Routledge,
458&ndash;479.</li>

<li>Kuhn, Jeremy and Valentina Aristodemo, 2017,
&ldquo;Pluractionality, Iconicity, and Scope in French Sign
Language&rdquo;, <em>Semantics and Pragmatics</em>, 10: article 6 (49
pages): doi:10.3765/sp.10.6</li>

<li>Lane, Harlan, 1984, <em>When the Mind Hears: A History of the
Deaf</em>, New York: Random House.</li>

<li>Liddell, Scott K., 1984, &ldquo;Unrealized-Inceptive Aspect in
American Sign Language: Feature Insertion in Syllabic Frames&rdquo;,
in <em>Papers from the Twentieth Regional Meeting of the Chicago
Linguistic Society</em>, Chicago: Chicago Linguistic Society,
257&ndash;270.</li>

<li>&ndash;&ndash;&ndash;, 2003, <em>Grammar, Gesture, and Meaning in
American Sign Language</em>, Cambridge/New York: Cambridge University
Press. doi:10.1017/CBO9780511615054</li>

<li>Lillo-Martin, Diane, 2012, &ldquo;Utterance Reports and
Constructed Action&rdquo;, in
 <a href="#PSW2012">Pfau, Steinbach, and Woll 2012</a>:
 365&ndash;387 (ch. 17). doi:10.1515/9783110261325.365</li>

<li>Lillo-Martin, Diane and Edward S. Klima, 1990, &ldquo;Pointing out
Differences: ASL Pronouns in Syntactic Theory&rdquo;, in
<em>Theoretical Issues in Sign Language Research: Volume 1,
Linguistics</em>, Susan D. Fischer and Patricia Siple (eds.), Chicago,
IL: The University of Chicago Press, 191&ndash;210.</li>

<li>Lin, Hao, Jeremy Kuhn, Huan Sheng, and Philippe Schlenker, 2021,
&ldquo;Timelines and Temporal Pointing in Chinese Sign
Language&rdquo;, <em>Glossa: A Journal of General Linguistics</em>,
6(1): article 133. doi:10.16995/glossa.5836</li>

<li>MacSweeney, Mair&eacute;ad, Cheryl M. Capek, Ruth Campbell, and
Bencie Woll, 2008, &ldquo;The Signing Brain: The Neurobiology of Sign
Language&rdquo;, <em>Trends in Cognitive Sciences</em>, 12(11):
432&ndash;440. doi:10.1016/j.tics.2008.07.010</li>

<li>Malaia, Evie, Ronnie B. Wilbur, and Marina Milkovi&#263;, 2013,
&ldquo;Kinematic Parameters of Signed Verbs&rdquo;, <em>Journal of
Speech, Language, and Hearing Research</em>, 56(5): 1677&ndash;1688.
doi:10.1044/1092-4388(2013/12-0257)</li>

<li>Matthewson, Lisa, 2001, &ldquo;Quantification and the Nature of
Crosslinguistic Variation&rdquo;, <em>Natural Language Semantics</em>,
9(2): 145&ndash;189. doi:10.1023/A:1012492911285</li>

<li>Meir, Irit, Wendy Sandler, Carol Padden, and Mark Aronoff, 2010,
&ldquo;Emerging Sign Languages&rdquo;, in <em>The Oxford Handbook of
Deaf Studies, Language, and Education</em>, Marc Marschark and
Patricia Elizabeth Spencer (eds.), Oxford/New York: Oxford University
Press, 2: 267&ndash;280.
doi:10.1093/oxfordhb/9780195390032.013.0018</li>

<li>Milkovi&#263;, Marina, 2011, <em>Verb classes in Croatian Sign
Language (HZJ): Syntactic and semantic properties</em>, PhD thesis,
University of Zagreb, Croatia.</li>

<li>Moltmann, Friederike, 2017, &ldquo;Natural Language
Ontology&rdquo;, in <em>Oxford Research Encyclopedia of
Linguistics</em>, Mark Aronoff (ed.), Oxford: Oxford University Press.
doi:10.1093/acrefore/9780199384655.013.330</li>

<li>Morford, Jill P. and Barbara H&auml;nel&#8208;Faulhaber, 2011,
&ldquo;Homesigners as Late Learners: Connecting the Dots from Delayed
Acquisition in Childhood to Sign Language Processing in
Adulthood&rdquo;, <em>Language and Linguistics Compass</em>, 5(8):
525&ndash;537. doi:10.1111/j.1749-818X.2011.00296.x</li>

<li>Napoli, Donna Jo, Nancy K. Mellon, John K. Niparko, Christian
Rathmann, Gaurav Mathur, Tom Humphries, Theresa Handley, Sasha
Scambler, and John D. Lantos, 2015, &ldquo;Should All Deaf Children
Learn Sign Language?&rdquo;, <em>Pediatrics</em>, 136(1):
170&ndash;176. doi:10.1542/peds.2014-1632</li>

<li>Napoli, Donna Jo, Rachel Sutton Spence, and Ronice M&uuml;ller de
Quadros, 2017, &ldquo;Influence of Predicate Sense on Word Order in
Sign Languages: Intensional and Extensional Verbs&rdquo;,
<em>Language</em>, 93(3): 641&ndash;670.
doi:10.1353/lan.2017.0039</li>

<li>Neidle, Carol Jan, Judy Kegl, Dawn MacLaughlin, Benjamin Bahan,
and Robert G. Lee (eds.), 2000, <em>The Syntax of American Sign
Language: Functional Categories and Hierarchical Structure</em>
(Language, Speech, and Communication), Cambridge, MA: MIT Press.</li>

<li>Ohori, Toshio, 2004, &ldquo;Coordination in Mentalese&rdquo;, in
<em>Coordinating Constructions</em> (Typological Studies in Language
58), Martin Haspelmath (ed.), Amsterdam: John Benjamins Publishing
Company, 41&ndash;66. doi:10.1075/tsl.58.04oho</li>

<li>Padden, Carol A., 1986, &ldquo;Verbs and Role-Shifting in American
Sign Language&rdquo;, <em>Proceedings of the Fourth National Symposium
on Sign Language Research and Teaching</em>, Silver Spring, MD:
National Association of the Deaf.</li>

<li>Partee, Barbara Hall, 1973, &ldquo;Some Structural Analogies
between Tenses and Pronouns in English&rdquo;, <em>The Journal of
Philosophy</em>, 70(18): 601&ndash;609. doi:10.2307/2025024</li>

<li>Pavli&#269;, Matic, 2016, &ldquo;The Word Order Parameter in
Slovenian Sign Language&#8239;: Transitive, Ditransitive, Classifier
and Locative Constructions&rdquo;, Doctoral Thesis, Universit&agrave;
Ca&rsquo; Foscari Venezia.</li>

<li>Pfau, Roland and Markus Steinbach, 2006, &ldquo;Pluralization in
Sign and in Speech: A Cross-Modal Typological Study&rdquo;,
<em>Linguistic Typology</em>, 10(2): 135&ndash;182.
doi:10.1515/LINGTY.2006.006</li>

<li>Pfau, Roland, Martin Salzmann, and Markus Steinbach, 2018,
&ldquo;The Syntax of Sign Language Agreement: Common Ingredients, but
Unusual Recipe&rdquo;, <em>Glossa: A Journal of General
Linguistics</em>, 3(1): article 107 (46 pages).
doi:10.5334/gjgl.511</li>

<li id="PSW2012">Pfau, Roland, Markus Steinbach, and Bencie Woll
(eds.), 2012, <em>Sign Language: An International Handbook</em>
(Handb&uuml;cher zur Sprach- und Kommunikationswissenschaft/Handbooks
of Linguistics and Communication Science 37), Berlin/Boston: De
Gruyter Mouton. doi:10.1515/9783110261325</li>

<li>Pinker, Steven, 1994, <em>The Language Instinct: How the Mind
Creates Language</em>, New York: William Morrow.</li>

<li>Postal, Paul, 1966, &ldquo;On so-called &lsquo;pronouns&rsquo; in
English&rdquo;, in <em>Report on the Seventeenth Annual Round Table
Meeting on Linguistics and Language Studies</em>, Washington, DC:
Georgetown University Press, pp. 177&ndash;206</li>

<li>Pustejovsky, James, 1991, &ldquo;The Syntax of Event
Structure&rdquo;, <em>Cognition</em>, 41(1&ndash;3): 47&ndash;81.
doi:10.1016/0010-0277(91)90032-Y</li>

<li>Quer, Josep, 2005, &ldquo;Context Shift and Indexical Variables in
Sign Languages&rdquo;, in <em>Proceedings of Semantics and Linguistic
Theory (SALT 15)</em>, 152&ndash;168. doi:10.3765/salt.v15i0.2923</li>

<li>&ndash;&ndash;&ndash;, 2013, &ldquo;Attitude Ascriptions in Sign
Languages and Role Shift&rdquo;, in <em>Proceedings of the
13<sup>th</sup> Meeting of the Texas Linguistics Society</em>, Leah C.
Geer (ed.), Austin: Texas Linguistics Forum, pp. 12&ndash;28.
 [<a href="https://tls.ling.utexas.edu/2012/proceedings/TLS13-02-Quer.pdf" target="other">Quer 2013 available online</a>]</li>
 
<li>Quine, Willard V., 1960, &ldquo;Variables Explained Away&rdquo;,
<em>Proceedings of the American Philosophical Society</em>, 104(3):
343&ndash;347.</li>

<li>Ramchand, Gillian, 2008, <em>Verb Meaning and the Lexicon: A
First-Phase Syntax</em> (Cambridge Studies in Linguistics 116),
Cambridge/New York: Cambridge University Press.
doi:10.1017/CBO9780511486319</li>

<li>Rothstein, Susan, 2004, <em>Structuring Events: A Study in the
Semantics of Lexical Aspect</em> (Explorations in Semantics),
Oxford/Malden, MA: Blackwell. doi:10.1002/9780470759127</li>

<li>Rubino, Carl, 2013, &ldquo;Reduplication&rdquo;, in <em>The Wolrd
Atlas of Language Structures Online</em> (v2020.3) [Data set], Matthew
S. Dryer and Martin Haspelmath (eds.), Leipzip: Max Planck Institute
for Evolutionary Anthropology.
 [<a href="https://wals.info/chapter/27" target="other">Rubino data set available online</a>]
 doi:10.5281/zenodo.7385533 </li>

<li>Sandler, Wendy and Diane C. Lillo-Martin, 2006, <em>Sign Language
and Linguistic Universals</em>, Cambridge/New York: Cambridge
University Press. doi:10.1017/CBO9781139163910</li>

<li>Sapir, Edward, 1921, <em>Language: An Introduction to the Study of
Speech</em>, New York: Harcourt, Brace and Company.</li>

<li>Schlenker, Philippe, 2018a, &ldquo;Visible Meaning: Sign Language
and the Foundations of Semantics&rdquo;, <em>Theoretical
Linguistics</em>, 44(3&ndash;4): 123&ndash;208.
doi:10.1515/tl-2018-0012</li>

<li>&ndash;&ndash;&ndash;, 2018b, &ldquo;Iconic Pragmatics&rdquo;,
<em>Natural Language &amp; Linguistic Theory</em>, 36(3):
877&ndash;936. doi:10.1007/s11049-017-9392-x</li>

<li>&ndash;&ndash;&ndash;, 2020, &ldquo;Gestural Grammar&rdquo;,
<em>Natural Language &amp; Linguistic Theory</em>, 38(3):
887&ndash;936. doi:10.1007/s11049-019-09460-z</li>

<li>Schlenker, Philippe, Marion Bonnet, Jonathan Lamberton, Jason
Lamberton, Emmanuel Chemla, Mirko Santoro, and Carlo Geraci, 2024,
&ldquo;Iconic Syntax: Sign Language Classifier Predicates and Gesture
Sequences&rdquo;, <em>Linguistics and Philosophy</em>, 47(1):
77&ndash;147. doi:10.1007/s10988-023-09388-z</li>

<li>Schlenker, Philippe and Jonathan Lamberton, 2022,
&ldquo;Meaningful Blurs: The Sources of Repetition-Based Plurals in
ASL&rdquo;, <em>Linguistics and Philosophy</em>, 45(2): 201&ndash;264.
doi:10.1007/s10988-020-09312-9</li>

<li>&ndash;&ndash;&ndash;, forthcoming, &ldquo;Iconological
Semantics&rdquo;, <em>Linguistics &amp; Philosophy</em>, accepted with
minor revisions.
 [<a href="https://lingbuzz.net/lingbuzz/007048" target="other">Schlenker &amp; Lamberton available online (lingbuzz/007048)</a>]
 <!-- lingbuzz/007048 needed in cite? --> </li>

<li>Schouwstra, Marieke and Henri&euml;tte De Swart, 2014, &ldquo;The
Semantic Origins of Word Order&rdquo;, <em>Cognition</em>, 131(3):
431&ndash;436. doi:10.1016/j.cognition.2014.03.004</li>

<li>von Stechow, Arnim, 2004, &ldquo;Binding by Verbs: Tense, Person,
and Mood under Attitudes&rdquo;, in <em>The Syntax and Semantics of
the Left Periphery</em> (Interface Explorations [IE] 9), Horst
Lohnstein and Susanne Trissler (eds.), Berlin/New York: De Gruyter,
431&ndash;488. doi:10.1515/9783110912111.431</li>

<li>Steinbach, Markus and Edgar Onea, 2016, &ldquo;A DRT Analysis of
Discourse Referents and Anaphora Resolution in Sign Language&rdquo;,
<em>Journal of Semantics</em>, 33(3): 409&ndash;448.
doi:10.1093/jos/ffv002</li>

<li>Stone, Matthew, 1997, &ldquo;The Anaphoric Parallel Between
Modality and Tense&rdquo;. <em>Technical Report MS-CIS-97-09</em>,
University of Pennsylvania, Department of Computer and Information
Science.
 [<a href="https://repository.upenn.edu/handle/20.500.14332/7078" target="other">Stone 1997 available online</a>]</li>
 
<li>Strickland, Brent, Carlo Geraci, Emmanuel Chemla, Philippe
Schlenker, Meltem Kelepir, and Roland Pfau, 2015, &ldquo;Event
Representations Constrain the Structure of Language: Sign Language as
a Window into Universally Accessible Linguistic Biases&rdquo;,
<em>Proceedings of the National Academy of Sciences</em>, 112(19):
5968&ndash;5973. doi:10.1073/pnas.1423080112</li>

<li>Supalla, Ted, 1982, <em>Structure and acquisition of verbs of
motion and location in American Sign Language</em>. Ph.D. Thesis,
University of California, San Diego.</li>

<li>Taub, Sarah F., 2001, <em>Language from the Body: Iconicity and
Metaphor in American Sign Language</em>, Cambridge/New York: Cambridge
University Press. doi:10.1017/CBO9780511509629</li>

<li>Wilbur, Ronnie B., 1996, &ldquo;Focus and Specificity in ASL
Structures Containing SELF&rdquo;, Linguistic Society of America
Annual Meeting, San Diego, January 1996.</li>

<li>&ndash;&ndash;&ndash;, 2003, &ldquo;Representations of Telicity in
ASL&rdquo;, in <em>Proceedings from the Annual Meeting of the Chicago
Linguistic Society</em>, 39(1): 354&ndash;368.</li>

<li>&ndash;&ndash;&ndash;, 2008, &ldquo;Complex Predicates Involving
Events, Time and Aspect: Is This Why Sign Languages Look So
Similar?&rdquo;, in <em>Signs of the time: Selected papers from TISLR
8 (2004)</em>, Josep Quer (ed.), Hamburg: Signum, pp.
217&ndash;250.</li>

<li>Wilbur, Ronnie B. and Evie Malaia, 2008, &ldquo;Event Visibility
Hypothesis: Motion Capture Evidence for Overt Marking of Telicity in
ASL&rdquo;, Linguistics Society of America Annual Meeting, Chicago,
January 2008. </li>

<li>Zucchi, Sandro, 2011, &ldquo;Event Descriptions and Classifier
Predicates in Sign Languages&rdquo;, Presentation given at FEAST in
Venice, 21 June 2011.</li>

<li>&ndash;&ndash;&ndash;, 2012, &ldquo;Formal Semantics of Sign
Languages&rdquo;, <em>Language and Linguistics Compass</em>, 6(11):
719&ndash;734. doi:10.1002/lnc3.348</li>

<li>&ndash;&ndash;&ndash;, 2017, &ldquo;Event Categorization in Sign
Languages&rdquo;, in <em>Handbook of Categorization in Cognitive
Science</em>, second edition, Henri Cohen and Claire Lefebvre (eds.),
Amsterdam: Elsevier, 377&ndash;396.
doi:10.1016/B978-0-08-101107-2.00016-6</li>
</ul>
</div> 

<div id="academic-tools">
<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=sign-language-semantics" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/sign-language-semantics/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=sign-language-semantics&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="https://philpapers.org/sep/sign-language-semantics/" target="other">Enhanced bibliography for this entry</a>
at <a href="https://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>
</div>

<div id="other-internet-resources">

<h2 id="Oth">Other Internet Resources</h2>

<ul>

<li>Cable, Seth, 2011,
 &ldquo;<a href="http://ling50.mit.edu/wp-content/uploads/Cable-handout.pdf" target="other">Understudied and Endangered Languages at the Semantics/Syntax Interface</a>&rdquo;
 (slides), presented at 50 Years of Linguistics at MIT: A Scientific
Reunion, 10 December 2011.</li>

<li>Ebert, Cornelia and Christian Ebert, 2014,
 &ldquo;<a href="https://www.semanticsarchive.net/Archive/GJjYzkwN/EbertEbert-SPE-2014-slides.pdf">Gestures, Demonstratives, and the Attributive/Referential Distinction</a>&rdquo;,
 slides of talk at Semantics and Philosophy in Europe 7, ZAS,
Berlin.</li>
</ul>
</div>

<div id="related-entries">

<h2 id="Rel">Related Entries</h2>

<p>

 <a href="../anaphora/">anaphora</a> |
 <a href="../innateness-language/">innateness: and language</a> |
 <a href="../logical-form/">logical form</a> |
 <a href="../natural-language-ontology/">ontology, natural language</a> |
 <a href="../plural-quant/">plural quantification</a> |
 <a href="../presupposition/">presupposition</a> |
 <a href="../quotation/">quotation</a> |
 <a href="../dynamic-semantics/">semantics: dynamic</a> |
 <a href="../tense-aspect/">tense and aspect</a>

 </p>
</div>

<div id="acknowledgments">

<h3>Acknowledgments</h3>

<p>
<strong>Author contributions:</strong> Schlenker and Kuhn wrote the
article. Lamberton commented and provided some of the ASL data.</p>

<p>
<strong>Acknowledgments:</strong> We are very grateful to Editor Ed
Zalta and to two anonymous reviewers for very constructive comments
and suggestions. Many thanks to Lucie Ravaux for help with the
formatting and with the bibliography.</p>

<p>
<strong>Funding:</strong> Schlenker, Lamberton, Kuhn: This research
received funding from the European Research Council (ERC) under the
European Union&rsquo;s Horizon 2020 research and innovation programme
(grant agreement No 788077, Orisem, PI: Schlenker).</p>

<p>
Schlenker, Kuhn: Research was conducted at the DEC, Ecole Normale
Sup&eacute;rieure - PSL Research University. The DEC is supported by
grant FrontCog ANR-17-EURE-0017.</p>
<script type="text/javascript" src="local.js"></script>
<script type="text/javascript" src="../../MathJax/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</div> 
</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2024</a> by

<br />
Philippe Schlenker
&lt;<a href="m&#97;ilto:philippe&#37;2eschlenker&#37;40gmail&#37;2ecom"><em>philippe<abbr title=" dot ">&#46;</abbr>schlenker<abbr title=" at ">&#64;</abbr>gmail<abbr title=" dot ">&#46;</abbr>com</em></a>&gt;<br />
Jeremy Kuhn
&lt;<a href="m&#97;ilto:jeremy&#37;2ed&#37;2ekuhn&#37;40gmail&#37;2ecom"><em>jeremy<abbr title=" dot ">&#46;</abbr>d<abbr title=" dot ">&#46;</abbr>kuhn<abbr title=" at ">&#64;</abbr>gmail<abbr title=" dot ">&#46;</abbr>com</em></a>&gt;<br />
Jonathan Lamberton
&lt;<a href="m&#97;ilto:jonlamberton&#37;40gmail&#37;2ecom"><em>jonlamberton<abbr title=" at ">&#64;</abbr>gmail<abbr title=" dot ">&#46;</abbr>com</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
            <li role="menuitem"><a href="../../new.html">What's New</a></li>
            <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li role="menuitem"><a href="../../published.html">Chronological</a></li>
            <li role="menuitem"><a href="../../archives/">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
            <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
            <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
            <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
            <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
            <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
            <li role="menuitem"><a href="../../accessibility.html">Accessibility</a></li>
            <li role="menuitem"><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
            <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
            <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2024</a> by <a href="https://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>
</html>
