<!doctype html>
<html lang="en-US">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="profile" href="https://gmpg.org/xfn/11">

	<script id="Cookiebot" src="https://consent.cookiebot.com/uc.js" data-cbid="095b91a6-f087-4380-b01d-e44b1c2af358" data-blockingmode="auto" type="text/javascript"></script>
	<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-XYTVD2CXR4"></script>
<script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());

	gtag('config', 'G-XYTVD2CXR4');
</script>

	<title>Defying Moore: Envisioning the Economics of a Semiconductor Revolution through 12nm Specialization &#8211; Communications of the ACM</title>
<meta name='robots' content='max-image-preview:large' />
	<style>img:is([sizes="auto" i], [sizes^="auto," i]) { contain-intrinsic-size: 3000px 1500px }</style>
	<link rel='dns-prefetch' href='//cdn.parsely.com' />
<link rel='dns-prefetch' href='//stats.wp.com' />
<link rel="alternate" type="application/rss+xml" title="Communications of the ACM &raquo; Feed" href="https://cacm.acm.org/feed/" />
<link rel="alternate" type="application/rss+xml" title="Communications of the ACM &raquo; Comments Feed" href="https://cacm.acm.org/comments/feed/" />
<link rel="alternate" type="application/rss+xml" title="Communications of the ACM &raquo; Defying Moore: Envisioning the Economics of a Semiconductor Revolution through 12nm Specialization Comments Feed" href="https://cacm.acm.org/research/defying-moore-envisioning-the-economics-of-a-semiconductor-revolution-through-12nm-specialization/feed/" />
<link rel="preload" href="https://cacm.acm.org/wp-content/themes/cacm/client/src/fonts/inter-v12-latin-regular.woff2" class="wp-asset-manager cacm-font-inter-regular-woff2" as="font" media="all" type="font/woff2" crossorigin /><link rel="preload" href="https://cacm.acm.org/wp-content/themes/cacm/client/src/fonts/inter-v12-latin-700.woff2" class="wp-asset-manager cacm-font-inter-700-woff2" as="font" media="all" type="font/woff2" crossorigin /><link rel="preload" href="https://cacm.acm.org/wp-content/themes/cacm/client/src/fonts/work-sans-bold.woff2?ver=1.0.0" class="wp-asset-manager cacm-font-work-sans-700-woff2" as="style" media="all" type="font/woff2" /><link rel="preload" href="https://cacm.acm.org/wp-content/themes/cacm/client/src/fonts/work-sans-extrabold.woff2?ver=1.0.0" class="wp-asset-manager cacm-font-work-sans-800-woff2" as="style" media="all" type="font/woff2" /><script class="wp-asset-manager usage-logger" type="text/javascript">window.amScripts = window.amScripts || {}; window.amScripts["usage-logger"] = {"nonce":"cb97c92390","id":768598,"type":"digital-library","doi":"10.1145\/3711920"}</script><style class="wp-asset-manager cacm-global-critical" type="text/css">@font-face{font-display:swap;font-family:Inter;font-style:normal;src:url(../be7cb18dc7caf47cf7e9.woff2) format("woff2"),url(../817c4274293e221c5076.woff) format("woff")}@font-face{font-display:swap;font-family:Inter;font-style:normal;font-weight:700;src:url(../54321e26b8bf4739a16d.woff2) format("woff2"),url(../7ad0df5561cc0933cead.woff) format("woff")}@font-face{font-display:swap;font-family:Work Sans;font-style:normal;font-weight:500;src:url(../2dd7c3c79fd1aa1d85ca.woff2) format("woff2"),url(../9a8cbe3b3bec955df411.woff) format("woff")}@font-face{font-display:swap;font-family:Work Sans;font-style:normal;font-weight:700;src:url(../ab8702255905c24de1c1.woff2) format("woff2"),url(../9ab52d2504cfe145b9bd.woff) format("woff")}@font-face{font-display:swap;font-family:Work Sans;font-style:normal;font-weight:800;src:url(../cef488e4e9f273a0a1e3.woff2) format("woff2"),url(../a99bf2b51c426338ae2c.woff) format("woff")}html{box-sizing:border-box}html *,html :after,html :before{box-sizing:inherit}a,abbr,address,article,aside,audio,b,blockquote,body,canvas,caption,cite,code,dd,del,details,dfn,div,dl,dt,em,embed,fieldset,figcaption,figure,footer,form,h1,h2,h3,h4,h5,h6,header,html,i,iframe,img,ins,kbd,label,legend,li,mark,menu,nav,object,ol,output,p,pre,q,ruby,s,samp,section,small,span,strike,strong,sub,summary,sup,table,tbody,td,tfoot,th,thead,time,tr,u,ul,var,video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}article,aside,details,figcaption,figure,footer,header,menu,nav,section{display:block}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:after,blockquote:before,q:after,q:before{content:"";content:none}table{border-collapse:collapse;border-spacing:0}fieldset{border:none;margin:0;padding:0}button,input,select,textarea{-webkit-appearance:none;-moz-appearance:none;appearance:none;border:0;border-radius:0;font:inherit;margin:0}button{background-color:transparent;padding:0}body,html{font-family:var(--wp--preset--font-family--inter);-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}html{scroll-padding-top:var(--wp--custom--siteheader-height)!important}body{overflow-x:hidden}a img{display:block}img{height:auto;max-width:100%}svg{display:block}.container{margin-left:auto;margin-right:auto;width:calc(min(100%,var(--wp--style--global--wide-size) + var(--wp--custom--site-edge)*2) - var(--wp--custom--site-edge)*2)}.screen-reader-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;padding:0;width:1px}.screen-reader-only,.skip-link{overflow:hidden;position:absolute}.skip-link{margin-left:auto;margin-right:auto;background-color:var(--wp--preset--color--white);color:inherit;left:0;opacity:0;padding:.625rem;right:0;text-align:center;text-decoration:none;top:0;transform:translateY(-100%);width:-moz-max-content;width:max-content;z-index:-1}.skip-link:focus{opacity:1;transform:translateY(0);z-index:2147483647}.site-content{padding-top:var(--wp--custom--siteheader-height)}@media(min-width:48rem){.site-content{padding-top:var(--wp--custom--siteheader-height)}}.site-header-hamburger-menu[aria-hidden=true]{display:none}.site-header-membership-nav{align-self:stretch;display:flex;position:relative}.site-header--expanded .site-header-membership-nav,.site-header:not(.site-header--member-logged-in) .site-header-membership-nav{display:none}.site-header{position:fixed;width:100%;z-index:7}.site-header--expanded{height:100%}.site-header--no-js{opacity:0}.site-header.headroom{transition:transform .2s linear;will-change:transform}.site-header.headroom--pinned{transform:translateY(0)}.site-header.headroom--unpinned{height:auto;transform:translateY(-100%)}.site-header-container{align-items:center;background-color:var(--wp--preset--color--white);border-bottom:var(--wp--custom--border-gray);display:flex;gap:1rem;height:var(--wp--custom--siteheader-height);justify-content:space-between;padding:0 1rem}.site-header-container a{text-decoration:none}.site-header-container a:active,.site-header-container a:focus,.site-header-container a:hover{text-decoration:underline;text-decoration-color:inherit;text-decoration-thickness:1px;text-underline-offset:2.5px}@media(min-width:37.5rem){.site-header-container{padding:0 1.5rem}}@media(min-width:48rem){.site-header-container{padding:0 0 0 1rem}}@media(min-width:64rem){.site-header-container{gap:2.25rem}}@media(min-width:80rem){.site-header-container{gap:3rem}}.site-header--member-logged-in .site-header-container{padding:0 0 0 1rem}@media(min-width:37.5rem){.site-header--member-logged-in .site-header-container{padding:0 0 0 1.5rem}}.site-header--expanded .site-header-container{background-color:var(--wp--preset--color--cacm-darker-blue)}@media(max-width:47.9375rem){.site-header-logo,.site-header-search{margin-left:auto}}.site-header-member-login-link{font-weight:var(--wp--custom--font-weight-bold)}.site-header-member-login-link[aria-hidden=true]{visibility:hidden}@media(max-width:47.9375rem){.site-header-member-login-link{display:none}}.site-header--member-logged-in .site-header-member-login-link{display:none}.site-header-magazine-menu,.site-header-topics-menu{position:relative}.site-header-magazine-menu-toggle,.site-header-topics-menu-toggle{font-size:.9375rem;font-weight:var(--wp--custom--font-weight-regular);line-height:1.21;align-items:center;cursor:pointer;display:flex;gap:.3333333333rem}@media(min-width:80rem){.site-header-magazine-menu-toggle,.site-header-topics-menu-toggle{font-size:1rem;font-weight:var(--wp--custom--font-weight-regular);line-height:1.21;gap:.65625rem}}.site-header-magazine-menu-toggle[aria-hidden=true],.site-header-topics-menu-toggle[aria-hidden=true]{visibility:hidden}.site-header-magazine-menu-toggle[aria-expanded=true]>svg,.site-header-topics-menu-toggle[aria-expanded=true]>svg{transform:rotate(180deg)}.site-header-magazine-menu-toggle:focus,.site-header-magazine-menu-toggle:hover,.site-header-topics-menu-toggle:focus,.site-header-topics-menu-toggle:hover{text-decoration:underline}.site-header-magazine-menu-expanded,.site-header-topics-menu-expanded{background-color:var(--wp--preset--color--white);border-radius:.3125rem;box-shadow:0 .125rem .25rem -.125rem rgba(24,39,75,.12),0 .25rem .25rem -.125rem rgba(24,39,75,.08);display:flex;gap:1.875rem;justify-content:space-between;padding:1.75rem 1.875rem 1.5rem;position:absolute;right:0;text-align:left;top:2.28125rem;white-space:nowrap;z-index:4}.site-header-magazine-menu-expanded[aria-hidden=true],.site-header-topics-menu-expanded[aria-hidden=true]{display:none}@media(max-width:47.9375rem){.site-header-magazine-menu,.site-header-topics-menu{display:none}}.site-header:not(.site-header--member-logged-in) .site-header-topics-menu-expanded{left:0;right:auto}</style><style class="wp-asset-manager cacm-article-critical" type="text/css">.article-header{left:50%;margin-left:-50vw;margin-right:-50vw;position:relative;right:50%;width:100vw;background-color:var(--cacm--article-header--background-color);border-bottom:1px solid var(--cacm--article-header--border-color);color:var(--cacm--article-header--text-color);margin-bottom:var(--wp--custom--gap)}@media(min-width:48rem){.article-header{grid-area:header;margin-bottom:1.5rem}}.article-header__inner{--wp--custom--vertical-block-rhythm:0.5rem;padding:2rem 0 0}@media(min-width:48rem){.article-header__inner{--wp--custom--vertical-block-rhythm:0.625rem;display:grid;gap:0 var(--cacm--article--gap);grid-template-columns:auto 1fr;padding:var(--cacm--article--gap) 0}}@media(min-width:64rem){.article-header__inner{grid-template-columns:var(--cacm--article--sidebarleft--width) 1fr}}.article-header__section{margin-bottom:var(--wp--custom--vertical-block-rhythm);display:inline-block}.article-header__section:last-child{margin-bottom:0}.article-header__section a{text-decoration:none}.article-header__section a:active,.article-header__section a:focus,.article-header__section a:hover{text-decoration:underline;text-decoration-color:inherit;text-decoration-thickness:1px;text-underline-offset:2.5px}@media(max-width:47.9375rem){.article-header__section{margin-right:.625rem}}@media(min-width:48rem){.article-header__section{grid-column:1/1;text-align:right}}.article-header__section>a{font-size:.875rem;font-weight:700;line-height:1.2142857143;background-color:var(--cacm--article-header--button--background-color);color:var(--cacm--article-header--button--text-color);display:inline-block;padding:.3125rem .625rem;text-transform:uppercase}@media(min-width:48rem){.article-header__figure,.article-header__meta,.article-header__share,.article-header__subtitle,.article-header__title,.article-header__topic-and-issue-section{grid-column:2/2}}.article-header__topic-and-issue-section{--wp--custom--vertical-block-rhythm:0.5rem;margin-bottom:var(--wp--custom--vertical-block-rhythm);font-size:.9375rem;line-height:1.5333333333;font-family:var(--wp--preset--font-family--inter);display:flex;flex-direction:column}.article-header__topic-and-issue-section:last-child{margin-bottom:0}@media(min-width:48rem){.article-header__topic-and-issue-section{--wp--custom--vertical-block-rhythm:1.25rem;align-items:center;flex-direction:row;gap:2rem}}.article-header__issue-section{color:var(--cacm--article-header--text-color)}.article-header__title{margin-bottom:var(--wp--custom--vertical-block-rhythm);font-family:var(--wp--preset--font-family--work-sans);font-size:var(--wp--preset--font-size--work-md);line-height:32.2px;font-weight:var(--wp--custom--font-weight-extrabold)}.article-header__title:last-child{margin-bottom:0}@media(min-width:48rem){.article-header__title{font-size:var(--wp--preset--font-size--work-xxxl);line-height:50.4px;font-weight:var(--wp--custom--font-weight-extrabold)}}@media(min-width:64rem){.article-header__title{font-size:var(--wp--preset--font-size--work-xxl);line-height:44.28px;font-weight:var(--wp--custom--font-weight-extrabold)}}.article-header__subtitle{font-family:var(--wp--preset--font-family--work-sans);font-size:var(--wp--preset--font-size--work-xxs);line-height:22.5px;font-weight:var(--wp--custom--font-weight-bold);font-size:1.3125rem;line-height:1.2380952381;letter-spacing:-.08px;font-weight:var(--wp--custom--font-weight-medium);letter-spacing:-.03125rem;margin-bottom:.125rem}.article-header__subtitle:last-child{margin-bottom:0}.article-header__subtitle a{word-break:break-word}.article-header__subtitle b,.article-header__subtitle strong{font-weight:var(--wp--custom--font-weight-bold)}.article-header__subtitle em,.article-header__subtitle i{font-style:italic}.article-header__subtitle del,.article-header__subtitle strike{text-decoration:line-through}.article-header__subtitle sub,.article-header__subtitle sup{font-size:75%;line-height:0;position:relative}.article-header__subtitle sub{bottom:-.25em}.article-header__subtitle sup{top:-.5em}.article-header__subtitle .monospace,.article-header__subtitle p code{font:var(--wp--custom--font-weight-regular) 90%/1.6 Courier,monospace}@media(min-width:48rem){.article-header__subtitle{--wp--custom--vertical-block-rhythm:1.25rem;font-family:var(--wp--preset--font-family--work-sans);font-size:var(--wp--preset--font-size--work-xs);line-height:25.2px;font-weight:var(--wp--custom--font-weight-bold);font-size:1.5625rem;line-height:1.2;letter-spacing:-.1px;font-weight:var(--wp--custom--font-weight-medium);letter-spacing:-.03125rem;margin:.5rem 0 .625rem}.article-header__subtitle:last-child{margin-bottom:0}}.article-header__meta{margin-bottom:var(--wp--custom--vertical-block-rhythm);font-size:.9375rem;line-height:1.5333333333;font-family:var(--wp--preset--font-family--inter);display:flex;flex-direction:column}.article-header__meta:last-child{margin-bottom:0}.article-header__meta>*{margin-bottom:var(--wp--custom--vertical-block-rhythm)}.article-header__meta>:last-child{margin-bottom:0}.article-header__byline{margin-top:.625rem}.article-header__byline>a{border-bottom:1px dotted var(--cacm--article-header--byline--text-color);color:var(--cacm--article-header--byline--text-color);text-decoration:none}@media(max-width:47.9375rem){.article-header__figure{left:50%;margin-left:-50vw;margin-right:-50vw;position:relative;right:50%;width:100vw}}@media(min-width:48rem){.article-header__figure{display:flex;flex-direction:column}}.article-header__figure .image-wrapper{margin-bottom:var(--wp--custom--vertical-block-rhythm)}.article-header__figure .image-wrapper:last-child{margin-bottom:0}@media(min-width:64rem){.article-header__figure .image-wrapper{grid-column:1/1}}.article-header__figure .image-wrapper>img{-o-object-fit:cover;object-fit:cover}.article-header__figure .video-wrapper{height:100%;overflow:hidden;position:relative;width:100%;padding-bottom:56.25%}.article-header__figure .video-wrapper>iframe{height:100%;left:0;-o-object-fit:contain;object-fit:contain;position:absolute;top:0;width:100%}.article-header__figure .video-wrapper>:not(iframe){display:none}.article-header__figure figcaption{font-size:.9375rem;line-height:1.4666666667;font-family:var(--wp--preset--font-family--inter);color:var(--cacm--article-header--caption--text-color)}@media(max-width:47.9375rem){.article-header__figure figcaption{margin:0 var(--wp--custom--site-edge)}}@media(min-width:64rem){.article-header__figure figcaption{grid-column:2/2;margin:0}}.article-header__figure figcaption>p.article-header--credit{font-style:italic}</style><script type="text/javascript">
/* <![CDATA[ */
window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.0.3\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.0.3\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/cacm.acm.org\/wp-includes\/js\/wp-emoji-release.min.js?ver=6.7.2"}};
/*! This file is auto-generated */
!function(i,n){var o,s,e;function c(e){try{var t={supportTests:e,timestamp:(new Date).valueOf()};sessionStorage.setItem(o,JSON.stringify(t))}catch(e){}}function p(e,t,n){e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(t,0,0);var t=new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data),r=(e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(n,0,0),new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data));return t.every(function(e,t){return e===r[t]})}function u(e,t,n){switch(t){case"flag":return n(e,"\ud83c\udff3\ufe0f\u200d\u26a7\ufe0f","\ud83c\udff3\ufe0f\u200b\u26a7\ufe0f")?!1:!n(e,"\ud83c\uddfa\ud83c\uddf3","\ud83c\uddfa\u200b\ud83c\uddf3")&&!n(e,"\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc65\udb40\udc6e\udb40\udc67\udb40\udc7f","\ud83c\udff4\u200b\udb40\udc67\u200b\udb40\udc62\u200b\udb40\udc65\u200b\udb40\udc6e\u200b\udb40\udc67\u200b\udb40\udc7f");case"emoji":return!n(e,"\ud83d\udc26\u200d\u2b1b","\ud83d\udc26\u200b\u2b1b")}return!1}function f(e,t,n){var r="undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?new OffscreenCanvas(300,150):i.createElement("canvas"),a=r.getContext("2d",{willReadFrequently:!0}),o=(a.textBaseline="top",a.font="600 32px Arial",{});return e.forEach(function(e){o[e]=t(a,e,n)}),o}function t(e){var t=i.createElement("script");t.src=e,t.defer=!0,i.head.appendChild(t)}"undefined"!=typeof Promise&&(o="wpEmojiSettingsSupports",s=["flag","emoji"],n.supports={everything:!0,everythingExceptFlag:!0},e=new Promise(function(e){i.addEventListener("DOMContentLoaded",e,{once:!0})}),new Promise(function(t){var n=function(){try{var e=JSON.parse(sessionStorage.getItem(o));if("object"==typeof e&&"number"==typeof e.timestamp&&(new Date).valueOf()<e.timestamp+604800&&"object"==typeof e.supportTests)return e.supportTests}catch(e){}return null}();if(!n){if("undefined"!=typeof Worker&&"undefined"!=typeof OffscreenCanvas&&"undefined"!=typeof URL&&URL.createObjectURL&&"undefined"!=typeof Blob)try{var e="postMessage("+f.toString()+"("+[JSON.stringify(s),u.toString(),p.toString()].join(",")+"));",r=new Blob([e],{type:"text/javascript"}),a=new Worker(URL.createObjectURL(r),{name:"wpTestEmojiSupports"});return void(a.onmessage=function(e){c(n=e.data),a.terminate(),t(n)})}catch(e){}c(n=f(s,u,p))}t(n)}).then(function(e){for(var t in e)n.supports[t]=e[t],n.supports.everything=n.supports.everything&&n.supports[t],"flag"!==t&&(n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&n.supports[t]);n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&!n.supports.flag,n.DOMReady=!1,n.readyCallback=function(){n.DOMReady=!0}}).then(function(){return e}).then(function(){var e;n.supports.everything||(n.readyCallback(),(e=n.source||{}).concatemoji?t(e.concatemoji):e.wpemoji&&e.twemoji&&(t(e.twemoji),t(e.wpemoji)))}))}((window,document),window._wpemojiSettings);
/* ]]> */
</script>
<style id='wp-emoji-styles-inline-css' type='text/css'>

	img.wp-smiley, img.emoji {
		display: inline !important;
		border: none !important;
		box-shadow: none !important;
		height: 1em !important;
		width: 1em !important;
		margin: 0 0.07em !important;
		vertical-align: -0.1em !important;
		background: none !important;
		padding: 0 !important;
	}
</style>
<link rel='stylesheet' id='wp-block-library-css' href='https://cacm.acm.org/wp-includes/css/dist/block-library/style.min.css?ver=6.7.2' type='text/css' media='all' />
<style id='wp-parsely-recommendations-style-inline-css' type='text/css'>
.parsely-recommendations-list-title{font-size:1.2em}.parsely-recommendations-list{list-style:none;padding:unset}.parsely-recommendations-cardbody{overflow:hidden;padding:.8em;text-overflow:ellipsis;white-space:nowrap}.parsely-recommendations-cardmedia{padding:.8em .8em 0}

</style>
<link rel='stylesheet' id='mediaelement-css' href='https://cacm.acm.org/wp-includes/js/mediaelement/mediaelementplayer-legacy.min.css?ver=4.2.17' type='text/css' media='all' />
<link rel='stylesheet' id='wp-mediaelement-css' href='https://cacm.acm.org/wp-includes/js/mediaelement/wp-mediaelement.min.css?ver=6.7.2' type='text/css' media='all' />
<style id='jetpack-sharing-buttons-style-inline-css' type='text/css'>
.jetpack-sharing-buttons__services-list{display:flex;flex-direction:row;flex-wrap:wrap;gap:0;list-style-type:none;margin:5px;padding:0}.jetpack-sharing-buttons__services-list.has-small-icon-size{font-size:12px}.jetpack-sharing-buttons__services-list.has-normal-icon-size{font-size:16px}.jetpack-sharing-buttons__services-list.has-large-icon-size{font-size:24px}.jetpack-sharing-buttons__services-list.has-huge-icon-size{font-size:36px}@media print{.jetpack-sharing-buttons__services-list{display:none!important}}.editor-styles-wrapper .wp-block-jetpack-sharing-buttons{gap:0;padding-inline-start:0}ul.jetpack-sharing-buttons__services-list.has-background{padding:1.25em 2.375em}
</style>
<style id='elasticpress-facet-style-inline-css' type='text/css'>
.widget_ep-facet input[type=search],.wp-block-elasticpress-facet input[type=search]{margin-bottom:1rem}.widget_ep-facet .searchable .inner,.wp-block-elasticpress-facet .searchable .inner{max-height:20em;overflow:scroll}.widget_ep-facet .term.hide,.wp-block-elasticpress-facet .term.hide{display:none}.widget_ep-facet .empty-term,.wp-block-elasticpress-facet .empty-term{opacity:.5;position:relative}.widget_ep-facet .empty-term:after,.wp-block-elasticpress-facet .empty-term:after{bottom:0;content:" ";display:block;left:0;position:absolute;right:0;top:0;width:100%;z-index:2}.widget_ep-facet .level-1,.wp-block-elasticpress-facet .level-1{padding-left:20px}.widget_ep-facet .level-2,.wp-block-elasticpress-facet .level-2{padding-left:40px}.widget_ep-facet .level-3,.wp-block-elasticpress-facet .level-3{padding-left:60px}.widget_ep-facet .level-4,.wp-block-elasticpress-facet .level-4{padding-left:5pc}.widget_ep-facet .level-5,.wp-block-elasticpress-facet .level-5{padding-left:75pt}.widget_ep-facet input[disabled],.wp-block-elasticpress-facet input[disabled]{cursor:pointer;opacity:1}.widget_ep-facet .term a,.wp-block-elasticpress-facet .term a{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex;position:relative}.widget_ep-facet .term a:hover .ep-checkbox,.wp-block-elasticpress-facet .term a:hover .ep-checkbox{background-color:#ccc}.ep-checkbox{-webkit-box-align:center;-ms-flex-align:center;-ms-flex-negative:0;-webkit-box-pack:center;-ms-flex-pack:center;align-items:center;background-color:#eee;display:-webkit-box;display:-ms-flexbox;display:flex;flex-shrink:0;height:1em;justify-content:center;margin-right:.25em;width:1em}.ep-checkbox:after{border:solid #fff;border-width:0 .125em .125em 0;content:"";display:none;height:.5em;-webkit-transform:rotate(45deg);transform:rotate(45deg);width:.25em}.ep-checkbox.checked{background-color:#5e5e5e}.ep-checkbox.checked:after{display:block}

</style>
<link rel='stylesheet' id='elasticpress-related-posts-block-css' href='https://cacm.acm.org/wp-content/mu-plugins/search/elasticpress/dist/css/related-posts-block-styles.min.css?ver=4.2.2' type='text/css' media='all' />
<style id='global-styles-inline-css' type='text/css'>
:root{--wp--preset--aspect-ratio--square: 1;--wp--preset--aspect-ratio--4-3: 4/3;--wp--preset--aspect-ratio--3-4: 3/4;--wp--preset--aspect-ratio--3-2: 3/2;--wp--preset--aspect-ratio--2-3: 2/3;--wp--preset--aspect-ratio--16-9: 16/9;--wp--preset--aspect-ratio--9-16: 9/16;--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--color--cacm-blue: #337AB5;--wp--preset--color--cacm-link-blue: #015FAC;--wp--preset--color--cacm-dark-blue: #1E4A88;--wp--preset--color--cacm-darker-blue: #29303C;--wp--preset--color--cacm-light-blue: #B6DEFF;--wp--preset--color--cacm-peach: #F7ACA5;--wp--preset--color--cacm-beige: #F5F2DC;--wp--preset--color--cacm-brown: #8C6A54;--wp--preset--color--cacm-green: #5F7D05;--wp--preset--color--cacm-light-green: #EFF7F1;--wp--preset--color--cacm-black: #141414;--wp--preset--color--cacm-gray-100: #FBFCFC;--wp--preset--color--cacm-gray-200: #F8F9FA;--wp--preset--color--cacm-gray-300: #EBEDEF;--wp--preset--color--cacm-gray-500: #A9ACB1;--wp--preset--color--cacm-gray-600: #5A6875;--wp--preset--color--cacm-gray-700: #3D4550;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--gradient--primary-gradient: linear-gradient(90deg, #80C2EF 0%, #337AB5 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;--wp--preset--font-size--work-xxxs: 16px;--wp--preset--font-size--work-xxs: 18px;--wp--preset--font-size--work-xs: 21px;--wp--preset--font-size--work-sm: 25px;--wp--preset--font-size--work-md: 28px;--wp--preset--font-size--work-lg: 33px;--wp--preset--font-size--work-xl: 37px;--wp--preset--font-size--work-xxl: 41px;--wp--preset--font-size--work-xxxl: 48px;--wp--preset--font-size--inter-xxxs: 15px;--wp--preset--font-size--inter-xxs: 18px;--wp--preset--font-size--inter-xs: 21px;--wp--preset--font-size--inter-sm: 24px;--wp--preset--font-size--inter-md: 28px;--wp--preset--font-size--inter-lg: 32px;--wp--preset--font-size--inter-xl: 36px;--wp--preset--font-size--inter-xxl: 41px;--wp--preset--font-size--inter-xxxl: 47px;--wp--preset--font-family--inter: 'Inter', helvetica, arial, sans-serif;--wp--preset--font-family--work-sans: 'Work Sans', helvetica, arial, sans-serif;--wp--preset--spacing--20: 0.44rem;--wp--preset--spacing--30: 0.67rem;--wp--preset--spacing--40: 1rem;--wp--preset--spacing--50: 1.5rem;--wp--preset--spacing--60: 2.25rem;--wp--preset--spacing--70: 3.38rem;--wp--preset--spacing--80: 5.06rem;--wp--preset--shadow--natural: 6px 6px 9px rgba(0, 0, 0, 0.2);--wp--preset--shadow--deep: 12px 12px 50px rgba(0, 0, 0, 0.4);--wp--preset--shadow--sharp: 6px 6px 0px rgba(0, 0, 0, 0.2);--wp--preset--shadow--outlined: 6px 6px 0px -3px rgba(255, 255, 255, 1), 6px 6px rgba(0, 0, 0, 1);--wp--preset--shadow--crisp: 6px 6px 0px rgba(0, 0, 0, 1);--wp--custom--adminbar-height: 0px;--wp--custom--siteheader-height: 72px;--wp--custom--site-edge: 20px;--wp--custom--gap: 40px;--wp--custom--gap-half: calc(var(--wp--custom--gap) / 2);--wp--custom--section-background-color: transparent;--wp--custom--placeholder-background-color: var(--wp--preset--color--cacm-gray-200);--wp--custom--vertical-block-rhythm: 40px;--wp--custom--border-gray: 1px solid var(--wp--preset--color--cacm-gray-300);--wp--custom--font-weight-regular: 400;--wp--custom--font-weight-medium: 500;--wp--custom--font-weight-bold: 700;--wp--custom--font-weight-extrabold: 900;}.wp-block-heading{--wp--preset--font-size--work-xxs: 18px;--wp--preset--font-size--work-xs: 21px;--wp--preset--font-size--work-sm: 25px;--wp--preset--font-size--work-md: 28px;--wp--preset--font-size--work-lg: 33px;--wp--preset--font-size--work-xl: 41px;}:root { --wp--style--global--content-size: 1280px;--wp--style--global--wide-size: 1280px; }:where(body) { margin: 0; }.wp-site-blocks > .alignleft { float: left; margin-right: 2em; }.wp-site-blocks > .alignright { float: right; margin-left: 2em; }.wp-site-blocks > .aligncenter { justify-content: center; margin-left: auto; margin-right: auto; }:where(.is-layout-flex){gap: 0.5em;}:where(.is-layout-grid){gap: 0.5em;}.is-layout-flow > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}.is-layout-flow > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}.is-layout-flow > .aligncenter{margin-left: auto !important;margin-right: auto !important;}.is-layout-constrained > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}.is-layout-constrained > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}.is-layout-constrained > .aligncenter{margin-left: auto !important;margin-right: auto !important;}.is-layout-constrained > :where(:not(.alignleft):not(.alignright):not(.alignfull)){max-width: var(--wp--style--global--content-size);margin-left: auto !important;margin-right: auto !important;}.is-layout-constrained > .alignwide{max-width: var(--wp--style--global--wide-size);}body .is-layout-flex{display: flex;}.is-layout-flex{flex-wrap: wrap;align-items: center;}.is-layout-flex > :is(*, div){margin: 0;}body .is-layout-grid{display: grid;}.is-layout-grid > :is(*, div){margin: 0;}body{padding-top: 0px;padding-right: 0px;padding-bottom: 0px;padding-left: 0px;}a:where(:not(.wp-element-button)){text-decoration: underline;}:root :where(.wp-element-button, .wp-block-button__link){background-color: #32373c;border-width: 0;color: #fff;font-family: inherit;font-size: inherit;line-height: inherit;padding: calc(0.667em + 2px) calc(1.333em + 2px);text-decoration: none;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-cacm-blue-color{color: var(--wp--preset--color--cacm-blue) !important;}.has-cacm-link-blue-color{color: var(--wp--preset--color--cacm-link-blue) !important;}.has-cacm-dark-blue-color{color: var(--wp--preset--color--cacm-dark-blue) !important;}.has-cacm-darker-blue-color{color: var(--wp--preset--color--cacm-darker-blue) !important;}.has-cacm-light-blue-color{color: var(--wp--preset--color--cacm-light-blue) !important;}.has-cacm-peach-color{color: var(--wp--preset--color--cacm-peach) !important;}.has-cacm-beige-color{color: var(--wp--preset--color--cacm-beige) !important;}.has-cacm-brown-color{color: var(--wp--preset--color--cacm-brown) !important;}.has-cacm-green-color{color: var(--wp--preset--color--cacm-green) !important;}.has-cacm-light-green-color{color: var(--wp--preset--color--cacm-light-green) !important;}.has-cacm-black-color{color: var(--wp--preset--color--cacm-black) !important;}.has-cacm-gray-100-color{color: var(--wp--preset--color--cacm-gray-100) !important;}.has-cacm-gray-200-color{color: var(--wp--preset--color--cacm-gray-200) !important;}.has-cacm-gray-300-color{color: var(--wp--preset--color--cacm-gray-300) !important;}.has-cacm-gray-500-color{color: var(--wp--preset--color--cacm-gray-500) !important;}.has-cacm-gray-600-color{color: var(--wp--preset--color--cacm-gray-600) !important;}.has-cacm-gray-700-color{color: var(--wp--preset--color--cacm-gray-700) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-cacm-blue-background-color{background-color: var(--wp--preset--color--cacm-blue) !important;}.has-cacm-link-blue-background-color{background-color: var(--wp--preset--color--cacm-link-blue) !important;}.has-cacm-dark-blue-background-color{background-color: var(--wp--preset--color--cacm-dark-blue) !important;}.has-cacm-darker-blue-background-color{background-color: var(--wp--preset--color--cacm-darker-blue) !important;}.has-cacm-light-blue-background-color{background-color: var(--wp--preset--color--cacm-light-blue) !important;}.has-cacm-peach-background-color{background-color: var(--wp--preset--color--cacm-peach) !important;}.has-cacm-beige-background-color{background-color: var(--wp--preset--color--cacm-beige) !important;}.has-cacm-brown-background-color{background-color: var(--wp--preset--color--cacm-brown) !important;}.has-cacm-green-background-color{background-color: var(--wp--preset--color--cacm-green) !important;}.has-cacm-light-green-background-color{background-color: var(--wp--preset--color--cacm-light-green) !important;}.has-cacm-black-background-color{background-color: var(--wp--preset--color--cacm-black) !important;}.has-cacm-gray-100-background-color{background-color: var(--wp--preset--color--cacm-gray-100) !important;}.has-cacm-gray-200-background-color{background-color: var(--wp--preset--color--cacm-gray-200) !important;}.has-cacm-gray-300-background-color{background-color: var(--wp--preset--color--cacm-gray-300) !important;}.has-cacm-gray-500-background-color{background-color: var(--wp--preset--color--cacm-gray-500) !important;}.has-cacm-gray-600-background-color{background-color: var(--wp--preset--color--cacm-gray-600) !important;}.has-cacm-gray-700-background-color{background-color: var(--wp--preset--color--cacm-gray-700) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-cacm-blue-border-color{border-color: var(--wp--preset--color--cacm-blue) !important;}.has-cacm-link-blue-border-color{border-color: var(--wp--preset--color--cacm-link-blue) !important;}.has-cacm-dark-blue-border-color{border-color: var(--wp--preset--color--cacm-dark-blue) !important;}.has-cacm-darker-blue-border-color{border-color: var(--wp--preset--color--cacm-darker-blue) !important;}.has-cacm-light-blue-border-color{border-color: var(--wp--preset--color--cacm-light-blue) !important;}.has-cacm-peach-border-color{border-color: var(--wp--preset--color--cacm-peach) !important;}.has-cacm-beige-border-color{border-color: var(--wp--preset--color--cacm-beige) !important;}.has-cacm-brown-border-color{border-color: var(--wp--preset--color--cacm-brown) !important;}.has-cacm-green-border-color{border-color: var(--wp--preset--color--cacm-green) !important;}.has-cacm-light-green-border-color{border-color: var(--wp--preset--color--cacm-light-green) !important;}.has-cacm-black-border-color{border-color: var(--wp--preset--color--cacm-black) !important;}.has-cacm-gray-100-border-color{border-color: var(--wp--preset--color--cacm-gray-100) !important;}.has-cacm-gray-200-border-color{border-color: var(--wp--preset--color--cacm-gray-200) !important;}.has-cacm-gray-300-border-color{border-color: var(--wp--preset--color--cacm-gray-300) !important;}.has-cacm-gray-500-border-color{border-color: var(--wp--preset--color--cacm-gray-500) !important;}.has-cacm-gray-600-border-color{border-color: var(--wp--preset--color--cacm-gray-600) !important;}.has-cacm-gray-700-border-color{border-color: var(--wp--preset--color--cacm-gray-700) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-primary-gradient-gradient-background{background: var(--wp--preset--gradient--primary-gradient) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}.has-work-xxxs-font-size{font-size: var(--wp--preset--font-size--work-xxxs) !important;}.has-work-xxs-font-size{font-size: var(--wp--preset--font-size--work-xxs) !important;}.has-work-xs-font-size{font-size: var(--wp--preset--font-size--work-xs) !important;}.has-work-sm-font-size{font-size: var(--wp--preset--font-size--work-sm) !important;}.has-work-md-font-size{font-size: var(--wp--preset--font-size--work-md) !important;}.has-work-lg-font-size{font-size: var(--wp--preset--font-size--work-lg) !important;}.has-work-xl-font-size{font-size: var(--wp--preset--font-size--work-xl) !important;}.has-work-xxl-font-size{font-size: var(--wp--preset--font-size--work-xxl) !important;}.has-work-xxxl-font-size{font-size: var(--wp--preset--font-size--work-xxxl) !important;}.has-inter-xxxs-font-size{font-size: var(--wp--preset--font-size--inter-xxxs) !important;}.has-inter-xxs-font-size{font-size: var(--wp--preset--font-size--inter-xxs) !important;}.has-inter-xs-font-size{font-size: var(--wp--preset--font-size--inter-xs) !important;}.has-inter-sm-font-size{font-size: var(--wp--preset--font-size--inter-sm) !important;}.has-inter-md-font-size{font-size: var(--wp--preset--font-size--inter-md) !important;}.has-inter-lg-font-size{font-size: var(--wp--preset--font-size--inter-lg) !important;}.has-inter-xl-font-size{font-size: var(--wp--preset--font-size--inter-xl) !important;}.has-inter-xxl-font-size{font-size: var(--wp--preset--font-size--inter-xxl) !important;}.has-inter-xxxl-font-size{font-size: var(--wp--preset--font-size--inter-xxxl) !important;}.has-inter-font-family{font-family: var(--wp--preset--font-family--inter) !important;}.has-work-sans-font-family{font-family: var(--wp--preset--font-family--work-sans) !important;}.wp-block-heading.has-work-xxs-font-size{font-size: var(--wp--preset--font-size--work-xxs) !important;}.wp-block-heading.has-work-xs-font-size{font-size: var(--wp--preset--font-size--work-xs) !important;}.wp-block-heading.has-work-sm-font-size{font-size: var(--wp--preset--font-size--work-sm) !important;}.wp-block-heading.has-work-md-font-size{font-size: var(--wp--preset--font-size--work-md) !important;}.wp-block-heading.has-work-lg-font-size{font-size: var(--wp--preset--font-size--work-lg) !important;}.wp-block-heading.has-work-xl-font-size{font-size: var(--wp--preset--font-size--work-xl) !important;}
:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}
:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}
:root :where(.wp-block-pullquote){font-size: 1.5em;line-height: 1.6;}
</style>
<link rel='stylesheet' id='qm-object-cache-style-css' href='https://cacm.acm.org/wp-content/mu-plugins/qm-plugins/qm-object-cache/css/style.css?ver=0.2' type='text/css' media='all' />
<link rel='stylesheet' id='cacm-global-css' href='https://cacm.acm.org/wp-content/themes/cacm/client/build/css/global.min.css?ver=917aa5edee76e173f6a5' type='text/css' media='all' />
<link rel='stylesheet' id='cacm-article-css' href='https://cacm.acm.org/wp-content/themes/cacm/client/build/css/article.min.css?ver=b9647d9dc6a60eb61132' type='text/css' media='all' />
<link rel="https://api.w.org/" href="https://cacm.acm.org/wp-json/" /><link rel="alternate" title="JSON" type="application/json" href="https://cacm.acm.org/wp-json/wp/v2/digital-library/768598" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://cacm.acm.org/xmlrpc.php?rsd" />
<meta name="generator" content="WordPress 6.7.2" />
<link rel="canonical" href="https://cacm.acm.org/research/defying-moore-envisioning-the-economics-of-a-semiconductor-revolution-through-12nm-specialization/" />
<link rel='shortlink' href='https://cacm.acm.org/?p=768598' />
<link rel="alternate" title="oEmbed (JSON)" type="application/json+oembed" href="https://cacm.acm.org/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fcacm.acm.org%2Fresearch%2Fdefying-moore-envisioning-the-economics-of-a-semiconductor-revolution-through-12nm-specialization%2F" />
<link rel="alternate" title="oEmbed (XML)" type="text/xml+oembed" href="https://cacm.acm.org/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fcacm.acm.org%2Fresearch%2Fdefying-moore-envisioning-the-economics-of-a-semiconductor-revolution-through-12nm-specialization%2F&#038;format=xml" />
        <style>
        .getty.aligncenter {
            text-align: center;
        }
        .getty.alignleft {
            float: none;
            margin-right: 0;
        }
        .getty.alignleft > div {
            float: left;
            margin-right: 5px;
        }
        .getty.alignright {
            float: none;
            margin-left: 0;
        }
        .getty.alignright > div {
            float: right;
            margin-left: 5px;
        }
        </style>
        	<style>img#wpstats{display:none}</style>
		<script type="application/ld+json" class="wp-parsely-metadata">{"@context":"https:\/\/schema.org","@type":"NewsArticle","headline":"Defying Moore: Envisioning the Economics of a Semiconductor Revolution through 12nm Specialization","url":"http:\/\/cacm.acm.org\/research\/defying-moore-envisioning-the-economics-of-a-semiconductor-revolution-through-12nm-specialization\/","mainEntityOfPage":{"@type":"WebPage","@id":"http:\/\/cacm.acm.org\/research\/defying-moore-envisioning-the-economics-of-a-semiconductor-revolution-through-12nm-specialization\/"},"thumbnailUrl":"https:\/\/cacm.acm.org\/wp-content\/uploads\/2025\/06\/062325.RE_.Defying-Moore.jpg?w=150&h=150&crop=1","image":{"@type":"ImageObject","url":"https:\/\/cacm.acm.org\/wp-content\/uploads\/2025\/06\/062325.RE_.Defying-Moore.jpg"},"articleSection":"Architecture and Hardware","author":[{"@type":"Person","name":"David Roman"}],"creator":["David Roman"],"publisher":{"@type":"Organization","name":"Communications of the ACM","logo":""},"keywords":[],"dateCreated":"2025-06-25T15:27:53Z","datePublished":"2025-06-25T15:27:53Z","dateModified":"2025-06-27T15:54:19Z"}</script><link rel="icon" href="https://cacm.acm.org/wp-content/uploads/2023/11/cropped-cropped-cacm_favicon-1.png?w=32" sizes="32x32" />
<link rel="icon" href="https://cacm.acm.org/wp-content/uploads/2023/11/cropped-cropped-cacm_favicon-1.png?w=192" sizes="192x192" />
<link rel="apple-touch-icon" href="https://cacm.acm.org/wp-content/uploads/2023/11/cropped-cropped-cacm_favicon-1.png?w=180" />
<meta name="msapplication-TileImage" content="https://cacm.acm.org/wp-content/uploads/2023/11/cropped-cropped-cacm_favicon-1.png?w=270" />
</head>

<body class="digital-library-template-default single single-digital-library postid-768598">
<svg xmlns="http://www.w3.org/2000/svg" focusable="false" height="0" role="none" style="left:-9999px;overflow:hidden;position:absolute" viewBox="0 0 0 0" width="0"><symbol id="am-symbol-icon-arrow-left" viewBox="0 0 18 12"><path clip-rule="evenodd" d="M18 6a.643.643 0 0 1-.643.643H2.196l4.046 4.044a.644.644 0 0 1-.91.91L.188 6.456a.643.643 0 0 1 0-.91L5.33.402a.644.644 0 1 1 .91.91L2.197 5.358h15.161A.643.643 0 0 1 18 6Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-arrow-right" viewBox="0 0 14 9"><path clip-rule="evenodd" d="M0 4.5A.5.5 0 0 1 .5 4h11.793L9.146.854a.5.5 0 1 1 .708-.708l4 4a.5.5 0 0 1 0 .708l-4 4a.5.5 0 1 1-.708-.708L12.293 5H.5a.5.5 0 0 1-.5-.5Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-comment" viewBox="0 0 19 20"><path clip-rule="evenodd" d="M1.781 1.542a.693.693 0 0 0-.693.693v11.876a.693.693 0 0 0 .693.693h2.375c.273 0 .494.221.494.494v2.574l3.96-2.97a.494.494 0 0 1 .296-.098h8.313a.693.693 0 0 0 .693-.694V2.236a.693.693 0 0 0-.693-.693H1.78ZM.592 1.046a1.681 1.681 0 0 1 1.19-.492h15.437A1.681 1.681 0 0 1 18.9 2.235v11.876a1.681 1.681 0 0 1-1.681 1.681H9.07l-4.618 3.464a.494.494 0 0 1-.79-.396v-3.068H1.78A1.682 1.682 0 0 1 .1 14.111V2.235c0-.446.177-.873.492-1.189Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-digital-library" viewBox="43 0 40 40"><g clip-path="url(#a)">
    <path d="m95.468 15.585-1.58 1.579c-.262.263-.584.41-.964.41h-6.813V4.707h6.813c.38 0 .702.146.965.409l1.579 1.579c.263.263.41.585.41.965v6.959c0 .38-.118.702-.41.965zm-1.9-7.544c0-.088-.03-.205-.118-.263l-.76-.76c-.088-.088-.146-.117-.263-.117H88.42v8.45h4.006c.117 0 .205-.03.263-.117l.76-.76a.357.357 0 0 0 .117-.264V8.04zm5.877 9.532v-2.047h2.309V6.754h-2.31V4.708h6.93v2.046h-2.31v8.772h2.31v2.047h-6.93zm19.853 0-.292-1.637-1.228 1.228c-.263.263-.585.41-.965.41h-3.918c-.38 0-.702-.147-.965-.41l-1.579-1.58a1.326 1.326 0 0 1-.409-.964V7.66c0-.38.146-.7.409-.964l1.579-1.579c.263-.263.585-.41.965-.41h5c.38 0 .701.147.965.41l1.666 1.667-1.549 1.55-1.316-1.316c-.088-.088-.146-.117-.263-.117h-4.006c-.117 0-.205.029-.263.117l-.761.76a.36.36 0 0 0-.117.263v6.199c0 .088.03.204.117.263l.761.76c.087.088.146.117.263.117h3.041c.117 0 .204-.03.263-.117l1.754-1.754c.088-.088.117-.146.117-.263v-.995h-3.187V10.06h5.497v4.97l.497 2.573h-2.076v-.029zm5.38 0v-2.047h2.31V6.754h-2.31V4.708h6.93v2.046h-2.31v8.772h2.31v2.047h-6.93zM140.029 6.9v10.644h-2.31V6.9h-3.713V4.708h9.737V6.9h-3.714zm14.299 10.673-1.229-3.216h-5.117l-1.228 3.216h-2.31l4.767-12.865h2.748l4.708 12.865h-2.339zm-3.772-10.38-1.784 5.088h3.567l-1.783-5.088zM160 17.573V4.708h2.31V15.35h6.316v2.193H160v.03zM86.111 35.41V22.543h2.31v10.643h6.316v2.193H86.11v.03zm11.813 0v-2.047h2.31V24.59h-2.31v-2.047h6.93v2.047h-2.31v8.772h2.31v2.046h-6.93zm20.497-1.638-1.257 1.257a1.28 1.28 0 0 1-.936.38h-7.164V22.544h7.164c.38 0 .673.146.936.38l1.257 1.257c.263.263.409.585.409.965v1.755c0 .38-.146.701-.409.965l-1.111 1.11 1.111 1.112c.263.263.409.584.409.965v1.783c0 .322-.146.673-.409.936zm-1.901-8.216c0-.117-.029-.205-.116-.264l-.439-.438c-.088-.088-.146-.117-.263-.117h-4.328v3.129h3.86c.088 0 .205-.03.263-.117l.877-.878c.088-.087.117-.146.117-.263v-1.052h.029zm0 5.789c0-.117-.029-.205-.116-.263l-.936-.936c-.088-.088-.146-.117-.263-.117h-3.831v3.158h4.328c.087 0 .204-.03.263-.117l.439-.438c.087-.088.116-.147.116-.264v-1.023zm14.65 4.065-3.802-4.884a.402.402 0 0 0-.321-.175h-1.404v5.058h-2.31V22.544h7.164c.38 0 .673.146.936.38l1.257 1.257c.263.263.409.585.409.965v2.544c0 .38-.146.702-.409.965l-1.257 1.257c-.263.263-.556.38-.936.38h-.468l3.977 5.059h-2.836v.058zm-.381-9.854c0-.117-.029-.205-.116-.264l-.439-.438c-.088-.088-.146-.117-.263-.117h-4.328v3.392h4.328c.117 0 .204-.03.263-.117l.439-.41c.087-.087.116-.146.116-.263v-1.783zm15.117 9.854-1.228-3.217h-5.117l-1.228 3.216h-2.31l4.766-12.865h2.749l4.708 12.865h-2.34zm-3.772-10.38-1.783 5.087h3.538l-1.755-5.088zm17.106 10.38-3.801-4.884a.405.405 0 0 0-.322-.175h-1.404v5.058h-2.309V22.544h7.163c.38 0 .673.146.936.38l1.257 1.257c.263.263.41.585.41.965v2.544c0 .38-.147.702-.41.965l-1.257 1.257c-.263.263-.556.38-.936.38h-.468l3.977 5.059h-2.836v.058zm-.41-9.854c0-.117-.029-.205-.117-.264l-.438-.438c-.088-.088-.146-.117-.263-.117h-4.328v3.392h4.328c.117 0 .204-.03.263-.117l.438-.41c.088-.087.117-.146.117-.263v-1.783zm11.696 4.152v5.672h-2.31v-5.672l-4.356-7.164h2.514l3.012 5 2.982-5h2.486l-4.328 7.164zM12.193 26.199 7.485 13.363H4.737L0 26.199h2.31l1.199-3.216h5.117l1.199 3.216h2.368zm-4.327-5.263h-3.54l1.784-5.088 1.755 5.088zm15.818 3.187-1.55-1.55-1.315 1.316c-.088.088-.146.117-.263.117h-3.188c-.116 0-.204-.03-.263-.117l-.76-.76a.357.357 0 0 1-.117-.264v-6.17c0-.087.03-.204.117-.262l.76-.76c.088-.088.146-.117.263-.117h3.188c.116 0 .204.029.263.117l1.316 1.315 1.55-1.55-1.668-1.666a1.326 1.326 0 0 0-.964-.41H16.87c-.38 0-.701.147-.965.41l-1.579 1.579a1.326 1.326 0 0 0-.409.965v6.959c0 .38.146.702.41.965l1.578 1.579c.264.263.585.41.965.41h4.182c.38 0 .701-.147.964-.41l1.667-1.696zm15.79 2.076V13.363h-3.538l-3.041 9.941-3.041-9.941h-3.538v12.836h2.251V15.994L31.696 26.2h2.398l3.128-10.205V26.2h2.252zM58.246 3.421l-5.351-1.403-1.404 5.35 3.86-1.052 2.895-2.895zm-4.474 4.532-7.72 2.106 1.17 4.385 6.55-6.49zm26.17 6.988 1.432-5.467-5.35-1.375 1.081 4.065 2.837 2.777zm-33.1 10.205-1.433 5.38 5.351 1.375-1.052-3.89-2.866-2.865zM73.333 2.66 68.89 3.89l6.579 6.579-2.135-7.807zm-.409 29.416 7.836-2.134-1.228-4.474-6.608 6.608zM68.45 36.55l5.468 1.433 1.404-5.351-4.065 1.081-2.807 2.837zm-15 .79 4.386-1.17-6.462-6.492 2.076 7.661zm26.2-13.656L83.332 20 71.637 8.304l-4.561-4.561L63.333 0l-6.52 6.52-9.708 9.708L43.333 20l6.58 6.579 9.707 9.707L63.333 40l6.492-6.491 9.824-9.825zm-16.434-.643c0 .35-.117.672-.38.906l-1.491 1.492c-.263.263-.556.38-.906.38h-6.462V13.626h6.462c.35 0 .672.117.906.38l1.491 1.491c.263.263.38.556.38.907v6.637zm3.597-9.415h2.193v10.117H75v2.076h-8.187V13.626z"></path>
    <path d="M60.205 15.819a.37.37 0 0 0-.264-.117h-3.8v8.04h3.8c.117 0 .176-.029.264-.116l.701-.702c.059-.088.117-.175.117-.263v-5.877a.357.357 0 0 0-.117-.264l-.701-.701z"></path>
  </g><defs>
    <clipPath id="a">
      <path d="M0 0h174.854v40H0z"></path>
    </clipPath>
  </defs></symbol><symbol id="am-symbol-icon-pdf-download" viewBox="0 0 19 20"><path clip-rule="evenodd" d="M1.781 1.542a.693.693 0 0 0-.693.693v13.063a.693.693 0 0 0 .693.694h4.75a.494.494 0 1 1 0 .988h-4.75A1.682 1.682 0 0 1 .1 15.298V2.235A1.681 1.681 0 0 1 1.78.554h8.415c.446 0 .873.177 1.188.492l2.274 2.274c.315.315.492.743.492 1.188v2.477a.494.494 0 1 1-.988 0V4.508a.694.694 0 0 0-.203-.49m0 0-2.273-2.273a.694.694 0 0 0-.49-.203H1.78m11.875 8.312a4.256 4.256 0 1 0 0 8.512 4.256 4.256 0 0 0 0-8.512Zm-5.244 4.257a5.244 5.244 0 1 1 10.488 0 5.244 5.244 0 0 1-10.488 0Zm5.244-2.87c.273 0 .494.222.494.495v3.557l.938-.938a.494.494 0 0 1 .699.698l-1.782 1.782a.494.494 0 0 1-.698 0l-1.781-1.782a.494.494 0 0 1 .698-.698l.938.938v-3.557c0-.273.221-.495.494-.495Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-print" viewBox="0 0 19 20"><path clip-rule="evenodd" d="M5.344 1.541a.693.693 0 0 0-.694.693v3.069h9.7V2.234a.693.693 0 0 0-.694-.693H5.344Zm9.994 3.762V2.234A1.681 1.681 0 0 0 13.656.553H5.344a1.681 1.681 0 0 0-1.682 1.681v3.069h-1.88A1.682 1.682 0 0 0 .1 6.984v5.938a1.682 1.682 0 0 0 1.681 1.681h1.881v4.257c0 .272.221.494.494.494h10.688a.494.494 0 0 0 .494-.494v-4.256h1.88a1.682 1.682 0 0 0 1.682-1.682V6.984a1.681 1.681 0 0 0-1.681-1.681h-1.881ZM1.78 6.291a.693.693 0 0 0-.693.693v5.938a.694.694 0 0 0 .693.694h1.881v-3.069c0-.273.221-.494.494-.494h10.688c.273 0 .494.221.494.494v3.069h1.88a.694.694 0 0 0 .694-.694V6.984a.693.693 0 0 0-.693-.693H1.78Zm12.569 4.75h-9.7v7.325h9.7V11.04ZM2.475 8.172c0-.273.22-.494.494-.494h1.187a.494.494 0 1 1 0 .988H2.97a.494.494 0 0 1-.494-.494Zm3.562 4.75c0-.273.221-.494.494-.494h5.938a.494.494 0 1 1 0 .988H6.53a.494.494 0 0 1-.494-.494Zm0 2.375c0-.273.221-.494.494-.494h4.157a.494.494 0 1 1 0 .988H6.53a.494.494 0 0 1-.494-.494Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-share" viewBox="0 0 19 18"><path clip-rule="evenodd" d="M14.844 1.73a2.475 2.475 0 1 0 0 4.949 2.475 2.475 0 0 0 0-4.95ZM11.38 4.203a3.463 3.463 0 1 1 .447 1.703L7.531 7.58a3.473 3.473 0 0 1-.087 1.873l4.555 2.278a3.463 3.463 0 1 1-.442.883L7 10.335a3.463 3.463 0 1 1 .171-3.677l4.298-1.671a3.473 3.473 0 0 1-.089-.783Zm1.242 8.407a2.475 2.475 0 1 0 4.441 2.187 2.475 2.475 0 0 0-4.44-2.187ZM4.156 5.886a2.475 2.475 0 1 0 0 4.95 2.475 2.475 0 0 0 0-4.95Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-bookmark" viewBox="0 0 13 19"><path clip-rule="evenodd" d="M12.05.948c-.293-.32-.7-.494-1.114-.494H2.007c-.421 0-.821.175-1.121.494a1.73 1.73 0 0 0-.457 1.186v15.488c0 .198.05.388.142.563.1.167.236.304.408.395a.89.89 0 0 0 .535.122.956.956 0 0 0 .522-.19l2.464-1.84h.007l1.964-1.459 1.958 1.46h.014l2.464 1.839c.15.114.329.182.522.19a.89.89 0 0 0 .535-.122 1.03 1.03 0 0 0 .4-.395c.1-.175.15-.365.15-.563V2.134c0-.449-.164-.874-.464-1.186ZM3.771 16.011 1.5 17.7s-.029.015-.05.022c-.014 0-.029-.007-.043-.015-.021-.008-.028-.023-.043-.038-.007-.015-.007-.03-.007-.053V2.134a.74.74 0 0 1 .186-.494.639.639 0 0 1 .464-.198h1.764v14.57Zm4.465-.691-1.5-1.125a.462.462 0 0 0-.536 0L4.7 15.32V1.442h3.536V15.32Zm3.35 2.378v-.053s-.015.015-.015.023a.089.089 0 0 1-.035.038c-.015 0-.036.015-.05.015-.015-.007-.036-.007-.05-.023l-2.272-1.687V1.442h1.772c.171 0 .335.069.457.198a.747.747 0 0 1 .193.494v15.564Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-bookmarked" viewBox="0 0 17 25"><path clip-rule="evenodd" d="M16.27.65C15.86.23 15.29 0 14.71 0H2.21A2.201 2.201 0 0 0 0 2.21v20.38c0 .26.07.51.2.74.14.22.33.4.57.52.23.13.49.18.75.16.26-.01.51-.1.73-.25l3.45-2.42h.01l1.15-.8 1.6-1.12 1.6 1.12 1.14.8h.02l3.45 2.42c.21.15.46.24.73.25.26.02.52-.03.75-.16.23-.12.43-.3.56-.52.14-.23.21-.48.21-.74V2.21c0-.59-.23-1.15-.65-1.56ZM4.68 20.47 1.5 22.69s-.04.02-.07.03c-.02 0-.04-.01-.06-.02-.03-.01-.04-.03-.06-.05V2.21c0-.24.09-.47.26-.65.17-.17.41-.26.65-.26h2.47v19.17h-.01Zm10.94 2.22v-.07s-.02.02-.02.03a.12.12 0 0 1-.05.05c-.02 0-.05.02-.07.02-.02-.01-.05-.01-.07-.03l-3.18-2.22V1.3h2.48a.9.9 0 0 1 .64.26c.17.18.27.41.27.65v20.48Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-chevron-down" viewBox="0 0 16 16"><path d="M1.646 4.646a.5.5 0 0 1 .708 0L8 10.293l5.646-5.647a.5.5 0 0 1 .708.708l-6 6a.5.5 0 0 1-.708 0l-6-6a.5.5 0 0 1 0-.708z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-search" viewBox="0 0 24 24"><path d="m23 21.85-6.145-6.146a8.966 8.966 0 1 0-1.151 1.15L21.849 23 23 21.85ZM2.656 9.98a7.324 7.324 0 1 1 7.324 7.324A7.332 7.332 0 0 1 2.656 9.98Z" fill="#015FAC"></path></symbol><symbol id="am-symbol-cacm-logo-small"><path d="M48.75 24c0 13.255-10.745 24-24 24s-24-10.745-24-24 10.745-24 24-24 24 10.745 24 24Z" fill="#fff"></path><path d="m24.998 9-15 15 15 15 15-15-15-15Z" fill="#027BA3"></path><path d="M34.196 24A9.195 9.195 0 0 1 25 33.196 9.195 9.195 0 0 1 15.804 24 9.195 9.195 0 0 1 25 14.804 9.195 9.195 0 0 1 34.196 24Z" fill="#fff"></path><path d="M33.28 24A8.275 8.275 0 0 1 25 32.275 8.275 8.275 0 0 1 16.72 24c0-4.57 3.705-8.28 8.28-8.28A8.276 8.276 0 0 1 33.28 24Z" fill="#027BA3"></path><path d="M20.18 25.613c-.084.07-.163.133-.23.191a1.641 1.641 0 0 1-.596.292c-.104.025-.25.041-.441.041-.35 0-.642-.116-.875-.354a1.219 1.219 0 0 1-.35-.891c0-.296.058-.534.175-.717.116-.183.287-.325.508-.433.225-.109.492-.184.804-.225.313-.042.646-.075 1.004-.1v-.021c0-.221-.083-.371-.241-.454-.163-.084-.405-.125-.73-.125-.145 0-.316.025-.512.079s-.388.12-.571.204h-.104v-.967c.12-.037.32-.079.596-.125.275-.05.55-.075.829-.075.687 0 1.187.117 1.5.342.312.23.47.575.47 1.046v2.712h-1.241v-.42h.004Zm0-.621v-.825c-.21.02-.38.041-.505.054-.13.017-.258.046-.38.091a.561.561 0 0 0-.253.171.488.488 0 0 0-.088.305c0 .187.05.312.15.383.1.07.246.104.442.104a.802.802 0 0 0 .329-.075c.113-.05.212-.12.304-.208ZM24.154 26.137c-.329 0-.633-.041-.904-.125a1.897 1.897 0 0 1-.712-.383c-.2-.17-.355-.387-.467-.65a2.336 2.336 0 0 1-.167-.925c0-.379.058-.704.183-.97.121-.267.284-.488.492-.659.2-.167.433-.288.7-.367a2.98 2.98 0 0 1 1.504-.046c.221.05.442.134.667.242v1.067h-.158c-.05-.046-.113-.1-.184-.154a1.673 1.673 0 0 0-.237-.159 1.349 1.349 0 0 0-.683-.175c-.317 0-.563.109-.738.33-.175.22-.262.516-.262.891 0 .4.091.696.279.892.187.196.433.296.741.296.155 0 .296-.017.413-.055a1.27 1.27 0 0 0 .517-.28c.058-.049.112-.099.154-.14h.158v1.062l-.246.108a2.925 2.925 0 0 1-.629.175 2.776 2.776 0 0 1-.417.026h-.004ZM30.867 26.033v-1.991c0-.196 0-.363-.013-.496a1.102 1.102 0 0 0-.062-.33.386.386 0 0 0-.167-.187.715.715 0 0 0-.317-.058.665.665 0 0 0-.279.062 1.99 1.99 0 0 0-.304.175v2.83h-1.242v-1.992c0-.192 0-.358-.012-.496a1 1 0 0 0-.067-.333.386.386 0 0 0-.166-.188.707.707 0 0 0-.313-.058c-.1 0-.2.025-.3.07-.096.05-.192.105-.283.167v2.83H26.1v-3.984h1.242v.438c.204-.175.396-.309.575-.405a1.27 1.27 0 0 1 .604-.145c.246 0 .458.058.642.175.183.116.325.287.42.516.238-.22.467-.391.675-.512.213-.121.425-.18.642-.18.183 0 .35.03.496.088.146.058.27.146.37.267.113.129.197.279.25.454.055.175.084.408.084.692v2.596h-1.242l.009-.005Z" fill="#fff"></path></symbol><symbol id="am-symbol-cacm-logo" viewBox="30.79 34.55 548.86 88.05"><path d="M54.75 71.41c-.8.8-1.77 1.2-2.85 1.2H39.52c-1.08 0-2.05-.4-2.85-1.2l-4.68-4.68c-.8-.8-1.2-1.77-1.2-2.85v-20.6c0-1.08.4-2.05 1.2-2.85l4.68-4.68c.8-.8 1.77-1.2 2.85-1.2H51.9c1.08 0 2.05.4 2.85 1.2l4.96 4.96-4.62 4.56-3.88-3.88c-.23-.23-.46-.34-.8-.34H41c-.34 0-.57.11-.8.34l-2.23 2.23c-.23.23-.34.51-.34.8v18.31c0 .29.11.57.34.8l2.23 2.23c.23.23.46.34.8.34h9.41c.34 0 .57-.11.8-.34l3.88-3.88 4.62 4.56-4.96 4.97zm44.5-4.68-4.68 4.68c-.8.8-1.77 1.2-2.85 1.2H76.83c-1.08 0-2.05-.4-2.85-1.2l-4.68-4.68c-.8-.8-1.2-1.77-1.2-2.85v-20.6c0-1.08.4-2.05 1.2-2.85l4.68-4.68c.8-.8 1.77-1.2 2.85-1.2h14.89c1.08 0 2.05.4 2.85 1.2l4.68 4.68c.8.8 1.2 1.77 1.2 2.85v20.6c0 1.08-.4 2.05-1.2 2.85zM93.6 44.42c0-.29-.11-.57-.34-.8l-2.23-2.23c-.23-.23-.46-.34-.8-.34H78.31c-.34 0-.57.11-.8.34l-2.23 2.23c-.23.23-.34.51-.34.8v18.31c0 .29.11.57.34.8l2.23 2.23c.23.23.46.34.8.34h11.92c.34 0 .57-.11.8-.34l2.23-2.23c.23-.23.34-.51.34-.8V44.42zm50.44 28.19V42.37l-9.3 30.24h-7.07l-9.3-30.24v30.24h-6.68V34.55h10.5l9.01 29.5 9.01-29.5h10.5V72.6h-6.67zm52.65 0V42.37l-9.3 30.24h-7.07l-9.3-30.24v30.24h-6.68V34.55h10.5l9.01 29.5 9.01-29.5h10.5V72.6h-6.67zm46.66-5.88-4.68 4.68c-.8.8-1.77 1.2-2.85 1.2h-11.47c-1.08 0-2.05-.4-2.85-1.2l-4.68-4.68c-.8-.8-1.2-1.77-1.2-2.85V34.55h6.85v28.18c0 .29.11.57.34.8l2.23 2.23c.23.23.46.34.8.34h8.5c.34 0 .57-.11.8-.34l2.23-2.23c.23-.23.34-.51.34-.8V34.55h6.85v29.33c-.01 1.08-.41 2.05-1.21 2.85zm32.69 5.88-12.55-29.5v29.5h-6.67V34.55h9.7l12.55 29.5v-29.5h6.67V72.6h-9.7zm20.82 0v-6.05h6.85V40.6h-6.85v-6.05h20.54v6.05h-6.85v25.96h6.85v6.05h-20.54zm53.46-1.2c-.8.8-1.77 1.2-2.85 1.2h-12.38c-1.08 0-2.05-.4-2.85-1.2l-4.68-4.68c-.8-.8-1.2-1.77-1.2-2.85v-20.6c0-1.08.4-2.05 1.2-2.85l4.68-4.68c.8-.8 1.77-1.2 2.85-1.2h12.38c1.08 0 2.05.4 2.85 1.2l4.96 4.96-4.62 4.56-3.88-3.88c-.23-.23-.46-.34-.8-.34h-9.41c-.34 0-.57.11-.8.34l-2.22 2.23c-.23.23-.34.51-.34.8v18.31c0 .29.11.57.34.8l2.22 2.23c.23.23.46.34.8.34h9.41c.34 0 .57-.11.8-.34l3.88-3.88 4.62 4.56-4.96 4.97zm39.47 1.2-3.59-9.53h-15.18l-3.6 9.53h-6.85l14.09-38.05h8.1l13.98 38.05h-6.95zm-11.18-30.7-5.25 15.06h10.5l-5.25-15.06zm35.94-.85v31.55h-6.85V41.06h-11.01v-6.5h28.87v6.5h-11.01zm19.27 31.55v-6.05h6.85V40.6h-6.85v-6.05h20.54v6.05h-6.85v25.96h6.85v6.05h-20.54zm61.89-5.88-4.68 4.68c-.8.8-1.77 1.2-2.85 1.2h-14.89c-1.08 0-2.05-.4-2.85-1.2l-4.68-4.68c-.8-.8-1.2-1.77-1.2-2.85v-20.6c0-1.08.4-2.05 1.2-2.85l4.68-4.68c.8-.8 1.77-1.2 2.85-1.2h14.89c1.08 0 2.05.4 2.85 1.2l4.68 4.68c.8.8 1.2 1.77 1.2 2.85v20.6c0 1.08-.4 2.05-1.2 2.85zm-5.64-22.31c0-.29-.11-.57-.34-.8l-2.22-2.23c-.23-.23-.46-.34-.8-.34h-11.92c-.34 0-.57.11-.8.34l-2.22 2.23c-.23.23-.34.51-.34.8v18.31c0 .29.12.57.34.8l2.22 2.23c.23.23.46.34.8.34h11.92c.34 0 .57-.11.8-.34l2.22-2.23c.23-.23.34-.51.34-.8V44.42zm37.65 28.19-12.55-29.5v29.5h-6.68V34.55h9.7l12.55 29.5v-29.5h6.68V72.6h-9.7zm50.72-5.88-4.68 4.68c-.8.8-1.77 1.2-2.85 1.2h-15.92c-1.08 0-2.05-.4-2.85-1.2l-4.85-4.85 4.56-4.62 3.82 3.82c.23.23.46.34.8.34h12.95c.34 0 .57-.11.8-.34l2.22-2.23c.23-.23.34-.51.34-.8v-3.65c0-.57-.51-1.08-1.08-1.14l-20.48-2.74c-2.23-.29-3.94-2.28-3.94-4.45v-7.47c0-1.08.4-2.05 1.2-2.85l4.68-4.68c.8-.8 1.77-1.2 2.85-1.2h15.92c1.08 0 2.05.4 2.85 1.2l4.85 4.85-4.56 4.62-3.82-3.82c-.23-.23-.46-.34-.8-.34H557.5c-.34 0-.57.11-.8.34l-2.22 2.23c-.23.23-.34.51-.34.8v3.65c0 .57.46 1.08 1.03 1.14l20.54 2.74c2.22.29 3.94 2.28 3.94 4.45v7.47c-.01 1.08-.41 2.05-1.21 2.85zM263.05 90.51l-.88.88c-.15.15-.33.22-.54.22h-2.79a.79.79 0 0 1-.54-.22l-.88-.88a.732.732 0 0 1-.22-.54v-3.86c0-.2.07-.38.22-.54l.88-.88c.15-.15.33-.22.54-.22h2.79c.2 0 .39.07.54.22l.88.88c.15.15.22.33.22.54v3.86c0 .2-.07.39-.22.54zm-1.06-4.19a.22.22 0 0 0-.06-.15l-.42-.42a.204.204 0 0 0-.15-.06h-2.24c-.06 0-.11.02-.15.06l-.42.42a.22.22 0 0 0-.06.15v3.43c0 .05.02.11.06.15l.42.42c.04.04.09.06.15.06h2.24c.06 0 .11-.02.15-.06l.42-.42c.04-.04.06-.1.06-.15v-3.43zm5.41 2.33v2.96h-1.28v-7.13h4.78v1.22h-3.5v1.73h3.5v1.22h-3.5zm12.04-2.96v5.92h-1.28v-5.92h-2.06v-1.22h5.41v1.22h-2.07zm8.45 5.92v-2.96h-2.86v2.96h-1.28v-7.13h1.28v2.95h2.86v-2.95h1.28v7.13h-1.28zm4.43 0v-7.13h4.78v1.22h-3.5v1.73h3.5v1.22h-3.5v1.74h3.5v1.22h-4.78zm30.16 30.99-3.59-9.53h-15.18l-3.59 9.53h-6.85l14.09-38.05h8.1l13.98 38.05h-6.96zM311.3 91.91l-5.25 15.06h10.5l-5.25-15.06zm49.12 29.49c-.8.8-1.77 1.2-2.85 1.2h-12.38c-1.08 0-2.05-.4-2.85-1.2l-4.68-4.68c-.8-.8-1.2-1.77-1.2-2.85v-20.6c0-1.08.4-2.05 1.2-2.85l4.68-4.68c.8-.8 1.77-1.2 2.85-1.2h12.38c1.08 0 2.05.4 2.85 1.2l4.96 4.96-4.62 4.56-3.88-3.88c-.23-.23-.46-.34-.8-.34h-9.41c-.34 0-.57.11-.8.34l-2.22 2.23c-.23.23-.34.51-.34.8v18.31c0 .29.12.57.34.8l2.22 2.23c.23.23.46.34.8.34h9.41c.34 0 .57-.12.8-.34l3.88-3.88 4.62 4.56-4.96 4.97zm47.51 1.2V92.36l-9.3 30.24h-7.07l-9.3-30.24v30.24h-6.68V84.55h10.5l9.01 29.5 9.01-29.5h10.5v38.05h-6.67z"></path></symbol><symbol id="am-symbol-icon-social-facebook"><path d="m22.723 20 .445-2.896h-2.779v-1.879c0-.792.388-1.564 1.633-1.564h1.263v-2.465S22.139 11 21.043 11c-2.289 0-3.784 1.387-3.784 3.898v2.206h-2.544V20h2.544v7h3.13v-7h2.334Z"></path></symbol><symbol id="am-symbol-icon-social-twitter"><path d="M27.613 13.657a7.057 7.057 0 0 1-2.03.557 3.54 3.54 0 0 0 1.555-1.955 7.08 7.08 0 0 1-2.245.857A3.53 3.53 0 0 0 22.313 12c-2.282 0-3.958 2.13-3.442 4.34a10.033 10.033 0 0 1-7.285-3.694 3.54 3.54 0 0 0 1.093 4.72 3.52 3.52 0 0 1-1.6-.442c-.038 1.637 1.135 3.169 2.835 3.51a3.542 3.542 0 0 1-1.596.06 3.538 3.538 0 0 0 3.301 2.454 7.106 7.106 0 0 1-5.232 1.465A10.006 10.006 0 0 0 15.804 26c6.562 0 10.27-5.542 10.046-10.513a7.195 7.195 0 0 0 1.763-1.83Z"></path></symbol><symbol id="am-symbol-icon-social-linkedin"><path d="M14.117 12.74c0 .96-.773 1.738-1.726 1.738a1.732 1.732 0 0 1-1.725-1.739c0-.96.772-1.739 1.725-1.739.953 0 1.726.78 1.726 1.74Zm.013 3.13h-3.478V27h3.479V15.87Zm5.553 0h-3.456V27h3.457v-5.843c0-3.248 4.194-3.514 4.194 0V27h3.47v-7.048c0-5.481-6.207-5.282-7.665-2.583v-1.5Z"></path></symbol><symbol id="am-symbol-icon-social-reddit"><path d="M27.764 21.071v.613c0 3.368-3.879 6.022-8.676 6.022-4.797 0-8.676-2.654-8.676-6.022v-.613c-1.122-.51-1.53-1.735-1.122-2.857.306-.817 1.123-1.327 1.939-1.225.612 0 1.123.204 1.531.612 1.735-1.122 3.776-1.837 5.818-1.837l1.122-5.103c0-.102.102-.204.102-.204.102-.102.205-.102.307-.102l3.572.816c.408-.714 1.327-1.123 2.041-.714.715.408 1.123 1.326.715 2.04-.409.715-1.327 1.124-2.042.715-.51-.204-.816-.714-.816-1.326l-3.164-.715-1.02 4.593c2.245.102 4.286.817 5.715 1.837.816-.816 2.245-.816 3.062 0 .408.408.612.919.612 1.531.306.919-.306 1.633-1.02 1.94Zm-11.942 1.123c.816 0 1.53-.714 1.53-1.53 0-.817-.714-1.532-1.53-1.532-.817 0-1.531.715-1.531 1.531 0 .817.612 1.531 1.53 1.531Zm7.042 1.94c-.204-.205-.408-.205-.51 0-.612.714-2.041.918-3.062.918-1.02 0-2.45-.204-3.062-.919-.204-.204-.408-.204-.51 0-.204.204-.204.409 0 .51 1.02 1.021 3.062 1.123 3.674 1.123.613 0 2.552-.102 3.675-1.122-.102-.102-.102-.306-.205-.51Zm1.225-3.47c0-.817-.714-1.532-1.53-1.532-.817 0-1.532.715-1.532 1.531 0 .817.715 1.531 1.531 1.531.817 0 1.531-.714 1.531-1.53Z"></path></symbol><symbol id="am-symbol-cacm-avatar-blank" viewBox="0 0 40 40"><g>
		<circle cx="20" cy="20" fill="var(--wp--preset--color--cacm-link-blue)" r="19" stroke="var(--wp--preset--color--cacm-link-blue)" stroke-width="2"></circle>
		<path clip-rule="evenodd" d="M5 33.23v-.73c0-4.987 9.994-7.5 15-7.5s15 2.513 15 7.5v.73A19.952 19.952 0 0 1 20 40a19.952 19.952 0 0 1-15-6.77ZM20 8.333a7.498 7.498 0 0 0-7.5 7.5c0 4.143 3.356 7.5 7.5 7.5s7.5-3.357 7.5-7.5c0-4.144-3.356-7.5-7.5-7.5Z" fill="var(--wp--preset--color--cacm-gray-200)" fill-rule="evenodd"></path>
	</g></symbol></svg><div id="page" class="site">
	<a class="skip-link" href="#content">Skip to content</a>

	<div class="site-header-wrapper" data-component="siteHeader">
		<header id="masthead" class="site-header site-header--no-js">
			<div class="site-header-container">
				
<button class="site-header-hamburger" aria-label="Main Menu">
	<span class="site-header-hamburger-closed">
		<svg xmlns="http://www.w3.org/2000/svg" version="1.2" viewBox="0 0 25 25">
	<path d="M.2.2h24.6v2.6H.2zm0 11h24.6v2.7H.2zm0 11h24.6v2.6H.2z" style="fill:#1a1a1a"/>
</svg>
 
	</span>
	<span class="site-header-hamburger-open">
		<svg xmlns="http://www.w3.org/2000/svg" version="1.2" viewBox="0 0 25 25">
	<path d="M1.7.9 24 23.8m-23 0L23.3.9" style="fill:none;stroke:#fff;stroke-width:1.3"/>
</svg>
 
	</span>
</button>
				<a class="site-header-logo" aria-label="Home" href="https://cacm.acm.org">
					<svg aria-hidden="true" focusable="false" width="548" height="88" fill="#000"><use href="#am-symbol-cacm-logo"></use></svg>					<svg aria-hidden="true" focusable="false" width="548" height="88" fill="#FFF"><use href="#am-symbol-cacm-logo"></use></svg>				</a>
				
<div class="site-header-topics-menu">
	<button class="site-header-topics-menu-toggle">
		Explore Topics		<svg xmlns="http://www.w3.org/2000/svg" width="14" height="8" fill="none">
	<path stroke="#1A1A1A" stroke-width="1.5" d="m1.5 1.5 5.5 5 5.5-5"/>
</svg>
 
	</button>
	<nav role="navigation" aria-label="Topics Menu" class="site-header-topics-menu-expanded" aria-hidden="true">
		<ul class="site-header-topics-menu-list">
																<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/architecture-and-hardware/">
							Architecture and Hardware						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/artificial-intelligence-machine-learning/">
							Artificial Intelligence and Machine Learning						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/computer-history/">
							Computer History						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/computing-applications/">
							Computing Applications						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/computing-profession/">
							Computing Profession						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/data-and-information/">
							Data and Information						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/education/">
							Education						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/hci/">
							HCI						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/philosophy-of-computing/">
							Philosophy of Computing						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/security-and-privacy/">
							Security and Privacy						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/society/">
							Society						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/software-engineering-and-programming-languages/">
							Software Engineering and Programming Languages						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/systems-and-networking/">
							Systems and Networking						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/theory/">
							Theory						</a>
					</li>
									</ul>
	</nav>
</div>
				
<div class="site-header-magazine-menu">
	<button class="site-header-magazine-menu-toggle">
		Latest Issue		<svg xmlns="http://www.w3.org/2000/svg" width="14" height="8" fill="none">
	<path stroke="#1A1A1A" stroke-width="1.5" d="m1.5 1.5 5.5 5 5.5-5"/>
</svg>
	</button>
	<nav role="navigation" aria-label="Magazine Menu" class="site-header-magazine-menu-expanded" aria-hidden="true">
					<a href="https://cacm.acm.org/issue/july-2025/">
				<figure class="site-header-magazine-menu-expanded-image">
					<div class="image-wrapper"><img width="1000" height="1338" src="https://cacm.acm.org/wp-content/uploads/2025/06/July-2025-Cover.1000x1338.jpg?w=1000" class="attachment-original size-original" alt="July 2025 cover" loading="lazy" decoding="async" srcset="https://cacm.acm.org/wp-content/uploads/2025/06/July-2025-Cover.1000x1338.jpg 1000w, https://cacm.acm.org/wp-content/uploads/2025/06/July-2025-Cover.1000x1338.jpg?resize=224,300 224w, https://cacm.acm.org/wp-content/uploads/2025/06/July-2025-Cover.1000x1338.jpg?resize=768,1028 768w, https://cacm.acm.org/wp-content/uploads/2025/06/July-2025-Cover.1000x1338.jpg?resize=765,1024 765w" sizes="auto, (max-width: 1000px) 100vw, 1000px" /></div>				</figure>
			</a>
				<div class="site-header-magazine-menu-expanded-text">
							<div class="site-header-magazine-menu-expanded-current">
					<h2 class="site-header-magazine-menu-expanded-heading">
						Latest Issue					</h2>
					<a href="https://cacm.acm.org/issue/july-2025/" class="site-header-magazine-menu-expanded-issue"><b>July 2025</b>, Vol. 68 No. 7</a>
				</div>
										<div class="site-header-magazine-menu-expanded-previous">
					<h2 class="site-header-magazine-menu-expanded-heading">
						Previous Issue					</h2>
					<a href="https://cacm.acm.org/issue/june-2025/" class="site-header-magazine-menu-expanded-issue"><b>June 2025</b>, Vol. 68 No. 6</a>
				</div>
						<a href="https://cacm.acm.org/issues" class="site-header-magazine-menu-expanded-link">
				Explore the archive				<svg xmlns="http://www.w3.org/2000/svg" width="12" height="10" fill="none" aria-hidden="true" tabindex="-1">
	<path fill="#000" d="m7 0-.715.697 3.79 3.803H0v1h10.075l-3.79 3.787L7 10l5-5-5-5Z"/>
</svg>
			</a>
		</div>
	</nav>
</div>
				
<a href="https://cacm.acm.org/?s=" aria-label="Search" class="site-header-search">
	<span class="site-header-search-text">
		Search	</span>
	<svg aria-hidden="true" focusable="false" width="24" height="24" class="site-header-search-icon"><use href="#am-symbol-icon-search"></use></svg></a>
				<nav class="site-header-membership-nav">
	<button class="site-header-membership-nav__button">
		<span
			class="site-header-membership-nav__button-text">Open Membership Navigation</span>
		<span class="site-header-membership-nav__button-icon">
			<svg aria-hidden="true" focusable="false" width="40" height="40" tabindex="-1"><use href="#am-symbol-cacm-avatar-blank"></use></svg>		</span>
	</button>
	<div class="site-header-membership-nav__menu-container" aria-hidden="true">
		<ul class="site-header-membership-nav__menu">
			<li class="site-header-membership-nav__menu-item">
				<a href="https://cacm.acm.org/account/settings">Settings</a>
			</li>
						<li class="site-header-membership-nav__menu-item">
				<a href="https://cacm.acm.org/logout/">Sign Out</a>
			</li>
		</ul>
	</div>
</nav>
<a class="site-header-member-login-link" href="https://cacm.acm.org/wp-login.php?saml_sso">Sign In</a>
<a href="https://cacm.acm.org/join-acm" class="site-header-cta-membership">
	<div class="site-header-cta-membership-container">
		<div class="site-header-cta-membership-text">
			Join ACM			<svg xmlns="http://www.w3.org/2000/svg" width="12" height="10" fill="none" aria-hidden="true" tabindex="-1">
	<path fill="#000" d="m7 0-.715.697 3.79 3.803H0v1h10.075l-3.79 3.787L7 10l5-5-5-5Z"/>
</svg>
		</div>
		<div class="site-header-cta-membership-logo">
			<svg aria-hidden="true" focusable="false" width="48" height="48"><use href="#am-symbol-cacm-logo-small"></use></svg>		</div>
	</div>
</a>
			</div>
			
<nav role="navigation" aria-label="Main Menu" class="site-header-hamburger-menu" aria-hidden="true">

	<!-- Search bar -->
	<form role="search" action="https://cacm.acm.org" method="get" class="site-header-hamburger-menu-search">
		<label for="site-navigation-expanded-search">
			<span class="site-header-hamburger-menu-search-icon">
					<svg xmlns="http://www.w3.org/2000/svg" width="21" height="21" fill="none">
		<path fill="#4C4C4C" d="m21 19.902-5.866-5.867a8.558 8.558 0 1 0-1.099 1.099L19.902 21 21 19.902ZM1.581 8.572a6.99 6.99 0 1 1 6.99 6.99 6.999 6.999 0 0 1-6.99-6.99Z"/>
	</svg>
			</span>
			<input type="text" name="s" id="site-navigation-expanded-search" class="site-header-hamburger-menu-search-input" placeholder="Search" value="" />
		</label>
	</form>

	<!-- Topics menu -->
	<div class="site-header-hamburger-menu-topics site-header-hamburger-menu-topics--expanded">
					<h2 class="site-header-hamburger-menu-heading">
				Topics				<span class="site-header-hamburger-menu-accordion-icon">
					<svg aria-hidden="true" focusable="false" width="16" height="16"><use href="#am-symbol-icon-chevron-down"></use></svg>				</span>
			</h2>
			<ul class="site-header-hamburger-menu-topics-menu">
																<li>
						<a href="https://cacm.acm.org/category/architecture-and-hardware/">
							Architecture and Hardware						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/artificial-intelligence-machine-learning/">
							Artificial Intelligence and Machine Learning						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/computer-history/">
							Computer History						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/computing-applications/">
							Computing Applications						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/computing-profession/">
							Computing Profession						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/data-and-information/">
							Data and Information						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/education/">
							Education						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/hci/">
							HCI						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/philosophy-of-computing/">
							Philosophy of Computing						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/security-and-privacy/">
							Security and Privacy						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/society/">
							Society						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/software-engineering-and-programming-languages/">
							Software Engineering and Programming Languages						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/systems-and-networking/">
							Systems and Networking						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/theory/">
							Theory						</a>
					</li>
										</ul>
			</div>

	<!-- Sections menu -->
	<div class="site-header-hamburger-menu-sections">
					<h2 class="site-header-hamburger-menu-heading">
				Sections				<span class="site-header-hamburger-menu-accordion-icon">
					<svg aria-hidden="true" focusable="false" width="16" height="16"><use href="#am-symbol-icon-chevron-down"></use></svg>				</span>
			</h2>
			<ul class="site-header-hamburger-menu-sections-menu">
																<li>
						<a href="https://cacm.acm.org/section/research/">
							Research and Advances						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/section/opinion/">
							Opinion						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/section/practice/">
							Practice						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/section/news/">
							News						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/section/research-highlights/">
							Research Highlights						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/section/careers/">
							Careers						</a>
					</li>
										</ul>
			</div>

	<!-- Magazine menu -->
	<div class="site-header-hamburger-menu-magazine">
		<h2 class="site-header-hamburger-menu-heading">
			Magazine			<span class="site-header-hamburger-menu-accordion-icon">
				<svg aria-hidden="true" focusable="false" width="16" height="16"><use href="#am-symbol-icon-chevron-down"></use></svg>			</span>
		</h2>
		<ul id="menu-magazine-header" class="site-header-hamburger-menu-magazine-menu"><li id="menu-item-217988" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-217988"><a href="/issue/latest/" id="menu-link-1">Latest Issue</a></li>
<li id="menu-item-217989" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-217989"><a href="/issues/" id="menu-link-2">Magazine Archive</a></li>
<li id="menu-item-224644" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224644"><a href="https://cacm.acm.org/editorial-staff-board/" id="menu-link-3">Editorial Staff and Board</a></li>
<li id="menu-item-751386" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-751386"><a href="https://cacm.acm.org/author-guidelines#CACMsubmission" id="menu-link-4">Submit an Article</a></li>
<li id="menu-item-224585" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224585"><a href="https://cacm.acm.org/feeds-2/" id="menu-link-5">Alerts &#038; Feeds</a></li>
<li id="menu-item-224645" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224645"><a href="https://cacm.acm.org/author-guidelines/" id="menu-link-6">Author Guidelines</a></li>
</ul>	</div>

	<div class="site-header-hamburger-menu-membership">
		<span class="site-header-hamburger-menu-membership-logo">
			<svg aria-hidden="true" focusable="false" width="49" height="48"><use href="#am-symbol-cacm-logo-small"></use></svg>		</span>
		<h2 class="site-header-hamburger-menu-heading site-header-hamburger-menu-membership-heading">
			CACM Web Account		</h2>
		<p class="site-header-hamburger-menu-membership-text">Membership in ACM includes a subscription to Communications of the ACM (CACM), the computing industry&#039;s most trusted source for staying connected to the world of advanced computing.</p>
		<div class="site-header-hamburger-menu-membership-buttons">
			<a href="https://cacm.acm.org/wp-login.php?saml_sso" class="site-header-hamburger-menu-membership-buttons-log-in">
				Sign In			</a>
			<a href="https://accounts.acm.org/" class="site-header-hamburger-menu-membership-buttons-sign-up">
				Sign Up			</a>
		</div>
	</div>

	<!-- Communications menu -->
	<div class="site-header-hamburger-menu-communications">
		<h2 class="site-header-hamburger-menu-heading">
			Communications of the ACM			<span class="site-header-hamburger-menu-accordion-icon">
				<svg aria-hidden="true" focusable="false" width="16" height="16"><use href="#am-symbol-icon-chevron-down"></use></svg>			</span>
		</h2>
		<ul id="menu-communications-header" class="site-header-hamburger-menu-communications-menu"><li id="menu-item-224641" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224641"><a href="https://cacm.acm.org/about-us/" id="menu-link-7">About Us</a></li>
<li id="menu-item-224663" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224663"><a href="https://cacm.acm.org/faq/" id="menu-link-8">Frequently Asked Questions</a></li>
<li id="menu-item-224640" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224640"><a href="https://cacm.acm.org/contact-us/" id="menu-link-9">Contact Us</a></li>
</ul>	</div>

	<div class="site-header-hamburger-menu-social">
		<h2 class="site-header-hamburger-menu-heading">
			Follow Us		</h2>
		<ul class="site-header-hamburger-menu-social-menu">
			<li>
				<a href="https://twitter.com/cacmmag">
					<span class="screen-reader-only">CACM on Twitter</span>
					<svg xmlns="http://www.w3.org/2000/svg" width="38" height="38" fill="none">
	<path fill="#1DA1F2" d="M27.613 13.657a7.057 7.057 0 0 1-2.03.557 3.54 3.54 0 0 0 1.555-1.955 7.08 7.08 0 0 1-2.245.857A3.53 3.53 0 0 0 22.313 12c-2.282 0-3.958 2.13-3.442 4.34a10.033 10.033 0 0 1-7.285-3.694 3.54 3.54 0 0 0 1.093 4.72 3.52 3.52 0 0 1-1.6-.442c-.038 1.637 1.135 3.169 2.835 3.51a3.542 3.542 0 0 1-1.596.06 3.538 3.538 0 0 0 3.301 2.454 7.106 7.106 0 0 1-5.232 1.465A10.006 10.006 0 0 0 15.804 26c6.562 0 10.27-5.542 10.046-10.513a7.195 7.195 0 0 0 1.763-1.83Z"/>
	<path fill="#000" d="M27.613 13.657a7.057 7.057 0 0 1-2.03.557 3.54 3.54 0 0 0 1.555-1.955 7.08 7.08 0 0 1-2.245.857A3.53 3.53 0 0 0 22.313 12c-2.282 0-3.958 2.13-3.442 4.34a10.033 10.033 0 0 1-7.285-3.694 3.54 3.54 0 0 0 1.093 4.72 3.52 3.52 0 0 1-1.6-.442c-.038 1.637 1.135 3.169 2.835 3.51a3.542 3.542 0 0 1-1.596.06 3.538 3.538 0 0 0 3.301 2.454 7.106 7.106 0 0 1-5.232 1.465A10.006 10.006 0 0 0 15.804 26c6.562 0 10.27-5.542 10.046-10.513a7.195 7.195 0 0 0 1.763-1.83Z"/>
	<rect width="37" height="37" x=".5" y=".5" stroke="#D8D8D8" rx="18.5"/>
</svg>
				</a>
			</li>
			<li>
				<a href="https://www.reddit.com/user/TheOfficialACM">
					<span class="screen-reader-only">CACM on Reddit</span>
					<svg xmlns="http://www.w3.org/2000/svg" width="38" height="38" fill="none">
	<path fill="#FF4500" d="M27.764 21.071v.613c0 3.368-3.879 6.022-8.676 6.022-4.797 0-8.676-2.654-8.676-6.022v-.613c-1.122-.51-1.53-1.735-1.122-2.857.306-.817 1.123-1.327 1.939-1.225.612 0 1.123.204 1.531.612 1.735-1.122 3.776-1.837 5.818-1.837l1.122-5.103c0-.102.102-.204.102-.204.102-.102.205-.102.307-.102l3.572.816c.408-.714 1.327-1.123 2.041-.714.715.408 1.123 1.326.715 2.04-.409.715-1.327 1.124-2.042.715-.51-.204-.816-.714-.816-1.326l-3.164-.715-1.02 4.593c2.245.102 4.286.817 5.715 1.837.816-.816 2.245-.816 3.062 0 .408.408.612.919.612 1.531.306.919-.306 1.633-1.02 1.94Zm-11.942 1.123c.816 0 1.53-.714 1.53-1.53 0-.817-.714-1.532-1.53-1.532-.817 0-1.531.715-1.531 1.531 0 .817.612 1.531 1.53 1.531Zm7.042 1.94c-.204-.205-.408-.205-.51 0-.612.714-2.041.918-3.062.918-1.02 0-2.45-.204-3.062-.919-.204-.204-.408-.204-.51 0-.204.204-.204.409 0 .51 1.02 1.021 3.062 1.123 3.674 1.123.613 0 2.552-.102 3.675-1.122-.102-.102-.102-.306-.205-.51Zm1.225-3.47c0-.817-.714-1.532-1.53-1.532-.817 0-1.532.715-1.532 1.531 0 .817.715 1.531 1.531 1.531.817 0 1.531-.714 1.531-1.53Z"/>
	<path fill="#000" d="M27.764 21.071v.613c0 3.368-3.879 6.022-8.676 6.022-4.797 0-8.676-2.654-8.676-6.022v-.613c-1.122-.51-1.53-1.735-1.122-2.857.306-.817 1.123-1.327 1.939-1.225.612 0 1.123.204 1.531.612 1.735-1.122 3.776-1.837 5.818-1.837l1.122-5.103c0-.102.102-.204.102-.204.102-.102.205-.102.307-.102l3.572.816c.408-.714 1.327-1.123 2.041-.714.715.408 1.123 1.326.715 2.04-.409.715-1.327 1.124-2.042.715-.51-.204-.816-.714-.816-1.326l-3.164-.715-1.02 4.593c2.245.102 4.286.817 5.715 1.837.816-.816 2.245-.816 3.062 0 .408.408.612.919.612 1.531.306.919-.306 1.633-1.02 1.94Zm-11.942 1.123c.816 0 1.53-.714 1.53-1.53 0-.817-.714-1.532-1.53-1.532-.817 0-1.531.715-1.531 1.531 0 .817.612 1.531 1.53 1.531Zm7.042 1.94c-.204-.205-.408-.205-.51 0-.612.714-2.041.918-3.062.918-1.02 0-2.45-.204-3.062-.919-.204-.204-.408-.204-.51 0-.204.204-.204.409 0 .51 1.02 1.021 3.062 1.123 3.674 1.123.613 0 2.552-.102 3.675-1.122-.102-.102-.102-.306-.205-.51Zm1.225-3.47c0-.817-.714-1.532-1.53-1.532-.817 0-1.532.715-1.532 1.531 0 .817.715 1.531 1.531 1.531.817 0 1.531-.714 1.531-1.53Z"/>
	<rect width="37" height="37" x=".5" y=".5" stroke="#D8D8D8" rx="18.5"/>
</svg>
				</a>
			</li>
			<li>
				<a href="https://www.linkedin.com/groups/36836/">
					<span class="screen-reader-only">CACM on LinkedIn</span>
					<svg xmlns="http://www.w3.org/2000/svg" width="38" height="38" fill="none">
	<path fill="#000" d="M14.117 12.74c0 .96-.773 1.738-1.726 1.738a1.732 1.732 0 0 1-1.725-1.739c0-.96.772-1.739 1.725-1.739.953 0 1.726.78 1.726 1.74Zm.013 3.13h-3.478V27h3.479V15.87Zm5.553 0h-3.456V27h3.457v-5.843c0-3.248 4.194-3.514 4.194 0V27h3.47v-7.048c0-5.481-6.207-5.282-7.665-2.583v-1.5Z"/>
	<rect width="37" height="37" x=".5" y=".5" stroke="#D8D8D8" rx="18.5"/>
</svg>
				</a>
			</li>
		</ul>
	</div>

</nav>
		</header>
	</div>

	<div id="content" class="site-content container">
		<div id="primary" class="content-area">
			<main id="main" class="site-main">

				
<article id="post-768598" class="post-768598 digital-library type-digital-library status-publish has-post-thumbnail hentry category-architecture-and-hardware category-artificial-intelligence-machine-learning issue-july-2025 section-research content-type-has-video content-type-video-archive">

			
<header class="article-header article-header--dark">
	<div class="article-header__inner container">
		<div class="article-header__section"><a href="https://cacm.acm.org/section/research/">Research and Advances</a></div>
		<div class="article-header__topic-and-issue-section">
			<span class="article-header__topic">
			<a href="https://cacm.acm.org/category/architecture-and-hardware/">Architecture and Hardware</a>			</span>
			<span class="article-header__issue-section">
							</span>
		</div>
		<h1 class="article-header__title">Defying Moore: Envisioning the Economics of a Semiconductor Revolution through 12nm Specialization</h1>
					<div class="article-header__subtitle"><p>Specialized 12nm semiconductors can outperform state-of-the-art 7nm and 5nm technology on deep-learning tasks, while offering gains in cost and sustainability.</p>
</div>
		
		<div class="article-header__meta">
			<div class="article-header__byline">
				By <a href="https://cacm.acm.org/author/michael-davies/" title="Posts by Michael Davies" class="author url fn" rel="author">Michael Davies</a> and <a href="https://cacm.acm.org/author/karthikeyan-sankaralingam/" title="Posts by Karthikeyan Sankaralingam" class="author url fn" rel="author">Karthikeyan Sankaralingam</a>			</div>
			<div class="article-header__posted-on">
				<span class="posted-on">Posted <time datetime="2025-06-25T11:27:53-04:00">Jun 25 2025</time></span>			</div>
		</div>

			<figure class="article-header__figure">
			<!-- Alternative image when Cookiebot blocks cookies for marketing purposes. -->
	<div class="cookieconsent-optout-statistics optout-placeholder">
		<div class="image-wrapper image-wrapper--widescreen"><img width="1024" height="576" src="https://cacm.acm.org/wp-content/uploads/2025/06/062325.RE_.Defying-Moore.jpg" class="attachment-full size-full" alt="colorful microchips" loading="eager" decoding="async" srcset="https://cacm.acm.org/wp-content/uploads/2025/06/062325.RE_.Defying-Moore.jpg 2400w, https://cacm.acm.org/wp-content/uploads/2025/06/062325.RE_.Defying-Moore.jpg?resize=300,169 300w, https://cacm.acm.org/wp-content/uploads/2025/06/062325.RE_.Defying-Moore.jpg?resize=768,432 768w, https://cacm.acm.org/wp-content/uploads/2025/06/062325.RE_.Defying-Moore.jpg?resize=1024,576 1024w, https://cacm.acm.org/wp-content/uploads/2025/06/062325.RE_.Defying-Moore.jpg?resize=1536,864 1536w, https://cacm.acm.org/wp-content/uploads/2025/06/062325.RE_.Defying-Moore.jpg?resize=2048,1152 2048w" sizes="(max-width: 1024px) 100vw, 1024px" /></div>	</div>
	<div class="video-wrapper cookieconsent-optin-statistics cookie-marketing-accepted" data-cookieconsent="marketing">
		<iframe title="vimeo-player" src="https://player.vimeo.com/video/1094382053?h=4703b28f49" width="640" height="360" frameborder="0" allowfullscreen></iframe>	</div>
	</figure>

		<div class="article-header__share">
			
<ul class="share">
	
<li class="share-link" data-component="share">
	<a href="#" class="share-toggle">
		<svg aria-hidden="true" focusable="false" width="19" height="18" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-share"></use></svg>		<span class="share-link-text">
			Share		</span>
	</a>
	<ul class="share-menu" aria-hidden="true">
		<li>
			<a href="https://twitter.com/intent/tweet?url=https://cacm.acm.org/research/defying-moore-envisioning-the-economics-of-a-semiconductor-revolution-through-12nm-specialization/&#038;text=Defying%20Moore:%20Envisioning%20the%20Economics%20of%20a%20Semiconductor%20Revolution%20through%2012nm%20Specialization" target="_blank">
				Twitter			</a>
		</li>
		<li>
			<a href="http://www.reddit.com/submit?url=https://cacm.acm.org/research/defying-moore-envisioning-the-economics-of-a-semiconductor-revolution-through-12nm-specialization/&#038;title=Defying%20Moore:%20Envisioning%20the%20Economics%20of%20a%20Semiconductor%20Revolution%20through%2012nm%20Specialization" target="_blank">
				Reddit			</a>
		</li>
		<li>
			<a href="https://news.ycombinator.com/submitlink?u=https://cacm.acm.org/research/defying-moore-envisioning-the-economics-of-a-semiconductor-revolution-through-12nm-specialization/&#038;t=Defying%20Moore:%20Envisioning%20the%20Economics%20of%20a%20Semiconductor%20Revolution%20through%2012nm%20Specialization" target="_blank">
				Hacker News			</a>
		</li>
	</ul>
</li>

<li class="share-link share-link-print" data-component="print">
	<a href="#" class="print">
		<svg aria-hidden="true" focusable="false" width="19" height="20" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-print"></use></svg>		<span class="share-link-text">
			Print		</span>
	</a>
</li>

	<li class="share-link share-link-discussion" data-component="share">
		<a class="share-link-comments" href="#comments">
			<svg aria-hidden="true" focusable="false" width="19" height="20" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-comment"></use></svg>			<span class="share-link-text">Join the Discussion</span>
		</a>
	</li>

<li class="share-link share-link-dl">
	<a href="https://dl.acm.org/doi/10.1145/3711920">
		<svg aria-hidden="true" focusable="false" width="21" height="21" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-digital-library"></use></svg>		<span class="share-link-text">
			View in the ACM Digital Library		</span>
		<svg aria-hidden="true" focusable="false" width="14" height="9" fill="var(--cacm--symbol--fill)" class="icon-dl"><use href="#am-symbol-icon-arrow-right"></use></svg>	</a>
</li>
</ul>
		</div>
	</div>
</header>

<section class="article-table-of-contents" data-component="articleToc">
			<ol class="article-table-of-contents__list">
			<ul>
<li><a href="#sec2">Key Questions and Framing</a></li>
<li><a href="#sec10">What Is the Role of Technology?</a></li>
<li><a href="#sec19">What Is the Role of Architecture?</a></li>
<li><a href="#sec36">Related Work</a></li>
<li><a href="#sec39">Conclusion</a></li>
<li><a href="#references">References</a></li>
<li><a href="#footnotes">Footnotes</a></li>
</ul>
		</ol>
	</section>
		<div class="article-contents">
			
<div class="article-content entry-content">
		<article><div class="body" lang="en"><section id="sec1" class="sec"><p id="p-1">The semiconductor industry is experiencing a significant transformation, raising questions about the advantages traditionally associated with Moore’s Law and Dennard scaling. This shift highlights four key trends that intersect with technology, economics, and society. The first trend is the <i>perceived end of Moore’s Law</i>. Analysis indicates that the benefits of advances in semiconductor technology—specifically in terms of cost, energy efficiency, and density—are diminishing (see Table <a class="xref xref-table" href="#T1" data-jats-ref-type="table" data-jats-rid="T1">1</a>). This suggests a departure from the era where technological advances consistently delivered substantial economic and performance improvements. The second trend is the <i>reevaluation of government subsidies.</i> In response to these technological challenges, governments worldwide have allocated significant subsidies to support the development of advanced chip-fabrication facilities. The economic justification for these investments, however, is being increasingly scrutinized, especially when considering the complex dynamics of workforce and ecosystem support that can affect the operational success of these facilities, as well as their time to becoming operational.<a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B36" data-jats-ref-type="bibr" data-jats-rid="B36"><sup>36</sup></a> The third trend is <i>access to semiconductor technology</i>. Recent policy measures have aimed to regulate access to certain semiconductor technologies based on geopolitical considerations.<a class="reference-link xref xref-bibr" href="#B10" data-jats-ref-type="bibr" data-jats-rid="B10"><sup>10</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B23" data-jats-ref-type="bibr" data-jats-rid="B23"><sup>23</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B25" data-jats-ref-type="bibr" data-jats-rid="B25"><sup>25</sup></a> In short, China is being prevented from accessing 7nm and lower technology.<a class="footnote-link xref xref-fn" href="#FN1" data-jats-rid="FN1" data-jats-ref-type="fn"><sup>a</sup></a> These measures are designed to address concerns over AI technological supremacy, but also must be understood within the context of the broader industry trend toward diminishing returns from further miniaturization. The fourth and final trend is the <i>role of architectural efficiency</i>. Economic and engineering considerations have prompted a renewed focus on architectural innovation. This trend illustrates how, despite the high costs of the latest technology nodes, thoughtful design at more accessible nodes, such as 12nm, can achieve competitive or even superior performance compared with designs at more advanced nodes, such as 5nm.<a class="reference-link xref xref-bibr" href="#B1" data-jats-ref-type="bibr" data-jats-rid="B1"><sup>1</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B33" data-jats-ref-type="bibr" data-jats-rid="B33"><sup>33</sup></a> This approach is also potentially more sustainable, offering reduced carbon footprints without compromising performance.<a class="reference-link xref xref-bibr" href="#B8" data-jats-ref-type="bibr" data-jats-rid="B8"><sup>8</sup></a> Together, these trends underscore a complex landscape where the relationship between technological scaling, economic viability, and environmental sustainability is being redefined, necessitating a nuanced understanding of the semiconductor industry’s future direction.</p><aside class="boxed-text"><div class="article-key-insights"><h2>Key Insights</h2><ul class="list" data-jats-list-type="bullet"><li class="list-item"><p id="p-2"> Performance gains in deep learning from advanced semiconductor nodes are limited, with scaling from 12nm to 3nm delivering substantially lower improvement (2.9x) than expected from classical Moore&#8217;s Law scaling (8x).</p></li><li class="list-item"><p id="p-3">Because of this, 12nm technology, combined with architectural specialization, can achieve performance in deep learning competitive with 7nm and 5nm designs, while reducing costs and improving sustainability.</p></li><li class="list-item"><p id="p-4">The diminishing returns from continued technology scaling highlight the importance of exploring cost-effective, specialized designs that address the growing computational demands of AI with better energy efficiency and economic viability.</p></li></ul></div></aside><figure id="T1" class="table-wrap" data-jats-position="float"><div class="caption"><span class="caption-label">Table 1. </span> <span class="p">Estimates of transistor cost, power, area, and timing scaling.<a class="reference-link xref xref-bibr" href="#B35" data-jats-ref-type="bibr" data-jats-rid="B35"><sup>35</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B40" data-jats-ref-type="bibr" data-jats-rid="B40"><sup>40</sup></a> <i>Note: all values are normalized to 12nm.</i></span></div><div class="table-container"><table class="table table-bordered table-condensed table-hover" data-jats-frame="hsides" data-jats-rules="rows"><colgroup> <col align="left" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> </colgroup><thead style="vertical-align: bottom;"><tr><th> </th><th style="text-align: left;">16nm</th><th style="text-align: left;">12nm</th><th style="text-align: left;">7nm</th><th style="text-align: left;">5nm</th><th style="text-align: left;">3nm</th></tr></thead><tbody><tr><td style="text-align: left;">Wafer price</td><td style="text-align: left;">1.00</td><td style="text-align: left;">1.00</td><td style="text-align: left;">1.69</td><td style="text-align: left;">2.11</td><td style="text-align: left;">2.62</td></tr><tr><td style="text-align: left;">Transistor cost</td><td style="text-align: left;">1.16</td><td style="text-align: left;">1.00</td><td style="text-align: left;">0.62</td><td style="text-align: left;">0.52</td><td style="text-align: left;">0.50</td></tr><tr><td style="text-align: left;">Area</td><td style="text-align: left;">1.16</td><td style="text-align: left;">1.00</td><td style="text-align: left;">0.40</td><td style="text-align: left;">0.22</td><td style="text-align: left;">0.14</td></tr><tr><td style="text-align: left;">Power</td><td style="text-align: left;">1.29</td><td style="text-align: left;">1.00</td><td style="text-align: left;">0.61</td><td style="text-align: left;">0.43</td><td style="text-align: left;">0.43</td></tr><tr><td style="text-align: left;">Delay</td><td style="text-align: left;">1.25</td><td style="text-align: left;">1.00</td><td style="text-align: left;">0.74</td><td style="text-align: left;">0.51</td><td style="text-align: left;">0.45</td></tr></tbody></table></div></figure><p id="p-6">In light of these trends, we observe that the relationship between <i>technology scaling</i> and <i>architecture</i> is not well understood. This is especially important to understand for high-capability deep-learning (DL) chips, given the popularity of DL applications. In this article, we seek to answer whether new AI chips can be built at 12nm technology using principles of specialization that match or exceed state-of-the-art (SOTA) chips made at 5nm or lower. We choose 12nm as a reference point because cost scaling beyond 12/10nm is less than 18% for successive nodes (shown in Table <a class="xref xref-table" href="#T1" data-jats-ref-type="table" data-jats-rid="T1">1</a>) and because it corresponds to the technology node at which the China bans come into effect.</p><p id="p-7">In our study, we sought to understand the benefits that technology scaling provides, as well as the benefits architectural innovation can bring over SOTA AI chips. To that end, we introduce the concept of <i>tiled decoupled control and compute</i> <i>(TDCC)</i> architecture, which encapsulates the evolution of AI chip architectures toward matrix engines integrated with decoupled data-movement mechanisms. One instantiation of a TDCC architecture is Galileo, which we use as a tangible example to help concretize our empirical results. Here are the key findings from our study:</p><ul class="list" data-jats-list-type="bullet"><li class="list-item"><p id="p-8">It confirms the well-established claim of the architecture field that specialization can provide large benefits also <i>applies to AI training and inference chips</i>, supplanting and superseding the benefits of technology scaling.</p></li><li class="list-item"><p id="p-9">Quantifying the role of technology scaling, we find that from 12nm to 3nm, device scaling provides a  best-case 2.9x improvement for “typical” DL workloads such as LLMs, when the die size is ≈ 800mm<sup>2</sup> at both nodes, contrary to the 8x conventionally expected from technology scaling. From 7nm to 3nm, this benefit is 1.45x.</p></li><li class="list-item"><p id="p-10">Setting aside the benefits of technology scaling, and isolating the benefits of architecture alone, we show that an architecture built at 12nm can surpass the performance of state-of-art 7nm (A100) and 5nm (H100) chips, by employing ideas from hardware specialization targeted to AI workloads.</p></li><li class="list-item"><p id="p-11">This new paradigm of specialized architecture, which pushes the limits of specialization at mature technology nodes like 12nm, can also improve the total coast of ownership (TCO), carbon footprint,<a class="reference-link xref xref-bibr" href="#B8" data-jats-ref-type="bibr" data-jats-rid="B8"><sup>8</sup></a> and economic productivity of the semiconductor industry—<i>even in regions where newer nodes are available</i>.</p></li></ul></section><section id="sec2" class="sec"><h2 class="heading">Key Questions and Framing</h2><p id="p-12">In this section, we first enumerate and explain the nuances behind our two key questions to determine what role technology scaling has independent of architecture. Then we describe the framing of our study in terms of the choice of platforms to compare to and a few of our simplifying assumptions. Finally, we describe our workloads in-depth, the TDCC terminology, and our modeling and simulation methodology.</p><section id="sec3" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Questions.</strong>  There are two key questions we seek to answer. The first is, <i>What is the role of technology?</i> Here we want to understand what the benefits are from technology scaling and how and whether new transistors can be effectively exploited by new chip architecture. The second question is, <i>What is the role of architecture?</i> We want to understand whether architectural changes are possible that can outperform SOTA chip implementations built at 7nm and 5nm. We define and then evaluate a practical TDCC architecture, Galileo, to empirically answer this question.</p><p data-jats-content-type="inline-heading"><strong>Framing.</strong></p></section><section id="sec4" class="inline-headings-section"><section id="sec5" class="inline-headings-section"><p data-jats-content-type="inline-heading"><i>SOTA platform choice. </i> Nvidia GPUs are the mainstream and practical option for <i>DL training </i>and, going by Nvidia chip-scarcity reports, probably for datacenter <i>inference</i> as well. Hence, we focus on matching that performance. In this work, we focus on big-iron datacenter chips, ignoring edge inference at the sub-200W regime. Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1</a> illustrates the chip-development process from the register transfer level (RTL) phase to chip bringup, showing a typical timeline of about 18 months. It showcases that creating new chips is a manageable effort that does not require years of development, making it accessible for diverse entities in the tech industry.</p><figure id="F1" class="fig" data-jats-position="float"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig01.jpg" data-type="image" data-caption="Figure 1. " href="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig01.jpg">
				<img decoding="async" class="graphic" title="Figure 1. " src="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig01.jpg" alt="" data-image-id="F1" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 1. </span> <span class="p">Typical chip design timeline at advanced nodes.</span><div class="figcaption-footer"> </div></figcaption></figure></section><section id="sec6" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Numerics.</em>  We assume the stability issues of FP16 can be addressed with the modest addition of FP32 capability without a substantial increase in area. In particular, we assume FP64 compute capability is not needed in substantial amounts.</p></section><section id="sec7" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>System scale.</em>  We focus on single-node training, with the observation that techniques for high-performance distributed training are orthogonal to single-node performance. Klenk et al.<a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a> show that perfect all-reduce improves performance by 10% to 40%.</p></section></section><section id="sec8" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Workload characterization.</strong>  We base our study on MLPerf, a standard benchmark for machine learning inference and training for hardware platforms,<a class="reference-link xref xref-bibr" href="#B29" data-jats-ref-type="bibr" data-jats-rid="B29"><sup>29</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B38" data-jats-ref-type="bibr" data-jats-rid="B38"><sup>38</sup></a> with application domains including image classification (ResNet50), object detection (SSD-ResNet34), speech recognition (RNN-T), recommendation systems (DLRM), medical image segmentation (UNET), and language transformers (BERT). LLMs like GPT3 and LLama2 have a DL-level architecture similar to BERT.</p><p id="p-19">Table <a class="xref xref-table" href="#T2" data-jats-ref-type="table" data-jats-rid="T2">2</a> presents a breakdown of the ResNet50 training mode by top contributing framework-level operations by percentage of runtime on V100 and A100 GPUs. Inference results in a similar breakdown for all applications, with backward operations not being present. We observe the operators found in MLPerf can be abstracted into three broad categories: <i>compute</i> operations, such as GEMMs, which often stress the compute resources of a chip; <i>element-wise</i> operations, which perform a small amount of independent computation for each element in a tensor; and <i>index and irregular access</i> operations, which involve retrieving memory through indirect addressing, often performing operations such as reductions or sorting. Based on the input tensor shapes to these operators, as well as the available machine resources such as peak compute, memory bandwidth, and OCN design, operators can become <i>compute heavy, latency heavy,</i> or <i>bandwidth heavy</i>. Table <a class="xref xref-table" href="#T3" data-jats-ref-type="table" data-jats-rid="T3">3</a> shows a breakdown of MLPerf (training) by percentage of runtime spent in each of these categories of operations for V100 and A100 GPUs. Again, inference is omitted since it is similar to training for all applications.</p><figure id="T2" class="table-wrap" data-jats-position="float"><div class="caption"><span class="caption-label">Table 2. </span> <span class="p">Top operators in ResNet50.</span></div><div class="table-container"><table class="table table-bordered table-condensed table-hover" data-jats-frame="hsides" data-jats-rules="rows"><colgroup> <col align="left" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> </colgroup><thead style="vertical-align: bottom;"><tr><th style="text-align: left;">Op Name</th><th style="text-align: left;">V100</th><th style="text-align: left;">A100</th></tr></thead><tbody><tr><td style="text-align: left;">batch_norm-bwd</td><td style="text-align: left;">24.60%</td><td style="text-align: left;">29.11%</td></tr><tr><td style="text-align: left;">batch_norm</td><td style="text-align: left;">15.36%</td><td style="text-align: left;">21.14%</td></tr><tr><td style="text-align: left;">conv-bwd</td><td style="text-align: left;">28.38%</td><td style="text-align: left;">20.57%</td></tr><tr><td style="text-align: left;">conv</td><td style="text-align: left;">13.05%</td><td style="text-align: left;">10.52%</td></tr><tr><td style="text-align: left;">add</td><td style="text-align: left;">6.42%</td><td style="text-align: left;">6.57%</td></tr><tr><td style="text-align: left;">threshold_backward</td><td style="text-align: left;">5.32%</td><td style="text-align: left;">5.26%</td></tr><tr><td style="text-align: left;">relu</td><td style="text-align: left;">3.62%</td><td style="text-align: left;">3.46%</td></tr><tr><td style="text-align: left;">max_pool2d_with_indices_backward</td><td style="text-align: left;">2.42%</td><td style="text-align: left;">2.35%</td></tr><tr><td style="text-align: left;">Other</td><td style="text-align: left;">0.83%</td><td style="text-align: left;">1.02%</td></tr></tbody></table></div></figure><figure id="T3" class="table-wrap" data-jats-position="float"><div class="caption"><span class="caption-label">Table 3. </span> <span class="p">Fraction of runtime based on operator type.</span></div><div class="table-container"><table class="table table-bordered table-condensed table-hover" data-jats-frame="hsides" data-jats-rules="rows"><colgroup> <col align="left" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> </colgroup><thead style="vertical-align: bottom;"><tr><th> </th><th style="text-align: center;" colspan="3">V100</th><th style="text-align: center;" colspan="3">A100</th></tr></thead><tbody><tr><td style="text-align: left;"><b>App Name</b></td><td style="text-align: left;"><b>EX</b></td><td style="text-align: left;"><b>LAT</b></td><td style="text-align: left;"><b>BW</b></td><td style="text-align: left;"><b>EX</b></td><td style="text-align: left;"><b>LAT</b></td><td style="text-align: left;"><b>BW</b></td></tr><tr><td style="text-align: left;">RN50</td><td style="text-align: left;">36%</td><td style="text-align: left;">11%</td><td style="text-align: left;">53%</td><td style="text-align: left;">43%</td><td style="text-align: left;">30%</td><td style="text-align: left;">26%</td></tr><tr><td style="text-align: left;">SSDEN34</td><td style="text-align: left;">55%</td><td style="text-align: left;">4%</td><td style="text-align: left;">40%</td><td style="text-align: left;">58%</td><td style="text-align: left;">28%</td><td style="text-align: left;">14%</td></tr><tr><td style="text-align: left;">BERT</td><td style="text-align: left;">72%</td><td style="text-align: left;">3%</td><td style="text-align: left;">25%</td><td style="text-align: left;">73%</td><td style="text-align: left;">9%</td><td style="text-align: left;">17%</td></tr><tr><td style="text-align: left;">DLRM</td><td style="text-align: left;">26%</td><td style="text-align: left;">65%</td><td style="text-align: left;">8%</td><td style="text-align: left;">14%</td><td style="text-align: left;">84%</td><td style="text-align: left;">2%</td></tr><tr><td style="text-align: left;">RNN-T</td><td style="text-align: left;">80%</td><td style="text-align: left;">5%</td><td style="text-align: left;">15%</td><td style="text-align: left;">63%</td><td style="text-align: left;">29%</td><td style="text-align: left;">8%</td></tr><tr><td style="text-align: left;">UNET</td><td style="text-align: left;">56%</td><td style="text-align: left;">9%</td><td style="text-align: left;">34%</td><td style="text-align: left;">75%</td><td style="text-align: left;">18%</td><td style="text-align: left;">7%</td></tr></tbody></table></div></figure><p id="p-22">Based on experimental measurements of memory and tensor usage on a GPU using performance counters, we categorize operators as compute bound (EX) if they sustain more than 20% tensor usage or more than 50% SIMT usage. We categorize operators as bandwidth bound (BW) if they are not compute bound and sustain more than 50% memory bandwidth usage. Operators that are neither are latency bound (LAT). Davies et al.<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a> do a deep dive on the behaviors of operators found in MLPerf applications by considering these three broad categories of DL operators, focusing on what causes operators to be compute heavy, bandwidth heavy, or latency heavy and their interaction with the underlying architecture. <i>We find that architectures can focus on these three categories of operations to achieve coverage and high performance for deep learning.</i></p></section><section id="sec9" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Tiled decoupled control and compute architecture.</strong>  GPUs and recent academic (for example, SIMBA,<a class="reference-link xref xref-bibr" href="#B34" data-jats-ref-type="bibr" data-jats-rid="B34"><sup>34</sup></a> SIGMA,<a class="reference-link xref xref-bibr" href="#B27" data-jats-ref-type="bibr" data-jats-rid="B27"><sup>27</sup></a> and EyerissV2<a class="reference-link xref xref-bibr" href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a>) and industry (for example, Gaudi<a class="reference-link xref xref-bibr" href="#B14" data-jats-ref-type="bibr" data-jats-rid="B14"><sup>14</sup></a> and others<a class="reference-link xref xref-bibr" href="#B30" data-jats-ref-type="bibr" data-jats-rid="B30"><sup>30</sup></a>) works belong to a paradigm of chip architecture we call <i>tiled decoupled control and compute</i> <i>(TDCC)</i>. The taxonomy and ideas developed by Nowatzki et al.<a class="reference-link xref xref-bibr" href="#B22" data-jats-ref-type="bibr" data-jats-rid="B22"><sup>22</sup></a> show that architectures can be categorized along five axes: <i>concurrency, coordination, communication, computation,</i> and <i>data reuse</i>. For the TDCC family of architectures, tiling is used to exploit concurrency. Control (called coordination in the Nowatzki taxonomy) and compute are decoupled to allow an imperative programming model, while also supporting high-density compute. TDCC architectures use subtly different approaches for <i>data-reuse</i> and <i>communication,</i> outlined in Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a>. Compared with the storage idioms explained in Pellauer et al.,<a class="reference-link xref xref-bibr" href="#B26" data-jats-ref-type="bibr" data-jats-rid="B26"><sup>26</sup></a> the TDCC taxonomy encompasses a broader scope, capturing functional unit organization, communication network design, and control mechanisms.</p><figure id="F2" class="fig" data-jats-position="float"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig02.jpg" data-type="image" data-caption="Figure 2. " href="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig02.jpg">
				<img decoding="async" class="graphic" title="Figure 2. " src="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig02.jpg" alt="" data-image-id="F2" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 2. </span> <span class="p">Comparison of the Galileo and TDCC architecture design space.</span><div class="figcaption-footer"> </div></figcaption></figure><p id="p-25">Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a> shows five example TDCCs (including Galileo, discussed in detail later), with a breakdown of how each addresses the five categories of specialization. We order the architectures by increasing level of generality and application to widespread DL (training and inference). Below each design, we indicate with red text which features are not appropriately provisioned for AI inference and training. Note that these architectures are quite capable. For DL, data-reuse specialization can be further broken into data storage and data orchestration (reshaping, transposing, and other layout modifications for data structures that hardware can make efficient). The top half of the figure redraws the architectures from the original references (with some stylizing) and colors the components according to the six components of specialization. All of them exploit concurrency through repeating homogeneous tiles and use some kind of control core for coordination. Compared with a GPU, other TDCCs are more area-efficient by eliminating overheads introduced by SIMT, such as a large register file, shared-memory, and hardware such as FP64, which is not necessary for DL. <i>Looking at DL chips through the lens of the TDCC taxonomy shows us that different compositions of architecture primitives are feasible and capable of outperforming state-of-the-art GPUs, allowing us to study the role of architecture.</i></p></section></section><section id="sec10" class="sec"><h2 class="heading">What Is the Role of Technology?</h2><p id="p-26">We now examine our first question and answer whether an architecture built at an advanced technology node would be a factor proportional to Moore’s Law in area-density increase compared with an architecture built at an older (larger) technology node. Using Amdhal’s law and knowledge of the three categories of operators, we developed an analytical performance model. Our model is architecture and implementation agnostic, allowing us to effectively estimate the performance gap attributable to technology alone. Based on well-accepted scaling equations<a class="reference-link xref xref-bibr" href="#B35" data-jats-ref-type="bibr" data-jats-rid="B35"><sup>35</sup></a> summarized in Table <a class="xref xref-table" href="#T1" data-jats-ref-type="table" data-jats-rid="T1">1</a>, we determine iso-power and iso-frequency scaling. For this article, we use iso-frequency scaling.</p><section id="sec11" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Definitions and modeling equations.</strong>  Let <i>r<sub>bw</sub></i>, <i>r<sub>c</sub></i>, and <i>r<sub>l</sub></i> denote the fraction of operators that are bandwidth heavy, compute heavy, and latency heavy, respectively. Recall that we can classify all operations into these categories, so for a given application, <i>r<sub>bw</sub></i> + <i>r<sub>c</sub></i> + <i>r<sub>l</sub></i> = 1. Given a baseline architecture and workload details, we model speedup with the following equation:</p><span class="disp-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML" display="block"> <mrow> <mi>s</mi> <mi>p</mi> <mi>e</mi> <mi>e</mi> <mi>d</mi> <mi>u</mi> <mi>p</mi> <mo>=</mo> <mfrac> <mn>1</mn> <mrow> <mfrac> <msub> <mi>r</mi> <mrow> <mi>bw</mi> </mrow> </msub> <msub> <mi>s</mi> <mrow> <mi>bw</mi> </mrow> </msub> </mfrac> <mo>+</mo> <mfrac> <msub> <mi>r</mi> <mi>c</mi> </msub> <msub> <mi>s</mi> <mi>c</mi> </msub> </mfrac> <mo>+</mo> <mfrac> <msub> <mi>r</mi> <mi>l</mi> </msub> <msub> <mi>s</mi> <mi>l</mi> </msub> </mfrac> </mrow> </mfrac> </mrow> </math> </span><p id="p-28">Where <i>r<sub>bw</sub></i>, <i>r<sub>c</sub></i>, and <i>r<sub>l</sub></i> are, as defined previously, and <i>s<sub>bw</sub></i>, <i>s<sub>c</sub></i>, and <i>s<sub>l</sub></i> denote the speedup for bandwidth-, compute-, and latency-heavy operators, respectively, over a given baseline architecture.</p><p id="p-29">We now discuss how we model the speedup that would be achieved when scaling a given architecture to a smaller technology node. As a running example, we consider modeling the speedup from an architecture built at 12nm scaled to 3nm.</p><section id="sec12" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Modeling bandwidth-heavy operator speedup. </em> Bandwidth-heavy operator performance scales proportionally with memory bandwidth. Memory bandwidth can scale independent of technology (HBM2 PHYs exist even at 16nm<a class="reference-link xref xref-bibr" href="#B33" data-jats-ref-type="bibr" data-jats-rid="B33"><sup>33</sup></a>), so a baseline architecture and its technology-scaled counterpart would have the same available memory bandwidth. Thus, we fix <i>s<sub>bw</sub></i> = 1. Benefits from narrower datatypes like FP8 and MSFP are also technology independent, reducing bandwidth needs and compute density.</p></section><section id="sec13" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Modeling compute-heavy operator speedup.</em>  We assume compute-heavy operator performance would scale proportionally to available peak compute. Considering area, peak compute is proportional to the amount of area dedicated to compute. Let <i>area<sub>chip</sub></i> denote chip area and <i>area<sub>mem</sub></i> denote the area occupied by HBM controllers and other peripherals. Then the compute area scale is:</p><span class="disp-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML" display="block"> <mrow> <msub> <mi>a</mi> <mi>c</mi> </msub> <mo>=</mo> <mfrac> <mrow> <msub> <mrow> <mi>area</mi> </mrow> <mrow> <mi>chip</mi> </mrow> </msub> <mo>&#8211;</mo> <msub> <mrow> <mi>area</mi> </mrow> <mrow> <mi>mem</mi> </mrow> </msub> </mrow> <mrow> <msubsup> <mrow> <mi>area</mi> </mrow> <mrow> <mi>chip</mi> </mrow> <mrow> <mi>baseline</mi> </mrow> </msubsup> <mo>&#8211;</mo> <msubsup> <mrow> <mi>area</mi> </mrow> <mrow> <mi>mem</mi> </mrow> <mrow> <mi>baseline</mi> </mrow> </msubsup> </mrow> </mfrac> <mo>≈</mo> <msub> <mi>s</mi> <mi>c</mi> </msub> <mo>=</mo> <mfrac> <mrow> <mi>FLOPS</mi> </mrow> <msup> <mrow> <mi>FLOPS</mi> </mrow> <mrow> <mi>baseline</mi> </mrow> </msup> </mfrac> </mrow> </math> </span><p id="p-32">To estimate <i>s<sub>c</sub></i>, we observe that if we hold total area constant, the factor increase in area devoted to compute follows the area scaling factor (from 12nm to 3nm we would estimate the compute density to increase by 6.7x). A further linear compute speedup can come from frequency increase at iso-power (2.165x = delay ratio from Table <a class="xref xref-table" href="#T1" data-jats-ref-type="table" data-jats-rid="T1">1</a> for 12nm to 3nm). Thus, for 12nm to 3nm, we would set <i>s<sub>c</sub></i> = 6.7 x 2.165 = 14.5.</p></section><section id="sec14" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Modeling latency-heavy operator speedup.</em>  For latency-dominated operators, caches and additional chip area provide speedup—for these operators, we model their speedup as <i>s<sub>l</sub></i> = (<i>a<sub>c</sub></i>)<sup>y</sup> for some power <i>γ</i> applied to the area scale. CPUs are an example of architectures that improve latency-bound applications by exploiting ILP/MLP, where speedup grows as a square root or cube root of chip area. We consider <i>γ</i> ranging from 0.25 to an extreme case where <i>γ</i> = 1.</p></section></section><section id="sec15" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Our findings.</strong>  Figure <a class="xref xref-fig" href="#F3" data-jats-ref-type="fig" data-jats-rid="F3">3</a> shows the speedup given by scaling an architecture from 12nm to 3nm for two different fractions of <i>r<sub>l</sub></i> (small, where <i>r<sub>l</sub></i> = 0.1, and vanishing, where <i>r<sub>l</sub></i> = 0.01), for a sweep of ratios for the other two regions, and three plots for <i>γ</i> = 0.25, 0.5, and 1. We call this speedup the <i>technology gap</i> that a 12nm node suffers. For context, BERT has an <i>r<sub>c</sub></i> = 0.64 (ratio computed on hypothetical 3nm H100 successor that is two times faster than H100) and essentially no latency-heavy operators. Because of simply Amdahl’s Law effects, <i>γ</i> does not have a large impact on final speedup because <i>r<sub>l</sub></i> is low in DNNs. We also observe that, when <i>r<sub>c</sub> &lt;</i> 0.64, regardless of <i>r</i>, maximum additional speedup from technology scaling from 12nm to 3nm is 2.9x. For heavily compute-dominated workloads (0.50 ≤ <i>r<sub>c</sub></i> ≤ 0.64), this gap is 2.9x for small <i>r<sub>l</sub></i> , and 2.5x for vanishing <i>r<sub>l</sub></i>.</p><figure id="F3" class="fig" data-jats-position="float"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig03.jpg" data-type="image" data-caption="Figure 3. " href="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig03.jpg">
				<img decoding="async" class="graphic" title="Figure 3. " src="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig03.jpg" alt="" data-image-id="F3" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 3. </span> <span class="p">Speedup achieved by scaling an architecture from 12nm to 3nm for various values of <i>r<sub>l</sub></i> and <i><i>γ</i></i>.</span><div class="figcaption-footer"> </div></figcaption></figure><p id="p-36">Because the area gap, and hence <i>s<sub>c</sub></i> and <i>s<sub>l</sub></i>, are the largest for 3nm, the technology gap of 12nm to 5nm and 7nm will be lower than the 3nm gap. The computed values from running our model are shown in Table <a class="xref xref-table" href="#T4" data-jats-ref-type="table" data-jats-rid="T4">4</a>. From our model, we can also compute the gap from 7nm to 5nm and 3nm, simply by dividing these speedups, shown in the last four rows in the table.</p><figure id="T4" class="table-wrap" data-jats-position="float"><div class="caption"><span class="caption-label">Table 4. </span> <span class="p">Modeled application performance normalized to 12nm (top) and 7nm (bottom).</span></div><div class="table-container"><table class="table table-bordered table-condensed table-hover" data-jats-frame="hsides" data-jats-rules="rows"><colgroup> <col align="left" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> </colgroup><thead style="vertical-align: bottom;"><tr><th style="text-align: left;"><i>r<sub>c</sub></i></th><th style="text-align: left;"><i>r<sub>l</sub></i></th><th style="text-align: left;">12nm</th><th style="text-align: left;">7nm</th><th style="text-align: left;">5nm</th><th style="text-align: left;">3nm</th></tr></thead><tbody><tr><td style="text-align: center;" colspan="6">Technology gap of 12nm node</td></tr><tr><td style="text-align: left;">0.64</td><td style="text-align: left;">0.10</td><td style="text-align: left;">1.0</td><td style="text-align: left;">2.0</td><td style="text-align: left;">2.6</td><td style="text-align: left;">2.9</td></tr><tr><td style="text-align: left;">0.64</td><td style="text-align: left;">0.01</td><td style="text-align: left;">1.0</td><td style="text-align: left;">1.8</td><td style="text-align: left;">2.3</td><td style="text-align: left;">2.5</td></tr><tr><td style="text-align: left;">0.50</td><td style="text-align: left;">0.10</td><td style="text-align: left;">1.0</td><td style="text-align: left;">1.6</td><td style="text-align: left;">2.0</td><td style="text-align: left;">2.1</td></tr><tr><td style="text-align: left;">0.50</td><td style="text-align: left;">0.01</td><td style="text-align: left;">1.0</td><td style="text-align: left;">1.6</td><td style="text-align: left;">1.8</td><td style="text-align: left;">1.9</td></tr><tr><td style="text-align: center;" colspan="6">Technology gap of 7nm node</td></tr><tr><td style="text-align: left;">0.64</td><td style="text-align: left;">0.10</td><td style="text-align: left;">0.5</td><td style="text-align: left;">1.0</td><td style="text-align: left;">1.3</td><td style="text-align: left;">1.45</td></tr><tr><td style="text-align: left;">0.64</td><td style="text-align: left;">0.01</td><td style="text-align: left;">0.6</td><td style="text-align: left;">1.0</td><td style="text-align: left;">1.3</td><td style="text-align: left;">1.4</td></tr><tr><td style="text-align: left;">0.50</td><td style="text-align: left;">0.10</td><td style="text-align: left;">0.6</td><td style="text-align: left;">1.0</td><td style="text-align: left;">1.25</td><td style="text-align: left;">1.3</td></tr><tr><td style="text-align: left;">0.50</td><td style="text-align: left;">0.01</td><td style="text-align: left;">0.6</td><td style="text-align: left;">1.0</td><td style="text-align: left;">1.1</td><td style="text-align: left;">1.2</td></tr></tbody></table></div></figure><section id="sec16" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Answer 1. </em> The technology gap—that is, the benefit of technology scaling that can be used to create improvements in DL performance—is limited to 2.9x (<i>r<sub>c</sub></i> = 0.64, <i>r<sub>l</sub></i> = 0.1 represents LLMs/transformer models; <i>r<sub>c</sub></i> = 0.5 represents many MLPerf applications) considering the benefits of 3nm technology, compared with the 12nm technology node. Considering transitioning from 7nm to 3nm technology, this gap is 1.45x for LLMs and 1.3x for the entire MLPerf suite.</p></section><section id="sec17" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Commentary.</em>  This 2.9x gap/speedup is significantly below the 8x gap expected based on traditional interpretations of Moore’s Law for three node generations. For the comprehensive set of MLPerf applications, this gap further reduces to only 2.1x. Overall, this raises profound questions about the adoption timelines of newer, more advanced nodes that the entire semiconductor industry must address, considering economics, access blockades, and sustainability.</p></section></section><section id="sec18" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Model validation.</strong>  We validate this model in two ways, shown in Table <a class="xref xref-table" href="#T5" data-jats-ref-type="table" data-jats-rid="T5">5</a>. First, we consider our application and, from the characterization in Table <a class="xref xref-table" href="#T3" data-jats-ref-type="table" data-jats-rid="T3">3</a>, we determine values for <i>r</i><i><sub>bw</sub></i> and <i>r<sub>c</sub></i> (<i>r<sub>l</sub></i> is always zero) for V100 execution. We then use measured values for <i>s<sub>bw</sub></i> and <i>s<sub>c</sub></i>, considering peak compute and peak bandwidth for the A100 and V100. From these measurements, we can determine the model’s predicted speedup of the A100 over the V100. We compare this speedup to the measured speedup from running the applications’ actual code and measuring time on the A100 compared with the V100.</p><figure id="T5" class="table-wrap" data-jats-position="float"><div class="caption"><span class="caption-label">Table 5. </span> <span class="p">Model validation.</span></div><div class="table-container"><table class="table table-bordered table-condensed table-hover" data-jats-frame="hsides" data-jats-rules="rows"><colgroup> <col align="left" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> </colgroup><thead style="vertical-align: bottom;"><tr><th style="text-align: left;">App/Shape</th><th style="text-align: left;">Measured</th><th style="text-align: left;">Predicted</th></tr></thead><tbody><tr><td style="text-align: left;">ResNet50</td><td style="text-align: left;">1.7x</td><td style="text-align: left;">2.0x</td></tr><tr><td style="text-align: left;">SSD-ResNet34</td><td style="text-align: left;">1.8x</td><td style="text-align: left;">2.1x</td></tr><tr><td style="text-align: left;">BERT</td><td style="text-align: left;">2.1x</td><td style="text-align: left;">2.3x</td></tr><tr><td style="text-align: left;">DLRM</td><td style="text-align: left;">1.2x</td><td style="text-align: left;">1.8x</td></tr><tr><td style="text-align: left;">RNN-T</td><td style="text-align: left;">2.2x</td><td style="text-align: left;">2.4x</td></tr><tr><td style="text-align: left;">UNET</td><td style="text-align: left;">2.1x</td><td style="text-align: left;">2.1x</td></tr><tr><td style="text-align: center;" colspan="3">BW-dominated operators</td></tr><tr><td style="text-align: left;">16384x128x256</td><td style="text-align: left;">1.6x</td><td style="text-align: left;">1.7x</td></tr><tr><td style="text-align: left;">32768x128x64</td><td style="text-align: left;">1.7x</td><td style="text-align: left;">1.7x</td></tr><tr><td style="text-align: left;">256x8192x4096</td><td style="text-align: left;">1.7x</td><td style="text-align: left;">1.7x</td></tr><tr><td style="text-align: center;" colspan="3">Compute-dominated operators</td></tr><tr><td style="text-align: left;">4096x2048x2048</td><td style="text-align: left;">2.5x</td><td style="text-align: left;">2.6x</td></tr><tr><td style="text-align: left;">1024x8192x2048</td><td style="text-align: left;">2.2x</td><td style="text-align: left;">2.6x</td></tr><tr><td style="text-align: center;" colspan="3">Latency-dominated operators</td></tr><tr><td style="text-align: left;">256x256x64</td><td style="text-align: left;">1.2x</td><td style="text-align: left;">1.6x</td></tr><tr><td style="text-align: left;">512x256x64</td><td style="text-align: left;">1.4x</td><td style="text-align: left;">1.6x</td></tr><tr><td style="text-align: left;">1024x256x128</td><td style="text-align: left;">1.3x</td><td style="text-align: left;">1.6x</td></tr></tbody></table></div></figure><p id="p-42">To validate using microbenchmarks, we selected a set of GEMM shapes (whose corresponding MLP hyperparameters are also shown) that we know are bandwidth limited (very large M dimension, but small K and small N) or compute limited (very large M, N, and K). For the former, <i>r<sub>bw</sub></i> = 1; <i>r<sub>c</sub></i>== <i>r<sub>l</sub></i> = 0. For the latter, <i>r<sub>c</sub></i> = 1; <i>r<sub>bw</sub></i> == <i>r<sub>l</sub></i> = 0. We also use a set of operators that are latency dominated (for which we run the model with <i>γ</i> = 0.5). Since <i>r<sub>l</sub></i> = 0 for all the other cases, the value of <i>γ</i> does not matter. We perform the same steps as for MLPerf: Run code on the V100, measure the <i>r</i>’s, project and measure speedups on the A100, and compare measured to projected.</p><p id="p-43">We find our model is quite accurate for MLPerf, BW-dominated, and compute-dominated microbenchmarks. For the latency-dominated microbenchmarks, even with <i>γ</i> = 0.5, our model overpredicts speedup. At least for these operators, <i>γ</i> = 0.25 provides a good curve fit.</p></section></section><section id="sec19" class="sec"><h2 class="heading">What Is the Role of Architecture?</h2><p id="p-44">We now examine our second question. In the context of domain-specific accelerators, this question can also be viewed as how architectural specialization can provide benefits independent of technology scaling. As a case study for this exploration, we introduce an example TDCC architecture, Galileo, and then compare it to current SOTA solutions.</p><section id="sec20" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Galileo organization.</strong>  At the system level, Galileo is a fabric of tiles that contain compute elements and slices of a distributed memory hierarchy and are connected via a mesh interconnect. The system includes a global thread scheduler that transmits work to cores based on software-defined work placement. It also includes a host interface controller (PCIe-like interface) to provide high-bandwidth, low-latency communication to a general purpose host computer that runs the DL framework code. Finally, one or more memory controllers and PHY on chip (HBM is preferred) feed the on-chip memory hierarchy. The organization of the tile, memory hierarchy, and on-chip network follow.</p><section id="sec21" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Tile organization. </em> Galileo’s tile organization is depicted in Figure <a class="xref xref-fig" href="#F4" data-jats-ref-type="fig" data-jats-rid="F4">4</a>. Tiles in Galileo consist of the following: 1) a general purpose core coupled with a short-vector SIMD engine, 2) a vector register file (VRF), and 3) a slice of a distributed, three-level memory hierarchy. The SIMD engine is designed to efficiently execute both matrix-multiply and element-wise operations, where each lane supports two Int8 and one FP16 multiply-accumulate operations per cycle. For dot-product operations on integer data, as found in matrix-multiply, a number of adjacent multiply-accumulate operations are combined into a wider output (for example, 4 Int8 MACs → 1 Int32). The effects of wide-accumulation and transposed matrix layouts is accommodated with a small custom “transpose unit” that buffers cache lines read from memory until full vectors can be written to the VRF. For element-wise operators, the SIMD engine alone is sufficient.</p><figure id="F4" class="fig" data-jats-position="float"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig04.jpg" data-type="image" data-caption="Figure 4. " href="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig04.jpg">
				<img decoding="async" class="graphic" title="Figure 4. " src="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig04.jpg" alt="" data-image-id="F4" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 4. </span> <span class="p">Organization of Galileo tile.</span><div class="figcaption-footer"> </div></figcaption></figure></section><section id="sec22" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Memory hierarchy. </em> Each tile has a private L1 cache designed to supply the high-bandwidth needed from the SIMD engine. Galileo also includes a distributed L2 cache shared among a cluster of tiles, and a globally distributed LLC shared by all tiles. The storage hierarchy is augmented with a small programmable core in each tile, allowing the local cache slices to “push” data to recipient tiles, effectively eliminating request traffic from the interconnect. Operator-specific information provided by DL frameworks enables static-analysis techniques to easily extract out dynamic data-movement needs, allowing this “push” style of data movement to be generated automatically by an operator compiler.</p></section><section id="sec23" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>On-chip network. </em> Tiles are connected via a simple 2D-mesh topology with dimension-ordered routing. The network allows data-movement cores within a tile to multicast data with a destination bitmask, enabling reuse of network hops that would otherwise be repeated for the same data to reach multiple destinations. The three-level cache hierarchy reduces the number of destinations at each level of transmission, allowing the bitmasks to fit within the packet header for each cache line of data.</p></section><section id="sec24" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Software stack. </em> Galileo adheres to the best practices that modern DL stacks have converged to: a layered approach to expose DL hardware to applications<a class="reference-link xref xref-bibr" href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a> comprising a framework-level parser, IR, operator mapping, and fusion optimization. Based on learnings from TimeLoop<a class="reference-link xref xref-bibr" href="#B24" data-jats-ref-type="bibr" data-jats-rid="B24"><sup>24</sup></a> and MEASTRO,<a class="reference-link xref xref-bibr" href="#B17" data-jats-ref-type="bibr" data-jats-rid="B17"><sup>17</sup></a> Galileo adopts output-stationary dataflow as a baseline strategy. For matrix-multiply and convolution, this lends to an easy-to-understand parallel algorithm since it does not use inter-thread communication—instead leaning on Galileo’s “push” data movement and dynamic multicast to exploit load-reuse opportunities, and the transpose engine to efficiently use the SIMD engine. In practice, we observe output-stationary to afford high performance. More complex tuning of dataflow patterns could be considered, and our performance results for Galileo can be viewed as a floor on what is possible via software tuning. Work tiles are sized to optimize for arithmetic intensity, respecting minimum tiling parameters to fill the SIMD vector width and L1 cache capacity. For each operator, we develop a kernel template that handles a single output work tile.</p></section><section id="sec25" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Understanding the design space. </em> Considering EyerissV2, Galileo primarily changes the compute units within the PEs, which are overspecialized for convolution operations to general-purpose SIMD units, and uses a dynamic (packet-switched) NoC to enable flexible communication. Simba is nearly identical to Galileo, with the main differences being the inclusion of the transpose engine to facilitate highly efficient intra-PE data orchestration and the generalization of specialized buffers to hardware-managed caches and push-based network communication. Sigma is also quite similar to Galileo but is very over-provisioned for data orchestration within the PE. Instead of expensive, software-programmable Benes and FAN networks for shuffling data to SIMD lanes, Galileo uses the transpose engine, which is sufficiently flexible for DL operators. Compared with a GPU, Galileo specializes data reuse by eliminating register file, SIMT execution in favor of the transpose engine. We specialize control by using a simple in-order core. For compute, we use SIMD execution with data-transpose. Instead of short-vector SIMD with data-shuffle operations, GPUs achieve efficient intra-PE matrix-multiply with systolic matrix-multiply-accumulate engines (for example, TensorCores).</p></section></section><section id="sec26" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Empirical methodology.</strong>  To evaluate the role of architecture, we need more detailed treatment of workloads and the actual architecture itself compared with the question of technology scaling. We detail this methodology below.</p><section id="sec27" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Technology modeling. </em> Similar to the technology scaling study, we use well-accepted scaling equations<a class="reference-link xref xref-bibr" href="#B35" data-jats-ref-type="bibr" data-jats-rid="B35"><sup>35</sup></a> (summarized in Table <a class="xref xref-table" href="#T1" data-jats-ref-type="table" data-jats-rid="T1">1)</a> and use iso-frequency scaling.</p></section><section id="sec28" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Architecture performance modeling.</em>  We insert region markers into TensorFlow and PyTorch at the operator boundary to generate an operator trace from our selected applications. We build a trace-based performance model that accounts for intra-tile operation, prefetch and data movement between tiles, and data movement from external HBM to on-chip memory. The core model accounts for the interaction between SIMD, transpose, load, and store instructions. The network model counts network hops at a cache-line granularity and uses bandwidth per link to estimate latency. We model external memory traffic with a simple roofline formula. Works including TimeLoop<a class="reference-link xref xref-bibr" href="#B24" data-jats-ref-type="bibr" data-jats-rid="B24"><sup>24</sup></a> and MAESTRO<a class="reference-link xref xref-bibr" href="#B17" data-jats-ref-type="bibr" data-jats-rid="B17"><sup>17</sup></a> offer an analytical model for the performance of TDCC-like architectures, though we found them to be insufficient for capturing the effects of dynamic cache state and interconnect topology and contention.</p></section><section id="sec29" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Architecture power and area estimation. </em> We use the methodology in Accelergy<a class="reference-link xref xref-bibr" href="#B39" data-jats-ref-type="bibr" data-jats-rid="B39"><sup>39</sup></a> and TimeLoop for our area and power modeling. We additionally use data for the Ara core<a class="reference-link xref xref-bibr" href="#B3" data-jats-ref-type="bibr" data-jats-rid="B3"><sup>3</sup></a> for modeling SIMD compute units and the LX3 core from Nowatzki et al.<a class="reference-link xref xref-bibr" href="#B22" data-jats-ref-type="bibr" data-jats-rid="B22"><sup>22</sup></a> for modeling an in-order core. We use the arithmetic units from Mach et al.<a class="reference-link xref xref-bibr" href="#B20" data-jats-ref-type="bibr" data-jats-rid="B20"><sup>20</sup></a> as a reference FP16 to complement Accelergy’s modeling. Finally, CACTI is used for power and area estimates of the last-level cache. All of these components are scaled to a target technology node using the methods from Stillmaker and Baas.<a class="reference-link xref xref-bibr" href="#B35" data-jats-ref-type="bibr" data-jats-rid="B35"><sup>35</sup></a> The power consumption of the memory controllers and PHY and HBM stacks is 6W per stack based on data sheets for HBM2. Our frequency-scaling parameters are derived from ARM’s published industry state of the art.<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a></p></section><section id="sec30" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Baseline and comparing architecture performance.</em>  To report our results, we obtained published performance results of the Nvidia A100 system. We paid close attention to ensure that we were using the exact same DL model as the Nvidia system. For some applications, we used Nvidia’s code published through MLPerf to replicate performance results and obtain results for different batch sizes.<a class="reference-link xref xref-bibr" href="#B21" data-jats-ref-type="bibr" data-jats-rid="B21"><sup>21</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B32" data-jats-ref-type="bibr" data-jats-rid="B32"><sup>32</sup></a> For BERT-large pre-training, we were unable to run Nvidia’s official code on a single GPU, so we used the ratio of large-batch inference to small-batch inference to estimate small-batch pre-training. To obtain layer-level performance and efficiency, we ran individual operators with PyTorch on an A100 and collected runtime (latency) for each layer using Nvidia’s NSYS, computing utilization with FLOP counts for each layer. To get the H100’s performance, we used the most recently published results from Nvidia, which report speedups over the A100.<a class="reference-link xref xref-bibr" href="#B32" data-jats-ref-type="bibr" data-jats-rid="B32"><sup>32</sup></a></p></section><section id="sec31" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Galileo design space.</em>  We first conducted an in-depth analysis of the design space of Galileo that is created over the parameters of SIMD-width, number of processing cores, and frequency. We plotted all of the design points in our space in terms of their area efficiency (TOPS/mm<sup>2</sup>) and power efficiency (pJ/op). Figure <a class="xref xref-fig" href="#F5" data-jats-ref-type="fig" data-jats-rid="F5">5</a> shows the results of this survey. We can see that there is quite a diverse spread of design points that vary by up to a factor of 5x in terms of area efficiency, and 6x in terms of power efficiency. Further, we observe that not all applications agree on which design point is the most efficient. <i>This shows that Galileo has a diverse design space that can provide good power and area efficiency for DL training and inference.</i></p><figure id="F5" class="fig" data-jats-position="float"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig05.jpg" data-type="image" data-caption="Figure 5. " href="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig05.jpg">
				<img decoding="async" class="graphic" title="Figure 5. " src="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig05.jpg" alt="" data-image-id="F5" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 5. </span> <span class="p">Design space of Galileo. Points of same color sweep from 1GHz–3GHz clock frequency with steps of 100MHz.</span><div class="figcaption-footer"> </div></figcaption></figure></section></section><section id="sec32" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Our findings.</strong>  We hold technology at 12nm for Galileo and quantify to what extent architectural changes <i>alone</i> can provide performance benefits by comparing different variants of Galileo to Nvidia’s SOTA A100 and H100 chips. Building on the insights from our design-space exploration, we chose two configurations of Galileo, which we call G7 and G5—both 12nm—that are designed to compete with the 7nm A100 and 5nm H100 GPUs, and evaluate their performance and efficiency. Note here that the Galileo architecture is built at 12nm, while the A100 and H100 are at 7nm and 5nm, respectively, thus isolating the role of architecture. Our evaluation is on the workloads from the entire MLPerf suite.</p><section id="sec33" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Matching 7nm performance with architectural specialization at 12nm. </em> First, we consider the G7 Galileo implementation against an Nvidia A100. Our G7 configuration comprises 2048 cores with 512-bit SIMD vectors. Table <a class="xref xref-table" href="#T6" data-jats-ref-type="table" data-jats-rid="T6">6</a> shows a comparison of the G7 to the A100. G7 is sized to (roughly) match the compute capability and memory capacity of an A100—its tile structure, on-chip network, and memory hierarchy are then determined through our DSE to achieve a balanced design. In particular, we observe Galileo’s bandwidth needs are much lower, allowing a slower HBM clock frequency.</p><figure id="T6" class="table-wrap" data-jats-position="float"><div class="caption"><span class="caption-label">Table 6. </span> <span class="p">Comparison of specs: G7 to A100.</span></div><div class="table-container"><table class="table table-bordered table-condensed table-hover" data-jats-frame="hsides" data-jats-rules="rows"><colgroup> <col align="left" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> </colgroup><thead style="vertical-align: bottom;"><tr><th style="text-align: left;">Spec</th><th style="text-align: left;">G7</th><th style="text-align: left;">A100</th></tr></thead><tbody><tr><td style="text-align: left;">Tech Node</td><td style="text-align: left;">12nm</td><td style="text-align: left;">7nm</td></tr><tr><td style="text-align: left;">Die Area</td><td style="text-align: left;">498mm<sup>2</sup></td><td style="text-align: left;">840mm<sup>2</sup></td></tr><tr><td style="text-align: left;">Peak TOPS (Int8/FP16)</td><td style="text-align: left;">628/324</td><td style="text-align: left;">624/312</td></tr><tr><td style="text-align: left;">Power (TDP)</td><td style="text-align: left;">200W</td><td style="text-align: left;">250W</td></tr><tr><td style="text-align: left;">Frequency</td><td style="text-align: left;">2.4GHz</td><td style="text-align: left;">1.4GHz</td></tr><tr><td style="text-align: left;">Total L1/L2/LLC Size</td><td style="text-align: left;">64/32/32MB</td><td style="text-align: left;">20.25/-/40MB</td></tr><tr><td style="text-align: left;">HBM2 Memory</td><td style="text-align: left;">16GB</td><td style="text-align: left;">40GB</td></tr><tr><td style="text-align: left;"># HBM2 Stacks</td><td style="text-align: left;">2</td><td style="text-align: left;">5</td></tr><tr><td style="text-align: left;">GM pJ/op</td><td style="text-align: left;">0.38</td><td style="text-align: left;">2.8</td></tr><tr><td style="text-align: left;" colspan="3">Note: We rename Nvidia’s L2 to LLC to compare with Galileo.</td></tr></tbody></table></div></figure><p id="p-62">As seen in the design-space exploration, Galileo is able to run efficiently at a smaller batch size than the A100 by being specialized with efficient mechanisms for memory transfers. Since GPUs need very high batch sizes to exploit parallelism, they end up suffering from higher bandwidth needs as well. We measure performance in terms of samples/second and, to be fair and generous to the GPU, pick a batch size that provides the highest samples/second.</p><p id="p-63">Figure <a class="xref xref-fig" href="#F6" data-jats-ref-type="fig" data-jats-rid="F6">6a</a> shows the performance comparison. Overall, the G7 achieves 2.5x/2.2x geo-mean speedup for inference/training with 7x/6x power efficiency. We intentionally picked a design point with roughly the same peak compute as the A100 to make it clear that the speedup we see with G7 comes from improving the utilization of compute resources by the same factor, with almost an order of magnitude lower energy. The energy efficiency of the G7 is much higher because we rely on power- and area-efficient microarchitecture targeted to DL exploiting reuse vs. a GPU that must adhere to a throughput-optimized execution model that constantly moves values in and out of main memory.</p><figure id="F6" class="fig" data-jats-position="float"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig06.jpg" data-type="image" data-caption="Figure 6. " href="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig06.jpg">
				<img decoding="async" class="graphic" title="Figure 6. " src="https://cacm.acm.org/wp-content/uploads/2025/05/3711920_fig06.jpg" alt="" data-image-id="F6" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 6. </span> <span class="p">(a) Galileo G7 vs. A100 and (b) G5 vs. H100 across MLPerf at optimal batch size. Throughput in samples/sec.</span><div class="figcaption-footer"> </div></figcaption></figure></section><section id="sec34" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Matching 5nm performance with architectural specialization at 12nm. </em> We defined the G5 configuration (also built at 12nm) to match the compute capacity of the H100. We provisioned its bandwidth and memory hierarchy to be balanced and sufficient for the compute. Table <a class="xref xref-table" href="#T7" data-jats-ref-type="table" data-jats-rid="T7">7</a> compares the G5 to the H100. When sized to match compute capacity of the H100, the G5 exceeds the reticle limit die area of 830mm<sup>2</sup>. When this area limit is enforced, a balanced G5 design is only able to achieve a peak of 590 FP16 TOPS compared with the H100’s 756.</p><figure id="T7" class="table-wrap" data-jats-position="float"><div class="caption"><span class="caption-label">Table 7. </span> <span class="p">Comparison of specs: G5 to H100.</span></div><div class="table-container"><table class="table table-bordered table-condensed table-hover" data-jats-frame="hsides" data-jats-rules="rows"><colgroup> <col align="left" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> </colgroup><thead style="vertical-align: bottom;"><tr><th style="text-align: left;">Spec</th><th style="text-align: left;">G5</th><th style="text-align: left;">H100</th></tr></thead><tbody><tr><td style="text-align: left;">Tech Node</td><td style="text-align: left;">12nm</td><td style="text-align: left;">5nm</td></tr><tr><td style="text-align: left;">Die Area</td><td style="text-align: left;">830mm<sup>2</sup></td><td style="text-align: left;">840mm<sup>2</sup></td></tr><tr><td style="text-align: left;">Peak TOPs (Int8/FP16)</td><td style="text-align: left;">1180/590</td><td style="text-align: left;">1513/756</td></tr><tr><td style="text-align: left;">Power (TDP)</td><td style="text-align: left;">350W</td><td style="text-align: left;">350W</td></tr><tr><td style="text-align: left;">Frequency</td><td style="text-align: left;">2.4GHz</td><td style="text-align: left;">1.4GHz</td></tr><tr><td style="text-align: left;">Total L1/L2/LLC Size</td><td style="text-align: left;">120/60/32MB</td><td style="text-align: left;">29/-/50MB</td></tr><tr><td style="text-align: left;">HBM2e Memory</td><td style="text-align: left;">32GB</td><td style="text-align: left;">80GB</td></tr><tr><td style="text-align: left;"># HBM2e Stacks</td><td style="text-align: left;">4</td><td style="text-align: left;">5</td></tr><tr><td style="text-align: left;">GM pJ/op</td><td style="text-align: left;">0.53</td><td style="text-align: left;">1.9</td></tr><tr><td style="text-align: left;" colspan="3">Note: We rename Nvidia’s L2 to LLC to compare with Galileo.</td></tr></tbody></table></div></figure><p id="p-67">Similar to the G7 vs. the A100, Figure <a class="xref xref-fig" href="#F6" data-jats-ref-type="fig" data-jats-rid="F6">6b</a> shows the performance comparison. Overall, the G5 achieves 1.4x/1.1x geo-mean speedup for inference/training with 3.8x/3.0x power efficiency. We observe that due to the limited area (and performance) of the G5 compared with the H100, Galileo is not able to achieve a similar performance improvement compared with the G7 vs. the A100. Because of the H100’s technology scaling, it is also able to achieve better power efficiency for its compute compared with the A100, resulting in the relatively lower power efficiency improvement of the G5 over the H100. We note that the <i>G5 is worse than the H100 on BERT training—</i>the H100’s performance is from arithmetic specialization of transparent FP8 conversion (sustaining 6.7x speedup over the A100 base<a class="reference-link xref xref-bibr" href="#B31" data-jats-ref-type="bibr" data-jats-rid="B31"><sup>31</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B32" data-jats-ref-type="bibr" data-jats-rid="B32"><sup>32</sup></a>), specialization that could also transparently help the G5 and is unrelated to transistor scaling.</p></section><section id="sec35" class="inline-headings-section"><p data-jats-content-type="inline-heading"><em>Answer 2.</em>  Architecture—hardware specialization—can provide a 2x savings in bandwidth and 1.7x savings in area, translating into tangible performance. Specifically, a 12nm Galileo implementation can meaningfully outperform a 7nm A100. Considering the 5nm H100, a Galileo implementation can modestly outperform the 5nm H100. As transistors become more plentiful, the raw compute becomes harder and harder to match with architectural specialization. Recall, however, that we are seeing diminishing improvements in area and power scaling.</p></section></section></section><section id="sec36" class="sec"><h2 class="heading">Related Work</h2><section id="sec37" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Technology projection.</strong>  Fuchs et al.<a class="reference-link xref xref-bibr" href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a> present a limit study of chip specialization, separating out contributions from technology scaling and architectural gains,<a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a> but the paper lacks concrete treatment for deep learning. The Dark Silicon work from nearly a decade ago alluded to the limits of technology-scaling benefits (but primarily considering parallelism levels in applications). Dally et al. discuss how domain-specific accelerators enable high performance by carefully considering memory movement and leveraging parallelism inherent in target algorithms.<a class="reference-link xref xref-bibr" href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a> Khazraee et al.<a class="reference-link xref xref-bibr" href="#B15" data-jats-ref-type="bibr" data-jats-rid="B15"><sup>15</sup></a> primarily focus on optimizing total cost of ownership (TCO) through specialization in older technology nodes (ranging from 250nm to 16nm) for workloads like Bitcoin mining, video transcoding, and deep learning. In contrast, we focus on the performance impact of specialization and technology for DL at nodes below 12nm.</p></section><section id="sec38" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Role of architecture.</strong>  There have been recent works on SIMD, in particular, looking at AVX extensions. These include an analysis of convolution performance<a class="reference-link xref xref-bibr" href="#B12" data-jats-ref-type="bibr" data-jats-rid="B12"><sup>12</sup></a> and an analysis of inference on CPUs.<a class="reference-link xref xref-bibr" href="#B19" data-jats-ref-type="bibr" data-jats-rid="B19"><sup>19</sup></a> Reuther et al.<a class="reference-link xref xref-bibr" href="#B30" data-jats-ref-type="bibr" data-jats-rid="B30"><sup>30</sup></a> present a survey of DL accelerators. These works do not look at the details of program behavior or the contribution of architecture or technology scaling. MAGNet<a class="reference-link xref xref-bibr" href="#B37" data-jats-ref-type="bibr" data-jats-rid="B37"><sup>37</sup></a> is an RTL generator that optimizes a parameterized Simba-like architecture for a <i>single application</i>.</p></section></section><section id="sec39" class="sec"><h2 class="heading">Conclusion</h2><p id="p-71">In light of the paradigm shifts confronting the semiconductor industry, our study revisits specialization within the context of advanced technology nodes becoming increasingly inaccessible due to economic considerations, sustainability concerns, and geopolitical strategies.</p><p id="p-72">Our findings reveal that a 12nm specialized chip can match the performance of SOTA 5nm chips for deep-learning tasks, challenging the impact of technology blockades. The benefits of scaling from 12nm to 3nm nodes show diminishing returns, with a maximum improvement of 2.9x for LLMs, and 1.45x scaling from 7nm to 3nm; for MLPerf this is even lower—2.1x and 1.3x, respectively.</p><p id="p-73">Workloads could change substantially, impacting both our findings. Disruptive technology solutions such as in-memory and analog processing are outside our study’s scope. Sophisticated DVFS techniques could alter the energy/performance trade-offs. Challenges in software development represent a significant hurdle<a class="reference-link xref xref-bibr" href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B28" data-jats-ref-type="bibr" data-jats-rid="B28"><sup>28</sup></a> for new architectures to demonstrate efficacy or surpass GPUs, yet the economic dynamics may shift favorably in contexts where alternatives are scarce,<a class="reference-link xref xref-bibr" href="#B13" data-jats-ref-type="bibr" data-jats-rid="B13"><sup>13</sup></a> suggesting a potential for investment and innovation in specialized architectures globally.</p><p id="p-74">In conclusion, while we acknowledge the ongoing relevance of miniaturization, our analysis underscores the underlooked transformative potential of specialization. Its substantial contribution to the economics and efficiency of sustaining a Moore’s Law’s cadence of improvements highlights specialization as a critical factor in navigating the semiconductor industry’s future. This approach could redefine the economic landscape of semiconductor manufacturing, making specialization not just a complementary strategy but also a central pillar in achieving significant advances amid the diminishing returns from new technology nodes.</p></section><section id="sec40" class="sec"></section></div><footer class="back"></footer></article>
</div>
		</div>
		<footer class="article-footer">
			
<section class="article-references" data-component="accordion" data-slide-to-refs="true">
	<a name="references"></a>
	<button class="accordion-controller" aria-expanded="false">
		<span class="article-references__title">
			References		</span>
		<span class="accordion-controller-icon">
			<svg aria-hidden="true" focusable="false" width="16" height="16" fill="var(--wp--preset--color--cacm-blue)"><use href="#am-symbol-icon-chevron-down"></use></svg>		</span>
	</button>
	<ul class="article-references__text accordion-content">
		<section id="references" class="ref-list-container">
<h2 class="heading">References</h2>
<ul id="reflist1" class="ref-list">
<li class="ref">
<div id="B1" class="citation"><span class="label">1.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Abts</span>, <span class="given-names">D. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">A software-defined tensor streaming multiprocessor for large-scale machine learning</span>. In <em><span class="source">Proceedings of the 49th Annual Intern. Symp. on Computer Architecture</span></em>. <span class="publisher-name">ACM</span> (<span class="year">2022</span>), <span class="fpage">567</span>–<span class="lpage">580</span>.</span></div>
</li>
<li class="ref">
<div id="B2" class="citation"><span class="label">2.</span> <span class="mixed-citation" data-jats-publication-type="other"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Burns</span>, <span class="given-names">A.</span></span> </span><span class="article-title">Taiwan’s tech king to Nancy Pelosi: U.S. is in over its head</span>. <em><span class="source">Politico </span></em> (Feb. <span class="year">2023</span>); <a class="ext-link" href="https://www.politico.com/news/2023/02/14/taiwan-tech-king-pelosi-powerhouse-microchip-industry-00082646" data-jats-ext-link-type="uri">https://www.politico.com/news/2023/02/14/taiwan-tech-king-pelosi-powerhouse-microchip-industry-00082646</a></span></div>
</li>
<li class="ref">
<div id="B3" class="citation"><span class="label">3.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Cavalcante</span>, <span class="given-names">M. </span></span><span class="etal">et al.</span> </span><span class="article-title">Ara: A 1-GHz+ Scalable and energy-efficient RISC-V vector processor with multiprecision floating-point support in 22-nm FD-SOI</span>. <em><span class="source">IEEE Trans. on Very Large Scale Integration (VLSI) Systems </span><span class="volume">28</span></em>, <span class="issue">2</span> (<span class="year">2020</span>), <span class="fpage">530</span>–<span class="lpage">543</span>.</span></div>
</li>
<li class="ref">
<div id="B4" class="citation"><span class="label">4.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Chen</span>, <span class="given-names">Y.-H. </span></span><span class="etal">et al.</span> </span><span class="article-title">Eyeriss v2: A flexible accelerator for emerging deep neural networks on mobile devices</span>. <em><span class="source">IEEE J. on Emerging and Selected Topics in Circuits and Systems </span><span class="volume">9</span></em>, <span class="issue">2</span> (<span class="year">2019</span>), <span class="fpage">292</span>–<span class="lpage">308</span>.</span></div>
</li>
<li class="ref">
<div id="B5" class="citation"><span class="label">5.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Christy</span>, <span class="given-names">R. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">8.3 A 3GHz ARM Neoverse N1 CPU in 7nm FinFET for infrastructure applications</span>. In <span class="source"><em>2020 IEEE Intern. Solid- State Circuits Conf.</em> </span><span class="publisher-name">IEEE </span>(<span class="year">2020</span>), <span class="fpage">148</span>–<span class="lpage">150</span>.</span></div>
</li>
<li class="ref">
<div id="B6" class="citation"><span class="label">6.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Dally</span>, <span class="given-names">W.J.</span></span>, <span class="string-name"><span class="surname">Turakhia</span>, <span class="given-names">Y.</span></span>, and <span class="string-name"><span class="surname">Han</span>, <span class="given-names">S.</span></span> </span><span class="article-title">Domain-specific hardware accelerators</span>. <em><span class="source">Commun. ACM </span><span class="volume">63</span></em>, <span class="issue">7</span> (<span class="year">2020</span>), <span class="fpage">48</span>–<span class="lpage">57</span>.</span></div>
</li>
<li class="ref">
<div id="B7" class="citation"><span class="label">7.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Davies</span>, <span class="given-names">M.</span></span> </span><em><span class="source">Composable Architecture Primitives for the Era of Efficient Generalization</span></em>. <span class="publisher-name">Ph.D. thesis, University of Wisconsin-Madison</span> (<span class="year">2024</span>).</span></div>
</li>
<li class="ref">
<div id="B8" class="citation"><span class="label">8.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Eeckhout</span>, <span class="given-names">L.</span></span> </span><span class="article-title">Kaya for computer architects: Toward sustainable computer systems</span>. <em><span class="source">IEEE Micro </span><span class="volume">43</span></em>, <span class="issue">1</span> (<span class="year">2023</span>), <span class="fpage">9</span>–<span class="lpage">18</span>.</span></div>
</li>
<li class="ref">
<div id="B9" class="citation"><span class="label">9.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Esmaeilzadeh</span>, <span class="given-names">H.</span></span><span class="etal"> et al.</span> </span><span class="chapter-title">Dark silicon and the end of multicore scaling</span>. In <span class="source"><em>Proceedings of the 38th Annual Intern. Symp. on Computer Architecture</em></span>. <span class="publisher-name">ACM</span> (<span class="year">2011</span>), <span class="fpage">365</span>–<span class="lpage">376</span>.</span></div>
</li>
<li class="ref">
<div id="B10" class="citation"><span class="label">10.</span> <span class="mixed-citation" data-jats-publication-type="other"><span class="collab">Federal Register</span>. <em><span class="source">Implementation of Additional Export Controls: Certain Advanced Computing and Semiconductor Manufacturing Items; Supercomputer and Semiconductor End Use; Entity List Modification</span></em> (Oct. 13, <span class="year">2022</span>); <a class="ext-link" href="https://bit.ly/4jPPTKt" data-jats-ext-link-type="uri">https://bit.ly/4jPPTKt</a></span></div>
</li>
<li class="ref">
<div id="B11" class="citation"><span class="label">11.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Fuchs</span>, <span class="given-names">A.</span></span> and <span class="string-name"><span class="surname">Wentzlaff</span>, <span class="given-names">D.</span></span> </span><span class="chapter-title">The accelerator wall: Limits of chip specialization</span>. In <em><span class="source">2019 IEEE Intern. Symp. on High Performance Computer Architecture</span></em>. <span class="publisher-name">IEEE</span> (<span class="year">2019</span>), <span class="fpage">1</span>–<span class="lpage">14</span>.</span></div>
</li>
<li class="ref">
<div id="B12" class="citation"><span class="label">12.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Georganas</span>, <span class="given-names">E. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">Anatomy of high-performance deep learning convolutions on SIMD architectures</span>. In <span class="source"><em>Proceedings of the Intern. Conf. for High Performance Computing, Networking, Storage and Analysis</em></span>. <span class="publisher-name">ACM</span> (<span class="year">2018</span>), <span class="fpage">830</span>–<span class="lpage">841</span>.</span></div>
</li>
<li class="ref">
<div id="B13" class="citation"><span class="label">13.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Handley</span>, <span class="given-names">L.</span></span> </span><span class="chapter-title">U.S. chip export ban is ‘great news,’ says partner at Chinese tech investment fund</span>. <em><span class="publisher-name">CNBC</span> </em>(Oct. 23, <span class="year">2023</span>); <a class="ext-link" href="https://bit.ly/431ldAc" data-jats-ext-link-type="uri">https://bit.ly/431ldAc</a></span></div>
</li>
<li class="ref">
<div id="B14" class="citation"><span class="label">14.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Kaplan</span>, <span class="given-names">R.</span></span> </span><span class="chapter-title">Intel Gaudi 3 AI accelerator: Architected for gen AI training and inference</span>. In <span class="source"><em>2024 IEEE Hot Chips 36 Symp.</em> </span><span class="publisher-name">IEEE</span> (<span class="year">2024</span>).</span></div>
</li>
<li class="ref">
<div id="B15" class="citation"><span class="label">15.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Khazraee</span>, <span class="given-names">M. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">Moonwalk: NRE optimization in ASIC clouds</span>. In <span class="source"><em>Proceedings of the Twenty-Second Intern. Conf. on Architectural Support for Programming Languages and Operating Systems</em></span>. <span class="publisher-name">ACM</span> (<span class="year">2017</span>).</span></div>
</li>
<li class="ref">
<div id="B16" class="citation"><span class="label">16.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Klenk</span>, <span class="given-names">B. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">An in-network architecture for accelerating shared-memory multiprocessor collectives</span>. In <span class="source"><em>2020 ACM/IEEE 47th Annual Intern. Symp. on Computer Architecture</em></span>. <span class="publisher-name">IEEE</span> (<span class="year">2020</span>), <span class="fpage">996</span>–<span class="lpage">1009</span>.</span></div>
</li>
<li class="ref">
<div id="B17" class="citation"><span class="label">17.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Kwon</span>, <span class="given-names">H. </span></span><span class="etal">et al.</span> </span><span class="article-title">MAESTRO: A data-centric approach to understand reuse, performance, and hardware cost of DNN mappings</span>. <em><span class="source">IEEE Micro </span><span class="volume">40</span></em>, <span class="issue">3</span> (<span class="year">2020</span>), <span class="fpage">20</span>–<span class="lpage">29</span>.</span></div>
</li>
<li class="ref">
<div id="B18" class="citation"><span class="label">18.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Li</span>, <span class="given-names">M. </span></span><span class="etal">et al.</span> </span><span class="article-title">The deep learning compiler: A comprehensive survey</span>. <em><span class="source">IEEE Trans. on Parallel and Distributed Systems </span><span class="volume">32</span></em>, <span class="issue">3</span> (<span class="year">2021</span>), <span class="fpage">708</span>–<span class="lpage">727</span>.</span></div>
</li>
<li class="ref">
<div id="B19" class="citation"><span class="label">19.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Liu</span>, <span class="given-names">Y. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">Optimizing CNN model inference on CPUs</span>. In <span class="source">P<em>roceedings of the 2019 USENIX Annual Technical Conf.</em> </span><span class="publisher-name">USENIX</span> (<span class="year">2019</span>), <span class="fpage">1025</span>–<span class="lpage">1040</span>.</span></div>
</li>
<li class="ref">
<div id="B20" class="citation"><span class="label">20.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Mach</span>, <span class="given-names">S. </span></span><span class="etal">et al.</span> </span><span class="article-title">FPnew: An open-source multiformat floating-point unit architecture for energy-proportional transprecision computing</span>. <em><span class="source">IEEE Trans. on Very Large Scale Integration (VLSI) Systems</span> <span class="volume">29</span></em>, <span class="issue">4</span> (<span class="year">2021</span>), <span class="fpage">774</span>–<span class="lpage">787</span>.</span></div>
</li>
<li class="ref">
<div id="B21" class="citation"><span class="label">21.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Mujtaba</span>, <span class="given-names">H.</span></span> </span><span class="chapter-title">Nvidia’s Ampere A100 GPU is unstoppable, breaks 16 AI performance records, up to 4.2x faster than Volta V100</span>. <em><span class="publisher-name">WCCF Tech</span></em> (Jul. 30, <span class="year">2020</span>); <a class="ext-link" href="https://bit.ly/3YJPjFS" data-jats-ext-link-type="uri">https://bit.ly/3YJPjFS</a></span></div>
</li>
<li class="ref">
<div id="B22" class="citation"><span class="label">22.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Nowatzki</span>, <span class="given-names">T. </span></span><span class="etal">et al.</span> </span><span class="article-title">Domain specialization is generally unnecessary for accelerators</span>. <em><span class="source">IEEE Micro Top Picks </span><span class="volume">37</span></em>, <span class="issue">3</span> (<span class="year">2017</span>), <span class="fpage">40</span>–<span class="lpage">50</span>.</span></div>
</li>
<li class="ref">
<div id="B23" class="citation"><span class="label">23.</span> <span class="mixed-citation" data-jats-publication-type="other"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Palmer</span>, <span class="given-names">A.W.</span></span> </span><span class="article-title">‘An act of war’: Inside America’s silicon blockade against China</span>. <em><span class="source">New York Times</span></em> (Jul. 12, <span class="year">2023</span>).</span></div>
</li>
<li class="ref">
<div id="B24" class="citation"><span class="label">24.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Parashar</span>, <span class="given-names">A. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">Timeloop: A systematic approach to DNN accelerator evaluation</span>. In <span class="source">2019 <em>IEEE Intern. Symp. on Performance Analysis of Systems and Software</em></span>. <span class="publisher-name">IEEE</span> (<span class="year">2019</span>), <span class="fpage">304</span>–<span class="lpage">315</span>.</span></div>
</li>
<li class="ref">
<div id="B25" class="citation"><span class="label">25.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Patel</span>, <span class="given-names">D. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">Wafer wars: Deciphering latest restrictions on AI and semiconductor manufacturing</span>. <span class="publisher-name">SemiAnalysis</span> (Oct. 24, <span class="year">2023</span>); <a class="ext-link" href="https://bit.ly/44DV63y" data-jats-ext-link-type="uri">https://bit.ly/44DV63y</a></span></div>
</li>
<li class="ref">
<div id="B26" class="citation"><span class="label">26.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Pellauer</span>, <span class="given-names">M. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">Buffets: An efficient and composable storage idiom for explicit decoupled data orchestration</span>. In <span class="source"><em>Proceedings of the Twenty-Fourth Intern. Conf. on Architectural Support for Programming Languages and Operating Systems</em></span>. <span class="publisher-name">ACM</span> (<span class="year">2019</span>), <span class="fpage">137</span>–<span class="lpage">151</span>.</span></div>
</li>
<li class="ref">
<div id="B27" class="citation"><span class="label">27.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Qin</span>, <span class="given-names">E. </span></span><span class="etal">et al. </span></span><span class="chapter-title">SIGMA: A sparse and irregular GEMM accelerator with flexible interconnects for DNN training</span>. In <em><span class="source">2020 IEEE Intern. Symp. on High Performance Computer Architecture</span></em>. <span class="publisher-name">IEEE</span> (<span class="year">2020</span>), <span class="fpage">58</span>–<span class="lpage">70</span>.</span></div>
</li>
<li class="ref">
<div id="B28" class="citation"><span class="label">28.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Ray</span>, <span class="given-names">T.</span></span> </span><span class="chapter-title">Chip industry is going to need a lot more software to catch Nvidia’s lead in AI</span>. <em><span class="publisher-name">ZDNet</span> </em>(Oct. 21, <span class="year">2020</span>); <a class="ext-link" href="https://bit.ly/4iA5EnD" data-jats-ext-link-type="uri">https://bit.ly/4iA5EnD</a></span></div>
</li>
<li class="ref">
<div id="B29" class="citation"><span class="label">29.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Reddi</span>, <span class="given-names">V.J. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">MLPerf inference benchmark</span>. In <span class="source"><em>2020 ACM/IEEE 47th Annual Intern. Symp. on Computer Architecture</em></span>. <span class="publisher-name">IEEE</span> (<span class="year">2020</span>), <span class="fpage">446</span>–<span class="lpage">459</span>.</span></div>
</li>
<li class="ref">
<div id="B30" class="citation"><span class="label">30.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Reuther</span>, <span class="given-names">A. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">Survey of machine learning accelerators</span>. In <span class="source"><em>2020 IEEE High Performance Extreme Computing Conf</em>. </span><span class="publisher-name">IEEE</span> (<span class="year">2020</span>), <span class="fpage">1</span>–<span class="lpage">12</span>.</span></div>
</li>
<li class="ref">
<div id="B31" class="citation"><span class="label">31.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Salvator</span>, <span class="given-names">D.</span></span> </span><span class="chapter-title">H100 Transformer engine supercharges AI training, delivering up to 6x higher performance without losing accuracy</span>. <span class="publisher-name">Nvidia</span> (Mar. 22, <span class="year">2022</span>); <a class="ext-link" href="https://bit.ly/42JD7Gl" data-jats-ext-link-type="uri">https://bit.ly/42JD7Gl</a></span></div>
</li>
<li class="ref">
<div id="B32" class="citation"><span class="label">32.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Salvator</span>, <span class="given-names">D.</span></span> </span><span class="chapter-title">Nvidia Hopper, Ampere GPUs sweep benchmarks in AI training</span>. <span class="publisher-name">Nvidia</span> (Nov. 9, <span class="year">2022</span>); <a class="ext-link" href="https://bit.ly/4jp1UGV" data-jats-ext-link-type="uri">https://bit.ly/4jp1UGV</a></span></div>
</li>
<li class="ref">
<div id="B33" class="citation"><span class="label">33.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Sankaralingam</span>, <span class="given-names">K. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">The Mozart reuse exposed dataflow processor for AI and beyond: Industrial product</span>. In <span class="source"><em>Proceedings of the 49th Annual Intern. Symp. on Computer Architecture</em></span>. <span class="publisher-name">ACM</span> (<span class="year">2022</span>), <span class="fpage">978</span>–<span class="lpage">992</span>.</span></div>
</li>
<li class="ref">
<div id="B34" class="citation"><span class="label">34.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Shao</span>, <span class="given-names">Y.S. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">Simba: Scaling deep-learning inference with multi-chip-module-based architecture</span>. In <em><span class="source">Proceedings of the 52nd Annual IEEE/ACM Intern. Symp. on Microarchitecture</span></em>. <span class="publisher-name">ACM</span> (<span class="year">2019</span>), <span class="fpage">14</span>–<span class="lpage">27</span>.</span></div>
</li>
<li class="ref">
<div id="B35" class="citation"><span class="label">35.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Stillmaker</span>, <span class="given-names">A.</span></span> and <span class="string-name"><span class="surname">Baas</span>, <span class="given-names">B.</span></span> </span><span class="article-title">Scaling equations for the accurate prediction of CMOS device performance from 180 nm to 7 nm</span>. <em><span class="source">Integration </span><span class="volume">58</span></em> (Jun. <span class="year">2017</span>), <span class="fpage">74</span>–<span class="lpage">81</span>.</span></div>
</li>
<li class="ref">
<div id="B36" class="citation"><span class="label">36.</span> <span class="mixed-citation" data-jats-publication-type="other"><span class="collab">U.S. Department of Commerce</span>. <span class="article-title">ICYMI: Three companies warn about delayed chip funding as global wafers announcement hinges on bipartisan innovation act passage</span>. (Jun. 29, <span class="year">2022</span>); <a class="ext-link" href="https://bit.ly/3Yb5lIP" data-jats-ext-link-type="uri">https://bit.ly/3Yb5lIP</a></span></div>
</li>
<li class="ref">
<div id="B37" class="citation"><span class="label">37.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Venkatesan</span>, <span class="given-names">R. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">MAGNet: A modular accelerator generator for neural networks</span>. In <em><span class="source">2019 IEEE/ACM Intern. Conf. on Computer-Aided Design</span></em>. <span class="publisher-name">IEEE</span> (<span class="year">2019</span>), <span class="fpage">1</span>–<span class="lpage">8</span>.</span></div>
</li>
<li class="ref">
<div id="B38" class="citation"><span class="label">38.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Verma</span>, <span class="given-names">S. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">Demystifying the MLPerf training benchmark suite</span>. In <span class="source"><em>2020 IEEE Intern. Symp. on Performance Analysis of Systems and Software</em></span>. <span class="publisher-name">IEEE</span> (<span class="year">2020</span>), <span class="fpage">24</span>–<span class="lpage">33</span>.</span></div>
</li>
<li class="ref">
<div id="B39" class="citation"><span class="label">39.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Wu</span>, <span class="given-names">Y.N.</span></span>, <span class="string-name"><span class="surname">Emer</span>, <span class="given-names">J.S.</span></span>, and <span class="string-name"><span class="surname">Sze</span>, <span class="given-names">V.</span></span>  </span><span class="chapter-title">Accelergy: An architecture-level energy estimation methodology for accelerator designs</span>. In <em><span class="source">2019 IEEE/ACM Intern. Conf. on Computer-Aided Design</span></em>. <span class="publisher-name">IEEE</span> (<span class="year">2019</span>), <span class="fpage">1</span>–<span class="lpage">8</span>.</span></div>
</li>
<li class="ref">
<div id="B40" class="citation"><span class="label">40.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Zafar</span>, <span class="given-names">R.</span></span> </span><span class="chapter-title">Apple A13 and beyond: How transistor count and costs will go up</span>. <em><span class="publisher-name">WCCF Tech</span></em> (Apr. 19, <span class="year">2019</span>); <a class="ext-link" href="https://bit.ly/3Yb5ZWL" data-jats-ext-link-type="uri">https://bit.ly/3Yb5ZWL</a></span></div>
</li>
</ul>
</section>
	</ul>
</section>

<section class="article-footnotes" data-component="accordion" data-slide-to-refs="true">
	<a name="footnotes"></a>
	<button class="accordion-controller" aria-expanded="false">
		<span class="article-footnotes__title">
			Footnotes		</span>
		<span class="accordion-controller-icon">
			<svg aria-hidden="true" focusable="false" width="16" height="16" fill="var(--wp--preset--color--cacm-blue)"><use href="#am-symbol-icon-chevron-down"></use></svg>		</span>
	</button>
	<ul class="article-footnotes__text accordion-content">
		<section id="footnotes" class="fn-group-container">
<ul class="fn-group" data-jats-content-type="footnotes">
<li id="FN1" class="fn"><a class="article-label">a</a> <span class="p">This is not a blanket ban, but defined by peak FLOP/s per mm2 and chip-to-chip signaling ability. In practical terms, chips with A100 and higher capability are effectively banned from being sold to China. The ban includes the purchase of chips manufactured by other entities, fabrication equipment to make 7nm fabs, CAD tools to make 7nm designs, and access to 7nm fabs.</span></li>
</ul>
</section>
	</ul>
</section>
<section id="authors" class="article-authors" data-component="accordion">
	<button class="accordion-controller" aria-expanded="false">
		<span class="article-authors__title">
			About the Authors		</span>
		<span class="accordion-controller-icon">
			<svg aria-hidden="true" focusable="false" width="16" height="16" fill="var(--wp--preset--color--cacm-blue)"><use href="#am-symbol-icon-chevron-down"></use></svg>		</span>
	</button>
	<div class="article-authors__info accordion-content">
		<div class="article-authors__info-text">
			<section id="sec41" class="biography">
<p id="p-1"><strong>Michael Davies</strong> (mdavies@nvidia.com) is a research scientist in computer architecture at Nvidia. In 2024, he received his Ph.D. in computer science from the University of Wisconsin-Madison, USA, where this research was conducted.</p>
<p id="p-2"><strong>Karthikeyan Sankaralingam</strong> is a professor at the University of Wisconsin-Madison and a principal research scientist at Nvidia. </p>
</section>
		</div>
	</div>
</section>

<ul class="share">
	
<li class="share-link" data-component="share">
	<a href="#" class="share-toggle">
		<svg aria-hidden="true" focusable="false" width="19" height="18" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-share"></use></svg>		<span class="share-link-text">
			Share		</span>
	</a>
	<ul class="share-menu" aria-hidden="true">
		<li>
			<a href="https://twitter.com/intent/tweet?url=https://cacm.acm.org/research/defying-moore-envisioning-the-economics-of-a-semiconductor-revolution-through-12nm-specialization/&#038;text=Defying%20Moore:%20Envisioning%20the%20Economics%20of%20a%20Semiconductor%20Revolution%20through%2012nm%20Specialization" target="_blank">
				Twitter			</a>
		</li>
		<li>
			<a href="http://www.reddit.com/submit?url=https://cacm.acm.org/research/defying-moore-envisioning-the-economics-of-a-semiconductor-revolution-through-12nm-specialization/&#038;title=Defying%20Moore:%20Envisioning%20the%20Economics%20of%20a%20Semiconductor%20Revolution%20through%2012nm%20Specialization" target="_blank">
				Reddit			</a>
		</li>
		<li>
			<a href="https://news.ycombinator.com/submitlink?u=https://cacm.acm.org/research/defying-moore-envisioning-the-economics-of-a-semiconductor-revolution-through-12nm-specialization/&#038;t=Defying%20Moore:%20Envisioning%20the%20Economics%20of%20a%20Semiconductor%20Revolution%20through%2012nm%20Specialization" target="_blank">
				Hacker News			</a>
		</li>
	</ul>
</li>

<li class="share-link share-link-print" data-component="print">
	<a href="#" class="print">
		<svg aria-hidden="true" focusable="false" width="19" height="20" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-print"></use></svg>		<span class="share-link-text">
			Print		</span>
	</a>
</li>

	<li class="share-link share-link-discussion" data-component="share">
		<a class="share-link-comments" href="#comments">
			<svg aria-hidden="true" focusable="false" width="19" height="20" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-comment"></use></svg>			<span class="share-link-text">Join the Discussion</span>
		</a>
	</li>
</ul>
		</footer>
		<div class="article-authors-digital-library">
			<section class="article-submission">
	<div class="article-submission__cta">
		<div class="article-submission__cta-container">
			<p class="article-submission__cta-title">
				Submit an Article to CACM			</p>
			<p class="article-submission__cta-text">
				CACM welcomes unsolicited <a href="https://cacm.acm.org/author-guidelines/#CACMsubmission">submissions</a> on topics of relevance and value to the computing community.			</p>
		</div>
	</div>
</section>

<section class="article-digital-library">
	<div class="article-digital-library__article-info">
		<p class="article-digital-library__intro-text">
			You Just Read		</p>
		<h4 class="article-digital-library__title">
			Defying Moore: Envisioning the Economics of a Semiconductor Revolution through 12nm Specialization		</h4>
					<a class="article-digital-library__link" href="https://dl.acm.org/doi/10.1145/3711920">
				<svg aria-hidden="true" focusable="false" width="21" height="21" fill="var(--wp--preset--color--cacm-black)"><use href="#am-symbol-icon-digital-library"></use></svg>				View in the ACM Digital Library				<svg aria-hidden="true" focusable="false" width="14" height="9" fill="var(--wp--preset--color--cacm-black)" class="icon-dl"><use href="#am-symbol-icon-arrow-right"></use></svg>			</a>
			</div>
	<div class="article-digital-library__copyright-info">
		<p><img class="alignnone  wp-image-768185" src="https://cacm.acm.org/wp-content/uploads/2025/05/by.png?w=300" alt="" width="94" height="33" />This work is licensed under a Creative Commons Attribution International 4.0 License.</p>
<p>© 2025 Copyright held by the owner/author(s).</p>
			</div>
</section>
		</div>
		<div class="article-sidebar">
			<section class="article-doi">
	<h3 class="article-doi__heading">DOI</h3>
	10.1145/3711920</section>
<section class="article-issue">
	<div class="article-issue__meta">
		<h3 class="article-issue__heading">July 2025 Issue</h3>
							<p class="article-issue__vol-info">Vol. 68 No. 7</p>
							<p class="article-issue__page-info">Pages: 108-119</p>
			</div>
			<a href="https://cacm.acm.org/issue/july-2025/" class="article-issue__toc-link">
			Table of Contents			<span class="article-issue__toc-icon-arrow"><svg aria-hidden="true" focusable="false" width="14" height="9" fill="var(--wp--preset--color--cacm-blue)"><use href="#am-symbol-icon-arrow-right"></use></svg></span>
		</a>
	</section>

<div class="ad ad-mobile ad--is-loading" data-component="ad" data-platform="mobile" data-show-ad="false">
		<div class="cacm-ad-unit">
		<p class="ad-label">Advertisement</p>
		<div class="ad-unit" data-pipeline-id="684700" data-dimension-id="599027"></div>
		<noscript><a href="https://acm.nui.media/pipeline/684700/0/cc?z=acm"><img src="https://acm.nui.media/pipeline/684700/0/vc?z=acm&#038;dim=599027&#038;kw=&#038;click=&#038;abr=$imginiframe" alt="" ></a></noscript>
	</div>
	</div>

<div class="ad ad-desktop ad--is-loading" data-component="ad" data-platform="desktop" data-show-ad="false">
		<div class="cacm-ad-unit">
		<p class="ad-label">Advertisement</p>
		<div class="ad-unit" data-pipeline-id="684700" data-dimension-id="599027"></div>
		<noscript><a href="https://acm.nui.media/pipeline/684700/0/cc?z=acm"><img src="https://acm.nui.media/pipeline/684700/0/vc?z=acm&#038;dim=599027&#038;kw=&#038;click=&#038;abr=$imginiframe" alt="" ></a></noscript>
	</div>
	</div>
		</div>
		
<section class="article-comments">
	<div class="article-comments__inner container">
		<h3 class="article-comments__heading">
			Join the Discussion (0)		</h3>
		
<section class="cta-join-the-discussion" id="article-discussion">
	<div class="cta-join-the-discussion__box">
		<h4 class="cta-join-the-discussion__heading">Become a Member or Sign In to Post a Comment</h4>
		<div class="cta-join-the-discussion__button-group">
			<a class="cta-join-the-discussion__button cta-join-the-discussion__button--login" href="https://cacm.acm.org/wp-login.php?saml_sso">Sign In</a>
			<a class="cta-join-the-discussion__button cta-join-the-discussion__button--signup" href="https://accounts.acm.org/">Sign Up</a>
		</div>
	</div>
</section>
		
<div id="comments" class="comments-area">

	
		<div id="respond" class="auth-comment-form" data-component="authCommentForm" data-replytocom="0">
		<div class="auth-comment-form__contents">
			<span class="auth-comment-form__loader">
				<svg version="1.1" id="L9" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 100 100" enable-background="new 0 0 0 0" xml:space="preserve">
					<path fill="var(--wp--preset--color--cacm-blue)" d="M73,50c0-12.7-10.3-23-23-23S27,37.3,27,50 M30.9,50c0-10.5,8.5-19.1,19.1-19.1S69.1,39.5,69.1,50">
						<animateTransform
							attributeName="transform"
							attributeType="XML"
							type="rotate"
							dur="1s"
							from="0 50 50"
							to="360 50 50"
							repeatCount="indefinite" />
					</path>
				</svg>
			</span>
		</div>
	</div>

</div><!-- #comments -->
	</div>
</section>

		<section
			class="post-list the-latest"
			data-layout="grid-three-up"
			data-component="postList"
		>
							
		<header class="section-header ">
			<h3				class="section-header__heading"
			>
									<a class="section-header__heading-link" href="/?s=">
						The Latest from CACM					</a>
							</h3>
							<div class="section-header__readmore">
					<a class="section-header__readmore-link" href="/?s=" aria-label="
						Explore more from The Latest from CACM					">
						<span class="section-header__readmore-text">Explore More</span>
						<span class="section-header__readmore-icon"><svg aria-hidden="true" focusable="false" width="14" height="9"><use href="#am-symbol-icon-arrow-right"></use></svg></span>
					</a>
				</div>
								</header>

					
			<div class="">
				<div class="post-list__content"><div class="post-list__item">
	<article id="post-769505" class="post-list__post post-769505 post type-post status-publish format-standard has-post-thumbnail hentry category-artificial-intelligence-machine-learning category-computing-applications category-society section-news">
		<div class="post-list__post-content">
			<div class="post-list__post-text">
									<div class="post-list__post-eyebrow">
						<a href="https://cacm.acm.org/section/news/">News</a>																			<span class="post-list__post-timestamp"><span class="posted-on"> Jul 3 2025</span></span>
																	</div>
													<p class="post-list__post-heading">
						<a href="https://cacm.acm.org/news/can-ai-replace-copilots-on-passenger-jets/">Can AI Replace Copilots on Passenger Jets?</a>
					</p>
												<div class="post-list__post-meta-group">
											<div class="post-list__post-byline">
							 Paul Marks						</div>
																<span class="post-list__post-topic"><a href="https://cacm.acm.org/category/artificial-intelligence-machine-learning/">Artificial Intelligence and Machine Learning</a></span>
									</div>
			</div>
							<figure class="post-list__post-figure">
					<a href="https://cacm.acm.org/news/can-ai-replace-copilots-on-passenger-jets/" aria-label="Can AI Replace Copilots on Passenger Jets?" aria-hidden="true" tabindex="-1">
													<div class="image-wrapper image-wrapper--widescreen"><img width="1024" height="576" src="https://cacm.acm.org/wp-content/uploads/2025/07/070325.News_.Can-AI-Replace-S.jpg" class="attachment-full size-full" alt="inside a cockpit" decoding="async" srcset="https://cacm.acm.org/wp-content/uploads/2025/07/070325.News_.Can-AI-Replace-S.jpg 2400w, https://cacm.acm.org/wp-content/uploads/2025/07/070325.News_.Can-AI-Replace-S.jpg?resize=300,169 300w, https://cacm.acm.org/wp-content/uploads/2025/07/070325.News_.Can-AI-Replace-S.jpg?resize=768,432 768w, https://cacm.acm.org/wp-content/uploads/2025/07/070325.News_.Can-AI-Replace-S.jpg?resize=1024,576 1024w, https://cacm.acm.org/wp-content/uploads/2025/07/070325.News_.Can-AI-Replace-S.jpg?resize=1536,864 1536w, https://cacm.acm.org/wp-content/uploads/2025/07/070325.News_.Can-AI-Replace-S.jpg?resize=2048,1152 2048w" sizes="(max-width: 1024px) 100vw, 1024px" /></div>											</a>
				</figure>
					</div>
	</article>
</div>

<div class="post-list__item">
	<article id="post-769299" class="post-list__post post-769299 post type-post status-publish format-standard has-post-thumbnail hentry category-architecture-and-hardware category-security-and-privacy section-blogcacm">
		<div class="post-list__post-content">
			<div class="post-list__post-text">
									<div class="post-list__post-eyebrow">
						<a href="https://cacm.acm.org/section/blogcacm/">BLOG@CACM</a>																			<span class="post-list__post-timestamp"><span class="posted-on"> Jul 3 2025</span></span>
																	</div>
													<p class="post-list__post-heading">
						<a href="https://cacm.acm.org/blogcacm/beyond-downtime-architectural-resilience-on-hyperscalers/">Beyond Downtime: Architectural Resilience on Hyperscalers</a>
					</p>
												<div class="post-list__post-meta-group">
											<div class="post-list__post-byline">
							 Azim Shaik						</div>
																<span class="post-list__post-topic"><a href="https://cacm.acm.org/category/architecture-and-hardware/">Architecture and Hardware</a></span>
									</div>
			</div>
							<figure class="post-list__post-figure">
					<a href="https://cacm.acm.org/blogcacm/beyond-downtime-architectural-resilience-on-hyperscalers/" aria-label="Beyond Downtime: Architectural Resilience on Hyperscalers" aria-hidden="true" tabindex="-1">
													<div class="image-wrapper image-wrapper--widescreen"><img width="1024" height="576" src="https://cacm.acm.org/wp-content/uploads/2025/07/070225.BLOG_.Beyond-Downtime-CC.jpg" class="attachment-full size-full" alt="Superman in the clouds" decoding="async" srcset="https://cacm.acm.org/wp-content/uploads/2025/07/070225.BLOG_.Beyond-Downtime-CC.jpg 1520w, https://cacm.acm.org/wp-content/uploads/2025/07/070225.BLOG_.Beyond-Downtime-CC.jpg?resize=300,169 300w, https://cacm.acm.org/wp-content/uploads/2025/07/070225.BLOG_.Beyond-Downtime-CC.jpg?resize=768,432 768w, https://cacm.acm.org/wp-content/uploads/2025/07/070225.BLOG_.Beyond-Downtime-CC.jpg?resize=1024,576 1024w" sizes="(max-width: 1024px) 100vw, 1024px" /></div>											</a>
				</figure>
					</div>
	</article>
</div>

<div class="post-list__item">
	<article id="post-769347" class="post-list__post post-769347 post type-post status-publish format-standard has-post-thumbnail hentry category-artificial-intelligence-machine-learning category-society section-news">
		<div class="post-list__post-content">
			<div class="post-list__post-text">
									<div class="post-list__post-eyebrow">
						<a href="https://cacm.acm.org/section/news/">News</a>																			<span class="post-list__post-timestamp"><span class="posted-on"> Jul 1 2025</span></span>
																	</div>
													<p class="post-list__post-heading">
						<a href="https://cacm.acm.org/news/can-eus-e200b-investai-initiative-close-europes-ai-gap-with-u-s-and-china/">Can EU’s €200B &#8216;InvestAI&#8217; Initiative Close Europe&#8217;s AI Gap with U.S. and China?</a>
					</p>
												<div class="post-list__post-meta-group">
											<div class="post-list__post-byline">
							 Mark Halper						</div>
																<span class="post-list__post-topic"><a href="https://cacm.acm.org/category/artificial-intelligence-machine-learning/">Artificial Intelligence and Machine Learning</a></span>
									</div>
			</div>
							<figure class="post-list__post-figure">
					<a href="https://cacm.acm.org/news/can-eus-e200b-investai-initiative-close-europes-ai-gap-with-u-s-and-china/" aria-label="Can EU’s €200B &#8216;InvestAI&#8217; Initiative Close Europe&#8217;s AI Gap with U.S. and China?" aria-hidden="true" tabindex="-1">
													<div class="image-wrapper image-wrapper--widescreen"><img width="1024" height="576" src="https://cacm.acm.org/wp-content/uploads/2025/07/070125.News_.Can-EUs-InvestAI-S.jpg" class="attachment-full size-full" alt="hologram Earth" decoding="async" srcset="https://cacm.acm.org/wp-content/uploads/2025/07/070125.News_.Can-EUs-InvestAI-S.jpg 2400w, https://cacm.acm.org/wp-content/uploads/2025/07/070125.News_.Can-EUs-InvestAI-S.jpg?resize=300,169 300w, https://cacm.acm.org/wp-content/uploads/2025/07/070125.News_.Can-EUs-InvestAI-S.jpg?resize=768,432 768w, https://cacm.acm.org/wp-content/uploads/2025/07/070125.News_.Can-EUs-InvestAI-S.jpg?resize=1024,576 1024w, https://cacm.acm.org/wp-content/uploads/2025/07/070125.News_.Can-EUs-InvestAI-S.jpg?resize=1536,864 1536w, https://cacm.acm.org/wp-content/uploads/2025/07/070125.News_.Can-EUs-InvestAI-S.jpg?resize=2048,1152 2048w" sizes="(max-width: 1024px) 100vw, 1024px" /></div>											</a>
				</figure>
					</div>
	</article>
</div>

</div>			</div>

		</section>

		
<div class="cta-membership cta-membership--no-js" data-component="ctaMembership">
	
		<section class="cta-become-a-member">
			<div class="cta-become-a-member__inner container">
				<h3					class="cta-become-a-member__heading">
					Shape the Future of Computing				</h3>
									<p class="cta-become-a-member__description">
						ACM encourages its members to take a direct hand in shaping the future of the association. There are more ways than ever to get involved.					</p>
													<a class="cta-become-a-member__link" href="https://www.acm.org/about-acm/get-involved">
						Get Involved											</a>
							</div>
		</section>

		
		<section class="cta-open-access">
			<div class="cta-open-access__inner container">
				<h3					class="cta-open-access__heading">
					Communications of the ACM (CACM) is now a fully Open Access publication.				</h3>
									<p class="cta-open-access__description">
						By opening CACM to the world, we hope to increase engagement among the broader computer science community and encourage non-members to discover the rich resources ACM has to offer.					</p>
													<a class="cta-open-access__link" href="https://cacm.acm.org/news/cacm-is-becoming-open-access">
						Learn More											</a>
							</div>
		</section>

		</div>

	
</article><!-- #post-## -->

			</main>
		</div>
	</div><!-- #content -->

	<footer id="colophon" class="site-footer">
		<div class="site-footer__inner container">
			<div class="site-footer__columns">
				<div class="site-footer__column site-footer__column-branding">
					<a class="site-footer__logo" aria-label="Home" href="https://cacm.acm.org">
						<svg aria-hidden="true" focusable="false" width="548" height="88" fill="#FFF"><use href="#am-symbol-cacm-logo"></use></svg>					</a>
					<nav class="social-navigation">
		<ul class="social-navigation__list">
		<li>
			<a href="https://twitter.com/cacmmag">
				<span class="screen-reader-only">CACM on Twitter</span>
				<svg aria-hidden="true" focusable="false" width="38" height="38" fill="#fff"><use href="#am-symbol-icon-social-twitter"></use></svg>			</a>
		</li>
		<li>
			<a href="https://www.reddit.com/user/TheOfficialACM">
				<span class="screen-reader-only">CACM on Reddit</span>
				<svg aria-hidden="true" focusable="false" width="38" height="38" fill="#fff"><use href="#am-symbol-icon-social-reddit"></use></svg>			</a>
		</li>
		<li>
			<a href="https://www.linkedin.com/groups/36836/">
				<span class="screen-reader-only">CACM on LinkedIn</span>
				<svg aria-hidden="true" focusable="false" width="38" height="38" fill="#fff"><use href="#am-symbol-icon-social-linkedin"></use></svg>			</a>
		</li>
	</ul>
</nav>
				</div>
				<div class="site-footer__column site-footer__column-topics">
					
<div class="site-footer__topics-menu">
			<p class="site-footer__heading">
			Topics		</p>
		<ul class="site-footer__topics-menu__list">
												<li>
					<a href="https://cacm.acm.org/category/architecture-and-hardware/">
						Architecture and Hardware					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/artificial-intelligence-machine-learning/">
						Artificial Intelligence and Machine Learning					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/computer-history/">
						Computer History					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/computing-applications/">
						Computing Applications					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/computing-profession/">
						Computing Profession					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/data-and-information/">
						Data and Information					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/education/">
						Education					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/hci/">
						HCI					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/philosophy-of-computing/">
						Philosophy of Computing					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/security-and-privacy/">
						Security and Privacy					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/society/">
						Society					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/software-engineering-and-programming-languages/">
						Software Engineering and Programming Languages					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/systems-and-networking/">
						Systems and Networking					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/theory/">
						Theory					</a>
				</li>
							</ul>
	</div>
				</div>
				<div class="site-footer__column site-footer__column-about">
					<div class="site-footer__menu-magazine">
						<p class="site-footer__heading">Magazine</p>
						<ul id="menu-magazine-footer" class="site-footer__menu-magazine-menu"><li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-217988"><a href="/issue/latest/" id="menu-link-10">Latest Issue</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-217989"><a href="/issues/" id="menu-link-11">Magazine Archive</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224644"><a href="https://cacm.acm.org/editorial-staff-board/" id="menu-link-12">Editorial Staff and Board</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-751386"><a href="https://cacm.acm.org/author-guidelines#CACMsubmission" id="menu-link-13">Submit an Article</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224585"><a href="https://cacm.acm.org/feeds-2/" id="menu-link-14">Alerts &#038; Feeds</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224645"><a href="https://cacm.acm.org/author-guidelines/" id="menu-link-15">Author Guidelines</a></li>
</ul>					</div>
					<div class="site-footer__menu-communications">
						<p class="site-footer__heading">Communications of the ACM</p>
						<ul id="menu-communications-footer" class="site-footer-communications-menu"><li id="menu-item-224637" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224637"><a href="https://cacm.acm.org/about-us/" id="menu-link-16">About Us</a></li>
<li id="menu-item-224664" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224664"><a href="https://cacm.acm.org/faq/" id="menu-link-17">Frequently Asked Questions</a></li>
<li id="menu-item-224638" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224638"><a href="https://cacm.acm.org/contact-us/" id="menu-link-18">Contact Us</a></li>
<li id="menu-item-217972" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-217972"><a href="https://www.acm.org/publications/advertising" id="menu-link-19">For Advertisers</a></li>
<li id="menu-item-224639" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224639"><a href="https://cacm.acm.org/join-acm/" id="menu-link-20">Join ACM</a></li>
</ul>					</div>
				</div>
			</div>
			<div class="site-footer__info">
				<div class="site-footer__info__inner">
					<p class="site-footer__info-copyright"><small>
						&copy; 2025 Communications of the ACM. All Rights Reserved. 						</small></p>
					<div class="menu-policy-menu-container"><ul id="menu-policy-footer" class="site-footer__info-policy-list"><li id="menu-item-217993" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-217993"><a href="https://www.acm.org/cookie-notice" id="menu-link-21">Cookie Notice</a></li>
<li id="menu-item-217994" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-217994"><a href="https://www.acm.org/about-acm/privacy-policy" id="menu-link-22">Privacy Policy</a></li>
</ul></div>				</div>
			</div>
		</div>
	</footer><!-- #colophon -->
</div><!-- #page -->

<script type="text/javascript" src="https://cacm.acm.org/wp-includes/js/dist/hooks.min.js?ver=4d63a3d491d11ffd8ac6" id="wp-hooks-js"></script>
<script type="text/javascript" src="https://cacm.acm.org/wp-includes/js/dist/i18n.min.js?ver=5e580eb46a90c2b997e6" id="wp-i18n-js"></script>
<script type="text/javascript" id="wp-i18n-js-after">
/* <![CDATA[ */
wp.i18n.setLocaleData( { 'text direction\u0004ltr': [ 'ltr' ] } );
/* ]]> */
</script>
<script type="text/javascript" id="wp-parsely-loader-js-before">
/* <![CDATA[ */
window.wpParselySiteId = 'acm.org';
/* ]]> */
</script>
<script type="text/javascript" src="https://cacm.acm.org/wp-content/mu-plugins/wp-parsely-3.20/build/loader.js?ver=ecf94842061bea03d54b" id="wp-parsely-loader-js"></script>
<script type="text/javascript" data-parsely-site="acm.org" src="https://cdn.parsely.com/keys/acm.org/p.js?ver=3.20.3" id="parsely-cfg"></script>
<script type="text/javascript" src="https://cacm.acm.org/wp-content/themes/cacm/client/build/js/global.bundle.min.js?ver=4b18fcd24c7110dd0a1b" id="cacm-global-js"></script>
<script type="text/javascript" id="cacm-article-js-extra">
/* <![CDATA[ */
var cacmLocalVars = {"restCommentsUrl":"https:\/\/cacm.acm.org\/wp-json\/wp\/v2\/comments","restCommentFormUrl":"https:\/\/cacm.acm.org\/wp-json\/cacm-plugin\/v1\/comment\/form\/768598"};
/* ]]> */
</script>
<script type="text/javascript" src="https://cacm.acm.org/wp-content/themes/cacm/client/build/js/article.bundle.min.js?ver=1c812bd1084810e0b400" id="cacm-article-js"></script>
<script type="text/javascript" src="https://cacm.acm.org/wp-includes/js/comment-reply.min.js?ver=6.7.2" id="comment-reply-js" async="async" data-wp-strategy="async"></script>
<script type="text/javascript" id="jetpack-stats-js-before">
/* <![CDATA[ */
_stq = window._stq || [];
_stq.push([ "view", JSON.parse("{\"v\":\"ext\",\"blog\":\"212686646\",\"post\":\"768598\",\"tz\":\"-4\",\"srv\":\"cacm.acm.org\",\"hp\":\"vip\",\"j\":\"1:14.7\"}") ]);
_stq.push([ "clickTrackerInit", "212686646", "768598" ]);
/* ]]> */
</script>
<script type="text/javascript" src="https://stats.wp.com/e-202527.js" id="jetpack-stats-js" defer="defer" data-wp-strategy="defer"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML" id="mathjax-js"></script>


<!-- Mopinion Pastea.se  start --><script type="text/javascript">(function(){var id="Sh2m7XRvbVWoA8uJG6g2wIBNDLfpsOxFx1ciwKwo";var js=document.createElement("script");js.setAttribute("type","text/javascript");js.setAttribute("src","//deploy.mopinion.com/js/pastease.js");js.async=true;document.getElementsByTagName("head")[0].appendChild(js);var t=setInterval(function(){try{Pastease.load(id);clearInterval(t)}catch(e){}},50)})();</script> <!-- Mopinion Pastea.se end -->

</body>
</html>
