<!doctype html>
<html lang="en-US">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="profile" href="https://gmpg.org/xfn/11">

	<script id="Cookiebot" src="https://consent.cookiebot.com/uc.js" data-cbid="095b91a6-f087-4380-b01d-e44b1c2af358" data-blockingmode="auto" type="text/javascript"></script>
	<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-XYTVD2CXR4"></script>
<script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());

	gtag('config', 'G-XYTVD2CXR4');
</script>

	<title>HammingMesh: A Network Topology for Large-Scale Deep Learning &#8211; Communications of the ACM</title>
<meta name='robots' content='max-image-preview:large' />
	<style>img:is([sizes="auto" i], [sizes^="auto," i]) { contain-intrinsic-size: 3000px 1500px }</style>
	<link rel='dns-prefetch' href='//stats.wp.com' />
<link rel="alternate" type="application/rss+xml" title="Communications of the ACM &raquo; Feed" href="https://cacm.acm.org/feed/" />
<link rel="alternate" type="application/rss+xml" title="Communications of the ACM &raquo; Comments Feed" href="https://cacm.acm.org/comments/feed/" />
<link rel="alternate" type="application/rss+xml" title="Communications of the ACM &raquo; HammingMesh: A Network Topology for Large-Scale Deep Learning Comments Feed" href="https://cacm.acm.org/research-highlights/hammingmesh-a-network-topology-for-large-scale-deep-learning/feed/" />
<script class="wp-asset-manager usage-logger" type="text/javascript">window.amScripts = window.amScripts || {}; window.amScripts["usage-logger"] = {"nonce":"b0294636e1","id":753517,"type":"digital-library","doi":"10.1145\/3623490"}</script><style class="wp-asset-manager cacm-global-critical" type="text/css">@font-face{font-display:swap;font-family:Inter;font-style:normal;src:url(../be7cb18dc7caf47cf7e9.woff2) format("woff2"),url(../817c4274293e221c5076.woff) format("woff")}@font-face{font-display:swap;font-family:Inter;font-style:normal;font-weight:700;src:url(../54321e26b8bf4739a16d.woff2) format("woff2"),url(../7ad0df5561cc0933cead.woff) format("woff")}@font-face{font-display:swap;font-family:Work Sans;font-style:normal;font-weight:500;src:url(../2dd7c3c79fd1aa1d85ca.woff2) format("woff2"),url(../9a8cbe3b3bec955df411.woff) format("woff")}@font-face{font-display:swap;font-family:Work Sans;font-style:normal;font-weight:700;src:url(../ab8702255905c24de1c1.woff2) format("woff2"),url(../9ab52d2504cfe145b9bd.woff) format("woff")}@font-face{font-display:swap;font-family:Work Sans;font-style:normal;font-weight:800;src:url(../cef488e4e9f273a0a1e3.woff2) format("woff2"),url(../a99bf2b51c426338ae2c.woff) format("woff")}html{box-sizing:border-box}html *,html :after,html :before{box-sizing:inherit}a,abbr,address,article,aside,audio,b,blockquote,body,canvas,caption,cite,code,dd,del,details,dfn,div,dl,dt,em,embed,fieldset,figcaption,figure,footer,form,h1,h2,h3,h4,h5,h6,header,html,i,iframe,img,ins,kbd,label,legend,li,mark,menu,nav,object,ol,output,p,pre,q,ruby,s,samp,section,small,span,strike,strong,sub,summary,sup,table,tbody,td,tfoot,th,thead,time,tr,u,ul,var,video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}article,aside,details,figcaption,figure,footer,header,menu,nav,section{display:block}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:after,blockquote:before,q:after,q:before{content:"";content:none}table{border-collapse:collapse;border-spacing:0}fieldset{border:none;margin:0;padding:0}button,input,select,textarea{-webkit-appearance:none;-moz-appearance:none;appearance:none;border:0;border-radius:0;font:inherit;margin:0}button{background-color:transparent;padding:0}body,html{font-family:var(--wp--preset--font-family--inter);-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}html{scroll-padding-top:var(--wp--custom--siteheader-height)!important}body{overflow-x:hidden}a img{display:block}img{height:auto;max-width:100%}svg{display:block}.container{margin-left:auto;margin-right:auto;width:calc(min(100%,var(--wp--style--global--wide-size) + var(--wp--custom--site-edge)*2) - var(--wp--custom--site-edge)*2)}.screen-reader-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;padding:0;width:1px}.screen-reader-only,.skip-link{overflow:hidden;position:absolute}.skip-link{margin-left:auto;margin-right:auto;background-color:var(--wp--preset--color--white);color:inherit;left:0;opacity:0;padding:.625rem;right:0;text-align:center;text-decoration:none;top:0;transform:translateY(-100%);width:-moz-max-content;width:max-content;z-index:-1}.skip-link:focus{opacity:1;transform:translateY(0);z-index:2147483647}.site-content{padding-top:var(--wp--custom--siteheader-height)}@media(min-width:48rem){.site-content{padding-top:var(--wp--custom--siteheader-height)}}.site-header-hamburger-menu[aria-hidden=true]{display:none}.site-header-membership-nav{align-self:stretch;display:flex;position:relative}.site-header--expanded .site-header-membership-nav,.site-header:not(.site-header--member-logged-in) .site-header-membership-nav{display:none}.site-header{position:fixed;width:100%;z-index:7}.site-header--expanded{height:100%}.site-header--no-js{opacity:0}.site-header.headroom{transition:transform .2s linear;will-change:transform}.site-header.headroom--pinned{transform:translateY(0)}.site-header.headroom--unpinned{height:auto;transform:translateY(-100%)}.site-header-container{align-items:center;background-color:var(--wp--preset--color--white);border-bottom:var(--wp--custom--border-gray);display:flex;gap:1rem;height:var(--wp--custom--siteheader-height);justify-content:space-between;padding:0 1rem}.site-header-container a{text-decoration:none}.site-header-container a:active,.site-header-container a:focus,.site-header-container a:hover{text-decoration:underline;text-decoration-color:inherit;text-decoration-thickness:1px;text-underline-offset:2.5px}@media(min-width:37.5rem){.site-header-container{padding:0 1.5rem}}@media(min-width:48rem){.site-header-container{padding:0 0 0 1rem}}@media(min-width:64rem){.site-header-container{gap:2.25rem}}@media(min-width:80rem){.site-header-container{gap:3rem}}.site-header--member-logged-in .site-header-container{padding:0 0 0 1rem}@media(min-width:37.5rem){.site-header--member-logged-in .site-header-container{padding:0 0 0 1.5rem}}.site-header--expanded .site-header-container{background-color:var(--wp--preset--color--cacm-darker-blue)}@media(max-width:47.9375rem){.site-header-logo,.site-header-search{margin-left:auto}}.site-header-member-login-link{font-weight:var(--wp--custom--font-weight-bold)}.site-header-member-login-link[aria-hidden=true]{visibility:hidden}@media(max-width:47.9375rem){.site-header-member-login-link{display:none}}.site-header--member-logged-in .site-header-member-login-link{display:none}.site-header-magazine-menu,.site-header-topics-menu{position:relative}.site-header-magazine-menu-toggle,.site-header-topics-menu-toggle{font-size:.9375rem;font-weight:var(--wp--custom--font-weight-regular);line-height:1.21;align-items:center;cursor:pointer;display:flex;gap:.3333333333rem}@media(min-width:80rem){.site-header-magazine-menu-toggle,.site-header-topics-menu-toggle{font-size:1rem;font-weight:var(--wp--custom--font-weight-regular);line-height:1.21;gap:.65625rem}}.site-header-magazine-menu-toggle[aria-hidden=true],.site-header-topics-menu-toggle[aria-hidden=true]{visibility:hidden}.site-header-magazine-menu-toggle[aria-expanded=true]>svg,.site-header-topics-menu-toggle[aria-expanded=true]>svg{transform:rotate(180deg)}.site-header-magazine-menu-toggle:focus,.site-header-magazine-menu-toggle:hover,.site-header-topics-menu-toggle:focus,.site-header-topics-menu-toggle:hover{text-decoration:underline}.site-header-magazine-menu-expanded,.site-header-topics-menu-expanded{background-color:var(--wp--preset--color--white);border-radius:.3125rem;box-shadow:0 .125rem .25rem -.125rem rgba(24,39,75,.12),0 .25rem .25rem -.125rem rgba(24,39,75,.08);display:flex;gap:1.875rem;justify-content:space-between;padding:1.75rem 1.875rem 1.5rem;position:absolute;right:0;text-align:left;top:2.28125rem;white-space:nowrap;z-index:4}.site-header-magazine-menu-expanded[aria-hidden=true],.site-header-topics-menu-expanded[aria-hidden=true]{display:none}@media(max-width:47.9375rem){.site-header-magazine-menu,.site-header-topics-menu{display:none}}.site-header:not(.site-header--member-logged-in) .site-header-topics-menu-expanded{left:0;right:auto}</style><style class="wp-asset-manager cacm-article-critical" type="text/css">.article-header{left:50%;margin-left:-50vw;margin-right:-50vw;position:relative;right:50%;width:100vw;background-color:var(--cacm--article-header--background-color);border-bottom:1px solid var(--cacm--article-header--border-color);color:var(--cacm--article-header--text-color);margin-bottom:var(--wp--custom--gap)}@media(min-width:48rem){.article-header{grid-area:header;margin-bottom:1.5rem}}.article-header__inner{--wp--custom--vertical-block-rhythm:0.5rem;padding:2rem 0 0}@media(min-width:48rem){.article-header__inner{--wp--custom--vertical-block-rhythm:0.625rem;display:grid;gap:0 var(--cacm--article--gap);grid-template-columns:auto 1fr;padding:var(--cacm--article--gap) 0}}@media(min-width:64rem){.article-header__inner{grid-template-columns:var(--cacm--article--sidebarleft--width) 1fr}}.article-header__section{margin-bottom:var(--wp--custom--vertical-block-rhythm);display:inline-block}.article-header__section:last-child{margin-bottom:0}.article-header__section a{text-decoration:none}.article-header__section a:active,.article-header__section a:focus,.article-header__section a:hover{text-decoration:underline;text-decoration-color:inherit;text-decoration-thickness:1px;text-underline-offset:2.5px}@media(max-width:47.9375rem){.article-header__section{margin-right:.625rem}}@media(min-width:48rem){.article-header__section{grid-column:1/1;text-align:right}}.article-header__section>a{font-size:.875rem;font-weight:700;line-height:1.2142857143;background-color:var(--cacm--article-header--button--background-color);color:var(--cacm--article-header--button--text-color);display:inline-block;padding:.3125rem .625rem;text-transform:uppercase}@media(min-width:48rem){.article-header__figure,.article-header__meta,.article-header__share,.article-header__subtitle,.article-header__title,.article-header__topic-and-issue-section{grid-column:2/2}}.article-header__topic-and-issue-section{--wp--custom--vertical-block-rhythm:0.5rem;margin-bottom:var(--wp--custom--vertical-block-rhythm);font-size:.9375rem;line-height:1.5333333333;font-family:var(--wp--preset--font-family--inter);display:flex;flex-direction:column}.article-header__topic-and-issue-section:last-child{margin-bottom:0}@media(min-width:48rem){.article-header__topic-and-issue-section{--wp--custom--vertical-block-rhythm:1.25rem;align-items:center;flex-direction:row;gap:2rem}}.article-header__issue-section{color:var(--cacm--article-header--text-color)}.article-header__title{margin-bottom:var(--wp--custom--vertical-block-rhythm);font-family:var(--wp--preset--font-family--work-sans);font-size:var(--wp--preset--font-size--work-md);line-height:32.2px;font-weight:var(--wp--custom--font-weight-extrabold)}.article-header__title:last-child{margin-bottom:0}@media(min-width:48rem){.article-header__title{font-size:var(--wp--preset--font-size--work-xxxl);line-height:50.4px;font-weight:var(--wp--custom--font-weight-extrabold)}}@media(min-width:64rem){.article-header__title{font-size:var(--wp--preset--font-size--work-xxl);line-height:44.28px;font-weight:var(--wp--custom--font-weight-extrabold)}}.article-header__subtitle{font-family:var(--wp--preset--font-family--work-sans);font-size:var(--wp--preset--font-size--work-xxs);line-height:22.5px;font-weight:var(--wp--custom--font-weight-bold);font-size:1.3125rem;line-height:1.2380952381;letter-spacing:-.08px;font-weight:var(--wp--custom--font-weight-medium);letter-spacing:-.03125rem;margin-bottom:.125rem}.article-header__subtitle:last-child{margin-bottom:0}.article-header__subtitle a{word-break:break-word}.article-header__subtitle b,.article-header__subtitle strong{font-weight:var(--wp--custom--font-weight-bold)}.article-header__subtitle em,.article-header__subtitle i{font-style:italic}.article-header__subtitle del,.article-header__subtitle strike{text-decoration:line-through}.article-header__subtitle sub,.article-header__subtitle sup{font-size:75%;line-height:0;position:relative}.article-header__subtitle sub{bottom:-.25em}.article-header__subtitle sup{top:-.5em}.article-header__subtitle .monospace,.article-header__subtitle p code{font:var(--wp--custom--font-weight-regular) 90%/1.6 Courier,monospace}@media(min-width:48rem){.article-header__subtitle{--wp--custom--vertical-block-rhythm:1.25rem;font-family:var(--wp--preset--font-family--work-sans);font-size:var(--wp--preset--font-size--work-xs);line-height:25.2px;font-weight:var(--wp--custom--font-weight-bold);font-size:1.5625rem;line-height:1.2;letter-spacing:-.1px;font-weight:var(--wp--custom--font-weight-medium);letter-spacing:-.03125rem;margin:.5rem 0 .625rem}.article-header__subtitle:last-child{margin-bottom:0}}.article-header__meta{margin-bottom:var(--wp--custom--vertical-block-rhythm);font-size:.9375rem;line-height:1.5333333333;font-family:var(--wp--preset--font-family--inter);display:flex;flex-direction:column}.article-header__meta:last-child{margin-bottom:0}.article-header__meta>*{margin-bottom:var(--wp--custom--vertical-block-rhythm)}.article-header__meta>:last-child{margin-bottom:0}.article-header__byline{margin-top:.625rem}.article-header__byline>a{border-bottom:1px dotted var(--cacm--article-header--byline--text-color);color:var(--cacm--article-header--byline--text-color);text-decoration:none}@media(max-width:47.9375rem){.article-header__figure{left:50%;margin-left:-50vw;margin-right:-50vw;position:relative;right:50%;width:100vw}}@media(min-width:48rem){.article-header__figure{display:flex;flex-direction:column}}.article-header__figure .image-wrapper{margin-bottom:var(--wp--custom--vertical-block-rhythm)}.article-header__figure .image-wrapper:last-child{margin-bottom:0}@media(min-width:64rem){.article-header__figure .image-wrapper{grid-column:1/1}}.article-header__figure .image-wrapper>img{-o-object-fit:cover;object-fit:cover}.article-header__figure .video-wrapper{height:100%;overflow:hidden;position:relative;width:100%;padding-bottom:56.25%}.article-header__figure .video-wrapper>iframe{height:100%;left:0;-o-object-fit:contain;object-fit:contain;position:absolute;top:0;width:100%}.article-header__figure .video-wrapper>:not(iframe){display:none}.article-header__figure figcaption{font-size:.9375rem;line-height:1.4666666667;font-family:var(--wp--preset--font-family--inter);color:var(--cacm--article-header--caption--text-color)}@media(max-width:47.9375rem){.article-header__figure figcaption{margin:0 var(--wp--custom--site-edge)}}@media(min-width:64rem){.article-header__figure figcaption{grid-column:2/2;margin:0}}.article-header__figure figcaption>p.article-header--credit{font-style:italic}</style><link rel="preload" href="https://cacm.acm.org/wp-content/themes/cacm/client/src/fonts/inter-v12-latin-regular.woff2" class="wp-asset-manager cacm-font-inter-regular-woff2" as="font" media="all" type="font/woff2" crossorigin /><link rel="preload" href="https://cacm.acm.org/wp-content/themes/cacm/client/src/fonts/inter-v12-latin-700.woff2" class="wp-asset-manager cacm-font-inter-700-woff2" as="font" media="all" type="font/woff2" crossorigin /><link rel="preload" href="https://cacm.acm.org/wp-content/themes/cacm/client/src/fonts/work-sans-bold.woff2?ver=1.0.0" class="wp-asset-manager cacm-font-work-sans-700-woff2" as="style" media="all" type="font/woff2" /><link rel="preload" href="https://cacm.acm.org/wp-content/themes/cacm/client/src/fonts/work-sans-extrabold.woff2?ver=1.0.0" class="wp-asset-manager cacm-font-work-sans-800-woff2" as="style" media="all" type="font/woff2" /><script type="text/javascript">
/* <![CDATA[ */
window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.0.3\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.0.3\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/cacm.acm.org\/wp-includes\/js\/wp-emoji-release.min.js?ver=6.7.1"}};
/*! This file is auto-generated */
!function(i,n){var o,s,e;function c(e){try{var t={supportTests:e,timestamp:(new Date).valueOf()};sessionStorage.setItem(o,JSON.stringify(t))}catch(e){}}function p(e,t,n){e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(t,0,0);var t=new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data),r=(e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(n,0,0),new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data));return t.every(function(e,t){return e===r[t]})}function u(e,t,n){switch(t){case"flag":return n(e,"\ud83c\udff3\ufe0f\u200d\u26a7\ufe0f","\ud83c\udff3\ufe0f\u200b\u26a7\ufe0f")?!1:!n(e,"\ud83c\uddfa\ud83c\uddf3","\ud83c\uddfa\u200b\ud83c\uddf3")&&!n(e,"\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc65\udb40\udc6e\udb40\udc67\udb40\udc7f","\ud83c\udff4\u200b\udb40\udc67\u200b\udb40\udc62\u200b\udb40\udc65\u200b\udb40\udc6e\u200b\udb40\udc67\u200b\udb40\udc7f");case"emoji":return!n(e,"\ud83d\udc26\u200d\u2b1b","\ud83d\udc26\u200b\u2b1b")}return!1}function f(e,t,n){var r="undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?new OffscreenCanvas(300,150):i.createElement("canvas"),a=r.getContext("2d",{willReadFrequently:!0}),o=(a.textBaseline="top",a.font="600 32px Arial",{});return e.forEach(function(e){o[e]=t(a,e,n)}),o}function t(e){var t=i.createElement("script");t.src=e,t.defer=!0,i.head.appendChild(t)}"undefined"!=typeof Promise&&(o="wpEmojiSettingsSupports",s=["flag","emoji"],n.supports={everything:!0,everythingExceptFlag:!0},e=new Promise(function(e){i.addEventListener("DOMContentLoaded",e,{once:!0})}),new Promise(function(t){var n=function(){try{var e=JSON.parse(sessionStorage.getItem(o));if("object"==typeof e&&"number"==typeof e.timestamp&&(new Date).valueOf()<e.timestamp+604800&&"object"==typeof e.supportTests)return e.supportTests}catch(e){}return null}();if(!n){if("undefined"!=typeof Worker&&"undefined"!=typeof OffscreenCanvas&&"undefined"!=typeof URL&&URL.createObjectURL&&"undefined"!=typeof Blob)try{var e="postMessage("+f.toString()+"("+[JSON.stringify(s),u.toString(),p.toString()].join(",")+"));",r=new Blob([e],{type:"text/javascript"}),a=new Worker(URL.createObjectURL(r),{name:"wpTestEmojiSupports"});return void(a.onmessage=function(e){c(n=e.data),a.terminate(),t(n)})}catch(e){}c(n=f(s,u,p))}t(n)}).then(function(e){for(var t in e)n.supports[t]=e[t],n.supports.everything=n.supports.everything&&n.supports[t],"flag"!==t&&(n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&n.supports[t]);n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&!n.supports.flag,n.DOMReady=!1,n.readyCallback=function(){n.DOMReady=!0}}).then(function(){return e}).then(function(){var e;n.supports.everything||(n.readyCallback(),(e=n.source||{}).concatemoji?t(e.concatemoji):e.wpemoji&&e.twemoji&&(t(e.twemoji),t(e.wpemoji)))}))}((window,document),window._wpemojiSettings);
/* ]]> */
</script>
<style id='wp-emoji-styles-inline-css' type='text/css'>

	img.wp-smiley, img.emoji {
		display: inline !important;
		border: none !important;
		box-shadow: none !important;
		height: 1em !important;
		width: 1em !important;
		margin: 0 0.07em !important;
		vertical-align: -0.1em !important;
		background: none !important;
		padding: 0 !important;
	}
</style>
<link rel='stylesheet' id='wp-block-library-css' href='https://cacm.acm.org/wp-includes/css/dist/block-library/style.min.css?ver=6.7.1' type='text/css' media='all' />
<link rel='stylesheet' id='mediaelement-css' href='https://cacm.acm.org/wp-includes/js/mediaelement/mediaelementplayer-legacy.min.css?ver=4.2.17' type='text/css' media='all' />
<link rel='stylesheet' id='wp-mediaelement-css' href='https://cacm.acm.org/wp-includes/js/mediaelement/wp-mediaelement.min.css?ver=6.7.1' type='text/css' media='all' />
<style id='jetpack-sharing-buttons-style-inline-css' type='text/css'>
.jetpack-sharing-buttons__services-list{display:flex;flex-direction:row;flex-wrap:wrap;gap:0;list-style-type:none;margin:5px;padding:0}.jetpack-sharing-buttons__services-list.has-small-icon-size{font-size:12px}.jetpack-sharing-buttons__services-list.has-normal-icon-size{font-size:16px}.jetpack-sharing-buttons__services-list.has-large-icon-size{font-size:24px}.jetpack-sharing-buttons__services-list.has-huge-icon-size{font-size:36px}@media print{.jetpack-sharing-buttons__services-list{display:none!important}}.editor-styles-wrapper .wp-block-jetpack-sharing-buttons{gap:0;padding-inline-start:0}ul.jetpack-sharing-buttons__services-list.has-background{padding:1.25em 2.375em}
</style>
<style id='elasticpress-facet-style-inline-css' type='text/css'>
.widget_ep-facet input[type=search],.wp-block-elasticpress-facet input[type=search]{margin-bottom:1rem}.widget_ep-facet .searchable .inner,.wp-block-elasticpress-facet .searchable .inner{max-height:20em;overflow:scroll}.widget_ep-facet .term.hide,.wp-block-elasticpress-facet .term.hide{display:none}.widget_ep-facet .empty-term,.wp-block-elasticpress-facet .empty-term{opacity:.5;position:relative}.widget_ep-facet .empty-term:after,.wp-block-elasticpress-facet .empty-term:after{bottom:0;content:" ";display:block;left:0;position:absolute;right:0;top:0;width:100%;z-index:2}.widget_ep-facet .level-1,.wp-block-elasticpress-facet .level-1{padding-left:20px}.widget_ep-facet .level-2,.wp-block-elasticpress-facet .level-2{padding-left:40px}.widget_ep-facet .level-3,.wp-block-elasticpress-facet .level-3{padding-left:60px}.widget_ep-facet .level-4,.wp-block-elasticpress-facet .level-4{padding-left:5pc}.widget_ep-facet .level-5,.wp-block-elasticpress-facet .level-5{padding-left:75pt}.widget_ep-facet input[disabled],.wp-block-elasticpress-facet input[disabled]{cursor:pointer;opacity:1}.widget_ep-facet .term a,.wp-block-elasticpress-facet .term a{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex;position:relative}.widget_ep-facet .term a:hover .ep-checkbox,.wp-block-elasticpress-facet .term a:hover .ep-checkbox{background-color:#ccc}.ep-checkbox{-webkit-box-align:center;-ms-flex-align:center;-ms-flex-negative:0;-webkit-box-pack:center;-ms-flex-pack:center;align-items:center;background-color:#eee;display:-webkit-box;display:-ms-flexbox;display:flex;flex-shrink:0;height:1em;justify-content:center;margin-right:.25em;width:1em}.ep-checkbox:after{border:solid #fff;border-width:0 .125em .125em 0;content:"";display:none;height:.5em;-webkit-transform:rotate(45deg);transform:rotate(45deg);width:.25em}.ep-checkbox.checked{background-color:#5e5e5e}.ep-checkbox.checked:after{display:block}

</style>
<link rel='stylesheet' id='elasticpress-related-posts-block-css' href='https://cacm.acm.org/wp-content/mu-plugins/search/elasticpress/dist/css/related-posts-block-styles.min.css?ver=4.2.2' type='text/css' media='all' />
<style id='global-styles-inline-css' type='text/css'>
:root{--wp--preset--aspect-ratio--square: 1;--wp--preset--aspect-ratio--4-3: 4/3;--wp--preset--aspect-ratio--3-4: 3/4;--wp--preset--aspect-ratio--3-2: 3/2;--wp--preset--aspect-ratio--2-3: 2/3;--wp--preset--aspect-ratio--16-9: 16/9;--wp--preset--aspect-ratio--9-16: 9/16;--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--color--cacm-blue: #337AB5;--wp--preset--color--cacm-link-blue: #015FAC;--wp--preset--color--cacm-dark-blue: #1E4A88;--wp--preset--color--cacm-darker-blue: #29303C;--wp--preset--color--cacm-light-blue: #B6DEFF;--wp--preset--color--cacm-peach: #F7ACA5;--wp--preset--color--cacm-beige: #F5F2DC;--wp--preset--color--cacm-brown: #8C6A54;--wp--preset--color--cacm-green: #5F7D05;--wp--preset--color--cacm-light-green: #EFF7F1;--wp--preset--color--cacm-black: #141414;--wp--preset--color--cacm-gray-100: #FBFCFC;--wp--preset--color--cacm-gray-200: #F8F9FA;--wp--preset--color--cacm-gray-300: #EBEDEF;--wp--preset--color--cacm-gray-500: #A9ACB1;--wp--preset--color--cacm-gray-600: #5A6875;--wp--preset--color--cacm-gray-700: #3D4550;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--gradient--primary-gradient: linear-gradient(90deg, #80C2EF 0%, #337AB5 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;--wp--preset--font-size--work-xxxs: 16px;--wp--preset--font-size--work-xxs: 18px;--wp--preset--font-size--work-xs: 21px;--wp--preset--font-size--work-sm: 25px;--wp--preset--font-size--work-md: 28px;--wp--preset--font-size--work-lg: 33px;--wp--preset--font-size--work-xl: 37px;--wp--preset--font-size--work-xxl: 41px;--wp--preset--font-size--work-xxxl: 48px;--wp--preset--font-size--inter-xxxs: 15px;--wp--preset--font-size--inter-xxs: 18px;--wp--preset--font-size--inter-xs: 21px;--wp--preset--font-size--inter-sm: 24px;--wp--preset--font-size--inter-md: 28px;--wp--preset--font-size--inter-lg: 32px;--wp--preset--font-size--inter-xl: 36px;--wp--preset--font-size--inter-xxl: 41px;--wp--preset--font-size--inter-xxxl: 47px;--wp--preset--font-family--inter: 'Inter', helvetica, arial, sans-serif;--wp--preset--font-family--work-sans: 'Work Sans', helvetica, arial, sans-serif;--wp--preset--spacing--20: 0.44rem;--wp--preset--spacing--30: 0.67rem;--wp--preset--spacing--40: 1rem;--wp--preset--spacing--50: 1.5rem;--wp--preset--spacing--60: 2.25rem;--wp--preset--spacing--70: 3.38rem;--wp--preset--spacing--80: 5.06rem;--wp--preset--shadow--natural: 6px 6px 9px rgba(0, 0, 0, 0.2);--wp--preset--shadow--deep: 12px 12px 50px rgba(0, 0, 0, 0.4);--wp--preset--shadow--sharp: 6px 6px 0px rgba(0, 0, 0, 0.2);--wp--preset--shadow--outlined: 6px 6px 0px -3px rgba(255, 255, 255, 1), 6px 6px rgba(0, 0, 0, 1);--wp--preset--shadow--crisp: 6px 6px 0px rgba(0, 0, 0, 1);--wp--custom--adminbar-height: 0px;--wp--custom--siteheader-height: 72px;--wp--custom--site-edge: 20px;--wp--custom--gap: 40px;--wp--custom--gap-half: calc(var(--wp--custom--gap) / 2);--wp--custom--section-background-color: transparent;--wp--custom--placeholder-background-color: var(--wp--preset--color--cacm-gray-200);--wp--custom--vertical-block-rhythm: 40px;--wp--custom--border-gray: 1px solid var(--wp--preset--color--cacm-gray-300);--wp--custom--font-weight-regular: 400;--wp--custom--font-weight-medium: 500;--wp--custom--font-weight-bold: 700;--wp--custom--font-weight-extrabold: 900;}.wp-block-heading{--wp--preset--font-size--work-xxs: 18px;--wp--preset--font-size--work-xs: 21px;--wp--preset--font-size--work-sm: 25px;--wp--preset--font-size--work-md: 28px;--wp--preset--font-size--work-lg: 33px;--wp--preset--font-size--work-xl: 41px;}:root { --wp--style--global--content-size: 1280px;--wp--style--global--wide-size: 1280px; }:where(body) { margin: 0; }.wp-site-blocks > .alignleft { float: left; margin-right: 2em; }.wp-site-blocks > .alignright { float: right; margin-left: 2em; }.wp-site-blocks > .aligncenter { justify-content: center; margin-left: auto; margin-right: auto; }:where(.is-layout-flex){gap: 0.5em;}:where(.is-layout-grid){gap: 0.5em;}.is-layout-flow > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}.is-layout-flow > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}.is-layout-flow > .aligncenter{margin-left: auto !important;margin-right: auto !important;}.is-layout-constrained > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}.is-layout-constrained > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}.is-layout-constrained > .aligncenter{margin-left: auto !important;margin-right: auto !important;}.is-layout-constrained > :where(:not(.alignleft):not(.alignright):not(.alignfull)){max-width: var(--wp--style--global--content-size);margin-left: auto !important;margin-right: auto !important;}.is-layout-constrained > .alignwide{max-width: var(--wp--style--global--wide-size);}body .is-layout-flex{display: flex;}.is-layout-flex{flex-wrap: wrap;align-items: center;}.is-layout-flex > :is(*, div){margin: 0;}body .is-layout-grid{display: grid;}.is-layout-grid > :is(*, div){margin: 0;}body{padding-top: 0px;padding-right: 0px;padding-bottom: 0px;padding-left: 0px;}a:where(:not(.wp-element-button)){text-decoration: underline;}:root :where(.wp-element-button, .wp-block-button__link){background-color: #32373c;border-width: 0;color: #fff;font-family: inherit;font-size: inherit;line-height: inherit;padding: calc(0.667em + 2px) calc(1.333em + 2px);text-decoration: none;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-cacm-blue-color{color: var(--wp--preset--color--cacm-blue) !important;}.has-cacm-link-blue-color{color: var(--wp--preset--color--cacm-link-blue) !important;}.has-cacm-dark-blue-color{color: var(--wp--preset--color--cacm-dark-blue) !important;}.has-cacm-darker-blue-color{color: var(--wp--preset--color--cacm-darker-blue) !important;}.has-cacm-light-blue-color{color: var(--wp--preset--color--cacm-light-blue) !important;}.has-cacm-peach-color{color: var(--wp--preset--color--cacm-peach) !important;}.has-cacm-beige-color{color: var(--wp--preset--color--cacm-beige) !important;}.has-cacm-brown-color{color: var(--wp--preset--color--cacm-brown) !important;}.has-cacm-green-color{color: var(--wp--preset--color--cacm-green) !important;}.has-cacm-light-green-color{color: var(--wp--preset--color--cacm-light-green) !important;}.has-cacm-black-color{color: var(--wp--preset--color--cacm-black) !important;}.has-cacm-gray-100-color{color: var(--wp--preset--color--cacm-gray-100) !important;}.has-cacm-gray-200-color{color: var(--wp--preset--color--cacm-gray-200) !important;}.has-cacm-gray-300-color{color: var(--wp--preset--color--cacm-gray-300) !important;}.has-cacm-gray-500-color{color: var(--wp--preset--color--cacm-gray-500) !important;}.has-cacm-gray-600-color{color: var(--wp--preset--color--cacm-gray-600) !important;}.has-cacm-gray-700-color{color: var(--wp--preset--color--cacm-gray-700) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-cacm-blue-background-color{background-color: var(--wp--preset--color--cacm-blue) !important;}.has-cacm-link-blue-background-color{background-color: var(--wp--preset--color--cacm-link-blue) !important;}.has-cacm-dark-blue-background-color{background-color: var(--wp--preset--color--cacm-dark-blue) !important;}.has-cacm-darker-blue-background-color{background-color: var(--wp--preset--color--cacm-darker-blue) !important;}.has-cacm-light-blue-background-color{background-color: var(--wp--preset--color--cacm-light-blue) !important;}.has-cacm-peach-background-color{background-color: var(--wp--preset--color--cacm-peach) !important;}.has-cacm-beige-background-color{background-color: var(--wp--preset--color--cacm-beige) !important;}.has-cacm-brown-background-color{background-color: var(--wp--preset--color--cacm-brown) !important;}.has-cacm-green-background-color{background-color: var(--wp--preset--color--cacm-green) !important;}.has-cacm-light-green-background-color{background-color: var(--wp--preset--color--cacm-light-green) !important;}.has-cacm-black-background-color{background-color: var(--wp--preset--color--cacm-black) !important;}.has-cacm-gray-100-background-color{background-color: var(--wp--preset--color--cacm-gray-100) !important;}.has-cacm-gray-200-background-color{background-color: var(--wp--preset--color--cacm-gray-200) !important;}.has-cacm-gray-300-background-color{background-color: var(--wp--preset--color--cacm-gray-300) !important;}.has-cacm-gray-500-background-color{background-color: var(--wp--preset--color--cacm-gray-500) !important;}.has-cacm-gray-600-background-color{background-color: var(--wp--preset--color--cacm-gray-600) !important;}.has-cacm-gray-700-background-color{background-color: var(--wp--preset--color--cacm-gray-700) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-cacm-blue-border-color{border-color: var(--wp--preset--color--cacm-blue) !important;}.has-cacm-link-blue-border-color{border-color: var(--wp--preset--color--cacm-link-blue) !important;}.has-cacm-dark-blue-border-color{border-color: var(--wp--preset--color--cacm-dark-blue) !important;}.has-cacm-darker-blue-border-color{border-color: var(--wp--preset--color--cacm-darker-blue) !important;}.has-cacm-light-blue-border-color{border-color: var(--wp--preset--color--cacm-light-blue) !important;}.has-cacm-peach-border-color{border-color: var(--wp--preset--color--cacm-peach) !important;}.has-cacm-beige-border-color{border-color: var(--wp--preset--color--cacm-beige) !important;}.has-cacm-brown-border-color{border-color: var(--wp--preset--color--cacm-brown) !important;}.has-cacm-green-border-color{border-color: var(--wp--preset--color--cacm-green) !important;}.has-cacm-light-green-border-color{border-color: var(--wp--preset--color--cacm-light-green) !important;}.has-cacm-black-border-color{border-color: var(--wp--preset--color--cacm-black) !important;}.has-cacm-gray-100-border-color{border-color: var(--wp--preset--color--cacm-gray-100) !important;}.has-cacm-gray-200-border-color{border-color: var(--wp--preset--color--cacm-gray-200) !important;}.has-cacm-gray-300-border-color{border-color: var(--wp--preset--color--cacm-gray-300) !important;}.has-cacm-gray-500-border-color{border-color: var(--wp--preset--color--cacm-gray-500) !important;}.has-cacm-gray-600-border-color{border-color: var(--wp--preset--color--cacm-gray-600) !important;}.has-cacm-gray-700-border-color{border-color: var(--wp--preset--color--cacm-gray-700) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-primary-gradient-gradient-background{background: var(--wp--preset--gradient--primary-gradient) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}.has-work-xxxs-font-size{font-size: var(--wp--preset--font-size--work-xxxs) !important;}.has-work-xxs-font-size{font-size: var(--wp--preset--font-size--work-xxs) !important;}.has-work-xs-font-size{font-size: var(--wp--preset--font-size--work-xs) !important;}.has-work-sm-font-size{font-size: var(--wp--preset--font-size--work-sm) !important;}.has-work-md-font-size{font-size: var(--wp--preset--font-size--work-md) !important;}.has-work-lg-font-size{font-size: var(--wp--preset--font-size--work-lg) !important;}.has-work-xl-font-size{font-size: var(--wp--preset--font-size--work-xl) !important;}.has-work-xxl-font-size{font-size: var(--wp--preset--font-size--work-xxl) !important;}.has-work-xxxl-font-size{font-size: var(--wp--preset--font-size--work-xxxl) !important;}.has-inter-xxxs-font-size{font-size: var(--wp--preset--font-size--inter-xxxs) !important;}.has-inter-xxs-font-size{font-size: var(--wp--preset--font-size--inter-xxs) !important;}.has-inter-xs-font-size{font-size: var(--wp--preset--font-size--inter-xs) !important;}.has-inter-sm-font-size{font-size: var(--wp--preset--font-size--inter-sm) !important;}.has-inter-md-font-size{font-size: var(--wp--preset--font-size--inter-md) !important;}.has-inter-lg-font-size{font-size: var(--wp--preset--font-size--inter-lg) !important;}.has-inter-xl-font-size{font-size: var(--wp--preset--font-size--inter-xl) !important;}.has-inter-xxl-font-size{font-size: var(--wp--preset--font-size--inter-xxl) !important;}.has-inter-xxxl-font-size{font-size: var(--wp--preset--font-size--inter-xxxl) !important;}.has-inter-font-family{font-family: var(--wp--preset--font-family--inter) !important;}.has-work-sans-font-family{font-family: var(--wp--preset--font-family--work-sans) !important;}.wp-block-heading.has-work-xxs-font-size{font-size: var(--wp--preset--font-size--work-xxs) !important;}.wp-block-heading.has-work-xs-font-size{font-size: var(--wp--preset--font-size--work-xs) !important;}.wp-block-heading.has-work-sm-font-size{font-size: var(--wp--preset--font-size--work-sm) !important;}.wp-block-heading.has-work-md-font-size{font-size: var(--wp--preset--font-size--work-md) !important;}.wp-block-heading.has-work-lg-font-size{font-size: var(--wp--preset--font-size--work-lg) !important;}.wp-block-heading.has-work-xl-font-size{font-size: var(--wp--preset--font-size--work-xl) !important;}
:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}
:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}
:root :where(.wp-block-pullquote){font-size: 1.5em;line-height: 1.6;}
</style>
<link rel='stylesheet' id='qm-object-cache-style-css' href='https://cacm.acm.org/wp-content/mu-plugins/qm-plugins/qm-object-cache/css/style.css?ver=0.2' type='text/css' media='all' />
<link rel='stylesheet' id='cacm-global-css' href='https://cacm.acm.org/wp-content/themes/cacm/client/build/css/global.min.css?ver=6f460684b3d49b0b7b10' type='text/css' media='all' />
<link rel='stylesheet' id='cacm-article-css' href='https://cacm.acm.org/wp-content/themes/cacm/client/build/css/article.min.css?ver=34500f5fcb3e83888a6c' type='text/css' media='all' />
<link rel="https://api.w.org/" href="https://cacm.acm.org/wp-json/" /><link rel="alternate" title="JSON" type="application/json" href="https://cacm.acm.org/wp-json/wp/v2/digital-library/753517" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://cacm.acm.org/xmlrpc.php?rsd" />
<meta name="generator" content="WordPress 6.7.1" />
<link rel="canonical" href="https://cacm.acm.org/research-highlights/hammingmesh-a-network-topology-for-large-scale-deep-learning/" />
<link rel='shortlink' href='https://cacm.acm.org/?p=753517' />
<link rel="alternate" title="oEmbed (JSON)" type="application/json+oembed" href="https://cacm.acm.org/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fcacm.acm.org%2Fresearch-highlights%2Fhammingmesh-a-network-topology-for-large-scale-deep-learning%2F" />
<link rel="alternate" title="oEmbed (XML)" type="text/xml+oembed" href="https://cacm.acm.org/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fcacm.acm.org%2Fresearch-highlights%2Fhammingmesh-a-network-topology-for-large-scale-deep-learning%2F&#038;format=xml" />
        <style>
        .getty.aligncenter {
            text-align: center;
        }
        .getty.alignleft {
            float: none;
            margin-right: 0;
        }
        .getty.alignleft > div {
            float: left;
            margin-right: 5px;
        }
        .getty.alignright {
            float: none;
            margin-left: 0;
        }
        .getty.alignright > div {
            float: right;
            margin-left: 5px;
        }
        </style>
        	<style>img#wpstats{display:none}</style>
		<link rel="icon" href="https://cacm.acm.org/wp-content/uploads/2023/11/cropped-cropped-cacm_favicon-1.png?w=32" sizes="32x32" />
<link rel="icon" href="https://cacm.acm.org/wp-content/uploads/2023/11/cropped-cropped-cacm_favicon-1.png?w=192" sizes="192x192" />
<link rel="apple-touch-icon" href="https://cacm.acm.org/wp-content/uploads/2023/11/cropped-cropped-cacm_favicon-1.png?w=180" />
<meta name="msapplication-TileImage" content="https://cacm.acm.org/wp-content/uploads/2023/11/cropped-cropped-cacm_favicon-1.png?w=270" />
</head>

<body class="digital-library-template-default single single-digital-library postid-753517">
<svg xmlns="http://www.w3.org/2000/svg" focusable="false" height="0" role="none" style="left:-9999px;overflow:hidden;position:absolute" viewBox="0 0 0 0" width="0"><symbol id="am-symbol-icon-arrow-left" viewBox="0 0 18 12"><path clip-rule="evenodd" d="M18 6a.643.643 0 0 1-.643.643H2.196l4.046 4.044a.644.644 0 0 1-.91.91L.188 6.456a.643.643 0 0 1 0-.91L5.33.402a.644.644 0 1 1 .91.91L2.197 5.358h15.161A.643.643 0 0 1 18 6Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-arrow-right" viewBox="0 0 14 9"><path clip-rule="evenodd" d="M0 4.5A.5.5 0 0 1 .5 4h11.793L9.146.854a.5.5 0 1 1 .708-.708l4 4a.5.5 0 0 1 0 .708l-4 4a.5.5 0 1 1-.708-.708L12.293 5H.5a.5.5 0 0 1-.5-.5Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-comment" viewBox="0 0 19 20"><path clip-rule="evenodd" d="M1.781 1.542a.693.693 0 0 0-.693.693v11.876a.693.693 0 0 0 .693.693h2.375c.273 0 .494.221.494.494v2.574l3.96-2.97a.494.494 0 0 1 .296-.098h8.313a.693.693 0 0 0 .693-.694V2.236a.693.693 0 0 0-.693-.693H1.78ZM.592 1.046a1.681 1.681 0 0 1 1.19-.492h15.437A1.681 1.681 0 0 1 18.9 2.235v11.876a1.681 1.681 0 0 1-1.681 1.681H9.07l-4.618 3.464a.494.494 0 0 1-.79-.396v-3.068H1.78A1.682 1.682 0 0 1 .1 14.111V2.235c0-.446.177-.873.492-1.189Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-digital-library" viewBox="43 0 40 40"><g clip-path="url(#a)">
    <path d="m95.468 15.585-1.58 1.579c-.262.263-.584.41-.964.41h-6.813V4.707h6.813c.38 0 .702.146.965.409l1.579 1.579c.263.263.41.585.41.965v6.959c0 .38-.118.702-.41.965zm-1.9-7.544c0-.088-.03-.205-.118-.263l-.76-.76c-.088-.088-.146-.117-.263-.117H88.42v8.45h4.006c.117 0 .205-.03.263-.117l.76-.76a.357.357 0 0 0 .117-.264V8.04zm5.877 9.532v-2.047h2.309V6.754h-2.31V4.708h6.93v2.046h-2.31v8.772h2.31v2.047h-6.93zm19.853 0-.292-1.637-1.228 1.228c-.263.263-.585.41-.965.41h-3.918c-.38 0-.702-.147-.965-.41l-1.579-1.58a1.326 1.326 0 0 1-.409-.964V7.66c0-.38.146-.7.409-.964l1.579-1.579c.263-.263.585-.41.965-.41h5c.38 0 .701.147.965.41l1.666 1.667-1.549 1.55-1.316-1.316c-.088-.088-.146-.117-.263-.117h-4.006c-.117 0-.205.029-.263.117l-.761.76a.36.36 0 0 0-.117.263v6.199c0 .088.03.204.117.263l.761.76c.087.088.146.117.263.117h3.041c.117 0 .204-.03.263-.117l1.754-1.754c.088-.088.117-.146.117-.263v-.995h-3.187V10.06h5.497v4.97l.497 2.573h-2.076v-.029zm5.38 0v-2.047h2.31V6.754h-2.31V4.708h6.93v2.046h-2.31v8.772h2.31v2.047h-6.93zM140.029 6.9v10.644h-2.31V6.9h-3.713V4.708h9.737V6.9h-3.714zm14.299 10.673-1.229-3.216h-5.117l-1.228 3.216h-2.31l4.767-12.865h2.748l4.708 12.865h-2.339zm-3.772-10.38-1.784 5.088h3.567l-1.783-5.088zM160 17.573V4.708h2.31V15.35h6.316v2.193H160v.03zM86.111 35.41V22.543h2.31v10.643h6.316v2.193H86.11v.03zm11.813 0v-2.047h2.31V24.59h-2.31v-2.047h6.93v2.047h-2.31v8.772h2.31v2.046h-6.93zm20.497-1.638-1.257 1.257a1.28 1.28 0 0 1-.936.38h-7.164V22.544h7.164c.38 0 .673.146.936.38l1.257 1.257c.263.263.409.585.409.965v1.755c0 .38-.146.701-.409.965l-1.111 1.11 1.111 1.112c.263.263.409.584.409.965v1.783c0 .322-.146.673-.409.936zm-1.901-8.216c0-.117-.029-.205-.116-.264l-.439-.438c-.088-.088-.146-.117-.263-.117h-4.328v3.129h3.86c.088 0 .205-.03.263-.117l.877-.878c.088-.087.117-.146.117-.263v-1.052h.029zm0 5.789c0-.117-.029-.205-.116-.263l-.936-.936c-.088-.088-.146-.117-.263-.117h-3.831v3.158h4.328c.087 0 .204-.03.263-.117l.439-.438c.087-.088.116-.147.116-.264v-1.023zm14.65 4.065-3.802-4.884a.402.402 0 0 0-.321-.175h-1.404v5.058h-2.31V22.544h7.164c.38 0 .673.146.936.38l1.257 1.257c.263.263.409.585.409.965v2.544c0 .38-.146.702-.409.965l-1.257 1.257c-.263.263-.556.38-.936.38h-.468l3.977 5.059h-2.836v.058zm-.381-9.854c0-.117-.029-.205-.116-.264l-.439-.438c-.088-.088-.146-.117-.263-.117h-4.328v3.392h4.328c.117 0 .204-.03.263-.117l.439-.41c.087-.087.116-.146.116-.263v-1.783zm15.117 9.854-1.228-3.217h-5.117l-1.228 3.216h-2.31l4.766-12.865h2.749l4.708 12.865h-2.34zm-3.772-10.38-1.783 5.087h3.538l-1.755-5.088zm17.106 10.38-3.801-4.884a.405.405 0 0 0-.322-.175h-1.404v5.058h-2.309V22.544h7.163c.38 0 .673.146.936.38l1.257 1.257c.263.263.41.585.41.965v2.544c0 .38-.147.702-.41.965l-1.257 1.257c-.263.263-.556.38-.936.38h-.468l3.977 5.059h-2.836v.058zm-.41-9.854c0-.117-.029-.205-.117-.264l-.438-.438c-.088-.088-.146-.117-.263-.117h-4.328v3.392h4.328c.117 0 .204-.03.263-.117l.438-.41c.088-.087.117-.146.117-.263v-1.783zm11.696 4.152v5.672h-2.31v-5.672l-4.356-7.164h2.514l3.012 5 2.982-5h2.486l-4.328 7.164zM12.193 26.199 7.485 13.363H4.737L0 26.199h2.31l1.199-3.216h5.117l1.199 3.216h2.368zm-4.327-5.263h-3.54l1.784-5.088 1.755 5.088zm15.818 3.187-1.55-1.55-1.315 1.316c-.088.088-.146.117-.263.117h-3.188c-.116 0-.204-.03-.263-.117l-.76-.76a.357.357 0 0 1-.117-.264v-6.17c0-.087.03-.204.117-.262l.76-.76c.088-.088.146-.117.263-.117h3.188c.116 0 .204.029.263.117l1.316 1.315 1.55-1.55-1.668-1.666a1.326 1.326 0 0 0-.964-.41H16.87c-.38 0-.701.147-.965.41l-1.579 1.579a1.326 1.326 0 0 0-.409.965v6.959c0 .38.146.702.41.965l1.578 1.579c.264.263.585.41.965.41h4.182c.38 0 .701-.147.964-.41l1.667-1.696zm15.79 2.076V13.363h-3.538l-3.041 9.941-3.041-9.941h-3.538v12.836h2.251V15.994L31.696 26.2h2.398l3.128-10.205V26.2h2.252zM58.246 3.421l-5.351-1.403-1.404 5.35 3.86-1.052 2.895-2.895zm-4.474 4.532-7.72 2.106 1.17 4.385 6.55-6.49zm26.17 6.988 1.432-5.467-5.35-1.375 1.081 4.065 2.837 2.777zm-33.1 10.205-1.433 5.38 5.351 1.375-1.052-3.89-2.866-2.865zM73.333 2.66 68.89 3.89l6.579 6.579-2.135-7.807zm-.409 29.416 7.836-2.134-1.228-4.474-6.608 6.608zM68.45 36.55l5.468 1.433 1.404-5.351-4.065 1.081-2.807 2.837zm-15 .79 4.386-1.17-6.462-6.492 2.076 7.661zm26.2-13.656L83.332 20 71.637 8.304l-4.561-4.561L63.333 0l-6.52 6.52-9.708 9.708L43.333 20l6.58 6.579 9.707 9.707L63.333 40l6.492-6.491 9.824-9.825zm-16.434-.643c0 .35-.117.672-.38.906l-1.491 1.492c-.263.263-.556.38-.906.38h-6.462V13.626h6.462c.35 0 .672.117.906.38l1.491 1.491c.263.263.38.556.38.907v6.637zm3.597-9.415h2.193v10.117H75v2.076h-8.187V13.626z"></path>
    <path d="M60.205 15.819a.37.37 0 0 0-.264-.117h-3.8v8.04h3.8c.117 0 .176-.029.264-.116l.701-.702c.059-.088.117-.175.117-.263v-5.877a.357.357 0 0 0-.117-.264l-.701-.701z"></path>
  </g><defs>
    <clipPath id="a">
      <path d="M0 0h174.854v40H0z"></path>
    </clipPath>
  </defs></symbol><symbol id="am-symbol-icon-pdf-download" viewBox="0 0 19 20"><path clip-rule="evenodd" d="M1.781 1.542a.693.693 0 0 0-.693.693v13.063a.693.693 0 0 0 .693.694h4.75a.494.494 0 1 1 0 .988h-4.75A1.682 1.682 0 0 1 .1 15.298V2.235A1.681 1.681 0 0 1 1.78.554h8.415c.446 0 .873.177 1.188.492l2.274 2.274c.315.315.492.743.492 1.188v2.477a.494.494 0 1 1-.988 0V4.508a.694.694 0 0 0-.203-.49m0 0-2.273-2.273a.694.694 0 0 0-.49-.203H1.78m11.875 8.312a4.256 4.256 0 1 0 0 8.512 4.256 4.256 0 0 0 0-8.512Zm-5.244 4.257a5.244 5.244 0 1 1 10.488 0 5.244 5.244 0 0 1-10.488 0Zm5.244-2.87c.273 0 .494.222.494.495v3.557l.938-.938a.494.494 0 0 1 .699.698l-1.782 1.782a.494.494 0 0 1-.698 0l-1.781-1.782a.494.494 0 0 1 .698-.698l.938.938v-3.557c0-.273.221-.495.494-.495Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-print" viewBox="0 0 19 20"><path clip-rule="evenodd" d="M5.344 1.541a.693.693 0 0 0-.694.693v3.069h9.7V2.234a.693.693 0 0 0-.694-.693H5.344Zm9.994 3.762V2.234A1.681 1.681 0 0 0 13.656.553H5.344a1.681 1.681 0 0 0-1.682 1.681v3.069h-1.88A1.682 1.682 0 0 0 .1 6.984v5.938a1.682 1.682 0 0 0 1.681 1.681h1.881v4.257c0 .272.221.494.494.494h10.688a.494.494 0 0 0 .494-.494v-4.256h1.88a1.682 1.682 0 0 0 1.682-1.682V6.984a1.681 1.681 0 0 0-1.681-1.681h-1.881ZM1.78 6.291a.693.693 0 0 0-.693.693v5.938a.694.694 0 0 0 .693.694h1.881v-3.069c0-.273.221-.494.494-.494h10.688c.273 0 .494.221.494.494v3.069h1.88a.694.694 0 0 0 .694-.694V6.984a.693.693 0 0 0-.693-.693H1.78Zm12.569 4.75h-9.7v7.325h9.7V11.04ZM2.475 8.172c0-.273.22-.494.494-.494h1.187a.494.494 0 1 1 0 .988H2.97a.494.494 0 0 1-.494-.494Zm3.562 4.75c0-.273.221-.494.494-.494h5.938a.494.494 0 1 1 0 .988H6.53a.494.494 0 0 1-.494-.494Zm0 2.375c0-.273.221-.494.494-.494h4.157a.494.494 0 1 1 0 .988H6.53a.494.494 0 0 1-.494-.494Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-share" viewBox="0 0 19 18"><path clip-rule="evenodd" d="M14.844 1.73a2.475 2.475 0 1 0 0 4.949 2.475 2.475 0 0 0 0-4.95ZM11.38 4.203a3.463 3.463 0 1 1 .447 1.703L7.531 7.58a3.473 3.473 0 0 1-.087 1.873l4.555 2.278a3.463 3.463 0 1 1-.442.883L7 10.335a3.463 3.463 0 1 1 .171-3.677l4.298-1.671a3.473 3.473 0 0 1-.089-.783Zm1.242 8.407a2.475 2.475 0 1 0 4.441 2.187 2.475 2.475 0 0 0-4.44-2.187ZM4.156 5.886a2.475 2.475 0 1 0 0 4.95 2.475 2.475 0 0 0 0-4.95Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-bookmark" viewBox="0 0 13 19"><path clip-rule="evenodd" d="M12.05.948c-.293-.32-.7-.494-1.114-.494H2.007c-.421 0-.821.175-1.121.494a1.73 1.73 0 0 0-.457 1.186v15.488c0 .198.05.388.142.563.1.167.236.304.408.395a.89.89 0 0 0 .535.122.956.956 0 0 0 .522-.19l2.464-1.84h.007l1.964-1.459 1.958 1.46h.014l2.464 1.839c.15.114.329.182.522.19a.89.89 0 0 0 .535-.122 1.03 1.03 0 0 0 .4-.395c.1-.175.15-.365.15-.563V2.134c0-.449-.164-.874-.464-1.186ZM3.771 16.011 1.5 17.7s-.029.015-.05.022c-.014 0-.029-.007-.043-.015-.021-.008-.028-.023-.043-.038-.007-.015-.007-.03-.007-.053V2.134a.74.74 0 0 1 .186-.494.639.639 0 0 1 .464-.198h1.764v14.57Zm4.465-.691-1.5-1.125a.462.462 0 0 0-.536 0L4.7 15.32V1.442h3.536V15.32Zm3.35 2.378v-.053s-.015.015-.015.023a.089.089 0 0 1-.035.038c-.015 0-.036.015-.05.015-.015-.007-.036-.007-.05-.023l-2.272-1.687V1.442h1.772c.171 0 .335.069.457.198a.747.747 0 0 1 .193.494v15.564Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-bookmarked" viewBox="0 0 17 25"><path clip-rule="evenodd" d="M16.27.65C15.86.23 15.29 0 14.71 0H2.21A2.201 2.201 0 0 0 0 2.21v20.38c0 .26.07.51.2.74.14.22.33.4.57.52.23.13.49.18.75.16.26-.01.51-.1.73-.25l3.45-2.42h.01l1.15-.8 1.6-1.12 1.6 1.12 1.14.8h.02l3.45 2.42c.21.15.46.24.73.25.26.02.52-.03.75-.16.23-.12.43-.3.56-.52.14-.23.21-.48.21-.74V2.21c0-.59-.23-1.15-.65-1.56ZM4.68 20.47 1.5 22.69s-.04.02-.07.03c-.02 0-.04-.01-.06-.02-.03-.01-.04-.03-.06-.05V2.21c0-.24.09-.47.26-.65.17-.17.41-.26.65-.26h2.47v19.17h-.01Zm10.94 2.22v-.07s-.02.02-.02.03a.12.12 0 0 1-.05.05c-.02 0-.05.02-.07.02-.02-.01-.05-.01-.07-.03l-3.18-2.22V1.3h2.48a.9.9 0 0 1 .64.26c.17.18.27.41.27.65v20.48Z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-chevron-down" viewBox="0 0 16 16"><path d="M1.646 4.646a.5.5 0 0 1 .708 0L8 10.293l5.646-5.647a.5.5 0 0 1 .708.708l-6 6a.5.5 0 0 1-.708 0l-6-6a.5.5 0 0 1 0-.708z" fill-rule="evenodd"></path></symbol><symbol id="am-symbol-icon-search" viewBox="0 0 24 24"><path d="m23 21.85-6.145-6.146a8.966 8.966 0 1 0-1.151 1.15L21.849 23 23 21.85ZM2.656 9.98a7.324 7.324 0 1 1 7.324 7.324A7.332 7.332 0 0 1 2.656 9.98Z" fill="#015FAC"></path></symbol><symbol id="am-symbol-cacm-logo-small"><path d="M48.75 24c0 13.255-10.745 24-24 24s-24-10.745-24-24 10.745-24 24-24 24 10.745 24 24Z" fill="#fff"></path><path d="m24.998 9-15 15 15 15 15-15-15-15Z" fill="#027BA3"></path><path d="M34.196 24A9.195 9.195 0 0 1 25 33.196 9.195 9.195 0 0 1 15.804 24 9.195 9.195 0 0 1 25 14.804 9.195 9.195 0 0 1 34.196 24Z" fill="#fff"></path><path d="M33.28 24A8.275 8.275 0 0 1 25 32.275 8.275 8.275 0 0 1 16.72 24c0-4.57 3.705-8.28 8.28-8.28A8.276 8.276 0 0 1 33.28 24Z" fill="#027BA3"></path><path d="M20.18 25.613c-.084.07-.163.133-.23.191a1.641 1.641 0 0 1-.596.292c-.104.025-.25.041-.441.041-.35 0-.642-.116-.875-.354a1.219 1.219 0 0 1-.35-.891c0-.296.058-.534.175-.717.116-.183.287-.325.508-.433.225-.109.492-.184.804-.225.313-.042.646-.075 1.004-.1v-.021c0-.221-.083-.371-.241-.454-.163-.084-.405-.125-.73-.125-.145 0-.316.025-.512.079s-.388.12-.571.204h-.104v-.967c.12-.037.32-.079.596-.125.275-.05.55-.075.829-.075.687 0 1.187.117 1.5.342.312.23.47.575.47 1.046v2.712h-1.241v-.42h.004Zm0-.621v-.825c-.21.02-.38.041-.505.054-.13.017-.258.046-.38.091a.561.561 0 0 0-.253.171.488.488 0 0 0-.088.305c0 .187.05.312.15.383.1.07.246.104.442.104a.802.802 0 0 0 .329-.075c.113-.05.212-.12.304-.208ZM24.154 26.137c-.329 0-.633-.041-.904-.125a1.897 1.897 0 0 1-.712-.383c-.2-.17-.355-.387-.467-.65a2.336 2.336 0 0 1-.167-.925c0-.379.058-.704.183-.97.121-.267.284-.488.492-.659.2-.167.433-.288.7-.367a2.98 2.98 0 0 1 1.504-.046c.221.05.442.134.667.242v1.067h-.158c-.05-.046-.113-.1-.184-.154a1.673 1.673 0 0 0-.237-.159 1.349 1.349 0 0 0-.683-.175c-.317 0-.563.109-.738.33-.175.22-.262.516-.262.891 0 .4.091.696.279.892.187.196.433.296.741.296.155 0 .296-.017.413-.055a1.27 1.27 0 0 0 .517-.28c.058-.049.112-.099.154-.14h.158v1.062l-.246.108a2.925 2.925 0 0 1-.629.175 2.776 2.776 0 0 1-.417.026h-.004ZM30.867 26.033v-1.991c0-.196 0-.363-.013-.496a1.102 1.102 0 0 0-.062-.33.386.386 0 0 0-.167-.187.715.715 0 0 0-.317-.058.665.665 0 0 0-.279.062 1.99 1.99 0 0 0-.304.175v2.83h-1.242v-1.992c0-.192 0-.358-.012-.496a1 1 0 0 0-.067-.333.386.386 0 0 0-.166-.188.707.707 0 0 0-.313-.058c-.1 0-.2.025-.3.07-.096.05-.192.105-.283.167v2.83H26.1v-3.984h1.242v.438c.204-.175.396-.309.575-.405a1.27 1.27 0 0 1 .604-.145c.246 0 .458.058.642.175.183.116.325.287.42.516.238-.22.467-.391.675-.512.213-.121.425-.18.642-.18.183 0 .35.03.496.088.146.058.27.146.37.267.113.129.197.279.25.454.055.175.084.408.084.692v2.596h-1.242l.009-.005Z" fill="#fff"></path></symbol><symbol id="am-symbol-cacm-logo" viewBox="30.79 34.55 548.86 88.05"><path d="M54.75 71.41c-.8.8-1.77 1.2-2.85 1.2H39.52c-1.08 0-2.05-.4-2.85-1.2l-4.68-4.68c-.8-.8-1.2-1.77-1.2-2.85v-20.6c0-1.08.4-2.05 1.2-2.85l4.68-4.68c.8-.8 1.77-1.2 2.85-1.2H51.9c1.08 0 2.05.4 2.85 1.2l4.96 4.96-4.62 4.56-3.88-3.88c-.23-.23-.46-.34-.8-.34H41c-.34 0-.57.11-.8.34l-2.23 2.23c-.23.23-.34.51-.34.8v18.31c0 .29.11.57.34.8l2.23 2.23c.23.23.46.34.8.34h9.41c.34 0 .57-.11.8-.34l3.88-3.88 4.62 4.56-4.96 4.97zm44.5-4.68-4.68 4.68c-.8.8-1.77 1.2-2.85 1.2H76.83c-1.08 0-2.05-.4-2.85-1.2l-4.68-4.68c-.8-.8-1.2-1.77-1.2-2.85v-20.6c0-1.08.4-2.05 1.2-2.85l4.68-4.68c.8-.8 1.77-1.2 2.85-1.2h14.89c1.08 0 2.05.4 2.85 1.2l4.68 4.68c.8.8 1.2 1.77 1.2 2.85v20.6c0 1.08-.4 2.05-1.2 2.85zM93.6 44.42c0-.29-.11-.57-.34-.8l-2.23-2.23c-.23-.23-.46-.34-.8-.34H78.31c-.34 0-.57.11-.8.34l-2.23 2.23c-.23.23-.34.51-.34.8v18.31c0 .29.11.57.34.8l2.23 2.23c.23.23.46.34.8.34h11.92c.34 0 .57-.11.8-.34l2.23-2.23c.23-.23.34-.51.34-.8V44.42zm50.44 28.19V42.37l-9.3 30.24h-7.07l-9.3-30.24v30.24h-6.68V34.55h10.5l9.01 29.5 9.01-29.5h10.5V72.6h-6.67zm52.65 0V42.37l-9.3 30.24h-7.07l-9.3-30.24v30.24h-6.68V34.55h10.5l9.01 29.5 9.01-29.5h10.5V72.6h-6.67zm46.66-5.88-4.68 4.68c-.8.8-1.77 1.2-2.85 1.2h-11.47c-1.08 0-2.05-.4-2.85-1.2l-4.68-4.68c-.8-.8-1.2-1.77-1.2-2.85V34.55h6.85v28.18c0 .29.11.57.34.8l2.23 2.23c.23.23.46.34.8.34h8.5c.34 0 .57-.11.8-.34l2.23-2.23c.23-.23.34-.51.34-.8V34.55h6.85v29.33c-.01 1.08-.41 2.05-1.21 2.85zm32.69 5.88-12.55-29.5v29.5h-6.67V34.55h9.7l12.55 29.5v-29.5h6.67V72.6h-9.7zm20.82 0v-6.05h6.85V40.6h-6.85v-6.05h20.54v6.05h-6.85v25.96h6.85v6.05h-20.54zm53.46-1.2c-.8.8-1.77 1.2-2.85 1.2h-12.38c-1.08 0-2.05-.4-2.85-1.2l-4.68-4.68c-.8-.8-1.2-1.77-1.2-2.85v-20.6c0-1.08.4-2.05 1.2-2.85l4.68-4.68c.8-.8 1.77-1.2 2.85-1.2h12.38c1.08 0 2.05.4 2.85 1.2l4.96 4.96-4.62 4.56-3.88-3.88c-.23-.23-.46-.34-.8-.34h-9.41c-.34 0-.57.11-.8.34l-2.22 2.23c-.23.23-.34.51-.34.8v18.31c0 .29.11.57.34.8l2.22 2.23c.23.23.46.34.8.34h9.41c.34 0 .57-.11.8-.34l3.88-3.88 4.62 4.56-4.96 4.97zm39.47 1.2-3.59-9.53h-15.18l-3.6 9.53h-6.85l14.09-38.05h8.1l13.98 38.05h-6.95zm-11.18-30.7-5.25 15.06h10.5l-5.25-15.06zm35.94-.85v31.55h-6.85V41.06h-11.01v-6.5h28.87v6.5h-11.01zm19.27 31.55v-6.05h6.85V40.6h-6.85v-6.05h20.54v6.05h-6.85v25.96h6.85v6.05h-20.54zm61.89-5.88-4.68 4.68c-.8.8-1.77 1.2-2.85 1.2h-14.89c-1.08 0-2.05-.4-2.85-1.2l-4.68-4.68c-.8-.8-1.2-1.77-1.2-2.85v-20.6c0-1.08.4-2.05 1.2-2.85l4.68-4.68c.8-.8 1.77-1.2 2.85-1.2h14.89c1.08 0 2.05.4 2.85 1.2l4.68 4.68c.8.8 1.2 1.77 1.2 2.85v20.6c0 1.08-.4 2.05-1.2 2.85zm-5.64-22.31c0-.29-.11-.57-.34-.8l-2.22-2.23c-.23-.23-.46-.34-.8-.34h-11.92c-.34 0-.57.11-.8.34l-2.22 2.23c-.23.23-.34.51-.34.8v18.31c0 .29.12.57.34.8l2.22 2.23c.23.23.46.34.8.34h11.92c.34 0 .57-.11.8-.34l2.22-2.23c.23-.23.34-.51.34-.8V44.42zm37.65 28.19-12.55-29.5v29.5h-6.68V34.55h9.7l12.55 29.5v-29.5h6.68V72.6h-9.7zm50.72-5.88-4.68 4.68c-.8.8-1.77 1.2-2.85 1.2h-15.92c-1.08 0-2.05-.4-2.85-1.2l-4.85-4.85 4.56-4.62 3.82 3.82c.23.23.46.34.8.34h12.95c.34 0 .57-.11.8-.34l2.22-2.23c.23-.23.34-.51.34-.8v-3.65c0-.57-.51-1.08-1.08-1.14l-20.48-2.74c-2.23-.29-3.94-2.28-3.94-4.45v-7.47c0-1.08.4-2.05 1.2-2.85l4.68-4.68c.8-.8 1.77-1.2 2.85-1.2h15.92c1.08 0 2.05.4 2.85 1.2l4.85 4.85-4.56 4.62-3.82-3.82c-.23-.23-.46-.34-.8-.34H557.5c-.34 0-.57.11-.8.34l-2.22 2.23c-.23.23-.34.51-.34.8v3.65c0 .57.46 1.08 1.03 1.14l20.54 2.74c2.22.29 3.94 2.28 3.94 4.45v7.47c-.01 1.08-.41 2.05-1.21 2.85zM263.05 90.51l-.88.88c-.15.15-.33.22-.54.22h-2.79a.79.79 0 0 1-.54-.22l-.88-.88a.732.732 0 0 1-.22-.54v-3.86c0-.2.07-.38.22-.54l.88-.88c.15-.15.33-.22.54-.22h2.79c.2 0 .39.07.54.22l.88.88c.15.15.22.33.22.54v3.86c0 .2-.07.39-.22.54zm-1.06-4.19a.22.22 0 0 0-.06-.15l-.42-.42a.204.204 0 0 0-.15-.06h-2.24c-.06 0-.11.02-.15.06l-.42.42a.22.22 0 0 0-.06.15v3.43c0 .05.02.11.06.15l.42.42c.04.04.09.06.15.06h2.24c.06 0 .11-.02.15-.06l.42-.42c.04-.04.06-.1.06-.15v-3.43zm5.41 2.33v2.96h-1.28v-7.13h4.78v1.22h-3.5v1.73h3.5v1.22h-3.5zm12.04-2.96v5.92h-1.28v-5.92h-2.06v-1.22h5.41v1.22h-2.07zm8.45 5.92v-2.96h-2.86v2.96h-1.28v-7.13h1.28v2.95h2.86v-2.95h1.28v7.13h-1.28zm4.43 0v-7.13h4.78v1.22h-3.5v1.73h3.5v1.22h-3.5v1.74h3.5v1.22h-4.78zm30.16 30.99-3.59-9.53h-15.18l-3.59 9.53h-6.85l14.09-38.05h8.1l13.98 38.05h-6.96zM311.3 91.91l-5.25 15.06h10.5l-5.25-15.06zm49.12 29.49c-.8.8-1.77 1.2-2.85 1.2h-12.38c-1.08 0-2.05-.4-2.85-1.2l-4.68-4.68c-.8-.8-1.2-1.77-1.2-2.85v-20.6c0-1.08.4-2.05 1.2-2.85l4.68-4.68c.8-.8 1.77-1.2 2.85-1.2h12.38c1.08 0 2.05.4 2.85 1.2l4.96 4.96-4.62 4.56-3.88-3.88c-.23-.23-.46-.34-.8-.34h-9.41c-.34 0-.57.11-.8.34l-2.22 2.23c-.23.23-.34.51-.34.8v18.31c0 .29.12.57.34.8l2.22 2.23c.23.23.46.34.8.34h9.41c.34 0 .57-.12.8-.34l3.88-3.88 4.62 4.56-4.96 4.97zm47.51 1.2V92.36l-9.3 30.24h-7.07l-9.3-30.24v30.24h-6.68V84.55h10.5l9.01 29.5 9.01-29.5h10.5v38.05h-6.67z"></path></symbol><symbol id="am-symbol-icon-social-facebook"><path d="m22.723 20 .445-2.896h-2.779v-1.879c0-.792.388-1.564 1.633-1.564h1.263v-2.465S22.139 11 21.043 11c-2.289 0-3.784 1.387-3.784 3.898v2.206h-2.544V20h2.544v7h3.13v-7h2.334Z"></path></symbol><symbol id="am-symbol-icon-social-twitter"><path d="M27.613 13.657a7.057 7.057 0 0 1-2.03.557 3.54 3.54 0 0 0 1.555-1.955 7.08 7.08 0 0 1-2.245.857A3.53 3.53 0 0 0 22.313 12c-2.282 0-3.958 2.13-3.442 4.34a10.033 10.033 0 0 1-7.285-3.694 3.54 3.54 0 0 0 1.093 4.72 3.52 3.52 0 0 1-1.6-.442c-.038 1.637 1.135 3.169 2.835 3.51a3.542 3.542 0 0 1-1.596.06 3.538 3.538 0 0 0 3.301 2.454 7.106 7.106 0 0 1-5.232 1.465A10.006 10.006 0 0 0 15.804 26c6.562 0 10.27-5.542 10.046-10.513a7.195 7.195 0 0 0 1.763-1.83Z"></path></symbol><symbol id="am-symbol-icon-social-linkedin"><path d="M14.117 12.74c0 .96-.773 1.738-1.726 1.738a1.732 1.732 0 0 1-1.725-1.739c0-.96.772-1.739 1.725-1.739.953 0 1.726.78 1.726 1.74Zm.013 3.13h-3.478V27h3.479V15.87Zm5.553 0h-3.456V27h3.457v-5.843c0-3.248 4.194-3.514 4.194 0V27h3.47v-7.048c0-5.481-6.207-5.282-7.665-2.583v-1.5Z"></path></symbol><symbol id="am-symbol-icon-social-reddit"><path d="M27.764 21.071v.613c0 3.368-3.879 6.022-8.676 6.022-4.797 0-8.676-2.654-8.676-6.022v-.613c-1.122-.51-1.53-1.735-1.122-2.857.306-.817 1.123-1.327 1.939-1.225.612 0 1.123.204 1.531.612 1.735-1.122 3.776-1.837 5.818-1.837l1.122-5.103c0-.102.102-.204.102-.204.102-.102.205-.102.307-.102l3.572.816c.408-.714 1.327-1.123 2.041-.714.715.408 1.123 1.326.715 2.04-.409.715-1.327 1.124-2.042.715-.51-.204-.816-.714-.816-1.326l-3.164-.715-1.02 4.593c2.245.102 4.286.817 5.715 1.837.816-.816 2.245-.816 3.062 0 .408.408.612.919.612 1.531.306.919-.306 1.633-1.02 1.94Zm-11.942 1.123c.816 0 1.53-.714 1.53-1.53 0-.817-.714-1.532-1.53-1.532-.817 0-1.531.715-1.531 1.531 0 .817.612 1.531 1.53 1.531Zm7.042 1.94c-.204-.205-.408-.205-.51 0-.612.714-2.041.918-3.062.918-1.02 0-2.45-.204-3.062-.919-.204-.204-.408-.204-.51 0-.204.204-.204.409 0 .51 1.02 1.021 3.062 1.123 3.674 1.123.613 0 2.552-.102 3.675-1.122-.102-.102-.102-.306-.205-.51Zm1.225-3.47c0-.817-.714-1.532-1.53-1.532-.817 0-1.532.715-1.532 1.531 0 .817.715 1.531 1.531 1.531.817 0 1.531-.714 1.531-1.53Z"></path></symbol><symbol id="am-symbol-cacm-avatar-blank" viewBox="0 0 40 40"><g>
		<circle cx="20" cy="20" fill="var(--wp--preset--color--cacm-link-blue)" r="19" stroke="var(--wp--preset--color--cacm-link-blue)" stroke-width="2"></circle>
		<path clip-rule="evenodd" d="M5 33.23v-.73c0-4.987 9.994-7.5 15-7.5s15 2.513 15 7.5v.73A19.952 19.952 0 0 1 20 40a19.952 19.952 0 0 1-15-6.77ZM20 8.333a7.498 7.498 0 0 0-7.5 7.5c0 4.143 3.356 7.5 7.5 7.5s7.5-3.357 7.5-7.5c0-4.144-3.356-7.5-7.5-7.5Z" fill="var(--wp--preset--color--cacm-gray-200)" fill-rule="evenodd"></path>
	</g></symbol></svg><div id="page" class="site">
	<a class="skip-link" href="#content">Skip to content</a>

	<div class="site-header-wrapper" data-component="siteHeader">
		<header id="masthead" class="site-header site-header--no-js">
			<div class="site-header-container">
				
<button class="site-header-hamburger" aria-label="Main Menu">
	<span class="site-header-hamburger-closed">
		<svg xmlns="http://www.w3.org/2000/svg" version="1.2" viewBox="0 0 25 25">
	<path d="M.2.2h24.6v2.6H.2zm0 11h24.6v2.7H.2zm0 11h24.6v2.6H.2z" style="fill:#1a1a1a"/>
</svg>
 
	</span>
	<span class="site-header-hamburger-open">
		<svg xmlns="http://www.w3.org/2000/svg" version="1.2" viewBox="0 0 25 25">
	<path d="M1.7.9 24 23.8m-23 0L23.3.9" style="fill:none;stroke:#fff;stroke-width:1.3"/>
</svg>
 
	</span>
</button>
				<a class="site-header-logo" aria-label="Home" href="https://cacm.acm.org">
					<svg aria-hidden="true" focusable="false" width="548" height="88" fill="#000"><use href="#am-symbol-cacm-logo"></use></svg>					<svg aria-hidden="true" focusable="false" width="548" height="88" fill="#FFF"><use href="#am-symbol-cacm-logo"></use></svg>				</a>
				
<div class="site-header-topics-menu">
	<button class="site-header-topics-menu-toggle">
		Explore Topics		<svg xmlns="http://www.w3.org/2000/svg" width="14" height="8" fill="none">
	<path stroke="#1A1A1A" stroke-width="1.5" d="m1.5 1.5 5.5 5 5.5-5"/>
</svg>
 
	</button>
	<nav role="navigation" aria-label="Topics Menu" class="site-header-topics-menu-expanded" aria-hidden="true">
		<ul class="site-header-topics-menu-list">
																<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/architecture-and-hardware/">
							Architecture and Hardware						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/artificial-intelligence-machine-learning/">
							Artificial Intelligence and Machine Learning						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/computer-history/">
							Computer History						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/computing-applications/">
							Computing Applications						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/computing-profession/">
							Computing Profession						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/data-and-information/">
							Data and Information						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/education/">
							Education						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/hci/">
							HCI						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/philosophy-of-computing/">
							Philosophy of Computing						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/security-and-privacy/">
							Security and Privacy						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/society/">
							Society						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/software-engineering-and-programming-languages/">
							Software Engineering and Programming Languages						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/systems-and-networking/">
							Systems and Networking						</a>
					</li>
																				<li class="site-header-topics-menu-list-item">
						<a href="https://cacm.acm.org/category/theory/">
							Theory						</a>
					</li>
									</ul>
	</nav>
</div>
				
<div class="site-header-magazine-menu">
	<button class="site-header-magazine-menu-toggle">
		Latest Issue		<svg xmlns="http://www.w3.org/2000/svg" width="14" height="8" fill="none">
	<path stroke="#1A1A1A" stroke-width="1.5" d="m1.5 1.5 5.5 5 5.5-5"/>
</svg>
	</button>
	<nav role="navigation" aria-label="Magazine Menu" class="site-header-magazine-menu-expanded" aria-hidden="true">
					<a href="https://cacm.acm.org/issue/december-2024/">
				<figure class="site-header-magazine-menu-expanded-image">
					<div class="image-wrapper"><img width="1000" height="1338" src="https://cacm.acm.org/wp-content/uploads/2024/11/Dec.2024-Cover-1000x1338-1.jpg?w=1000" class="attachment-original size-original" alt="December 2024 CACM cover" loading="lazy" decoding="async" srcset="https://cacm.acm.org/wp-content/uploads/2024/11/Dec.2024-Cover-1000x1338-1.jpg 1000w, https://cacm.acm.org/wp-content/uploads/2024/11/Dec.2024-Cover-1000x1338-1.jpg?resize=224,300 224w, https://cacm.acm.org/wp-content/uploads/2024/11/Dec.2024-Cover-1000x1338-1.jpg?resize=768,1028 768w, https://cacm.acm.org/wp-content/uploads/2024/11/Dec.2024-Cover-1000x1338-1.jpg?resize=765,1024 765w" sizes="auto, (max-width: 1000px) 100vw, 1000px" /></div>				</figure>
			</a>
				<div class="site-header-magazine-menu-expanded-text">
							<div class="site-header-magazine-menu-expanded-current">
					<h2 class="site-header-magazine-menu-expanded-heading">
						Latest Issue					</h2>
					<a href="https://cacm.acm.org/issue/december-2024/" class="site-header-magazine-menu-expanded-issue"><b>December 2024</b>, Vol. 67 No. 12</a>
				</div>
										<div class="site-header-magazine-menu-expanded-previous">
					<h2 class="site-header-magazine-menu-expanded-heading">
						Previous Issue					</h2>
					<a href="https://cacm.acm.org/issue/november-2024/" class="site-header-magazine-menu-expanded-issue"><b>November 2024</b>, Vol. 67 No. 11</a>
				</div>
						<a href="https://cacm.acm.org/issues" class="site-header-magazine-menu-expanded-link">
				Explore the archive				<svg xmlns="http://www.w3.org/2000/svg" width="12" height="10" fill="none" aria-hidden="true" tabindex="-1">
	<path fill="#000" d="m7 0-.715.697 3.79 3.803H0v1h10.075l-3.79 3.787L7 10l5-5-5-5Z"/>
</svg>
			</a>
		</div>
	</nav>
</div>
				
<a href="https://cacm.acm.org/?s=" aria-label="Search" class="site-header-search">
	<span class="site-header-search-text">
		Search	</span>
	<svg aria-hidden="true" focusable="false" width="24" height="24" class="site-header-search-icon"><use href="#am-symbol-icon-search"></use></svg></a>
				<nav class="site-header-membership-nav">
	<button class="site-header-membership-nav__button">
		<span
			class="site-header-membership-nav__button-text">Open Membership Navigation</span>
		<span class="site-header-membership-nav__button-icon">
			<svg aria-hidden="true" focusable="false" width="40" height="40" tabindex="-1"><use href="#am-symbol-cacm-avatar-blank"></use></svg>		</span>
	</button>
	<div class="site-header-membership-nav__menu-container" aria-hidden="true">
		<ul class="site-header-membership-nav__menu">
			<li class="site-header-membership-nav__menu-item">
				<a href="https://cacm.acm.org/account/settings">Settings</a>
			</li>
						<li class="site-header-membership-nav__menu-item">
				<a href="https://cacm.acm.org/logout/">Sign Out</a>
			</li>
		</ul>
	</div>
</nav>
<a class="site-header-member-login-link" href="https://cacm.acm.org/wp-login.php?saml_sso">Sign In</a>
<a href="https://cacm.acm.org/join-acm" class="site-header-cta-membership">
	<div class="site-header-cta-membership-container">
		<div class="site-header-cta-membership-text">
			Join ACM			<svg xmlns="http://www.w3.org/2000/svg" width="12" height="10" fill="none" aria-hidden="true" tabindex="-1">
	<path fill="#000" d="m7 0-.715.697 3.79 3.803H0v1h10.075l-3.79 3.787L7 10l5-5-5-5Z"/>
</svg>
		</div>
		<div class="site-header-cta-membership-logo">
			<svg aria-hidden="true" focusable="false" width="48" height="48"><use href="#am-symbol-cacm-logo-small"></use></svg>		</div>
	</div>
</a>
			</div>
			
<nav role="navigation" aria-label="Main Menu" class="site-header-hamburger-menu" aria-hidden="true">

	<!-- Search bar -->
	<form role="search" action="https://cacm.acm.org" method="get" class="site-header-hamburger-menu-search">
		<label for="site-navigation-expanded-search">
			<span class="site-header-hamburger-menu-search-icon">
					<svg xmlns="http://www.w3.org/2000/svg" width="21" height="21" fill="none">
		<path fill="#4C4C4C" d="m21 19.902-5.866-5.867a8.558 8.558 0 1 0-1.099 1.099L19.902 21 21 19.902ZM1.581 8.572a6.99 6.99 0 1 1 6.99 6.99 6.999 6.999 0 0 1-6.99-6.99Z"/>
	</svg>
			</span>
			<input type="text" name="s" id="site-navigation-expanded-search" class="site-header-hamburger-menu-search-input" placeholder="Search" value="" />
		</label>
	</form>

	<!-- Topics menu -->
	<div class="site-header-hamburger-menu-topics site-header-hamburger-menu-topics--expanded">
					<h2 class="site-header-hamburger-menu-heading">
				Topics				<span class="site-header-hamburger-menu-accordion-icon">
					<svg aria-hidden="true" focusable="false" width="16" height="16"><use href="#am-symbol-icon-chevron-down"></use></svg>				</span>
			</h2>
			<ul class="site-header-hamburger-menu-topics-menu">
																<li>
						<a href="https://cacm.acm.org/category/architecture-and-hardware/">
							Architecture and Hardware						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/artificial-intelligence-machine-learning/">
							Artificial Intelligence and Machine Learning						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/computer-history/">
							Computer History						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/computing-applications/">
							Computing Applications						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/computing-profession/">
							Computing Profession						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/data-and-information/">
							Data and Information						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/education/">
							Education						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/hci/">
							HCI						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/philosophy-of-computing/">
							Philosophy of Computing						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/security-and-privacy/">
							Security and Privacy						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/society/">
							Society						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/software-engineering-and-programming-languages/">
							Software Engineering and Programming Languages						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/systems-and-networking/">
							Systems and Networking						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/category/theory/">
							Theory						</a>
					</li>
										</ul>
			</div>

	<!-- Sections menu -->
	<div class="site-header-hamburger-menu-sections">
					<h2 class="site-header-hamburger-menu-heading">
				Sections				<span class="site-header-hamburger-menu-accordion-icon">
					<svg aria-hidden="true" focusable="false" width="16" height="16"><use href="#am-symbol-icon-chevron-down"></use></svg>				</span>
			</h2>
			<ul class="site-header-hamburger-menu-sections-menu">
																<li>
						<a href="https://cacm.acm.org/section/research/">
							Research and Advances						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/section/opinion/">
							Opinion						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/section/practice/">
							Practice						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/section/news/">
							News						</a>
					</li>
																				<li>
						<a href="https://cacm.acm.org/section/careers/">
							Careers						</a>
					</li>
										</ul>
			</div>

	<!-- Magazine menu -->
	<div class="site-header-hamburger-menu-magazine">
		<h2 class="site-header-hamburger-menu-heading">
			Magazine			<span class="site-header-hamburger-menu-accordion-icon">
				<svg aria-hidden="true" focusable="false" width="16" height="16"><use href="#am-symbol-icon-chevron-down"></use></svg>			</span>
		</h2>
		<ul id="menu-magazine-header" class="site-header-hamburger-menu-magazine-menu"><li id="menu-item-217988" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-217988"><a href="/issue/latest/" id="menu-link-1">Latest Issue</a></li>
<li id="menu-item-217989" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-217989"><a href="/issues/" id="menu-link-2">Magazine Archive</a></li>
<li id="menu-item-224644" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224644"><a href="https://cacm.acm.org/editorial-staff-board/" id="menu-link-3">Editorial Staff and Board</a></li>
<li id="menu-item-751386" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-751386"><a href="https://cacm.acm.org/author-guidelines#CACMsubmission" id="menu-link-4">Submit an Article</a></li>
<li id="menu-item-224585" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224585"><a href="https://cacm.acm.org/feeds-2/" id="menu-link-5">Alerts &#038; Feeds</a></li>
<li id="menu-item-224645" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224645"><a href="https://cacm.acm.org/author-guidelines/" id="menu-link-6">Author Guidelines</a></li>
</ul>	</div>

	<div class="site-header-hamburger-menu-membership">
		<span class="site-header-hamburger-menu-membership-logo">
			<svg aria-hidden="true" focusable="false" width="49" height="48"><use href="#am-symbol-cacm-logo-small"></use></svg>		</span>
		<h2 class="site-header-hamburger-menu-heading site-header-hamburger-menu-membership-heading">
			CACM Web Account		</h2>
		<p class="site-header-hamburger-menu-membership-text">Membership in ACM includes a subscription to Communications of the ACM (CACM), the computing industry&#039;s most trusted source for staying connected to the world of advanced computing.</p>
		<div class="site-header-hamburger-menu-membership-buttons">
			<a href="https://cacm.acm.org/wp-login.php?saml_sso" class="site-header-hamburger-menu-membership-buttons-log-in">
				Sign In			</a>
			<a href="https://accounts.acm.org/" class="site-header-hamburger-menu-membership-buttons-sign-up">
				Sign Up			</a>
		</div>
	</div>

	<!-- Communications menu -->
	<div class="site-header-hamburger-menu-communications">
		<h2 class="site-header-hamburger-menu-heading">
			Communications of the ACM			<span class="site-header-hamburger-menu-accordion-icon">
				<svg aria-hidden="true" focusable="false" width="16" height="16"><use href="#am-symbol-icon-chevron-down"></use></svg>			</span>
		</h2>
		<ul id="menu-communications-header" class="site-header-hamburger-menu-communications-menu"><li id="menu-item-224641" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224641"><a href="https://cacm.acm.org/about-us/" id="menu-link-7">About Us</a></li>
<li id="menu-item-224663" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224663"><a href="https://cacm.acm.org/faq/" id="menu-link-8">Frequently Asked Questions</a></li>
<li id="menu-item-224640" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224640"><a href="https://cacm.acm.org/contact-us/" id="menu-link-9">Contact Us</a></li>
</ul>	</div>

	<div class="site-header-hamburger-menu-social">
		<h2 class="site-header-hamburger-menu-heading">
			Follow Us		</h2>
		<ul class="site-header-hamburger-menu-social-menu">
			<li>
				<a href="https://twitter.com/cacmmag">
					<span class="screen-reader-only">CACM on Twitter</span>
					<svg xmlns="http://www.w3.org/2000/svg" width="38" height="38" fill="none">
	<path fill="#1DA1F2" d="M27.613 13.657a7.057 7.057 0 0 1-2.03.557 3.54 3.54 0 0 0 1.555-1.955 7.08 7.08 0 0 1-2.245.857A3.53 3.53 0 0 0 22.313 12c-2.282 0-3.958 2.13-3.442 4.34a10.033 10.033 0 0 1-7.285-3.694 3.54 3.54 0 0 0 1.093 4.72 3.52 3.52 0 0 1-1.6-.442c-.038 1.637 1.135 3.169 2.835 3.51a3.542 3.542 0 0 1-1.596.06 3.538 3.538 0 0 0 3.301 2.454 7.106 7.106 0 0 1-5.232 1.465A10.006 10.006 0 0 0 15.804 26c6.562 0 10.27-5.542 10.046-10.513a7.195 7.195 0 0 0 1.763-1.83Z"/>
	<path fill="#000" d="M27.613 13.657a7.057 7.057 0 0 1-2.03.557 3.54 3.54 0 0 0 1.555-1.955 7.08 7.08 0 0 1-2.245.857A3.53 3.53 0 0 0 22.313 12c-2.282 0-3.958 2.13-3.442 4.34a10.033 10.033 0 0 1-7.285-3.694 3.54 3.54 0 0 0 1.093 4.72 3.52 3.52 0 0 1-1.6-.442c-.038 1.637 1.135 3.169 2.835 3.51a3.542 3.542 0 0 1-1.596.06 3.538 3.538 0 0 0 3.301 2.454 7.106 7.106 0 0 1-5.232 1.465A10.006 10.006 0 0 0 15.804 26c6.562 0 10.27-5.542 10.046-10.513a7.195 7.195 0 0 0 1.763-1.83Z"/>
	<rect width="37" height="37" x=".5" y=".5" stroke="#D8D8D8" rx="18.5"/>
</svg>
				</a>
			</li>
			<li>
				<a href="https://www.reddit.com/user/TheOfficialACM">
					<span class="screen-reader-only">CACM on Reddit</span>
					<svg xmlns="http://www.w3.org/2000/svg" width="38" height="38" fill="none">
	<path fill="#FF4500" d="M27.764 21.071v.613c0 3.368-3.879 6.022-8.676 6.022-4.797 0-8.676-2.654-8.676-6.022v-.613c-1.122-.51-1.53-1.735-1.122-2.857.306-.817 1.123-1.327 1.939-1.225.612 0 1.123.204 1.531.612 1.735-1.122 3.776-1.837 5.818-1.837l1.122-5.103c0-.102.102-.204.102-.204.102-.102.205-.102.307-.102l3.572.816c.408-.714 1.327-1.123 2.041-.714.715.408 1.123 1.326.715 2.04-.409.715-1.327 1.124-2.042.715-.51-.204-.816-.714-.816-1.326l-3.164-.715-1.02 4.593c2.245.102 4.286.817 5.715 1.837.816-.816 2.245-.816 3.062 0 .408.408.612.919.612 1.531.306.919-.306 1.633-1.02 1.94Zm-11.942 1.123c.816 0 1.53-.714 1.53-1.53 0-.817-.714-1.532-1.53-1.532-.817 0-1.531.715-1.531 1.531 0 .817.612 1.531 1.53 1.531Zm7.042 1.94c-.204-.205-.408-.205-.51 0-.612.714-2.041.918-3.062.918-1.02 0-2.45-.204-3.062-.919-.204-.204-.408-.204-.51 0-.204.204-.204.409 0 .51 1.02 1.021 3.062 1.123 3.674 1.123.613 0 2.552-.102 3.675-1.122-.102-.102-.102-.306-.205-.51Zm1.225-3.47c0-.817-.714-1.532-1.53-1.532-.817 0-1.532.715-1.532 1.531 0 .817.715 1.531 1.531 1.531.817 0 1.531-.714 1.531-1.53Z"/>
	<path fill="#000" d="M27.764 21.071v.613c0 3.368-3.879 6.022-8.676 6.022-4.797 0-8.676-2.654-8.676-6.022v-.613c-1.122-.51-1.53-1.735-1.122-2.857.306-.817 1.123-1.327 1.939-1.225.612 0 1.123.204 1.531.612 1.735-1.122 3.776-1.837 5.818-1.837l1.122-5.103c0-.102.102-.204.102-.204.102-.102.205-.102.307-.102l3.572.816c.408-.714 1.327-1.123 2.041-.714.715.408 1.123 1.326.715 2.04-.409.715-1.327 1.124-2.042.715-.51-.204-.816-.714-.816-1.326l-3.164-.715-1.02 4.593c2.245.102 4.286.817 5.715 1.837.816-.816 2.245-.816 3.062 0 .408.408.612.919.612 1.531.306.919-.306 1.633-1.02 1.94Zm-11.942 1.123c.816 0 1.53-.714 1.53-1.53 0-.817-.714-1.532-1.53-1.532-.817 0-1.531.715-1.531 1.531 0 .817.612 1.531 1.53 1.531Zm7.042 1.94c-.204-.205-.408-.205-.51 0-.612.714-2.041.918-3.062.918-1.02 0-2.45-.204-3.062-.919-.204-.204-.408-.204-.51 0-.204.204-.204.409 0 .51 1.02 1.021 3.062 1.123 3.674 1.123.613 0 2.552-.102 3.675-1.122-.102-.102-.102-.306-.205-.51Zm1.225-3.47c0-.817-.714-1.532-1.53-1.532-.817 0-1.532.715-1.532 1.531 0 .817.715 1.531 1.531 1.531.817 0 1.531-.714 1.531-1.53Z"/>
	<rect width="37" height="37" x=".5" y=".5" stroke="#D8D8D8" rx="18.5"/>
</svg>
				</a>
			</li>
			<li>
				<a href="https://www.linkedin.com/groups/36836/">
					<span class="screen-reader-only">CACM on LinkedIn</span>
					<svg xmlns="http://www.w3.org/2000/svg" width="38" height="38" fill="none">
	<path fill="#000" d="M14.117 12.74c0 .96-.773 1.738-1.726 1.738a1.732 1.732 0 0 1-1.725-1.739c0-.96.772-1.739 1.725-1.739.953 0 1.726.78 1.726 1.74Zm.013 3.13h-3.478V27h3.479V15.87Zm5.553 0h-3.456V27h3.457v-5.843c0-3.248 4.194-3.514 4.194 0V27h3.47v-7.048c0-5.481-6.207-5.282-7.665-2.583v-1.5Z"/>
	<rect width="37" height="37" x=".5" y=".5" stroke="#D8D8D8" rx="18.5"/>
</svg>
				</a>
			</li>
		</ul>
	</div>

</nav>
		</header>
	</div>

	<div id="content" class="site-content container">
		<div id="primary" class="content-area">
			<main id="main" class="site-main">

				
<article id="post-753517" class="post-753517 digital-library type-digital-library status-publish has-post-thumbnail hentry category-architecture-and-hardware category-systems-and-networking issue-december-2024 section-research-highlights">

			
<header class="article-header article-header--default">
	<div class="article-header__inner container">
		<div class="article-header__section"><a href="https://cacm.acm.org/section/research-highlights/">Research Highlights</a></div>
		<div class="article-header__topic-and-issue-section">
			<span class="article-header__topic">
			<a href="https://cacm.acm.org/category/architecture-and-hardware/">Architecture and Hardware</a>			</span>
			<span class="article-header__issue-section">
							</span>
		</div>
		<h1 class="article-header__title">HammingMesh: A Network Topology for Large-Scale Deep Learning</h1>
					<div class="article-header__subtitle"><p>Flexible network topology can adjust the ratio of local and global bandwidth for deep learning workloads.</p>
</div>
		
		<div class="article-header__meta">
			<div class="article-header__byline">
				By <a href="https://cacm.acm.org/author/torsten-hoefler/" title="Posts by Torsten Hoefler" class="author url fn" rel="author">Torsten Hoefler</a>, <a href="https://cacm.acm.org/author/tommaso-bonoto/" title="Posts by Tommaso Bonoto" class="author url fn" rel="author">Tommaso Bonoto</a>, <a href="https://cacm.acm.org/author/daniele-de-sensi/" title="Posts by Daniele De Sensi" class="author url fn" rel="author">Daniele De Sensi</a>, <a href="https://cacm.acm.org/author/salvatore-di-girolamo/" title="Posts by Salvatore Di Girolamo" class="author url fn" rel="author">Salvatore Di Girolamo</a>, <a href="https://cacm.acm.org/author/shigang-li/" title="Posts by Shigang Li" class="author url fn" rel="author">Shigang Li</a>, <a href="https://cacm.acm.org/author/marco-heddes/" title="Posts by Marco Heddes" class="author url fn" rel="author">Marco Heddes</a>, <a href="https://cacm.acm.org/author/deepak-goel/" title="Posts by Deepak Goel" class="author url fn" rel="author">Deepak Goel</a>, <a href="https://cacm.acm.org/author/miguel-castro/" title="Posts by Miguel Castro" class="author url fn" rel="author">Miguel Castro</a>, and <a href="https://cacm.acm.org/author/steve-scott/" title="Posts by Steve Scott" class="author url fn" rel="author">Steve Scott</a>			</div>
			<div class="article-header__posted-on">
				<span class="posted-on">Posted <time datetime="2024-11-21T11:07:59-05:00">Nov 21 2024</time></span>			</div>
		</div>

			<figure class="article-header__figure">
			<div class="image-wrapper image-wrapper--widescreen"><img width="1024" height="576" src="https://cacm.acm.org/wp-content/uploads/2024/11/111824.RH-HammingMesh2-G.jpg" class="attachment-full size-full" alt="canal foot bridge interior architecture" loading="eager" decoding="async" srcset="https://cacm.acm.org/wp-content/uploads/2024/11/111824.RH-HammingMesh2-G.jpg 2400w, https://cacm.acm.org/wp-content/uploads/2024/11/111824.RH-HammingMesh2-G.jpg?resize=300,169 300w, https://cacm.acm.org/wp-content/uploads/2024/11/111824.RH-HammingMesh2-G.jpg?resize=768,432 768w, https://cacm.acm.org/wp-content/uploads/2024/11/111824.RH-HammingMesh2-G.jpg?resize=1024,576 1024w, https://cacm.acm.org/wp-content/uploads/2024/11/111824.RH-HammingMesh2-G.jpg?resize=1536,864 1536w, https://cacm.acm.org/wp-content/uploads/2024/11/111824.RH-HammingMesh2-G.jpg?resize=2048,1152 2048w" sizes="(max-width: 1024px) 100vw, 1024px" /></div>		</figure>

		<div class="article-header__share">
			
<ul class="share">
	
<li class="share-link" data-component="share">
	<a href="#" class="share-toggle">
		<svg aria-hidden="true" focusable="false" width="19" height="18" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-share"></use></svg>		<span class="share-link-text">
			Share		</span>
	</a>
	<ul class="share-menu" aria-hidden="true">
		<li>
			<a href="https://twitter.com/intent/tweet?url=https://cacm.acm.org/research-highlights/hammingmesh-a-network-topology-for-large-scale-deep-learning/&#038;text=HammingMesh:%20A%20Network%20Topology%20for%20Large-Scale%20Deep%20Learning" target="_blank">
				Twitter			</a>
		</li>
		<li>
			<a href="http://www.reddit.com/submit?url=https://cacm.acm.org/research-highlights/hammingmesh-a-network-topology-for-large-scale-deep-learning/&#038;title=HammingMesh:%20A%20Network%20Topology%20for%20Large-Scale%20Deep%20Learning" target="_blank">
				Reddit			</a>
		</li>
		<li>
			<a href="https://news.ycombinator.com/submitlink?u=https://cacm.acm.org/research-highlights/hammingmesh-a-network-topology-for-large-scale-deep-learning/&#038;t=HammingMesh:%20A%20Network%20Topology%20for%20Large-Scale%20Deep%20Learning" target="_blank">
				Hacker News			</a>
		</li>
	</ul>
</li>
			
<li class="share-link share-link-pdf">
	<a href="https://dl.acm.org/doi/pdf/10.1145/3623490" target="_blank">
		<svg aria-hidden="true" focusable="false" width="19" height="20" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-pdf-download"></use></svg>		<span class="share-link-text">
			Download PDF		</span>
	</a>
</li>
		
<li class="share-link share-link-print" data-component="print">
	<a href="#" class="print">
		<svg aria-hidden="true" focusable="false" width="19" height="20" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-print"></use></svg>		<span class="share-link-text">
			Print		</span>
	</a>
</li>
		
	<li class="share-link share-link-discussion" data-component="share">
		<a class="share-link-comments" href="#comments">
			<svg aria-hidden="true" focusable="false" width="19" height="20" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-comment"></use></svg>			<span class="share-link-text">Join the Discussion</span>
		</a>
	</li>
			
<li class="share-link share-link-dl">
	<a href="https://dl.acm.org/doi/10.1145/3623490">
		<svg aria-hidden="true" focusable="false" width="21" height="21" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-digital-library"></use></svg>		<span class="share-link-text">
			View in the ACM Digital Library		</span>
		<svg aria-hidden="true" focusable="false" width="14" height="9" fill="var(--cacm--symbol--fill)" class="icon-dl"><use href="#am-symbol-icon-arrow-right"></use></svg>	</a>
</li>
	</ul>
		</div>
	</div>
</header>

<section class="article-table-of-contents" data-component="articleToc">
			<ol class="article-table-of-contents__list">
			<ul>
<li><a href="#sec1">Motivation</a></li>
<li><a href="#sec2">Communication in Distributed Deep Learning</a></li>
<li><a href="#sec7">Hammingmesh</a></li>
<li><a href="#sec12">Results and Comparison</a></li>
<li><a href="#sec30">Conclusions</a></li>
<li><a href="#sec31">Acknowledgment</a></li>
<li><a href="#references">References</a></li>
<li><a href="#footnotes">Footnotes</a></li>
</ul>
		</ol>
	</section>
		<div class="article-contents">
			
<a class="article-connected-content" href="https://cacm.acm.org/research-highlights/technical-perspective-mirror-mirror-on-the-wall-what-is-the-best-topology-of-them-all/">
	Read the related Technical Perspective	<svg aria-hidden="true" focusable="false" width="24.88" height="16" fill="var(--wp--preset--color--cacm-link-blue)"><use href="#am-symbol-icon-arrow-right"></use></svg></a>

<div class="article-content entry-content">
		<article><div class="body" lang="en"><section id="sec1" class="sec"><h3>Abstract</h3><div class="article-key-insights"><p>Numerous microarchitectural optimizations unlocked tremendous processing power for deep neural networks that in turn fueled the AI revolution. With the exhaustion of such optimizations, the growth of modern AI is now gated by the performance of training systems, especially their data movement. Instead of focusing on single accelerators, we investigate data-movement characteristics of large-scale training at full system scale. Based on our workload analysis, we design HammingMesh, a novel network topology that provides high bandwidth at low cost with high job scheduling flexibility. Specifically, HammingMesh can support full bandwidth and isolation to deep learning training jobs with two dimensions of parallelism. Furthermore, it also supports high global bandwidth for generic traffic. Thus, HammingMesh will power future large-scale deep learning systems with extreme bandwidth requirements.</p></div><h2 class="heading"><span class="caption-label">1</span>Motivation</h2><p id="p-1">Artificial intelligence (AI) is experiencing unprecedented growth providing seemingly open-ended opportunity. <i>Deep learning</i> models combine many layers of operators into a complex function that is <i>trained</i> by optimizing its parameters to large datasets. Given the abundance of sensor, simulation, and human artifact data, this new model of designing computer programs, also known as data-driven programming or software 2.0, is mainly limited by the capability of machines to perform the compute- and data-intensive training jobs. In fact, the predictive quality of models improves as their size and training data grow to unprecedented scales.<a class="reference-link xref xref-bibr" href="#bib15" data-jats-ref-type="bibr" data-jats-rid="bib15"><sup>15</sup></a> Building <i>deep learning supercomputers</i>, to both explore the limits of artificial intelligence and commoditize it, is becoming not only interesting to big industry but also humanity as a whole.</p><iframe title="YouTube video player" src="https://www.youtube.com/embed/4_Ma01QtttQ?si=YB9aJH9PZ74o3yfz" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe><p id="p-2">A plethora of different model types exist in deep learning and new major models are developed every two to three years. Yet, their computational structure is similarthey consist of layers of operators and they are fundamentally <i>data-intensive</i>.<a class="reference-link xref xref-bibr" href="#bib14" data-jats-ref-type="bibr" data-jats-rid="bib14"><sup>14</sup></a> Many domain-specific accelerators take advantage of peculiarities of deep learning workloads be it matrix multiply units (tensor cores), specialized vector cores, or specific low-precision datatypes. Those optimizations can lead to orders of magnitude efficiency improvements. Yet, as we are approaching the limits of such microarchitectural improvements, we need to direct our focus to the system level.</p><p id="p-3">Todays training jobs are already limited by data movement.<a class="reference-link xref xref-bibr" href="#bib14" data-jats-ref-type="bibr" data-jats-rid="bib14"><sup>14</sup></a> In addition, trends in deep neural networks, such as sparsity, further increase those bandwidth demands in the near future.<a class="reference-link xref xref-bibr" href="#bib9" data-jats-ref-type="bibr" data-jats-rid="bib9"><sup>9</sup></a> Memory and network bandwidth are expensivein fact, they form the largest cost component in todays systems. Standard HPC systems with the newest InfiniBand adapters can offer 400Gb/s but modern deep learning training systems offer much higher bandwidths. Googles TPUv2, designed seven years ago, has 1Tbps off-chip bandwidth, AWS Trainium has up to 1.6Tbps per Tm1n instance, and Nvidia A100 and H100 chips have 4.8 and 7.2Tbps (local) NVLINK connectivity, respectively. The chips in Teslas Dojo deep learning supercomputer even have 128Tbps off-chip bandwidth<i>more than a network switch</i>. Connecting these extreme-bandwidth chips at reasonable cost is a daunting task and todays solutions, such as NVLINK, provide only local islands of high bandwidth.</p><p id="p-4">We argue that general-purpose HPC and datacenter topologies are not cost-effective at these endpoint injection bandwidths. Yet, workload specialization, similar to existing microarchitectural optimizations, can lead to an efficient design that provides the needed high-bandwidth networking. We begin with developing a generic model that accurately represents the fundamental data movement characteristics of deep learning workloads. Our model shows the inadequacy of the simplistic view that the main communication in deep learning is allreduce. In fact, we show that communication can be expressed as a concurrent mixture of pipelines and orthogonal reductions forming toroidal data movement patterns. This formulation shows that todays HPC networks, optimized for full global (bisection) bandwidth, are inefficient for deep learning workloads. Specifically, their <i>global bandwidth is overprovisioned while their local bandwidth is underprovisioned</i>.</p><p id="p-5">We use our insights to develop HammingMesh, a flexible topology that can adjust the ratio of local and global bandwidth for deep learning workloads. HammingMesh combines ideas from torus and global-bandwidth topologies (for example, fat tree) to enable a flexibility-cost tradeoff shown schematically in Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1</a>. Inspired by machine learning traffic patterns, HammingMesh connects local high-bandwidth 2D meshes using row and column (blue and red) switches into global networks.<a class="footnote-link xref xref-fn" href="#fn1" data-jats-ref-type="fn" data-jats-rid="fn1"><sup>a</sup></a></p><figure id="F1" class="fig" data-jats-position="float"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig01.jpg" data-type="image" data-caption="Figure 1. " href="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig01.jpg">
				<img decoding="async" class="graphic" title="Figure 1. " src="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig01.jpg" alt="" width="797" height="360" data-image-id="F1" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 1.</span> <span class="p">HammingMeshs bandwidth-cost-flexibility tradeoff.</span><div class="figcaption-footer"></div></figcaption></figure><p>In summary, we show how deep learning communication can be modeled as sets of orthogonal and parallel Hamiltonian cycles to simplify mapping and reasoning. Based on this observation, we define principles for network design for deep learning workloads. Specifically, our HammingMesh topology</p><ul class="list" data-jats-list-type="bullet"><li class="list-item"><p id="p-8">uses technology-optimized local (for example, PCB board) and global (optical, switched) connectivity.</p></li><li class="list-item"><p id="p-9">utilizes limited packet forwarding capabilities in the network endpoints to achieve lower cost and higher flexibility.</p></li><li class="list-item"><p id="p-10">enables full-bandwidth embedding of virtual topologies with deep learning traffic characteristics.</p></li><li class="list-item"><p id="p-11">supports flexible job allocation even with failed nodes.</p></li><li class="list-item"><p id="p-12">enables flexible configuration of oversubscription factors to adjust global bandwidth.</p></li></ul><p id="p-13">With those principles, HammingMesh enables extreme off-chip bandwidths to nearest neighbors at more than 8x cheaper allreduce bandwidth compared to standard HPC topologies such as fat trees. HammingMesh reduces the number of external switches and cables and thus reduces overall system cost. Furthermore, it provides significantly higher flexibility than torus networks. HammingMesh also enables seamless scaling to larger domains without separation between on- and off-chassis programming models (like NVLINK vs. InfiniBand). And last but not least, we believe that HammingMesh topologies extend to other machine learning, (multi)linear algebra, parallel solvers, and many other workloads with similar traffic characteristics.</p><p id="p-14">We start with a characterization of parallel deep learning and the related data movement patterns. For reference, we provide an overview of symbols used in this paper in Table <a class="xref xref-table" href="#T1" data-jats-ref-type="table" data-jats-rid="T1">1</a>.</p><figure id="T1" class="table-wrap" data-jats-position="float"><div class="caption"><span class="caption-label">Table 1.</span> <span class="p">Symbols used in the paper</span></div><div class="table-container"><table class="table table-bordered table-condensed table-hover" data-jats-frame="hsides" data-jats-rules="rows"><colgroup> <col align="center" valign="top" /> <col align="center" valign="top" /> </colgroup><thead style="vertical-align: bottom;"><tr><th style="text-align: center;">Symbol</th><th style="text-align: center;">Description</th></tr></thead><tbody><tr><td style="text-align: center;"><i>M</i></td><td style="text-align: center;">number of examples per minibatch</td></tr><tr><td style="text-align: center;"><i>N<sub>P</sub></i></td><td style="text-align: center;">number of network parameters</td></tr><tr><td style="text-align: center;"><i>W</i></td><td style="text-align: center;">size of a word</td></tr><tr><td style="text-align: center;"><i>D</i>, <i>P</i>, <i>O</i></td><td style="text-align: center;">degree of data, pipeline, operator parallelism</td></tr><tr><td style="text-align: center;"><i>a</i>, <i>b</i> and <i>x</i>, <i>y</i></td><td style="text-align: center;">2D HammingMesh board and global sizes</td></tr></tbody></table></div></figure></section><section id="sec2" class="sec"><h2 class="heading"><span class="caption-label">2</span>Communication in Distributed Deep Learning</h2><p id="p-16">One iteration of deep learning training with Stochastic Gradient Descent (SGD) consists of two phases: the forward pass and the backward pass. The forward pass evaluates the network function <i>f</i>(<i>x</i>) on a set of <i>M</i> examples, also called a minibatch. The backward pass of SGD computes the average loss <i>L</i> and propagates the errors <em>e</em> backwards through the network to adapt the parameters <i>P</i>. This training process proceeds through multiple (computationally identical) iterations until the model achieves the desired accuracy.</p><figure id="UF1" class="fig"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_uf01.jpg" data-type="image" data-caption=" " href="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_uf01.jpg">
				<img decoding="async" class="graphic" title=" " src="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_uf01.jpg" alt="" data-image-id="UF1" data-image-type="figure" />
			</a>
		</div></figure><p id="p-17">Parallelism and data distribution can fundamentally be arranged along three axes: <i>data parallelism, pipeline parallelism, and operator parallelism</i>.<a class="reference-link xref xref-bibr" href="#bib5" data-jats-ref-type="bibr" data-jats-rid="bib5"><sup>5</sup></a> The latter two are often summarized as <i>model parallelism</i> and operator parallelism is sometimes called tensor parallelism. We now briefly discuss their main characteristics.</p><section id="sec3" class="sec"><h3 class="heading"><span class="caption-label">2.1</span>Data parallelism.</h3><p id="p-18">When parallelizing over the training data, we train <i>D</i> separate copies of the model, each with different examples. To achieve exactly the same result as in serial training, we sum the distributed gradients before applying them to the weights at the end of each iteration. If the network has <i>N<sub>P</sub></i> parameters, then the communication volume of this step is <i>WN<sub>P</sub></i>.</p><p id="p-19">Modern deep neural networks have millions or billions of parameters, making this communication step expensive. Thus, many optimizations target gradient summation<a class="reference-link xref xref-bibr" href="#bib22" data-jats-ref-type="bibr" data-jats-rid="bib22"><sup>22</sup></a>some even change convergence properties during the training process but maintain final result quality.<a class="reference-link xref xref-bibr" href="#bib2" data-jats-ref-type="bibr" data-jats-rid="bib2"><sup>2</sup></a> Dozens of different techniques have been developed to optimize this communicationhowever, all perform some form of distributed summation operation like <i>MPI_Allreduce</i>. Data-parallelism differs thus mostly in the details such as invocation frequency, consistency, and sparsity.</p></section><section id="sec4" class="sec"><h3 class="heading"><span class="caption-label">2.2</span>Pipeline parallelism.</h3><p id="p-20">Deep neural networks are evaluated layer by layer with the outputs of layer <i>i</i> feeding as inputs into layer <i>i</i> + 1. Back-propagation is performed along the reverse direction starting at the loss function <i>L</i> after the last layer and proceeding from layer <i>i</i> + 1 to layer <i>i</i>. We can model the network as a pipeline with <i>P</i> stages with one or more layers per stage. Forward and backward passes can be interleaved at each processing element to form a bidirectional training pipeline. Pipelines suffer from characteristic start-up and tear-down overheads. These can be reduced by running two pipelines in both directions<a class="reference-link xref xref-bibr" href="#bib19" data-jats-ref-type="bibr" data-jats-rid="bib19"><sup>19</sup></a> or by using asynchronous schemes that impact convergence.</p><p id="p-21">Overall, pipelining schemes can use <i>P</i> processors with a nearest-neighbor communication volume proportional to the number of output activations at the cut layers.</p></section><section id="sec5" class="sec"><h3 class="heading"><span class="caption-label">2.3</span>Operator parallelism.</h3><p id="p-22">Very large layer computations (operators) can be distributed to <i>O</i> processors. Most deep learning layer operators follow computational schedules of (multi-)linear algebra and tensor contractions and require either (tightly coupled) distributed reductions or nearest-neighbor communications.</p></section><section id="sec6" class="sec"><h3 class="heading"><span class="caption-label">2.4</span>Overall communication pattern.</h3><p id="p-23">When all forms of parallelism are used, then the resulting job comprises <i>D</i>  <i>P</i>  <i>O</i> accelerators; each accelerator in a job has a logical address (1..<i>D</i>, 1..<i>P</i>, 1..<i>O</i>). The data-, pipeline-, and operator-parallel communication can be arranged as one-dimensional slices (rings) by varying only one coordinate of the Cartesian structure. Pipelines would leave one connection of the ring unused. For example, the data-parallel dimension consists of <i>P</i>  <i>O</i> rings of length <i>D</i> each. Each of those rings represents a single allreduce. We show efficient ring-based reduction and broadcast algorithms for large data volumes in Section <a class="xref xref-sec" href="#sec18" data-jats-ref-type="sec" data-jats-rid="sec18">4.1.2</a>.</p><p id="p-24">The overall composition of communication patterns forms a torus as illustrated in the right part of Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a> for a 333 example: Both the operator and the data parallel dimensions use nine simultaneous allreductions of size three each. The pipeline parallel dimension uses nine three-deep pipelines on three different model replicas, each split in three pieces.</p><figure id="F2" class="fig"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig02.jpg" data-type="image" data-caption="Figure 2. " href="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig02.jpg">
				<img decoding="async" class="graphic" title="Figure 2. " src="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig02.jpg" alt="" width="778" height="128" data-image-id="F2" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 2.</span> <span class="p">Distribution strategies for parallel deep neural network training.</span><div class="figcaption-footer"></div></figcaption></figure><p id="p-26">While we can map such a logical torus to a full-bandwidth network topology, it seems wasteful to provide full bandwidth for sparse communication. For example, a 400Gb/s non-blocking fat tree with 16,384 endpoints provides full bisection bandwidth of more than <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mfrac><mrow><mn>16</mn><mo>,</mo><mn>384.50</mn><mtext></mtext><mtext></mtext><mtext></mtext><mi>GB</mi><mo>/</mo><mtext>s</mtext></mrow><mn>2</mn></mfrac><mo>=</mo><mn>410</mn><mtext></mtext><mi>TB</mi><mo>/</mo><mtext>s</mtext></mrow></math></span>. A bi-directional 32x32x16 torus communication pattern requires at most 32  16  2  50GB/s= 51.2TB/s bisections (cutting one dimension of size 32)a mere 12.5% of the offered bandwidth. In other words, <i>88% of the available bandwidth will remain unused and is wasted</i>. Furthermore, it is not always simple to map such torus communication patterns efficiently to full-bandwidth low-diameter topologies in practice.</p></section></section><section id="sec7" class="sec"><h2 class="heading"><span class="caption-label">3</span>HammingMesh</h2><p id="p-27">Based on the communication workload analysis, we now design a flexible and efficient network topology. The basic requirements are to support highest injection bandwidth for a set of jobs, each following a virtual toroidal communication topology. We note that medium-size models are often decomposed only in two dimensions in practice (usually data and pipeline or data and operator). Only extreme-scale workloads require all three dimensionseven then, communication along the data parallel dimension only happens after one complete iteration. Thus, we use a two-dimensional physical topology.</p><p id="p-28">As a case study, we assume a modern deep learning accelerator package with 16 400Gb/s off-chip network links, a total network injection bandwidth of 800GB/s (top left in Figure <a class="xref xref-fig" href="#F3" data-jats-ref-type="fig" data-jats-rid="F3">3</a>). Our topology design also takes technology costs into account: Similar to Dragonfly, which combines local short copper cables with global long fiber cables to design a cost-effective overall topology, we combine such local groups with a global topology. Different from Dragonfly, we choose two quite distinct topologies: The local groups are formed by a local inexpensive high-bandwidth 2D mesh using short metal traces on PCB boards. This is the opposite of Dragonfly designs, which combine densely-connected local groups (virtual switches) and connect those fully globally. HammingMesh combines sparsely connected boards in a dimension-wise (not globally) fully-connected topology. Those boards are connected by a two-dimensional Hamming graph, in which each dimension is logically fully connected (for example, by a fat tree). All accelerator ports are arranged in <i>planes</i> with four directions each. Our example accelerator has four planes (top left in Figure <a class="xref xref-fig" href="#F3" data-jats-ref-type="fig" data-jats-rid="F3">3</a>), for example, plane 1 has ports E1, W1, N1, and S1. We assume that each accelerator can forward packets within a plane like any network switch. Accelerators do not have to forward packets between planes, for example, packets arriving at N1 may only be forwarded to E1, W1, or S1 but none of the other ports. Thus, only simple 4&#215;4 switches are needed at each accelerator. Figure <a class="xref xref-fig" href="#F3" data-jats-ref-type="fig" data-jats-rid="F3">3</a> illustrates the structure in detail.</p><figure id="F3" class="fig"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig03.jpg" data-type="image" data-caption="Figure 3. " href="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig03.jpg">
				<img decoding="async" class="graphic" title="Figure 3. " src="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig03.jpg" alt="" data-image-id="F3" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 3.</span> <span class="p">HammingMesh structure: left <i>x  y</i> Hx2Mesh, right Hx4Mesh board, both with four planes.</span><div class="figcaption-footer"></div></figcaption></figure><p id="p-30">A 2D HammingMesh is parameterized by its number of planes and four additional numbers: (<i>a</i>, <i>b</i>), the dimensions of the board, and (<i>x</i>, <i>y</i>), the dimensions of the global topology. It connects a total of <i>abxy</i> accelerators. We abbreviate HammingMesh with HxMesh in the following. Furthermore, an HxMesh with an <i>a</i>  <i>b</i> accelerator board is called H<i>a</i>x<i>b</i>Mesh, for example, for a 2&#215;2 board, H2x2Mesh. For square board topologies, we skip the first number, for example, an H2x2Mesh that connects 10&#215;10 boards is called a 10&#215;10 Hx2Mesh.</p><p id="p-31">HxMesh has a large design space: We can combine different board and global topologies, for example, 3D mesh boards with global Slim Fly topologies.<a class="reference-link xref xref-bibr" href="#bib6" data-jats-ref-type="bibr" data-jats-rid="bib6"><sup>6</sup></a> In this work, we consider 2D boards as most practical for PCB traces. The board arrangement could be reduced to a 1D HxMesh, where <i>y</i> = 1 and each N<i>k</i> link is connected to the corresponding S<i>k</i> link (wrapped around). The same global topology can also span multiple rows or columns (for example, full boards in a single fat tree). For ease of exposition, we limit ourselves to 2D HxMeshes using 2D boards and row/column-separated global topologies. We use two-level fat trees as global topologies to connect the boards column and row wise. If the boards can be connected with a single 64-port switch, we use that instead of a fat tree.</p><section id="sec8" class="sec"><h3 class="heading"><span class="caption-label">3.1</span>Bisection and global bandwidth.</h3><p id="p-32">Bisection cut is defined as the minimal number of connections that would need to be cut in order to bisect the network into two pieces, each with an equal number of accelerators. The bisection bandwidth is the cut multiplied by the link bandwidth. Let us assume a single-plane of an <i>x</i>  <i>y</i> Hx<i>a</i>Mesh (square board) with <i>x</i>  <i>y</i> and <i>y</i> even, wlog. We now consider the <i>xy</i>/2 lower half boards with <i>y</i> coordinates 1, 2,  <i>y</i>/2. We split the HxMesh into two equal pieces by cutting the 2<i>a</i> links in <i>y</i> direction of each of the lower half of the boards. This results in a total cut width of <i>axy</i>. Each accelerator has four network links per plane, a total injection bandwidth of 4<i>a</i><sup>2</sup> per board. We have <i>xy</i>/2 boards with a total injection bandwidth of 4<i>a</i><sup>2</sup><i>xy</i>/2 = 2<i>xya</i><sup>2</sup> in each partition. Thus, the relative bisection bandwidth is <i>axy</i>/2<i>xya</i><sup>2</sup> = 1/2<i>a</i>.</p><p id="p-33">In a bisection traffic pattern, all traffic crosses the network bisection (any two communicating endpoints are in different sets of the bisection). Such (worst-case) patterns are rare in practice. A more useful pattern, more often observed in practice is alltoall, where each process sends to all other processes. This pattern is the basis of parallel transpositions, Fast Fourier Transforms, and many graph algorithms. The achievable theoretical bandwidth for such alltoall patterns is often called global bandwidth. Some topology constructions take advantage of the fact that global bandwidth is higher than bisection bandwidth. Prisacari et al.<a class="reference-link xref xref-bibr" href="#bib21" data-jats-ref-type="bibr" data-jats-rid="bib21"><sup>21</sup></a> shows that full-global bandwidth (alltoall) fat trees can be constructed with 25% less switches than nonblocking fat trees. Dragonfly,<a class="reference-link xref xref-bibr" href="#bib17" data-jats-ref-type="bibr" data-jats-rid="bib17"><sup>17</sup></a> Slim Fly,<a class="reference-link xref xref-bibr" href="#bib6" data-jats-ref-type="bibr" data-jats-rid="bib6"><sup>6</sup></a> or other low-diameter topologies<a class="reference-link xref xref-bibr" href="#bib16" data-jats-ref-type="bibr" data-jats-rid="bib16"><sup>16</sup></a> can further reduce the number of switches in very large installations while maintaining full global bandwidth. As is customary for low-diameter topologies,<a class="reference-link xref xref-bibr" href="#bib6" data-jats-ref-type="bibr" data-jats-rid="bib6"><sup>6</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#bib17" data-jats-ref-type="bibr" data-jats-rid="bib17"><sup>17</sup></a> we assess it using packet-level simulations of alltoall traffic.</p></section><section id="sec9" class="sec"><h3 class="heading"><span class="caption-label">3.2</span>Example topologies.</h3><p id="p-34">We consider a small cluster with approximately 1,000 accelerators and a large cluster with approximately 16,000 accelerators as specific design points to compare realistic networks. We compare various fat trees (nonblocking, 50%, 75% tapered), full bandwidth Dragonfly, two-dimensional torus, and HyperX,<a class="footnote-link xref xref-fn" href="#fn2" data-jats-ref-type="fn" data-jats-rid="fn2"><sup>b</sup></a> with Hx2Mesh and Hx4Mesh example topologies.</p><p id="p-35">Table <a class="xref xref-table" href="#T2" data-jats-ref-type="table" data-jats-rid="T2">2</a> summarizes the main cost and bandwidth results. Global and allreduce bandwidth are determined using packet-level simulations (see Section <a class="xref xref-sec" href="#sec13" data-jats-ref-type="sec" data-jats-rid="sec13">4</a>) for large messages. <i>For all experiments, we simulated a single plane of HammingMesh and four planes for all other topologies, i.e., a total injection bandwidth of 4400Gb/s.</i> We use industry-standard layouts and cable configurations for the cost estimates: fat trees are tapered beginning from the second level and connect all endpoints using DAC and all switches using AoC. Dragonfly topologies use full-bandwidth groups with <i>a</i> = 16 routers each, <i>p</i> = 8 endpoints per router, and <i>h</i> = 8 links to other groups with DAC links inside the groups and AoC links between groups. The torus uses 2 <i></i> 2 board topologies with discounted local PCB connectivity, similar to Hx2Mesh and only DAC cables between the boards. For HxMeshes, we use DAC links to connect endpoints to switches along one dimension, and AoC links for the other dimension. All inter-switch links are AoC as in fat trees.</p><figure id="T2" class="table-wrap" data-jats-position="float"><div class="caption"><span class="caption-label">Table 2.</span> <span class="p">Overview of our example networks (small and large cluster) using the cost model that is described in the full version of this paper.<a class="reference-link xref xref-bibr" href="#bib10" data-jats-ref-type="bibr" data-jats-rid="bib10"><sup>10</sup></a> All bandwidths are the result of the packet-level simulations detailed in Section <a class="xref xref-sec" href="#sec14" data-jats-ref-type="sec" data-jats-rid="sec14">4.1</a>. Global alltoall bandwidth is reported as share of the injection bandwidth for large messages (1.6Tb/s). Allreduce bandwidth is reported as share of the theoretical optimum (1/2 of the injection bandwidth) for large messages. The cost savings for global and allreduce bandwidth are relative to the corresponding network cost of the nonblocking fat tree.</span></div><div class="table-container"><table class="table table-bordered table-condensed table-hover" data-jats-frame="hsides" data-jats-rules="rows"><colgroup> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> <col align="center" valign="top" /> </colgroup><thead><tr><th style="text-align: center;" rowspan="3">Topology</th><th style="text-align: center;" colspan="6">Small Cluster (1,000 accelerators)</th><th style="text-align: center;" colspan="6">Large Cluster (16,000 accelerators)</th></tr><tr><th style="text-align: center;">cost</th><th style="text-align: center;">glob. BW</th><th style="text-align: center;">global</th><th style="text-align: center;">ared. BW</th><th style="text-align: center;">ared.</th><th style="text-align: center;">diam.</th><th style="text-align: center;">cost</th><th style="text-align: center;">glob. BW</th><th style="text-align: center;">global</th><th style="text-align: center;">ared. BW</th><th style="text-align: center;">ared.</th><th style="text-align: center;">diam.</th></tr><tr><th style="text-align: center;">[M$]</th><th style="text-align: center;">[% inject]</th><th style="text-align: center;">saving</th><th style="text-align: center;">[% peak]</th><th style="text-align: center;">saving</th><th></th><th style="text-align: center;">[M$]</th><th style="text-align: center;">[% inject]</th><th style="text-align: center;">saving</th><th style="text-align: center;">[% peak]</th><th style="text-align: center;">saving</th><th></th></tr></thead><tbody><tr><td style="text-align: center;">nonbl. FT</td><td style="text-align: center;">25.3</td><td style="text-align: center;">99.9</td><td style="text-align: center;">1.0x</td><td style="text-align: center;">98.9</td><td style="text-align: center;">1.0x</td><td style="text-align: center;">4</td><td style="text-align: center;">680</td><td style="text-align: center;">98.9</td><td style="text-align: center;">1.0x</td><td style="text-align: center;">99.8</td><td style="text-align: center;">1.0x</td><td style="text-align: center;">6</td></tr><tr><td style="text-align: center;">50% tap. FT</td><td style="text-align: center;">17.6</td><td style="text-align: center;">51.2</td><td style="text-align: center;">0.7x</td><td style="text-align: center;">98.9</td><td style="text-align: center;">1.4x</td><td style="text-align: center;">4</td><td style="text-align: center;">419</td><td style="text-align: center;">47.6</td><td style="text-align: center;">0.8x</td><td style="text-align: center;">99.8</td><td style="text-align: center;">1.6x</td><td style="text-align: center;">6</td></tr><tr><td style="text-align: center;">75% tap. FT</td><td style="text-align: center;">13.2</td><td style="text-align: center;">25.7</td><td style="text-align: center;">0.5x</td><td style="text-align: center;">98.9</td><td style="text-align: center;">1.9x</td><td style="text-align: center;">4</td><td style="text-align: center;">271</td><td style="text-align: center;">24</td><td style="text-align: center;">0.6x</td><td style="text-align: center;">99.8</td><td style="text-align: center;">2.5x</td><td style="text-align: center;">6</td></tr><tr><td style="text-align: center;">Dragonfly</td><td style="text-align: center;">27.9</td><td style="text-align: center;">62.9</td><td style="text-align: center;">0.6x</td><td style="text-align: center;">98.8</td><td style="text-align: center;">0.9x</td><td style="text-align: center;">3</td><td style="text-align: center;">429</td><td style="text-align: center;">71.5</td><td style="text-align: center;">1.2x</td><td style="text-align: center;">98.6</td><td style="text-align: center;">1.6x</td><td style="text-align: center;">5</td></tr><tr><td style="text-align: center;">2D HyperX</td><td style="text-align: center;">10.8</td><td style="text-align: center;">91.6</td><td style="text-align: center;"><b>2.1x</b></td><td style="text-align: center;">98.1</td><td style="text-align: center;">2.3x</td><td style="text-align: center;">4</td><td style="text-align: center;">448</td><td style="text-align: center;">95.8</td><td style="text-align: center;">1.5x</td><td style="text-align: center;">99.2</td><td style="text-align: center;">1.5x</td><td style="text-align: center;">8</td></tr><tr><td style="text-align: center;">Hx2Mesh</td><td style="text-align: center;">5.4</td><td style="text-align: center;">25.4</td><td style="text-align: center;">1.2x</td><td style="text-align: center;">98.3</td><td style="text-align: center;">4.7x</td><td style="text-align: center;">4</td><td style="text-align: center;">224</td><td style="text-align: center;">25</td><td style="text-align: center;">0.8x</td><td style="text-align: center;">92.3</td><td style="text-align: center;">2.8x</td><td style="text-align: center;">8</td></tr><tr><td style="text-align: center;">Hx4Mesh</td><td style="text-align: center;">2.7</td><td style="text-align: center;">11.3</td><td style="text-align: center;">1.0x</td><td style="text-align: center;">98.4</td><td style="text-align: center;"><b>9.3x</b></td><td style="text-align: center;">8</td><td style="text-align: center;">43.3</td><td style="text-align: center;">10.5</td><td style="text-align: center;"><b>1.7x</b></td><td style="text-align: center;">98</td><td style="text-align: center;"><b>15.4x</b></td><td style="text-align: center;">8</td></tr><tr><td style="text-align: center;">2D torus</td><td style="text-align: center;">2.5</td><td style="text-align: center;">2</td><td style="text-align: center;">0.2x</td><td style="text-align: center;">98.1</td><td style="text-align: center;">10.1x</td><td style="text-align: center;">32</td><td style="text-align: center;">39.5</td><td style="text-align: center;">1.1</td><td style="text-align: center;">0.2x</td><td style="text-align: center;">99.2</td><td style="text-align: center;">17.1x</td><td style="text-align: center;">128</td></tr></tbody></table></div></figure></section><section id="sec10" class="sec"><h3 class="heading"><span class="caption-label">3.3</span>Logical job topologies and failures in HxMesh.</h3><p id="p-37">As we discussed in Section <a class="xref xref-sec" href="#sec7" data-jats-ref-type="sec" data-jats-rid="sec7">2.4</a>, communication patterns in deep learning can be modeled as sets of cycles. Typical learning jobs use either logical 1D cycles for small models with only data parallelism or 2D tori that combine data and pipeline parallelism for medium-scale models or combining pipeline and model parallelism for very large models. Each specific training job will have a different optimal decomposition resulting in 1D, 2D, or sometimes even 3D logical communication topologies.</p><p id="p-38">We use logical 2D topologies for our training jobs. Each job uses several boards and requests a <i>u</i>  <i>v</i> layout (that is, <i>a</i>, <i>b</i> divides <i>u</i>, <i>v</i>, respectively). If the application topology follows a 1D or 3D scheme, then users use standard folding techniques to embed it into two dimensional jobs. Figure <a class="xref xref-fig" href="#F4" data-jats-ref-type="fig" data-jats-rid="F4">4</a> shows an example of 3D virtual topology mapped on an Hx2Mesh physical topology. Processes can be sliced on the third dimension and mapped on different boards. Communications between different slices of the third dimension are routed over the per-column or per-row fat trees, depending how different slices are mapped. To minimize communication latency between slices, consecutive slices should be adjacent to each other.</p><figure id="F4" class="fig" data-jats-position="float"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig04.jpg" data-type="image" data-caption="Figure 4. " href="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig04.jpg">
				<img decoding="async" class="graphic" title="Figure 4. " src="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig04.jpg" alt="" data-image-id="F4" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 4.</span> <span class="p">3D workload mapping onto Hx2Mesh example. Left: virtual 4x4x2 topology. Right: mapping on Hx2Mesh.</span><div class="figcaption-footer"></div></figcaption></figure><p id="p-40">It is easy to see that any consecutive <i>u</i>  <i>v</i> block of boards in a 2D HxMesh has the same properties as a full <i>u</i>  <i>v</i> HxMesh. We call such subnetworks <i>virtual sub-HxMeshes</i>. They are a major strength of HxMesh compared to torus networks in terms of fault tolerance as well as for allocating jobs. In fact, HxMeshes major strength compared to torus networks is that virtual subnetworks can be formed with non-consecutive sets of boards (not only blocks): any set of boards in an HxMesh where all boards that are in the same row have the same sequence of column coordinates can form a virtual subnetwork. We will show examples below together with a motivation for subnetworksfaults.</p><section id="sec11" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Fault-tolerance.</strong> We assume that a board is the unit of failure in an HxMesh, that is, if an accelerator or link in a board fail, the whole board is considered failed. This simplifies system design and service. Partial failure modes (for example, per plane) are outside the scope of this work.</p><p id="p-42">The left part of Figure <a class="xref xref-fig" href="#F5" data-jats-ref-type="fig" data-jats-rid="F5">5</a> shows a 4&#215;4 Hx2Mesh and three board failures. We show two different subnetworks (many more are possible): a 2&#215;4 subnetwork (blue) with the physical boards (1, 1), (1, 4), (2, 1), (2, 4), (3, 1), (3, 4), (4, 1), (4, 4) and a 3&#215;3 subnetwork (yellow) with the physical boards (1, 1), (1, 2), (1, 4), (2, 1), (2, 2), (2, 4), (4, 1), (4, 2), (4, 4). We also annotate the new coordinates of boards in the virtual subnetworks. Remapping can be performed transparently to the user application, which does not observe a difference between a virtual and physical HxMesh in terms of network performance. The right part of the figure shows the output of our automatic mapping tool (described in detail in the full version of this paper<a class="reference-link xref xref-bibr" href="#bib10" data-jats-ref-type="bibr" data-jats-rid="bib10"><sup>10</sup></a>) for a more complex configuration of jobs (top, read job ids 1-3 are 3  3 logical jobs, and so on).</p><figure id="F5" class="fig" data-jats-position="float"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig05.jpg" data-type="image" data-caption="Figure 5. " href="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig05.jpg">
				<img decoding="async" class="graphic" title="Figure 5. " src="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig05.jpg" alt="" data-image-id="F5" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 5.</span> <span class="p">Subnetworks in the case of failures</span><div class="figcaption-footer"></div></figcaption></figure></section></section></section><section id="sec12" class="sec"><h2 class="heading"><span class="caption-label">4</span>Results and Comparison</h2><p id="p-44">We now evaluate HxMesh topology options in comparison with all topologies listed in Table <a class="xref xref-table" href="#T2" data-jats-ref-type="table" data-jats-rid="T2">2</a>. We use the Structural Simulation Toolkit (SST),<a class="reference-link xref xref-bibr" href="#bib1" data-jats-ref-type="bibr" data-jats-rid="bib1"><sup>1</sup></a> a packet-level network simulator, which has been validated against the Cray Slingshot interconnect.<a class="reference-link xref xref-bibr" href="#bib8" data-jats-ref-type="bibr" data-jats-rid="bib8"><sup>8</sup></a> SST enables us to reproduce the behavior of full MPI applications directly in the simulation environment where <i>they react to dynamic network changes (for example, congestion)</i>. In total, we ran simulations of more than 120 billion packets using more than 0.6 million core hours with parallel simulations. We select various representative microbenchmarks and scenarios for deep learning jobs and <i>publish the full simulation infrastructure such that readers can simulate their own job setup</i>.</p><section id="sec13" class="sec"><h3 class="heading"><span class="caption-label">4.1</span>Microbenchmarks.</h3><p id="p-45">We start by analyzing well-known microbenchmark traffic patterns to assess and compare achievable peak bandwidth.</p><section id="sec14" class="sec"><h4 class="heading"><span class="caption-label">4.1.1</span><em>Global traffic patterns.</em></h4><p id="p-46">We first investigate global traffic patterns such as alltoall and random permutations as global-traffic workloads. We note that HammingMesh is not optimized for those patterns as they are rare on deep learning traffic.</p><section id="sec15" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Alltoall.</strong> Alltoall sends messages from each process to all other processes. In our implementation, each of the <i>p</i> processes performs <i>p</i>  1 iterations. In each iteration <i>i</i>, process <i>j</i> sends to process <i>j</i> + <i>i</i> mod <i>p</i> in a balanced shift pattern.</p><p id="p-48">Table <a class="xref xref-table" href="#T2" data-jats-ref-type="table" data-jats-rid="T2">2</a> shows the results for 1 MiB messages while Figure <a class="xref xref-fig" href="#F6" data-jats-ref-type="fig" data-jats-rid="F6">6</a> shows the global bandwidth at different message sizes. Small Hx2 and Hx4Meshes achieve bandwidths around the cut width of 1/4 and 1/8, respectively (cf. Section <a class="xref xref-sec" href="#sec9" data-jats-ref-type="sec" data-jats-rid="sec9">3.1</a>). This is because not all global traffic crosses the bisection cuts, especially for smaller clusters. The large cluster configuration performs closer to those bounds and loses some bandwidth due to adaptive routing overheads. Despite its lower bandwidth, even large HxMeshes remain competitive in terms of cost-per global bandwidth and some are even more cost effective on global bandwidth than fat trees.</p><figure id="F6" class="fig" data-jats-position="float"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig06.jpg" data-type="image" data-caption="Figure 6. " href="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig06.jpg">
				<img decoding="async" class="graphic" title="Figure 6. " src="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig06.jpg" alt="" data-image-id="F6" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 6.</span> <span class="p">Alltoall on the small topologies.</span><div class="figcaption-footer"></div></figcaption></figure></section><section id="sec16" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Random permutation.</strong> In permutation traffic, each accelerator selects a unique random peer to send to and receive from. Here, the achieved bandwidth also depends on the location of both peers. Figure <a class="xref xref-fig" href="#F7" data-jats-ref-type="fig" data-jats-rid="F7">7</a> shows the distributions of receive bandwidths across all of the 1k accelerators in the small cluster configurations.</p><figure id="F7" class="fig" data-jats-position="float"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig07.jpg" data-type="image" data-caption="Figure 7. " href="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig07.jpg">
				<img decoding="async" class="graphic" title="Figure 7. " src="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig07.jpg" alt="" data-image-id="F7" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 7.</span> <span class="p">Bandwidth distribution per accelerator.</span><div class="figcaption-footer"></div></figcaption></figure><p id="p-52">Our results indicate that all topologies have significant variance across different connections (between different node pairs), which makes job placement and locality significant. HxMeshes are among the most cost effective topologies.</p></section></section><section id="sec17" class="sec"><h4 class="heading"><strong><em><span class="caption-label">4.1.2</span>Reduction traffic patterns.</em></strong></h4><p id="p-53">We distinguish three fundamental algorithm types: trees, pipelines, and near-optimal full-global bandwidth algorithms.</p><section id="sec18" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Simple trees.</strong> For small data, simple binary or binomial tree reductions are the best choice. They perform a reduction of <i>S</i> bytes on <i>p</i> processors in time <i>T</i>  log<sub>2</sub> (<i>p</i>) + log<sub>2</sub> (<i>p</i>)<i>S</i>.<a class="footnote-link xref xref-fn" href="#fn3" data-jats-ref-type="fn" data-jats-rid="fn3"><sup>c</sup></a> This algorithm sends each data item a logarithmic number of times. It is thus inefficient for the large data sizes in deep learning training workloads and we do not consider trees in this work.</p></section><section id="sec19" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Pipelined rings.</strong> With a single network interface, large data volumes can be reduced in a simple pipelined ring. Here, the data at each process is split into <i>p</i> segments. The operation proceeds in two epochs and <i>p</i>  1 rounds per epoch. In the first reduction epoch, each process <i>i</i> sends segment <i>i</i> to process <i>i</i> + 1 mod <i>p</i> and receives a segment from process <i>i</i>  1 mod p. The received segment is added to the local data and sent on to process <i>i</i> + 1 mod <i>p</i> in the next round. After <i>p</i>  1 such rounds, each process has the full sum of one segment. The second epoch is simply sending the summed segments along the pipeline. The overall time <i>Tp</i>  2<i>p</i> + 2<i>S</i> is bandwidth optimal because each process only sends and receives each segment twice.<a class="reference-link xref xref-bibr" href="#bib4" data-jats-ref-type="bibr" data-jats-rid="bib4"><sup>4</sup></a></p><p id="p-56">We propose bidirectional pipelined rings to utilize two network interfaces by splitting the data size in half and sending each half along a different direction. The latency stays unchanged because each segment travels twice through the whole ring but the data is half in each direction, leading to a runtime of <i>T<sub>bp</sub></i>  2<i>p</i> + <i>S</i>. Here and in the following, <i></i> is the time per Byte of each interface, i.e., a system with <i>k</i> network interfaces can inject <i>k/</i> Bytes per second.</p><p id="p-57">We now extend this idea to four network interfaces per HxMesh plane: we use two bidirectional rings, each reducing a quarter of the data across all accelerators. The two rings are mapped to two disjoint Hamiltonian cycles covering all accelerators of the HxMesh.<a class="reference-link xref xref-bibr" href="#bib3" data-jats-ref-type="bibr" data-jats-rid="bib3"><sup>3</sup></a> The overall time for this scheme is <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>T</mi><mrow><mi>r</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>s</mi></mrow></msub><mo></mo><mn>2</mn><mi>p</mi><mi></mi><mo>+</mo><mfrac><mi>s</mi><mn>2</mn></mfrac><mi></mi></mrow></math></span>.</p></section><section id="sec20" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Bucket.</strong> Pipelined rings are bandwidth-optimal if they can be mapped to Hamiltonian cycles on the topology. However, we find that for large HxMeshes and moderate message sizes, the latency component can become a bottleneck. We thus use the state-of-the-art bucket algorithm.<a class="reference-link xref xref-bibr" href="#bib23" data-jats-ref-type="bibr" data-jats-rid="bib23"><sup>23</sup></a><sup>,</sup><a class="footnote-link xref xref-fn" href="#fn4" data-jats-ref-type="fn" data-jats-rid="fn4"><sup>d</sup></a> The bucket algorithm arranges communications in 2D toroidal communication patterns with <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msqrt><mi>p</mi></msqrt></mrow></math></span> latency and good bandwidth usage. Each process executes first a reduce-scatter with the other processes on the same row <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>(</mo><mrow><mi>cost</mi><mtext></mtext><mtext></mtext><msqrt><mrow><mi>p</mi><mi></mi></mrow></msqrt><mo>+</mo><mfrac><mi>s</mi><mn>2</mn></mfrac><mi></mi></mrow><mo>)</mo></math></span>. Then each process runs an allreduce with the other processes on the same column, on the previously reduced chunk of size <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mfrac><mi>s</mi><mrow><msqrt><mi>p</mi></msqrt></mrow></mfrac><mrow><mo>(</mo><mrow><mi>cos</mi><mtext></mtext><mtext></mtext><mn>2</mn><mrow><mo>(</mo><mrow><msqrt><mrow><mi>p</mi><mi></mi></mrow></msqrt><mo>+</mo><mfrac><mi>s</mi><mrow><mn>2</mn><msqrt><mi>p</mi></msqrt></mrow></mfrac><mi></mi></mrow><mo>)</mo></mrow><mtext></mtext></mrow><mo>)</mo></mrow><mtext></mtext></mrow></math></span> and, eventually, an allgather with the other processes on the same row <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>(</mo><mrow><mi>cost</mi><mtext></mtext><mtext></mtext><msqrt><mrow><mi>p</mi><mi></mi></mrow></msqrt><mo>+</mo><mfrac><mi>s</mi><mn>2</mn></mfrac><mi></mi></mrow><mo>)</mo></math></span>. To use all four network interfaces at the same time, four of these allreduce can be executed in parallel, each starting from a different port and working on a quarter of the data.<a class="reference-link xref xref-bibr" href="#bib23" data-jats-ref-type="bibr" data-jats-rid="bib23"><sup>23</sup></a> Thus, the overall time for this scheme is <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>T</mi><mo></mo><mn>2</mn><mtext></mtext><mtext></mtext><mo></mo><mtext></mtext><mtext></mtext><mn>2</mn><msqrt><mrow><mi>p</mi><mi></mi></mrow></msqrt><mo>+</mo><mi>S</mi><mi></mi><mrow><mo>(</mo><mrow><mfrac><mrow><mn>1</mn><mo>+</mo><mn>2</mn><msqrt><mi>p</mi></msqrt></mrow><mrow><mn>4</mn><msqrt><mi>p</mi></msqrt></mrow></mfrac></mrow><mo>)</mo></mrow></mrow></math></span>.</p></section><section id="sec21" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Summary.</strong> The pipeline ring and bucket algorithms have sparse communication patterns: each process only communicates with two or four direct neighbors that can be mapped perfectly to HxMesh. Broadcast and other collectives can be implemented similarly (for example, as the second part of our allreduce) and follow similar tradeoffs. Furthermore, each dimension of a logical job topology is typically small as the total number of accelerators is the product of all dimensions. For example, even for a very large system with 32,768 accelerators, each of the dimensions could only be of size 32 if we decompose the problem along all dimensions. This means that the largest allreduce or broadcast would only be on 32 processes where ring algorithms would perform efficiently.</p></section><section id="sec22" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Full system allreduce job.</strong> This experiment shows a single job using the last two allreduce algorithms on various topologies. In Dragonfly and fat tree, each accelerator connects with a single NIC to each of the four planes and we use the standard ring algorithm. For the single allreduce on the large HxMesh clusters, we use both the two bidirectional rings (rings) as well as the bucket (bucket) algorithm. Figure <a class="xref xref-fig" href="#F8" data-jats-ref-type="fig" data-jats-rid="F8">8</a> shows the achieved bandwidths.</p><figure id="F8" class="fig" data-jats-position="float"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig08.jpg" data-type="image" data-caption="Figure 8. " href="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig08.jpg">
				<img decoding="async" class="graphic" title="Figure 8. " src="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig08.jpg" alt="" data-image-id="F8" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 8.</span> <span class="p">Global allreduce using different algorithms.</span><div class="figcaption-footer"></div></figcaption></figure><p id="p-62">We see that all topologies deliver nearly full bandwidth for the ring algorithms. For large messages, HxMesh is 2.8x to 14.5x cheaper per bandwidth than a nonblocking fat tree (Table <a class="xref xref-table" href="#T2" data-jats-ref-type="table" data-jats-rid="T2">2</a>). On networks with a Cartesian structure (HammingMesh, Torus, and HyperX) the bucket algorithm outperforms the ring algorithm at any message size. The only exception is for jobs where one of the two dimension is much smaller than the other, where the ring algorithm outperforms the bucket algorithm (not shown), highlighting the importance of using multi-algorithms to optimize performance, similar to established practice in MPI.<a class="reference-link xref xref-bibr" href="#bib25" data-jats-ref-type="bibr" data-jats-rid="bib25"><sup>25</sup></a></p></section></section></section><section id="sec23" class="sec"><h3 class="heading"><span class="caption-label">4.2</span>DNN Workloads</h3><p id="p-63">We now proceed to define accurate communication patterns including computation times for real DNN models. For this, we choose four large representative models: ResNet-152, CosmoFlow, DLRM, and Transformers (GPT3) trained in FP32. We discuss only DLRM and Transformers, and a more detailed discussion covering the other models can be found in the full version of this paper.<a class="reference-link xref xref-bibr" href="#bib10" data-jats-ref-type="bibr" data-jats-rid="bib10"><sup>10</sup></a> We use NVIDIAs A100 GPU to benchmark runtimes of operators and we model communication times based on the data volumes.</p><section id="sec24" class="sec"><h4 class="heading"><em><span class="caption-label">4.2.1</span>Communication traffic characterization.</em></h4><p id="p-64">All example models are constructed of a sequence of identical layers containing multiple operators. Each parallel dimension carries a different volume, depending on the details of the model, training hyperparameters, and the other dimensions. We assume the most general case where the network can utilize all three forms of parallelism running on <i>D</i>  <i>P</i>  <i>O</i> accelerators.</p><section id="sec25" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Data dimension.</strong> If we only have data parallelism (<i>O</i> = <i>P</i> = 1), then each process needs to reduce all gradients. If we distribute the model between <i>O</i> or <i>P</i> dimension processes, then the total allreduce size is <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>V</mi><mi>D</mi></msub><mo>=</mo><mfrac><mrow><mi>W</mi><msub><mi>N</mi><mi>P</mi></msub></mrow><mrow><mi>O</mi><mi>P</mi></mrow></mfrac></mrow></math></span>. The reduction happens once at the end of each iteration after processing a full minibatch and draining the pipeline. It can be overlapped per layer using nonblocking allreduce.<a class="reference-link xref xref-bibr" href="#bib13" data-jats-ref-type="bibr" data-jats-rid="bib13"><sup>13</sup></a></p></section><section id="sec26" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Pipeline dimension.</strong> If we only have pipeline parallelism (<i>D</i> = <i>O</i> = 1) and NA output activations at the cut layer then each process sends all <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mfrac><mi>M</mi><mi>P</mi></mfrac><msub><mi>N</mi><mi>A</mi></msub></mrow></math></span> output values to the next process in the forward pass and the same volume of errors during the backward pass. If the layer and its inputs and outputs are distributed to <i>O</i> PEs, then the total send volume in this dimension is <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>V</mi><mi>P</mi></msub><mo>=</mo><mfrac><mrow><mi>M</mi><mi>W</mi><msub><mi>N</mi><mi>A</mi></msub></mrow><mrow><mi>D</mi><mi>P</mi><mi>O</mi></mrow></mfrac></mrow></math></span>. This communication can be hidden at each accelerator as shown in Figure <a class="xref xref-fig" href="#F9" data-jats-ref-type="fig" data-jats-rid="F9">9</a> by overlapping nonblocking send/receive operations (bottom, blue) with operator computation (top, green).</p><figure id="F9" class="fig" data-jats-position="float"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig09.jpg" data-type="image" data-caption="Figure 9. " href="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig09.jpg">
				<img decoding="async" class="graphic" title="Figure 9. " src="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig09.jpg" alt="" data-image-id="F9" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 9.</span> <span class="p">Overlap in pipelined-parallel execution</span><div class="figcaption-footer"></div></figcaption></figure></section><section id="sec27" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Operator dimension.</strong> For operator parallelism, each process send volume depends only on the operator parallelization itself and is not influenced by either <i>D</i> or <i>P</i>. The operator can be seen as the innermost loop in this sense. Each operator distribution scheme will have its own characteristics that we capture by <i>V<sub>O</sub></i> = <i>WN<sub>O</sub></i>. The operator communication volume during each forward and backward pass is a function of the local minibatch size <i>M/DP</i> per process.</p></section></section><section id="sec28" class="sec"><h4 class="heading"><em><span class="caption-label">4.2.2</span>DLRM.</em></h4><p id="p-69">DLRM<a class="reference-link xref xref-bibr" href="#bib20" data-jats-ref-type="bibr" data-jats-rid="bib20"><sup>20</sup></a> uses a combination of model parallelism and data parallelism for its embedding and MLP layers, respectively. Two alltoall operations aggregate sparse embedding lookups in the forward pass, and their corresponding gradients in backward pass. Allreduce is required to synchronize the gradients of the data-parallel MLP layers. The parallelism of DLRM is limited by both the mini-batch size and the embedding dimension. DLRM is trained with up to 128 GPU nodes. The total runtimes on the fat tree variants are 2.96 ms, 2.97 ms, and 2.99 ms, respectively. On torus, the code executes for 3.12 ms. HyperX is at 2.94 ms. Hx2Mesh and Hx4Mesh are at 2.97 ms and 3.00 ms, respectively. On A100, DLRM computes around 95 us, 209 us, and 796 us for the embedding, feature interaction, and MLP layers respectively, and communicates 1 MB per alltoall and 2.96 MB per allreduce.</p></section><section id="sec29" class="sec"><h4 class="heading"><span class="caption-label">4.2.3</span>Transformers</h4><p id="p-70">Transformers are the most communication intensive.<a class="reference-link xref xref-bibr" href="#bib14" data-jats-ref-type="bibr" data-jats-rid="bib14"><sup>14</sup></a> A transformer block consists of multi-head attention (MHA) and two feed-forward (FF) layers. The MHA and FF input/outputs are of size (embedding dimensionbatchsequence length). For example, GPT-3s<a class="reference-link xref xref-bibr" href="#bib7" data-jats-ref-type="bibr" data-jats-rid="bib7"><sup>7</sup></a> feed forward layers multiply 49,15212,288 with 12,2882,048 matrices per example in each layer.</p><p id="p-71">GPT-3 has a total of 96 layers and each layer has activations of size <i>N<sub>A</sub></i> = 4  2,048  12, 288  100MB per example as input and output. We choose <i>P</i> = 96, such that each pipeline stage processes one layer, and no data parallelism (<i>D</i> = 1). For operator parallelism, we use <i>O</i> = 4 and the scheme outlined by Megatron-LM,<a class="reference-link xref xref-bibr" href="#bib24" data-jats-ref-type="bibr" data-jats-rid="bib24"><sup>24</sup></a> which performs one allreduce for FF and one for MHA in both the forward and backward passes.</p><p id="p-72">All operations are the same size as the layer input/output. Thus, the volume for both pipeline communication and operator-dimension allreduce is <i>N<sub>A</sub></i> per example for forward and backward passes. One iteration of GPT-3 computes for 31.8ms. The total runtimes on the three fat tree variants are 34.8ms, 36.4ms, and 37.5ms, respectively. On torus, the code executes for 72.2 ms per iteration. HyperX is at 40.9ms. Hx2 and Hx4Mesh are at 41.7ms and 49.9ms, respectively.</p><p id="p-73">For GPT-3 with Mixture-of-Experts (MoEs),<a class="reference-link xref xref-bibr" href="#bib18" data-jats-ref-type="bibr" data-jats-rid="bib18"><sup>18</sup></a> we use 16 experts. In GPT-3, the FFs have 1.8<i>B</i> parameters. Therefore, each expert has 1.8<i>B</i>/16  113M parameters. MoEs perform two alltoalls for FF in both the forward and backward passes, and all operations are the same size as the input/output. The computation time on an A100 is 49.9ms. The total runtime on the fat trees varies from 52.2ms to 52.9 ms depending on tapering. On torus, the code executes for 73.8ms per iteration. HyperX takes 53.9ms while Hx2 and Hx4Mesh are at 58.3ms and 63.3ms, respectively.</p><p id="p-74">Figure <a class="xref xref-fig" href="#F10" data-jats-ref-type="fig" data-jats-rid="F10">10</a> shows the relative cost savings of HxMesh compared to other topologies. These are calculated as the ratio of the network costs in Section <a class="xref xref-sec" href="#sec2" data-jats-ref-type="sec" data-jats-rid="sec2">2</a> times the inverse of the ratio of communication overheads presented in this section.</p><figure id="F10" class="fig" data-jats-position="float"><div class="image-container">
			<a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig10.jpg" data-type="image" data-caption="Figure 10. " href="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig10.jpg">
				<img decoding="async" class="graphic" title="Figure 10. " src="https://cacm.acm.org/wp-content/uploads/2024/03/3623490_fig10.jpg" alt="" data-image-id="F10" data-image-type="figure" />
			</a>
		</div><figcaption><span class="caption-label">Figure 10.</span> <span class="p">HxMesh cost savings relative to other topologies.</span><div class="figcaption-footer"></div></figcaption></figure><p id="p-76">We conclude that both Hx2 and Hx4Mesh significantly reduce network costs for DNN workloads. While some torus network configurations can be cheaper than Hx2Mesh, they provide significantly less allocation and management flexibility, especially in the presence of failures. Moreover, we also conclude that even in the presence of alltoall communications patterns in GPT-3 MoE and DLRM HxMesh topologies still offer a significant cost advantage compared to traditional topologies. As the scale of the network increases, Hx4Mesh becomes significantly more cost efficient than Hx2Mesh especially in the presence of alltoall traffic.</p><p id="p-77" data-jats-content-type="noindent"><b>Discussion:</b> We cover all additional related work and comparisons to other topologies, as well as significantly more detail on HammingMesh configuration options, tapering, diameter, cost, routing and deadlock avoidance, as well as scheduling with and without board failures in the full version of this paper.<a class="reference-link xref xref-bibr" href="#bib10" data-jats-ref-type="bibr" data-jats-rid="bib10"><sup>10</sup></a></p></section></section></section><section id="sec30" class="sec"><h2 class="heading"><span class="caption-label">5</span>Conclusions</h2><p id="p-78">HammingMesh is optimized specifically for machine learning workloads and their communication patterns. It relies on the observation that deep learning training uses three-dimensional communication patterns and rarely needs global bandwidth. It supports extreme local bandwidth while controlling the cost of global bandwidth. It banks on an inexpensive local PCB-mesh interconnect together with a workload-optimized global connectivity forming virtual torus networks at adjustable global bandwidth.</p><p id="p-79">Due to the lower number of switches and external cables, it can be nearly always more cost effective than torus networks while also offering higher global bandwidth and significantly higher flexibility in job allocation and dealing with failures.</p><p id="p-80">All-in-all, we believe that HammingMesh will drive future deep learning systems and will also support adjacent workloads, such as (multi)linear algebra, quantum simulation, or parallel solvers, that have Cartesian communication patterns.</p></section><section id="sec31" class="sec"><h2 class="heading"><span class="caption-label">6</span>Acknowledgment</h2><p id="p-81">We thank Microsoft for hosting THs sabbatical where much of the idea was developed.<a class="reference-link xref xref-bibr" href="#bib11" data-jats-ref-type="bibr" data-jats-rid="bib11"><sup>11</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#bib12" data-jats-ref-type="bibr" data-jats-rid="bib12"><sup>12</sup></a> We thank the whole Azure Hardware Architecture team and especially Doug Burger for their continued support and deep technical discussions. We thank the Swiss National Supercomputing Center (CSCS) for the compute resources on Piz Daint and the Slim Fly cluster (thanks to Hussein Harake) to run the simulations. Daniele De Sensi is supported by an ETH Post-doctoral Fellowship (19-2 FEL-50).</p></section></div><footer class="back"></footer></article>
</div>
		</div>
		<footer class="article-footer">
			
<section class="article-references" data-component="accordion" data-slide-to-refs="true">
	<a name="references"></a>
	<button class="accordion-controller" aria-expanded="false">
		<span class="article-references__title">
			References		</span>
		<span class="accordion-controller-icon">
			<svg aria-hidden="true" focusable="false" width="16" height="16" fill="var(--wp--preset--color--cacm-blue)"><use href="#am-symbol-icon-chevron-down"></use></svg>		</span>
	</button>
	<ul class="article-references__text accordion-content">
		<section id="references" class="ref-list-container">
<h2 class="heading">References</h2>
<ul id="reflist1" class="ref-list">
<li class="ref">
<div id="bib1" class="citation"><span class="label">1.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Adalsteinsson</span>, <span class="given-names">H. </span></span><span class="etal">et al.</span> </span><span class="article-title">A simulator for large-scale parallel computer architectures</span>. <span class="source"><em>Int. J. Distrib. Syst. Technol.</em></span><em><span class="volume">1</span></em>, <span class="issue">2</span> (<span class="year">Apr. 2010</span>), <span class="fpage">5773</span>.</span></div>
</li>
<li class="ref">
<div id="bib2" class="citation"><span class="label">2.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Alistarh</span>, <span class="given-names">D. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">The convergence of sparsified gradient methods</span>. <span class="source"><em>Advances in Neural Information Processing Systems</em> <em>31</em></span>. <span class="publisher-name">Curran Associates, Inc.</span>, <span class="year">Dec. 2018</span>.</span></div>
</li>
<li class="ref">
<div id="bib3" class="citation"><span class="label">3.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Bae</span>, <span class="given-names">M.M.</span></span>, <span class="string-name"><span class="surname">AlBdaiwi</span>, <span class="given-names">B.F.</span></span>, and <span class="string-name"><span class="surname">Bose</span>, <span class="given-names">B.</span></span> </span><span class="article-title">Edge-disjoint Hamiltonian cycles in two-dimensional torus</span>. <span class="source"><em>Int. J. Math. Math. Sci.</em></span><em><span class="issue">25</span></em> (<span class="year">2004</span>), <span class="fpage">1299</span><span class="lpage">1308</span>.</span></div>
</li>
<li class="ref">
<div id="bib4" class="citation"><span class="label">4.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Barnett</span>, <span class="given-names">M.</span></span>, <span class="string-name"><span class="surname">Littlefield</span>, <span class="given-names">R.</span></span>, <span class="string-name"><span class="surname">Payne</span>, <span class="given-names">D.</span></span>, and <span class="string-name"><span class="surname">Vandegeijn</span>, <span class="given-names">R.</span></span> </span><span class="article-title">Global combine algorithms for 2-d meshes with wormhole routing</span>. <span class="source"><em>J. Parallel Distrib. Comput.</em></span><em><span class="volume">24</span></em>, <span class="issue">2</span> (<span class="year">Feb. 1995</span>), <span class="fpage">191201</span>.</span></div>
</li>
<li class="ref">
<div id="bib5" class="citation"><span class="label">5.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Ben-Nun</span>, <span class="given-names">T.</span></span> and <span class="string-name"><span class="surname">Hoefler</span>, <span class="given-names">T.</span></span> </span><span class="article-title">Demystifying parallel and distributed deep learning: An in-depth concurrency analysis</span>. <span class="source"><em>ACM Comput. Surv.</em></span><em><span class="volume">52</span></em>, <span class="issue">4</span> (<span class="year">Aug. 2019</span>), <span class="fpage">65:1</span><span class="lpage">65:43</span>.</span></div>
</li>
<li class="ref">
<div id="bib6" class="citation"><span class="label">6.</span> <span class="mixed-citation" data-jats-publication-type="other"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Besta</span>, <span class="given-names">M.</span></span> and <span class="string-name"><span class="surname">Hoefler</span>, <span class="given-names">T.</span></span> </span><span class="article-title">Slim fly: A cost effective low-diameter network topology</span>. In <span class="source"><em>Proceedings of the Intern. Conf. On High Performance Computing, Networking, Storage and Analysis (SC14)</em></span>, <span class="year">Nov. 2014</span>.</span></div>
</li>
<li class="ref">
<div id="bib7" class="citation"><span class="label">7.</span> <span class="mixed-citation" data-jats-publication-type="other"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Brown</span>, <span class="given-names">T.B. </span></span><span class="etal">et al.</span> </span><span class="source">Language Models Are Few-Shot Learners</span>, <span class="year">2020</span>.</span></div>
</li>
<li class="ref">
<div id="bib8" class="citation"><span class="label">8.</span> <span class="mixed-citation" data-jats-publication-type="other"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">De Sensi</span>, <span class="given-names">D. </span></span><span class="etal">et al.</span> </span><span class="article-title">An in-depth analysis of the slingshot interconnect</span>. In <span class="source"><em>Proceedings of the Intern. Conf. For High Performance Computing, Networking, Storage and Analysis (SC20)</em></span>, <span class="year">Nov. 2020</span>.</span></div>
</li>
<li class="ref">
<div id="bib9" class="citation"><span class="label">9.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Hoefler</span>, <span class="given-names">T. </span></span><span class="etal">et al.</span> </span><span class="article-title">Sparsity in deep learning: Pruning and growth for efficient inference and training in neural networks</span>. <span class="source"><em>J. of Machine Learning Research</em></span><em><span class="volume">22</span></em>, <span class="issue">241</span> (<span class="year">Sep. 2021</span>), <span class="fpage">1</span><span class="lpage">124</span>.</span></div>
</li>
<li class="ref">
<div id="bib10" class="citation"><span class="label">10.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Hoefler</span>, <span class="given-names">T. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">Hammingmesh: A network topology for large-scale deep learning</span>. In <span class="source"><em>Proceedings of the Intern. Conf. On High Performance Computing, Networking, Storage and Analysis, SC 22</em></span>. <span class="publisher-name">IEEE Press</span>, <span class="year">2022</span>.</span></div>
</li>
<li class="ref">
<div id="bib11" class="citation"><span class="label">11.</span> <span class="mixed-citation" data-jats-publication-type="other"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Hoefler</span>, <span class="given-names">T.</span></span>, <span class="string-name"><span class="surname">Heddes</span>, <span class="given-names">M.C.</span></span>, and <span class="string-name"><span class="surname">Belk</span>, <span class="given-names">J.R.</span></span> </span><span class="article-title">Distributed processing architecture</span>. <span class="source">US Patent US11076210B1</span>, <span class="year">Jul. 2021</span>.</span></div>
</li>
<li class="ref">
<div id="bib12" class="citation"><span class="label">12.</span> <span class="mixed-citation" data-jats-publication-type="other"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Hoefler</span>, <span class="given-names">T.</span></span>, <span class="string-name"><span class="surname">Heddes</span>, <span class="given-names">M.C.</span></span>, <span class="string-name"><span class="surname">Goel</span>, <span class="given-names">D.</span></span>, and <span class="string-name"><span class="surname">Belk</span>, <span class="given-names">J.R.</span></span> </span><span class="article-title">Distributed processing architecture</span>. <span class="source">US Patent US20210209460A1</span>, <span class="year">Jul. 2021</span>.</span></div>
</li>
<li class="ref">
<div id="bib13" class="citation"><span class="label">13.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Hoefler</span>, <span class="given-names">T.</span></span>, <span class="string-name"><span class="surname">Lumsdaine</span>, <span class="given-names">A.</span></span>, and <span class="string-name"><span class="surname">Rehm</span>, <span class="given-names">W.</span></span> </span><span class="chapter-title">Implementation and performance analysis of non-blocking collective operations for MPI</span>. In <span class="source"><em>Proceedings of the 2007 Intern. Conf. On High Performance Computing, Networking, Storage and Analysis, Sc07</em></span>. <span class="publisher-name">IEEE Computer Society/ACM</span>, <span class="year">Nov. 2007</span>.</span></div>
</li>
<li class="ref">
<div id="bib14" class="citation"><span class="label">14.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Ivanov</span>, <span class="given-names">A. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">Data movement is all you need: A case study on optimizing transformers</span>. In <span class="source"><em>Proceedings of Machine Learning and Systems</em> <em>3</em> (MLSys 2021)</span>, <span class="publisher-name">Apr. 2021</span>.</span></div>
</li>
<li class="ref">
<div id="bib15" class="citation"><span class="label">15.</span> <span class="mixed-citation" data-jats-publication-type="other"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Kaplan</span>, <span class="given-names">J. </span></span><span class="etal">et al.</span> </span><span class="source">Scaling Laws for Neural Language Models</span>, <span class="year">2020</span>.</span></div>
</li>
<li class="ref">
<div id="bib16" class="citation"><span class="label">16.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Kathareios</span>, <span class="given-names">G. </span></span><span class="etal">et al.</span> </span><span class="chapter-title">Cost-effective diametertwo topologies: Analysis and evaluation</span>. In <span class="source"><em>Proceedings of the Intern. Conf. For High Performance Computing, Networking, Storage and Analysis (SC15)</em></span>. <span class="publisher-name">ACM</span>, <span class="year">Nov. 2015</span>.</span></div>
</li>
<li class="ref">
<div id="bib17" class="citation"><span class="label">17.</span> <span class="mixed-citation" data-jats-publication-type="other"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Kim</span>, <span class="given-names">J.</span></span>, <span class="string-name"><span class="surname">Dally</span>, <span class="given-names">W.J.</span></span>, <span class="string-name"><span class="surname">Scott</span>, <span class="given-names">S.</span></span>, and <span class="string-name"><span class="surname">Abts</span>, <span class="given-names">D.</span></span> </span><span class="article-title">Technology-driven, highly-scalable dragonfly topology</span>. In <span class="source"><em>Proceedings of 2008 Intern. Symp. on Computer Architecture</em></span>, <span class="year">2008</span>, <span class="fpage">77</span><span class="lpage">88</span>.</span></div>
</li>
<li class="ref">
<div id="bib18" class="citation"><span class="label">18.</span> <span class="mixed-citation" data-jats-publication-type="other"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Lepikhin</span>, <span class="given-names">D. </span></span><span class="etal">et al</span></span>. <span class="source">Gshard: Scaling Giant Models with Conditional Computation and Automatic Sharding</span>, <span class="year">2020</span>.</span></div>
</li>
<li class="ref">
<div id="bib19" class="citation"><span class="label">19.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Li</span>, <span class="given-names">S.</span></span> and <span class="string-name"><span class="surname">Hoefler</span>, <span class="given-names">T.</span></span> </span><span class="chapter-title">Chimera: Efficiently training large-scale neural networks with bidirectional pipelines</span>. In <span class="source"><em>Proceedings of the Intern. Conf. for High Performance Computing, Networking, Storage and Analysis (SC21)</em></span>. <span class="publisher-name">ACM</span>, <span class="year">Nov. 2021</span>.</span></div>
</li>
<li class="ref">
<div id="bib20" class="citation"><span class="label">20.</span> <span class="mixed-citation" data-jats-publication-type="other"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Naumov</span>, <span class="given-names">M. </span></span><span class="etal">et al.</span> </span><span class="article-title">Deep learning recommendation model for personalization and recommendation systems</span>. <span class="source">Arxiv Preprint Arxiv:1906.00091</span>, <span class="year">2019</span>.</span></div>
</li>
<li class="ref">
<div id="bib21" class="citation"><span class="label">21.</span> <span class="mixed-citation" data-jats-publication-type="book"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Prisacari</span>, <span class="given-names">B.</span></span>, <span class="string-name"><span class="surname">Rodriguez</span>, <span class="given-names">G.</span></span>, <span class="string-name"><span class="surname">Minkenberg</span>, <span class="given-names">C.</span></span>, and <span class="string-name"><span class="surname">Hoefler</span>, <span class="given-names">T.</span></span> </span><span class="chapter-title">Bandwidth-optimal all-to-all exchanges in fat tree networks</span>. In <span class="source"><em>Proceedings of the 27th Intern. ACM Conf. on Intern. Conf. on Supercomputing</em></span>. <span class="publisher-name">ACM</span>, <span class="year">Jun. 2013</span>, <span class="fpage">139</span><span class="lpage">148</span>.</span></div>
</li>
<li class="ref">
<div id="bib22" class="citation"><span class="label">22.</span> <span class="mixed-citation" data-jats-publication-type="other"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Renggli</span>, <span class="given-names">C.</span></span>, <span class="string-name"><span class="surname">Alistarh</span>, <span class="given-names">D.</span></span>, <span class="string-name"><span class="surname">Aghagolzadeh</span>, <span class="given-names">M.</span></span>, and <span class="string-name"><span class="surname">Hoefler</span>, <span class="given-names">T.</span></span> </span><span class="article-title">SparCML: High-performance sparse communication for machine learning</span>. In <em><span class="source">Proceedings of the Intern. Conf. for High Performance Computing, Networking, Storage and Analysis (SC19)</span></em>, <span class="year">Nov. 2019</span>.</span></div>
</li>
<li class="ref">
<div id="bib23" class="citation"><span class="label">23.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Sack</span>, <span class="given-names">P.</span></span> and <span class="string-name"><span class="surname">Gropp</span>, <span class="given-names">W.</span></span> </span><span class="article-title">Collective algorithms for multiported torus networks</span>. <span class="source"><em>ACM Trans. Parallel Comput.</em></span><em><span class="volume">1</span></em>, <span class="issue">2</span> (<span class="year">Feb. 2015</span>).</span></div>
</li>
<li class="ref">
<div id="bib24" class="citation"><span class="label">24.</span> <span class="mixed-citation" data-jats-publication-type="other"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Shoeybi</span>, <span class="given-names">M. </span></span><span class="etal">et al.</span> </span><span class="source">Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</span>, <span class="year">2020</span>.</span></div>
</li>
<li class="ref">
<div id="bib25" class="citation"><span class="label">25.</span> <span class="mixed-citation" data-jats-publication-type="journal"><span class="person-group" data-jats-person-group-type="author"><span class="string-name"><span class="surname">Thakur</span>, <span class="given-names">R.</span></span>, <span class="string-name"><span class="surname">Rabenseifner</span>, <span class="given-names">R.</span></span>, and <span class="string-name"><span class="surname">Gropp</span>, <span class="given-names">W.</span></span> </span><span class="article-title">Optimization of collective communication operations in MPICH</span>. <span class="source"><em>Int. J. High Perform. Comput. Appl.</em></span><em><span class="volume">19</span></em>, <span class="issue">1</span> (<span class="year">Feb. 2005</span>), <span class="fpage">4966</span>.</span></div>
</li>
</ul>
</section>
	</ul>
</section>

<section class="article-footnotes" data-component="accordion" data-slide-to-refs="true">
	<a name="footnotes"></a>
	<button class="accordion-controller" aria-expanded="false">
		<span class="article-footnotes__title">
			Footnotes		</span>
		<span class="accordion-controller-icon">
			<svg aria-hidden="true" focusable="false" width="16" height="16" fill="var(--wp--preset--color--cacm-blue)"><use href="#am-symbol-icon-chevron-down"></use></svg>		</span>
	</button>
	<ul class="article-footnotes__text accordion-content">
		<section id="footnotes" class="fn-group-container">
<ul class="fn-group" data-jats-content-type="footnotes">
<li id="fn1" class="fn"><a class="article-label">a</a> <span class="p">The name <span class="italic">HammingMesh</span> is inspired by the structural similarity to 2D Hamming Graphs with Meshes as vertices.</span></li>
<li id="fn2" class="fn"><a class="article-label">b</a> <span class="p">Note that a 2D HyperX is identical to an Hx1Mesh</span></li>
<li id="fn3" class="fn"><a class="article-label">c</a> <span class="p">We define with <span class="italic"></span> the latency and with <span class="italic"></span> the inverse of the bandwidth. With , we omit additive constants and minor lower-order terms for clarity.</span></li>
<li id="fn4" class="fn"><a class="article-label">d</a> <span class="p">Compared to the original version of this paper,<a class="reference-link xref xref-bibr" href="#bib10" data-jats-ref-type="bibr" data-jats-rid="bib10"><span class="sup">10</span></a> we replaced the torus algorithm with the better bucket algorithm.</span></li>
</ul>
</section>
	</ul>
</section>
<section id="authors" class="article-authors" data-component="accordion">
	<button class="accordion-controller" aria-expanded="false">
		<span class="article-authors__title">
			About the Authors		</span>
		<span class="accordion-controller-icon">
			<svg aria-hidden="true" focusable="false" width="16" height="16" fill="var(--wp--preset--color--cacm-blue)"><use href="#am-symbol-icon-chevron-down"></use></svg>		</span>
	</button>
	<div class="article-authors__info accordion-content">
		<div class="article-authors__info-text">
			<section id="sec32" class="biography">
<p id="p-1"><b>Torsten Hoefler</b> (torsten.hoefler@inf.ethz.ch) ETH Zurich, Switzerland, Microsoft, Corp.</p>
<p id="p-2"><b>Tommaso Bonato</b> (tommaso.bonato@inf.ethz.ch) ETH Zurich, Switzerland.</p>
<p id="p-3"><b>Daniel De Sensi</b> (daniele.desensi@inf.ethz.ch) ETH Zurich, Switzerland.</p>
<p id="p-4"><b>Salvatore Di Girolamo</b> (salvatore.digirolamo@inf.ethz.ch) ETH Zurich, Switzerland.</p>
<p id="p-5"><b>Shigang Li</b> (shigang.li@inf.ethz.ch) ETH Zurich, Switzerland.</p>
<p id="p-6"><b>Marco Heddes</b> (marco.heddes@microsoft.com) Microsoft, Redmond, WA, USA.</p>
<p id="p-7"><b>Deepak Goel</b> (deepak.goel@microsoft.com) Microsoft, Sunnyvale, CA, USA.</p>
<p id="p-8"><b>Miguel Castro</b> (miguel.castr@microsoft.com) Microsoft, Cambridge, MA, USA.</p>
<p id="p-9"><b>Steve Scott</b> (steve.scott@microsoft.com) Microsoft, Redmond, WA, USA.</p>
</section>
		</div>
	</div>
</section>

<ul class="share">
	
<li class="share-link" data-component="share">
	<a href="#" class="share-toggle">
		<svg aria-hidden="true" focusable="false" width="19" height="18" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-share"></use></svg>		<span class="share-link-text">
			Share		</span>
	</a>
	<ul class="share-menu" aria-hidden="true">
		<li>
			<a href="https://twitter.com/intent/tweet?url=https://cacm.acm.org/research-highlights/hammingmesh-a-network-topology-for-large-scale-deep-learning/&#038;text=HammingMesh:%20A%20Network%20Topology%20for%20Large-Scale%20Deep%20Learning" target="_blank">
				Twitter			</a>
		</li>
		<li>
			<a href="http://www.reddit.com/submit?url=https://cacm.acm.org/research-highlights/hammingmesh-a-network-topology-for-large-scale-deep-learning/&#038;title=HammingMesh:%20A%20Network%20Topology%20for%20Large-Scale%20Deep%20Learning" target="_blank">
				Reddit			</a>
		</li>
		<li>
			<a href="https://news.ycombinator.com/submitlink?u=https://cacm.acm.org/research-highlights/hammingmesh-a-network-topology-for-large-scale-deep-learning/&#038;t=HammingMesh:%20A%20Network%20Topology%20for%20Large-Scale%20Deep%20Learning" target="_blank">
				Hacker News			</a>
		</li>
	</ul>
</li>
			
<li class="share-link share-link-pdf">
	<a href="https://dl.acm.org/doi/pdf/10.1145/3623490" target="_blank">
		<svg aria-hidden="true" focusable="false" width="19" height="20" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-pdf-download"></use></svg>		<span class="share-link-text">
			Download PDF		</span>
	</a>
</li>
		
<li class="share-link share-link-print" data-component="print">
	<a href="#" class="print">
		<svg aria-hidden="true" focusable="false" width="19" height="20" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-print"></use></svg>		<span class="share-link-text">
			Print		</span>
	</a>
</li>
		
	<li class="share-link share-link-discussion" data-component="share">
		<a class="share-link-comments" href="#comments">
			<svg aria-hidden="true" focusable="false" width="19" height="20" fill="var(--cacm--symbol--fill)"><use href="#am-symbol-icon-comment"></use></svg>			<span class="share-link-text">Join the Discussion</span>
		</a>
	</li>
	</ul>
		</footer>
		<div class="article-authors-digital-library">
			<section class="article-submission">
	<div class="article-submission__cta">
		<div class="article-submission__cta-container">
			<p class="article-submission__cta-title">
				Submit an Article to CACM			</p>
			<p class="article-submission__cta-text">
				CACM welcomes unsolicited <a href="https://cacm.acm.org/author-guidelines/#CACMsubmission">submissions</a> on topics of relevance and value to the computing community.			</p>
		</div>
	</div>
</section>

<section class="article-digital-library">
	<div class="article-digital-library__article-info">
		<p class="article-digital-library__intro-text">
			You Just Read		</p>
		<h4 class="article-digital-library__title">
			HammingMesh: A Network Topology for Large-Scale Deep Learning		</h4>
					<a class="article-digital-library__link" href="https://dl.acm.org/doi/10.1145/3623490">
				<svg aria-hidden="true" focusable="false" width="21" height="21" fill="var(--wp--preset--color--cacm-black)"><use href="#am-symbol-icon-digital-library"></use></svg>				View in the ACM Digital Library				<svg aria-hidden="true" focusable="false" width="14" height="9" fill="var(--wp--preset--color--cacm-black)" class="icon-dl"><use href="#am-symbol-icon-arrow-right"></use></svg>			</a>
			</div>
	<div class="article-digital-library__copyright-info">
		<p> 2024 Copyright held by owner/author. Publication rights licensed to ACM.</p>
			</div>
</section>
		</div>
		<div class="article-sidebar">
			<section class="article-doi">
	<h3 class="article-doi__heading">DOI</h3>
	10.1145/3623490</section>
<section class="article-issue">
	<div class="article-issue__meta">
		<h3 class="article-issue__heading">December 2024 Issue</h3>
							<p class="article-issue__vol-info">Vol. 67 No. 12</p>
							<p class="article-issue__page-info">Pages: 97-105</p>
			</div>
			<a href="https://cacm.acm.org/issue/december-2024/" class="article-issue__toc-link">
			Table of Contents			<span class="article-issue__toc-icon-arrow"><svg aria-hidden="true" focusable="false" width="14" height="9" fill="var(--wp--preset--color--cacm-blue)"><use href="#am-symbol-icon-arrow-right"></use></svg></span>
		</a>
	</section>

<section class="article-related">
	<div class="article-related-content">
		<h3 class="article-related__heading">Related Reading</h3>
		<!-- Related reading post list -->
		<ul>
							<li class="article-related-item">
					<p class="article-related-section">
						<a href="https://cacm.acm.org/section/research-highlights/">Research Highlights</a>					</p>
					<p class="article-related-title">
						<a href="https://cacm.acm.org/research-highlights/technical-perspective-mirror-mirror-on-the-wall-what-is-the-best-topology-of-them-all/">
							Technical Perspective: Mirror, Mirror on the Wall, What Is the Best Topology of Them All?						</a>
					</p>
					<p class="article-related-topic">
						<a href="https://cacm.acm.org/category/architecture-and-hardware/">Architecture and Hardware</a>					</p>
				</li>
					</ul>
	</div>
</section>

<div class="ad ad-mobile ad--is-loading" data-component="ad" data-platform="mobile" data-show-ad="false">
		<div class="cacm-ad-unit">
		<p class="ad-label">Advertisement</p>
		<div class="ad-unit" data-pipeline-id="684700" data-dimension-id="599027"></div>
		<noscript><a href="https://acm.nui.media/pipeline/684700/0/cc?z=acm"><img src="https://acm.nui.media/pipeline/684700/0/vc?z=acm&#038;dim=599027&#038;kw=&#038;click=&#038;abr=$imginiframe" alt="" ></a></noscript>
	</div>
	</div>

<div class="ad ad-desktop ad--is-loading" data-component="ad" data-platform="desktop" data-show-ad="false">
		<div class="cacm-ad-unit">
		<p class="ad-label">Advertisement</p>
		<div class="ad-unit" data-pipeline-id="684700" data-dimension-id="599027"></div>
		<noscript><a href="https://acm.nui.media/pipeline/684700/0/cc?z=acm"><img src="https://acm.nui.media/pipeline/684700/0/vc?z=acm&#038;dim=599027&#038;kw=&#038;click=&#038;abr=$imginiframe" alt="" ></a></noscript>
	</div>
	</div>
		</div>
		
<section class="article-comments">
	<div class="article-comments__inner container">
		<h3 class="article-comments__heading">
			Join the Discussion (0)		</h3>
		
<section class="cta-join-the-discussion" id="article-discussion">
	<div class="cta-join-the-discussion__box">
		<h4 class="cta-join-the-discussion__heading">Become a Member or Sign In to Post a Comment</h4>
		<div class="cta-join-the-discussion__button-group">
			<a class="cta-join-the-discussion__button cta-join-the-discussion__button--login" href="https://cacm.acm.org/wp-login.php?saml_sso">Sign In</a>
			<a class="cta-join-the-discussion__button cta-join-the-discussion__button--signup" href="https://accounts.acm.org/">Sign Up</a>
		</div>
	</div>
</section>
		
<div id="comments" class="comments-area">

	
		<div id="respond" class="auth-comment-form" data-component="authCommentForm" data-replytocom="0">
		<div class="auth-comment-form__contents">
			<span class="auth-comment-form__loader">
				<svg version="1.1" id="L9" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 100 100" enable-background="new 0 0 0 0" xml:space="preserve">
					<path fill="var(--wp--preset--color--cacm-blue)" d="M73,50c0-12.7-10.3-23-23-23S27,37.3,27,50 M30.9,50c0-10.5,8.5-19.1,19.1-19.1S69.1,39.5,69.1,50">
						<animateTransform
							attributeName="transform"
							attributeType="XML"
							type="rotate"
							dur="1s"
							from="0 50 50"
							to="360 50 50"
							repeatCount="indefinite" />
					</path>
				</svg>
			</span>
		</div>
	</div>

</div><!-- #comments -->
	</div>
</section>

		<section
			class="post-list the-latest"
			data-layout="grid-three-up"
			data-component="postList"
		>
							
		<header class="section-header ">
			<h3				class="section-header__heading"
			>
									<a class="section-header__heading-link" href="/?s=">
						The Latest from CACM					</a>
							</h3>
							<div class="section-header__readmore">
					<a class="section-header__readmore-link" href="/?s=" aria-label="
						Explore more from The Latest from CACM					">
						<span class="section-header__readmore-text">Explore More</span>
						<span class="section-header__readmore-icon"><svg aria-hidden="true" focusable="false" width="14" height="9"><use href="#am-symbol-icon-arrow-right"></use></svg></span>
					</a>
				</div>
								</header>

					
			<div class="">
				<div class="post-list__content"><div class="post-list__item">
	<article id="post-762756" class="post-list__post post-762756 post type-post status-publish format-standard has-post-thumbnail hentry category-education section-blogcacm">
		<div class="post-list__post-content">
			<div class="post-list__post-text">
									<div class="post-list__post-eyebrow">
						<a href="https://cacm.acm.org/section/blogcacm/">BLOG@CACM</a>																			<span class="post-list__post-timestamp"><span class="posted-on"> Nov 26 2024</span></span>
																	</div>
													<p class="post-list__post-heading">
						<a href="https://cacm.acm.org/blogcacm/heutagogy-in-computer-science-education/">Heutagogy in Computer Science Education</a>
					</p>
												<div class="post-list__post-meta-group">
											<div class="post-list__post-byline">
							 <a href="https://cacm.acm.org/author/orit-hazzan/" title="Posts by Orit Hazzan" class="author url fn" rel="author">Orit Hazzan</a>						</div>
																<span class="post-list__post-topic"><a href="https://cacm.acm.org/category/education/">Education</a></span>
									</div>
			</div>
							<figure class="post-list__post-figure">
					<a href="https://cacm.acm.org/blogcacm/heutagogy-in-computer-science-education/" aria-label="Heutagogy in Computer Science Education" aria-hidden="true" tabindex="-1">
													<div class="image-wrapper image-wrapper--widescreen"><img width="1024" height="576" src="https://cacm.acm.org/wp-content/uploads/2024/11/112224.BLOG_.Heutagogy-G.jpg" class="attachment-full size-full" alt="lower legs climbing colorful stairs" decoding="async" loading="lazy" srcset="https://cacm.acm.org/wp-content/uploads/2024/11/112224.BLOG_.Heutagogy-G.jpg 2400w, https://cacm.acm.org/wp-content/uploads/2024/11/112224.BLOG_.Heutagogy-G.jpg?resize=300,169 300w, https://cacm.acm.org/wp-content/uploads/2024/11/112224.BLOG_.Heutagogy-G.jpg?resize=768,432 768w, https://cacm.acm.org/wp-content/uploads/2024/11/112224.BLOG_.Heutagogy-G.jpg?resize=1024,576 1024w, https://cacm.acm.org/wp-content/uploads/2024/11/112224.BLOG_.Heutagogy-G.jpg?resize=1536,864 1536w, https://cacm.acm.org/wp-content/uploads/2024/11/112224.BLOG_.Heutagogy-G.jpg?resize=2048,1152 2048w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></div>											</a>
				</figure>
					</div>
	</article>
</div>

<div class="post-list__item">
	<article id="post-762751" class="post-list__post post-762751 post type-post status-publish format-standard has-post-thumbnail hentry category-security-and-privacy category-systems-and-networking section-news">
		<div class="post-list__post-content">
			<div class="post-list__post-text">
									<div class="post-list__post-eyebrow">
						<a href="https://cacm.acm.org/section/news/">News</a>																			<span class="post-list__post-timestamp"><span class="posted-on"> Nov 25 2024</span></span>
																	</div>
													<p class="post-list__post-heading">
						<a href="https://cacm.acm.org/news/email-insecurity/">Email Insecurity</a>
					</p>
												<div class="post-list__post-meta-group">
											<div class="post-list__post-byline">
							 <a href="https://cacm.acm.org/author/david-geer/" title="Posts by David Geer" class="author url fn" rel="author">David Geer</a>						</div>
																<span class="post-list__post-topic"><a href="https://cacm.acm.org/category/security-and-privacy/">Security and Privacy</a></span>
									</div>
			</div>
							<figure class="post-list__post-figure">
					<a href="https://cacm.acm.org/news/email-insecurity/" aria-label="Email Insecurity" aria-hidden="true" tabindex="-1">
													<div class="image-wrapper image-wrapper--widescreen"><img width="1024" height="576" src="https://cacm.acm.org/wp-content/uploads/2024/11/112024.News_.Email-Insecurity-S.jpg" class="attachment-full size-full" alt="U.S. Capitol building seen through a pair of open doors" decoding="async" loading="lazy" srcset="https://cacm.acm.org/wp-content/uploads/2024/11/112024.News_.Email-Insecurity-S.jpg 2400w, https://cacm.acm.org/wp-content/uploads/2024/11/112024.News_.Email-Insecurity-S.jpg?resize=300,169 300w, https://cacm.acm.org/wp-content/uploads/2024/11/112024.News_.Email-Insecurity-S.jpg?resize=768,432 768w, https://cacm.acm.org/wp-content/uploads/2024/11/112024.News_.Email-Insecurity-S.jpg?resize=1024,576 1024w, https://cacm.acm.org/wp-content/uploads/2024/11/112024.News_.Email-Insecurity-S.jpg?resize=1536,864 1536w, https://cacm.acm.org/wp-content/uploads/2024/11/112024.News_.Email-Insecurity-S.jpg?resize=2048,1152 2048w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></div>											</a>
				</figure>
					</div>
	</article>
</div>

<div class="post-list__item">
	<article id="post-762633" class="post-list__post post-762633 post type-post status-publish format-standard has-post-thumbnail hentry category-artificial-intelligence-machine-learning category-security-and-privacy section-news">
		<div class="post-list__post-content">
			<div class="post-list__post-text">
									<div class="post-list__post-eyebrow">
						<a href="https://cacm.acm.org/section/news/">News</a>																			<span class="post-list__post-timestamp"><span class="posted-on"> Nov 21 2024</span></span>
																	</div>
													<p class="post-list__post-heading">
						<a href="https://cacm.acm.org/news/detecting-explaining-industrial-hacks/">Detecting/Explaining Industrial Hacks</a>
					</p>
												<div class="post-list__post-meta-group">
											<div class="post-list__post-byline">
							 <a href="https://cacm.acm.org/author/r-colin-johnson/" title="Posts by R. Colin Johnson" class="author url fn" rel="author">R. Colin Johnson</a>						</div>
																<span class="post-list__post-topic"><a href="https://cacm.acm.org/category/artificial-intelligence-machine-learning/">Artificial Intelligence and Machine Learning</a></span>
									</div>
			</div>
							<figure class="post-list__post-figure">
					<a href="https://cacm.acm.org/news/detecting-explaining-industrial-hacks/" aria-label="Detecting/Explaining Industrial Hacks" aria-hidden="true" tabindex="-1">
													<div class="image-wrapper image-wrapper--widescreen"><img width="1024" height="576" src="https://cacm.acm.org/wp-content/uploads/2024/11/112024.News_.Detecting-Explaining-S.jpg" class="attachment-full size-full" alt="crack with light effect, illustration" decoding="async" loading="lazy" srcset="https://cacm.acm.org/wp-content/uploads/2024/11/112024.News_.Detecting-Explaining-S.jpg 2400w, https://cacm.acm.org/wp-content/uploads/2024/11/112024.News_.Detecting-Explaining-S.jpg?resize=300,169 300w, https://cacm.acm.org/wp-content/uploads/2024/11/112024.News_.Detecting-Explaining-S.jpg?resize=768,432 768w, https://cacm.acm.org/wp-content/uploads/2024/11/112024.News_.Detecting-Explaining-S.jpg?resize=1024,576 1024w, https://cacm.acm.org/wp-content/uploads/2024/11/112024.News_.Detecting-Explaining-S.jpg?resize=1536,864 1536w, https://cacm.acm.org/wp-content/uploads/2024/11/112024.News_.Detecting-Explaining-S.jpg?resize=2048,1152 2048w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /></div>											</a>
				</figure>
					</div>
	</article>
</div>

</div>			</div>

		</section>

		
<div class="cta-membership cta-membership--no-js" data-component="ctaMembership">
	
		<section class="cta-become-a-member">
			<div class="cta-become-a-member__inner container">
				<h3					class="cta-become-a-member__heading">
					Shape the Future of Computing				</h3>
									<p class="cta-become-a-member__description">
						ACM encourages its members to take a direct hand in shaping the future of the association. There are more ways than ever to get involved.					</p>
													<a class="cta-become-a-member__link" href="https://www.acm.org/about-acm/get-involved">
						Get Involved											</a>
							</div>
		</section>

		
		<section class="cta-open-access">
			<div class="cta-open-access__inner container">
				<h3					class="cta-open-access__heading">
					Communications of the ACM (CACM) is now a fully Open Access publication.				</h3>
									<p class="cta-open-access__description">
						By opening CACM to the world, we hope to increase engagement among the broader computer science community and encourage non-members to discover the rich resources ACM has to offer.					</p>
													<a class="cta-open-access__link" href="https://cacm.acm.org/news/cacm-is-becoming-open-access">
						Learn More											</a>
							</div>
		</section>

		</div>

	
</article><!-- #post-## -->

			</main>
		</div>
	</div><!-- #content -->

	<footer id="colophon" class="site-footer">
		<div class="site-footer__inner container">
			<div class="site-footer__columns">
				<div class="site-footer__column site-footer__column-branding">
					<a class="site-footer__logo" aria-label="Home" href="https://cacm.acm.org">
						<svg aria-hidden="true" focusable="false" width="548" height="88" fill="#FFF"><use href="#am-symbol-cacm-logo"></use></svg>					</a>
					<nav class="social-navigation">
		<ul class="social-navigation__list">
		<li>
			<a href="https://twitter.com/cacmmag">
				<span class="screen-reader-only">CACM on Twitter</span>
				<svg aria-hidden="true" focusable="false" width="38" height="38" fill="#fff"><use href="#am-symbol-icon-social-twitter"></use></svg>			</a>
		</li>
		<li>
			<a href="https://www.reddit.com/user/TheOfficialACM">
				<span class="screen-reader-only">CACM on Reddit</span>
				<svg aria-hidden="true" focusable="false" width="38" height="38" fill="#fff"><use href="#am-symbol-icon-social-reddit"></use></svg>			</a>
		</li>
		<li>
			<a href="https://www.linkedin.com/groups/36836/">
				<span class="screen-reader-only">CACM on LinkedIn</span>
				<svg aria-hidden="true" focusable="false" width="38" height="38" fill="#fff"><use href="#am-symbol-icon-social-linkedin"></use></svg>			</a>
		</li>
	</ul>
</nav>
				</div>
				<div class="site-footer__column site-footer__column-topics">
					
<div class="site-footer__topics-menu">
			<p class="site-footer__heading">
			Topics		</p>
		<ul class="site-footer__topics-menu__list">
												<li>
					<a href="https://cacm.acm.org/category/architecture-and-hardware/">
						Architecture and Hardware					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/artificial-intelligence-machine-learning/">
						Artificial Intelligence and Machine Learning					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/computer-history/">
						Computer History					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/computing-applications/">
						Computing Applications					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/computing-profession/">
						Computing Profession					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/data-and-information/">
						Data and Information					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/education/">
						Education					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/hci/">
						HCI					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/philosophy-of-computing/">
						Philosophy of Computing					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/security-and-privacy/">
						Security and Privacy					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/society/">
						Society					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/software-engineering-and-programming-languages/">
						Software Engineering and Programming Languages					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/systems-and-networking/">
						Systems and Networking					</a>
				</li>
															<li>
					<a href="https://cacm.acm.org/category/theory/">
						Theory					</a>
				</li>
							</ul>
	</div>
				</div>
				<div class="site-footer__column site-footer__column-about">
					<div class="site-footer__menu-magazine">
						<p class="site-footer__heading">Magazine</p>
						<ul id="menu-magazine-footer" class="site-footer__menu-magazine-menu"><li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-217988"><a href="/issue/latest/" id="menu-link-10">Latest Issue</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-217989"><a href="/issues/" id="menu-link-11">Magazine Archive</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224644"><a href="https://cacm.acm.org/editorial-staff-board/" id="menu-link-12">Editorial Staff and Board</a></li>
<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-751386"><a href="https://cacm.acm.org/author-guidelines#CACMsubmission" id="menu-link-13">Submit an Article</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224585"><a href="https://cacm.acm.org/feeds-2/" id="menu-link-14">Alerts &#038; Feeds</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224645"><a href="https://cacm.acm.org/author-guidelines/" id="menu-link-15">Author Guidelines</a></li>
</ul>					</div>
					<div class="site-footer__menu-communications">
						<p class="site-footer__heading">Communications of the ACM</p>
						<ul id="menu-communications-footer" class="site-footer-communications-menu"><li id="menu-item-224637" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224637"><a href="https://cacm.acm.org/about-us/" id="menu-link-16">About Us</a></li>
<li id="menu-item-224664" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224664"><a href="https://cacm.acm.org/faq/" id="menu-link-17">Frequently Asked Questions</a></li>
<li id="menu-item-224638" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224638"><a href="https://cacm.acm.org/contact-us/" id="menu-link-18">Contact Us</a></li>
<li id="menu-item-217972" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-217972"><a href="https://www.acm.org/publications/advertising" id="menu-link-19">For Advertisers</a></li>
<li id="menu-item-224639" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-224639"><a href="https://cacm.acm.org/join-acm/" id="menu-link-20">Join ACM</a></li>
</ul>					</div>
				</div>
			</div>
			<div class="site-footer__info">
				<div class="site-footer__info__inner">
					<p class="site-footer__info-copyright"><small>
						&copy; 2024 Communications of the ACM. All Rights Reserved. 						</small></p>
					<div class="menu-policy-menu-container"><ul id="menu-policy-footer" class="site-footer__info-policy-list"><li id="menu-item-217993" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-217993"><a href="https://www.acm.org/cookie-notice" id="menu-link-21">Cookie Notice</a></li>
<li id="menu-item-217994" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-217994"><a href="https://www.acm.org/about-acm/privacy-policy" id="menu-link-22">Privacy Policy</a></li>
</ul></div>				</div>
			</div>
		</div>
	</footer><!-- #colophon -->
</div><!-- #page -->

<script type="text/javascript" src="https://cacm.acm.org/wp-content/themes/cacm/client/build/js/global.bundle.min.js?ver=e97a984b44ccc756957f" id="cacm-global-js"></script>
<script type="text/javascript" src="https://cacm.acm.org/wp-includes/js/dist/hooks.min.js?ver=4d63a3d491d11ffd8ac6" id="wp-hooks-js"></script>
<script type="text/javascript" src="https://cacm.acm.org/wp-includes/js/dist/i18n.min.js?ver=5e580eb46a90c2b997e6" id="wp-i18n-js"></script>
<script type="text/javascript" id="wp-i18n-js-after">
/* <![CDATA[ */
wp.i18n.setLocaleData( { 'text direction\u0004ltr': [ 'ltr' ] } );
/* ]]> */
</script>
<script type="text/javascript" id="cacm-article-js-extra">
/* <![CDATA[ */
var cacmLocalVars = {"restCommentsUrl":"https:\/\/cacm.acm.org\/wp-json\/wp\/v2\/comments","restCommentFormUrl":"https:\/\/cacm.acm.org\/wp-json\/cacm-plugin\/v1\/comment\/form\/753517"};
/* ]]> */
</script>
<script type="text/javascript" src="https://cacm.acm.org/wp-content/themes/cacm/client/build/js/article.bundle.min.js?ver=237e66042b6c917cfd09" id="cacm-article-js"></script>
<script type="text/javascript" src="https://cacm.acm.org/wp-includes/js/comment-reply.min.js?ver=6.7.1" id="comment-reply-js" async="async" data-wp-strategy="async"></script>
<script type="text/javascript" src="https://stats.wp.com/e-202448.js" id="jetpack-stats-js" data-wp-strategy="defer"></script>
<script type="text/javascript" id="jetpack-stats-js-after">
/* <![CDATA[ */
_stq = window._stq || [];
_stq.push([ "view", JSON.parse("{\"v\":\"ext\",\"blog\":\"212686646\",\"post\":\"753517\",\"tz\":\"-5\",\"srv\":\"cacm.acm.org\",\"hp\":\"vip\",\"j\":\"1:14.0\"}") ]);
_stq.push([ "clickTrackerInit", "212686646", "753517" ]);
/* ]]> */
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML" id="mathjax-js"></script>


<!-- Mopinion Pastea.se  start --><script type="text/javascript">(function(){var id="Sh2m7XRvbVWoA8uJG6g2wIBNDLfpsOxFx1ciwKwo";var js=document.createElement("script");js.setAttribute("type","text/javascript");js.setAttribute("src","//deploy.mopinion.com/js/pastease.js");js.async=true;document.getElementsByTagName("head")[0].appendChild(js);var t=setInterval(function(){try{Pastease.load(id);clearInterval(t)}catch(e){}},50)})();</script> <!-- Mopinion Pastea.se end -->

</body>
</html>
